# project name: Gatto Nero Ai Manager (PY+JSX+WebView no md)

WORKSPACE ROOT: D:\Unity\Projects\GattoNeroPhotoshop

SCRIPT LOCATION: D:\Unity\Projects\GattoNeroPhotoshop\.doc-gen

---

## Spis Grup

1. **Kod główny** (32 plików)
   - Pliki Markdown z dokumentacją algorytmów
   - Wykluczenia: *test*, *__pycache__*, *.pyc, *legacy*, *temp*

2. **Webview** (2 plików)
   - Wszystkie pliki Python w workspace
   - Wykluczenia: *test*, *__pycache__*, *.pyc, *temp*

3. **Skrypty JSX** (5 plików)
   - Skrypty Adobe JSX dla Photoshop
   - Wykluczenia: *backup*, *old*

**Łącznie plików: 39**

---

## Grupa 1: Kod główny

*Pliki Markdown z dokumentacją algorytmów*

### Lista plików (32)

- .comb-doc.py ()
- .comb-scripts.py ()
- .comb-scripts-v3.py (\.doc-gen)
- config-selector.py (\.doc-gen)
- .server_info.json ()
- __init__.py (\app)
- __init__.py (\app\algorithms)
- __init__.py (\app\algorithms\algorithm_01_palette)
- algorithm.py (\app\algorithms\algorithm_01_palette)
- config.py (\app\algorithms\algorithm_01_palette)
- __init__.py (\app\algorithms\algorithm_02_statistical)
- algorithm.py (\app\algorithms\algorithm_02_statistical)
- __init__.py (\app\algorithms\algorithm_03_histogram)
- algorithm.py (\app\algorithms\algorithm_03_histogram)
- __init__.py (\app\api)
- routes.py (\app\api)
- __init__.py (\app\core)
- development_logger.py (\app\core)
- file_handler.py (\app\core)
- health_monitor.py (\app\core)
- health_monitor_simple.py (\app\core)
- performance_profiler.py (\app\core)
- __init__.py (\app\processing)
- palette_analyzer.py (\app\processing)
- server.py (\app)
- __init__.py (\app\webview)
- routes.py (\app\webview)
- __init__.py (\app\webview\utils)
- run_server.py ()
- server_config.json ()
- server_manager_enhanced.py ()
- server_manager_enhanced_fixed.py ()

### Zawartość plików

#### .comb-doc.py - ./.comb-doc.py

``````
﻿import os
from pathlib import Path

# =================================================================================
# SCRIPT FOR FILE AGGREGATION
#
# Wersja: 4.0 (Uniwersalna)
# Opis: Skrypt wyszukuje pliki pasujące do podanych wzorców (np. *.md, *.py)
#       w określonych katalogach, filtruje je na podstawie .gitignore,
#       a następnie łączy ich zawartość w jeden zbiorczy plik .md.
# =================================================================================

# --- KONFIGURACJA ---
# W tej sekcji możesz dostosować działanie skryptu do swoich potrzeb.

# Nazwa projektu, która pojawi się w nagłówku pliku wyjściowego.
PROJECT_NAME = "Gatto Nero Ai Manager (Dokumentacja)"

# Nazwa pliku, do którego zostanie zapisany wynik.
OUTPUT_FILE = ".comb-doc.md"

# ---------------------------------------------------------------------------------
# WZORCE PLIKÓW (FILE_PATTERNS)
# ---------------------------------------------------------------------------------
# Zdefiniuj, jakie pliki mają być wyszukiwane. Możesz podać jeden lub wiele wzorców.
#
# PRZYKŁADY:
# - Tylko pliki Markdown:      FILE_PATTERNS = ['*.md']
# - Pliki Python i JSX:        FILE_PATTERNS = ['*.py', '*.jsx']
# - Tylko pliki tekstowe:      FILE_PATTERNS = ['*.txt']
#
FILE_PATTERNS = ['*.md']
# ---------------------------------------------------------------------------------

# ŚCIEŻKI DO PRZESZUKANIA ($includePaths)
# Lista katalogów do przeszukania. Użyj ['all'] aby przeszukać wszystko.
INCLUDE_PATHS = ['app/algorithms/algorithm_01_palette']

# Nazwa pliku .gitignore, używanego do wykluczeń.
GITIGNORE_FILE = ".gitignore"


# =================================================================================
# --- SILNIK SKRYPTU (zazwyczaj nie wymaga modyfikacji) ---
# =================================================================================

def load_gitignore_patterns(root_path):
    """Wczytuje i przetwarza wzorce z pliku .gitignore."""
    gitignore_path = root_path / GITIGNORE_FILE
    patterns = []
    if gitignore_path.exists():
        print("Znaleziono plik .gitignore. Stosuję reguły wykluczeń.")
        with open(gitignore_path, 'r', encoding='utf-8') as f:
            for line in f:
                stripped_line = line.strip()
                if stripped_line and not stripped_line.startswith('#'):
                    patterns.append(stripped_line)
    else:
        print(".gitignore nie został znaleziony.")
    return patterns

def is_ignored(file_path, root_path, ignore_patterns):
    """Sprawdza, czy dany plik powinien być zignorowany na podstawie wzorców."""
    relative_path_str = str(file_path.relative_to(root_path).as_posix())
    for pattern in ignore_patterns:
        if pattern.endswith('/'):
            if f"/{pattern[:-1]}/" in f"/{relative_path_str}":
                return True
        elif file_path.match(pattern):
             return True
    return False

def find_files_to_process(root_path, ignore_patterns):
    """Znajduje wszystkie pliki do przetworzenia zgodnie z konfiguracją."""
    print(f"Wyszukiwanie plików pasujących do wzorców: {', '.join(FILE_PATTERNS)}...")
    all_found_files = []

    search_paths = []
    if 'all' in INCLUDE_PATHS:
        search_paths.append(root_path)
    else:
        for include_path in INCLUDE_PATHS:
            full_search_path = root_path / include_path
            if full_search_path.is_dir():
                search_paths.append(full_search_path)
            else:
                print(f"UWAGA: Ścieżka '{include_path}' nie istnieje i została pominięta.")

    for path in search_paths:
        for pattern in FILE_PATTERNS:
            # Używamy **/{pattern}, aby szukać rekursywnie
            all_found_files.extend(path.glob(f'**/{pattern}'))
    
    files_to_process = []
    for file in all_found_files:
        if file.name == OUTPUT_FILE or is_ignored(file, root_path, ignore_patterns):
            continue
        files_to_process.append(file)
            
    unique_files = sorted(list(set(files_to_process)))
    print(f"Znaleziono {len(unique_files)} unikalnych plików do przetworzenia.")
    return unique_files

def read_file_with_fallback_encoding(file_path):
    """Probuje odczytac plik jako UTF-8, a jesli sie nie uda, jako windows-1250."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except UnicodeDecodeError:
        print(f"  -> Plik '{file_path.name}' nie jest w UTF-8, próba odczytu jako windows-1250.")
        try:
            with open(file_path, 'r', encoding='windows-1250') as f:
                return f.read()
        except Exception as e:
            return f"BŁĄD ODCZYTU PLIKU {file_path.name}: {e}"
    except Exception as e:
        return f"NIEOCZEKIWANY BŁĄD ODCZYTU PLIKU {file_path.name}: {e}"

def main():
    """Główna funkcja skryptu."""
    root_path = Path.cwd()
    print(f"Rozpoczynam agregację dla projektu: {PROJECT_NAME}")

    ignore_patterns = load_gitignore_patterns(root_path)
    files_to_process = find_files_to_process(root_path, ignore_patterns)
    
    markdown_content = []
    markdown_content.append(f"# project name: {PROJECT_NAME}\n\nROOT: {root_path}\n\n---\n")
    markdown_content.append("## file tree list\n")
    if files_to_process:
        markdown_content.append(f"### Found Files ({len(files_to_process)})")
        for file in files_to_process:
            dir_path = str(file.parent.relative_to(root_path))
            dir_path = '' if dir_path == '.' else f"\\{dir_path}"
            markdown_content.append(f"- {file.name} ({dir_path})")
        markdown_content.append("")
    markdown_content.append("---\n")

    markdown_content.append("## file content\n")
    for file in files_to_process:
        relative_path = file.relative_to(root_path).as_posix()
        markdown_content.append(f"### {file.name} - ./{relative_path}\n")
        markdown_content.append('``````')
        content = read_file_with_fallback_encoding(file)
        markdown_content.append(content)
        markdown_content.append('``````\n')

    final_content = "\n".join(markdown_content)
    try:
        # Zapisujemy z 'utf-8-sig' dla najlepszej kompatybilnosci z programami na Windows
        with open(root_path / OUTPUT_FILE, 'w', encoding='utf-8-sig') as f:
            f.write(final_content)
        print(f"Gotowe! Plik '{OUTPUT_FILE}' został utworzony.")
    except Exception as e:
        print(f"BŁĄD ZAPISU PLIKU: {e}")

if __name__ == "__main__":
    main()
``````

#### .comb-scripts.py - ./.comb-scripts.py

``````
﻿import os
from pathlib import Path

# =================================================================================
# SCRIPT FOR FILE AGGREGATION
#
# Wersja: 4.0 (Uniwersalna)
# Opis: Skrypt wyszukuje pliki pasujące do podanych wzorców (np. *.md, *.py)
#       w określonych katalogach, filtruje je na podstawie .gitignore,
#       a następnie łączy ich zawartość w jeden zbiorczy plik .md.
# =================================================================================

# --- KONFIGURACJA ---
# W tej sekcji możesz dostosować działanie skryptu do swoich potrzeb.

# Nazwa projektu, która pojawi się w nagłówku pliku wyjściowego.
PROJECT_NAME = "Gatto Nero Ai Manager (PY+JSX)"

# Nazwa pliku, do którego zostanie zapisany wynik.
OUTPUT_FILE = ".comb-scripts.md"

# ---------------------------------------------------------------------------------
# WZORCE PLIKÓW (FILE_PATTERNS)
# ---------------------------------------------------------------------------------
# Zdefiniuj, jakie pliki mają być wyszukiwane. Możesz podać jeden lub wiele wzorców.
#
# PRZYKŁADY:
# - Tylko pliki Markdown:      FILE_PATTERNS = ['*.md']
# - Pliki Python i JSX:        FILE_PATTERNS = ['*.py', '*.jsx']
# - Tylko pliki tekstowe:      FILE_PATTERNS = ['*.txt']
#
FILE_PATTERNS = ['*.py', '*.jsx']
# ---------------------------------------------------------------------------------

# ŚCIEŻKI DO PRZESZUKANIA ($includePaths)
# Lista katalogów do przeszukania. Użyj ['all'] aby przeszukać wszystko.
INCLUDE_PATHS = ['all']

# Nazwa pliku .gitignore, używanego do wykluczeń.
GITIGNORE_FILE = ".gitignore"


# =================================================================================
# --- SILNIK SKRYPTU (zazwyczaj nie wymaga modyfikacji) ---
# =================================================================================

def load_gitignore_patterns(root_path):
    """Wczytuje i przetwarza wzorce z pliku .gitignore."""
    gitignore_path = root_path / GITIGNORE_FILE
    patterns = []
    if gitignore_path.exists():
        print("Znaleziono plik .gitignore. Stosuję reguły wykluczeń.")
        with open(gitignore_path, 'r', encoding='utf-8') as f:
            for line in f:
                stripped_line = line.strip()
                if stripped_line and not stripped_line.startswith('#'):
                    patterns.append(stripped_line)
    else:
        print(".gitignore nie został znaleziony.")
    return patterns

def is_ignored(file_path, root_path, ignore_patterns):
    """Sprawdza, czy dany plik powinien być zignorowany na podstawie wzorców."""
    relative_path_str = str(file_path.relative_to(root_path).as_posix())
    for pattern in ignore_patterns:
        if pattern.endswith('/'):
            if f"/{pattern[:-1]}/" in f"/{relative_path_str}":
                return True
        elif file_path.match(pattern):
             return True
    return False

def find_files_to_process(root_path, ignore_patterns):
    """Znajduje wszystkie pliki do przetworzenia zgodnie z konfiguracją."""
    print(f"Wyszukiwanie plików pasujących do wzorców: {', '.join(FILE_PATTERNS)}...")
    all_found_files = []

    search_paths = []
    if 'all' in INCLUDE_PATHS:
        search_paths.append(root_path)
    else:
        for include_path in INCLUDE_PATHS:
            full_search_path = root_path / include_path
            if full_search_path.is_dir():
                search_paths.append(full_search_path)
            else:
                print(f"UWAGA: Ścieżka '{include_path}' nie istnieje i została pominięta.")

    for path in search_paths:
        for pattern in FILE_PATTERNS:
            # Używamy **/{pattern}, aby szukać rekursywnie
            all_found_files.extend(path.glob(f'**/{pattern}'))
    
    files_to_process = []
    for file in all_found_files:
        if file.name == OUTPUT_FILE or is_ignored(file, root_path, ignore_patterns):
            continue
        files_to_process.append(file)
            
    unique_files = sorted(list(set(files_to_process)))
    print(f"Znaleziono {len(unique_files)} unikalnych plików do przetworzenia.")
    return unique_files

def read_file_with_fallback_encoding(file_path):
    """Probuje odczytac plik jako UTF-8, a jesli sie nie uda, jako windows-1250."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except UnicodeDecodeError:
        print(f"  -> Plik '{file_path.name}' nie jest w UTF-8, próba odczytu jako windows-1250.")
        try:
            with open(file_path, 'r', encoding='windows-1250') as f:
                return f.read()
        except Exception as e:
            return f"BŁĄD ODCZYTU PLIKU {file_path.name}: {e}"
    except Exception as e:
        return f"NIEOCZEKIWANY BŁĄD ODCZYTU PLIKU {file_path.name}: {e}"

def main():
    """Główna funkcja skryptu."""
    root_path = Path.cwd()
    print(f"Rozpoczynam agregację dla projektu: {PROJECT_NAME}")

    ignore_patterns = load_gitignore_patterns(root_path)
    files_to_process = find_files_to_process(root_path, ignore_patterns)
    
    markdown_content = []
    markdown_content.append(f"# project name: {PROJECT_NAME}\n\nROOT: {root_path}\n\n---\n")
    markdown_content.append("## file tree list\n")
    if files_to_process:
        markdown_content.append(f"### Found Files ({len(files_to_process)})")
        for file in files_to_process:
            dir_path = str(file.parent.relative_to(root_path))
            dir_path = '' if dir_path == '.' else f"\\{dir_path}"
            markdown_content.append(f"- {file.name} ({dir_path})")
        markdown_content.append("")
    markdown_content.append("---\n")

    markdown_content.append("## file content\n")
    for file in files_to_process:
        relative_path = file.relative_to(root_path).as_posix()
        markdown_content.append(f"### {file.name} - ./{relative_path}\n")
        markdown_content.append('``````')
        content = read_file_with_fallback_encoding(file)
        markdown_content.append(content)
        markdown_content.append('``````\n')

    final_content = "\n".join(markdown_content)
    try:
        # Zapisujemy z 'utf-8-sig' dla najlepszej kompatybilnosci z programami na Windows
        with open(root_path / OUTPUT_FILE, 'w', encoding='utf-8-sig') as f:
            f.write(final_content)
        print(f"Gotowe! Plik '{OUTPUT_FILE}' został utworzony.")
    except Exception as e:
        print(f"BŁĄD ZAPISU PLIKU: {e}")

if __name__ == "__main__":
    main()
``````

#### .comb-scripts-v3.py - ./.doc-gen/.comb-scripts-v3.py

``````
import os
import yaml
from pathlib import Path
import fnmatch

# =================================================================================
# SCRIPT FOR FILE AGGREGATION WITH GROUPS AND EXCLUDE PATTERNS
#
# Wersja: 5.1 (z grupami, konfiguracją YAML i exclude_patterns)
# Opis: Skrypt wyszukuje pliki w grupach zdefiniowanych w pliku YAML,
#       filtruje je na podstawie .gitignore i exclude_patterns,
#       a następnie łączy ich zawartość w jeden zbiorczy plik .md z podziałem na grupy.
# =================================================================================

# Domyślna nazwa pliku konfiguracyjnego
DEFAULT_CONFIG_FILE = ".comb-scripts-config01.yaml"

def get_workspace_root():
    """Zwraca ścieżkę do workspace root (katalog wyżej niż lokalizacja skryptu)."""
    script_dir = Path(__file__).parent
    workspace_root = script_dir.parent
    return workspace_root

def load_config(config_file_path):
    """Wczytuje konfigurację z pliku YAML."""
    try:
        with open(config_file_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        print(f"Wczytano konfigurację z: {config_file_path}")
        return config
    except FileNotFoundError:
        print(f"BŁĄD: Nie znaleziono pliku konfiguracyjnego: {config_file_path}")
        return None
    except yaml.YAMLError as e:
        print(f"BŁĄD: Nieprawidłowy format YAML: {e}")
        return None
    except Exception as e:
        print(f"BŁĄD: Nie można wczytać konfiguracji: {e}")
        return None

def load_gitignore_patterns(workspace_root, gitignore_file):
    """Wczytuje i przetwarza wzorce z pliku .gitignore."""
    gitignore_path = workspace_root / gitignore_file
    patterns = []
    if gitignore_path.exists():
        print(f"Znaleziono plik .gitignore: {gitignore_path}")
        with open(gitignore_path, 'r', encoding='utf-8') as f:
            for line in f:
                stripped_line = line.strip()
                if stripped_line and not stripped_line.startswith('#'):
                    patterns.append(stripped_line)
    else:
        print(f"Plik .gitignore nie został znaleziony: {gitignore_path}")
    return patterns

def is_ignored(file_path, workspace_root, ignore_patterns):
    """Sprawdza, czy dany plik powinien być zignorowany na podstawie wzorców."""
    try:
        relative_path_str = str(file_path.relative_to(workspace_root).as_posix())
        for pattern in ignore_patterns:
            if pattern.endswith('/'):
                if f"/{pattern[:-1]}/" in f"/{relative_path_str}":
                    return True
            elif file_path.match(pattern):
                return True
    except ValueError:
        # Plik jest poza workspace_root
        return True
    return False

def matches_exclude_pattern(file_path, exclude_patterns):
    """Sprawdza, czy plik pasuje do wzorców wykluczenia."""
    if not exclude_patterns:
        return False
    
    file_name = file_path.name
    file_path_str = str(file_path)
    
    for pattern in exclude_patterns:
        # Sprawdź czy wzorzec pasuje do nazwy pliku
        if fnmatch.fnmatch(file_name.lower(), pattern.lower()):
            return True
        # Sprawdź czy wzorzec pasuje do pełnej ścieżki
        if fnmatch.fnmatch(file_path_str.lower(), f"*{pattern.lower()}*"):
            return True
    
    return False

def find_files_for_group(group, workspace_root, ignore_patterns):
    """Znajduje pliki dla konkretnej grupy."""
    group_name = group.get('name', 'Unnamed Group')
    patterns = group.get('patterns', [])
    exclude_patterns = group.get('exclude_patterns', [])
    paths = group.get('paths', [])
    recursive = group.get('recursive', True)
    
    print(f"\nPrzetwarzanie grupy: {group_name}")
    print(f"  Wzorce: {', '.join(patterns)}")
    if exclude_patterns:
        print(f"  Wykluczenia: {', '.join(exclude_patterns)}")
    print(f"  Ścieżki: {', '.join(paths)}")
    print(f"  Rekursywnie: {recursive}")
    
    all_found_files = []
    
    # Określ ścieżki do przeszukania
    search_paths = []
    for path_str in paths:
        if path_str == 'all':
            search_paths.append(workspace_root)
        elif path_str == '.':
            search_paths.append(workspace_root)
        elif path_str == '**/*' or path_str == '**':
            # Wzorzec **/* oznacza przeszukiwanie całego workspace rekursywnie
            search_paths.append(workspace_root)
        else:
            full_path = workspace_root / path_str
            if full_path.exists() and full_path.is_dir():
                search_paths.append(full_path)
            else:
                print(f"  UWAGA: Ścieżka '{path_str}' nie istnieje i została pominięta.")
    
    # Wyszukaj pliki
    for search_path in search_paths:
        for pattern in patterns:
            if recursive:
                found_files = search_path.glob(f'**/{pattern}')
            else:
                found_files = search_path.glob(pattern)
            all_found_files.extend(found_files)
    
    # Filtruj pliki
    files_to_process = []
    excluded_count = 0
    
    for file in all_found_files:
        if file.is_file():
            # Sprawdź .gitignore
            if is_ignored(file, workspace_root, ignore_patterns):
                continue
            
            # Sprawdź exclude_patterns
            if matches_exclude_pattern(file, exclude_patterns):
                excluded_count += 1
                continue
            
            files_to_process.append(file)
    
    unique_files = sorted(list(set(files_to_process)))
    print(f"  Znaleziono {len(unique_files)} plików (wykluczono {excluded_count})")
    
    return unique_files

def read_file_with_fallback_encoding(file_path):
    """Próbuje odczytać plik jako UTF-8, a jeśli się nie uda, jako windows-1250."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except UnicodeDecodeError:
        print(f"  -> Plik '{file_path.name}' nie jest w UTF-8, próba odczytu jako windows-1250.")
        try:
            with open(file_path, 'r', encoding='windows-1250') as f:
                return f.read()
        except Exception as e:
            return f"BŁĄD ODCZYTU PLIKU {file_path.name}: {e}"
    except Exception as e:
        return f"NIEOCZEKIWANY BŁĄD ODCZYTU PLIKU {file_path.name}: {e}"

def generate_markdown_content(config, workspace_root, all_groups_files):
    """Generuje zawartość pliku Markdown."""
    project_name = config.get('project_name', 'Unknown Project')
    
    markdown_content = []
    markdown_content.append(f"# project name: {project_name}\n")
    markdown_content.append(f"WORKSPACE ROOT: {workspace_root}\n")
    markdown_content.append(f"SCRIPT LOCATION: {Path(__file__).parent}\n\n---\n")
    
    # Spis treści grup
    markdown_content.append("## Spis Grup\n")
    total_files = 0
    for i, (group, files) in enumerate(all_groups_files, 1):
        group_name = group.get('name', f'Grupa {i}')
        group_desc = group.get('description', '')
        file_count = len(files)
        total_files += file_count
        
        markdown_content.append(f"{i}. **{group_name}** ({file_count} plików)")
        if group_desc:
            markdown_content.append(f"   - {group_desc}")
        
        # Pokaż wzorce wykluczenia jeśli są
        exclude_patterns = group.get('exclude_patterns', [])
        if exclude_patterns:
            markdown_content.append(f"   - Wykluczenia: {', '.join(exclude_patterns)}")
        
        markdown_content.append("")
    
    markdown_content.append(f"**Łącznie plików: {total_files}**\n\n---\n")
    
    # Zawartość grup
    for i, (group, files) in enumerate(all_groups_files, 1):
        group_name = group.get('name', f'Grupa {i}')
        group_desc = group.get('description', '')
        
        markdown_content.append(f"## Grupa {i}: {group_name}\n")
        if group_desc:
            markdown_content.append(f"*{group_desc}*\n")
        
        if not files:
            markdown_content.append("*Brak plików w tej grupie.*\n\n---\n")
            continue
        
        # Lista plików w grupie
        markdown_content.append(f"### Lista plików ({len(files)})\n")
        for file in files:
            try:
                relative_path = file.relative_to(workspace_root)
                dir_path = str(relative_path.parent)
                dir_path = '' if dir_path == '.' else f"\\{dir_path}"
                markdown_content.append(f"- {file.name} ({dir_path})")
            except ValueError:
                markdown_content.append(f"- {file.name} (poza workspace)")
        markdown_content.append("")
        
        # Zawartość plików
        markdown_content.append("### Zawartość plików\n")
        for file in files:
            try:
                relative_path = file.relative_to(workspace_root).as_posix()
                markdown_content.append(f"#### {file.name} - ./{relative_path}\n")
            except ValueError:
                markdown_content.append(f"#### {file.name} - {file}\n")
            
            markdown_content.append('``````')
            content = read_file_with_fallback_encoding(file)
            markdown_content.append(content)
            markdown_content.append('``````\n')
        
        markdown_content.append("---\n")
    
    return "\n".join(markdown_content)

def main():
    """Główna funkcja skryptu."""
    import sys
    
    # Ustaw workspace root
    workspace_root = get_workspace_root()
    print(f"Workspace Root: {workspace_root}")
    print(f"Script Location: {Path(__file__).parent}")
    
    # Wczytaj konfigurację (sprawdź czy podano plik jako argument)
    if len(sys.argv) > 1:
        config_file_path = Path(sys.argv[1])  # Pełna ścieżka do pliku konfiguracyjnego
        if not config_file_path.is_absolute():
            config_file_path = Path(__file__).parent / config_file_path
    else:
        config_file_path = Path(__file__).parent / DEFAULT_CONFIG_FILE
    
    # Sprawdź czy podano katalog export jako drugi argument
    export_dir = None
    if len(sys.argv) > 2:
        export_dir = Path(sys.argv[2])
        print(f"Katalog export: {export_dir}")
    
    print(f"Używam pliku konfiguracyjnego: {config_file_path}")
    config = load_config(config_file_path)
    if not config:
        return
    
    project_name = config.get('project_name', 'Unknown Project')
    output_file = config.get('output_file', '.doc-gen/comb-scripts.md')
    gitignore_file = config.get('gitignore_file', '.gitignore')
    groups = config.get('groups', [])
    
    print(f"\nRozpoczynam agregację dla projektu: {project_name}")
    print(f"Plik wyjściowy: {output_file}")
    print(f"Liczba grup: {len(groups)}")
    
    # Wczytaj wzorce .gitignore
    ignore_patterns = load_gitignore_patterns(workspace_root, gitignore_file)
    
    # Przetwórz każdą grupę z wykluczaniem duplikatów
    all_groups_files = []
    already_processed_files = set()  # Zbiór już przetworzonych plików
    
    for i, group in enumerate(groups):
        files = find_files_for_group(group, workspace_root, ignore_patterns)
        
        # Wykluczamy pliki już przetworzone w poprzednich grupach
        unique_files = []
        duplicates_count = 0
        
        for file in files:
            if file not in already_processed_files:
                unique_files.append(file)
                already_processed_files.add(file)
            else:
                duplicates_count += 1
        
        print(f"  Grupa {i+1}: {len(unique_files)} unikalnych plików (wykluczono {duplicates_count} duplikatów)")
        all_groups_files.append((group, unique_files))
    
    # Generuj zawartość Markdown
    markdown_content = generate_markdown_content(config, workspace_root, all_groups_files)
    
    # Zapisz plik - użyj katalogu export jeśli został podany
    if export_dir:
        # Jeśli podano katalog export, zapisz tam plik
        export_dir.mkdir(parents=True, exist_ok=True)
        output_filename = Path(output_file).name  # Tylko nazwa pliku bez ścieżki
        output_path = export_dir / output_filename
        print(f"Zapisuję do katalogu export: {export_dir}")
    else:
        # Standardowa ścieżka względem workspace_root
        output_path = workspace_root / output_file
    
    try:
        with open(output_path, 'w', encoding='utf-8-sig') as f:
            f.write(markdown_content)
        print(f"\nGotowe! Plik '{output_path.name}' został utworzony w: {output_path}")
    except Exception as e:
        print(f"BŁĄD ZAPISU PLIKU: {e}")

if __name__ == "__main__":
    main()
``````

#### config-selector.py - ./.doc-gen/config-selector.py

``````
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
INTERAKTYWNY SELEKTOR PLIKÓW KONFIGURACYJNYCH
Skrypt do wyboru i uruchamiania różnych konfiguracji .comb-scripts
"""

import os
import sys
import subprocess
from pathlib import Path
import yaml

def load_config_info(config_path):
    """Wczytuje podstawowe informacje z pliku konfiguracyjnego."""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        project_name = config.get('project_name', 'Nieznany projekt')
        output_file = config.get('output_file', 'Nieznany plik wyjściowy')
        groups_count = len(config.get('groups', []))
        
        return {
            'project_name': project_name,
            'output_file': output_file,
            'groups_count': groups_count,
            'valid': True
        }
    except Exception as e:
        return {
            'project_name': 'BŁĄD ODCZYTU',
            'output_file': f'Błąd: {str(e)}',
            'groups_count': 0,
            'valid': False
        }

def get_config_files():
    """Znajduje wszystkie pliki konfiguracyjne YAML w katalogu config-lists."""
    script_dir = Path(__file__).parent
    config_lists_dir = script_dir / 'config-lists'
    config_files = []
    
    # Sprawdź czy katalog config-lists istnieje
    if not config_lists_dir.exists():
        print(f"⚠️  Katalog config-lists nie istnieje: {config_lists_dir}")
        return config_files
    
    # Szukaj plików .yaml i .yml w katalogu config-lists
    for pattern in ['*.yaml', '*.yml']:
        for config_file in config_lists_dir.glob(pattern):
            if 'config' in config_file.name.lower():
                config_files.append(config_file)
    
    return sorted(config_files)

def display_config_list(config_files):
    """Wyświetla listę dostępnych plików konfiguracyjnych."""
    print("\n" + "="*80)
    print("📋 DOSTĘPNE PLIKI KONFIGURACYJNE")
    print("="*80)
    
    for i, config_file in enumerate(config_files, 1):
        info = load_config_info(config_file)
        
        print(f"\n[{i}] {config_file.name}")
        print(f"    📁 Ścieżka: {config_file}")
        print(f"    📝 Projekt: {info['project_name']}")
        print(f"    📄 Wyjście: {info['output_file']}")
        print(f"    📊 Grup: {info['groups_count']}")
        
        if not info['valid']:
            print(f"    ⚠️  Status: BŁĄD KONFIGURACJI")
        else:
            print(f"    ✅ Status: OK")
    
    print("\n" + "="*80)

def run_script_with_config(config_file):
    """Uruchamia skrypt .comb-scripts-v3.py z wybraną konfiguracją."""
    script_dir = Path(__file__).parent
    main_script = script_dir / '.comb-scripts-v3.py'
    export_dir = script_dir / 'export'
    
    if not main_script.exists():
        print(f"❌ BŁĄD: Nie znaleziono skryptu {main_script}")
        return False
    
    # Upewnij się, że katalog export istnieje
    export_dir.mkdir(exist_ok=True)
    
    try:
        print(f"\n🚀 Uruchamiam skrypt z konfiguracją: {config_file.name}")
        print(f"📝 Komenda: python {main_script.name} {str(config_file)} {str(export_dir)}")
        print("-" * 60)
        
        # Uruchom skrypt z pełną ścieżką do pliku konfiguracyjnego i katalogu export
        result = subprocess.run(
            [sys.executable, str(main_script), str(config_file), str(export_dir)],
            cwd=script_dir,
            capture_output=False,
            text=True
        )
        
        print("-" * 60)
        if result.returncode == 0:
            print("✅ Skrypt zakończony pomyślnie!")
            return True
        else:
            print(f"❌ Skrypt zakończony z błędem (kod: {result.returncode})")
            return False
            
    except Exception as e:
        print(f"❌ BŁĄD URUCHAMIANIA: {e}")
        return False

def main():
    """Główna funkcja programu."""
    print("🔧 INTERAKTYWNY SELEKTOR KONFIGURACJI COMB-SCRIPTS")
    
    # Znajdź pliki konfiguracyjne
    config_files = get_config_files()
    
    if not config_files:
        print("❌ Nie znaleziono żadnych plików konfiguracyjnych!")
        return
    
    while True:
        # Wyświetl listę
        display_config_list(config_files)
        
        # Opcje wyboru
        print("\n🎯 OPCJE:")
        for i in range(1, len(config_files) + 1):
            print(f"  {i} - Uruchom z konfiguracją [{i}]")
        print(f"  0 - Wyjście")
        print(f"  r - Odśwież listę")
        
        # Pobierz wybór użytkownika
        try:
            choice = input("\n👉 Wybierz opcję: ").strip().lower()
            
            if choice == '0' or choice == 'q' or choice == 'quit':
                print("👋 Do widzenia!")
                break
            elif choice == 'r' or choice == 'refresh':
                config_files = get_config_files()
                continue
            else:
                choice_num = int(choice)
                if 1 <= choice_num <= len(config_files):
                    selected_config = config_files[choice_num - 1]
                    run_script_with_config(selected_config)
                    
                    # Zapytaj czy kontynuować
                    cont = input("\n❓ Chcesz wybrać inną konfigurację? (t/n): ").strip().lower()
                    if cont not in ['t', 'tak', 'y', 'yes']:
                        break
                else:
                    print(f"❌ Nieprawidłowy wybór: {choice}")
                    
        except ValueError:
            print(f"❌ Nieprawidłowy wybór: {choice}")
        except KeyboardInterrupt:
            print("\n\n👋 Przerwano przez użytkownika")
            break
        except Exception as e:
            print(f"❌ Nieoczekiwany błąd: {e}")

if __name__ == "__main__":
    main()
``````

#### .server_info.json - ./.server_info.json

``````
{
    "pid": 17576,
    "port": 5000,
    "started_at": 1749605706.2779598
}
``````

#### __init__.py - ./app/__init__.py

``````
# Makes 'app' a package

``````

#### __init__.py - ./app/algorithms/__init__.py

``````
"""
GattoNero AI Assistant - Algorithm Modules
==========================================

This package contains modular algorithm implementations for color matching
and image processing. Each algorithm is self-contained with comprehensive
monitoring, testing, and documentation.

Available Algorithms:
- Algorithm 01: Palette Mapping (K-means based color palette extraction)
- Algorithm 02: Statistical Transfer (LAB color space statistical matching)
- Algorithm 03: Histogram Matching (Luminance channel histogram specification)
"""

# Import algorithm factories for easy access
from .algorithm_01_palette import (
    create_palette_mapping_algorithm
)
from .algorithm_02_statistical import (
    create_statistical_transfer_algorithm,
    basic_statistical_transfer
)
from .algorithm_03_histogram import (
    create_histogram_matching_algorithm,
    simple_histogram_matching
)

# Algorithm registry for dynamic access
ALGORITHM_REGISTRY = {
    'algorithm_01_palette': create_palette_mapping_algorithm,
    'algorithm_02_statistical': create_statistical_transfer_algorithm,
    'algorithm_03_histogram': create_histogram_matching_algorithm,
}

# Legacy function mapping for backward compatibility
LEGACY_FUNCTIONS = {
    'method2': basic_statistical_transfer,
    'method3': simple_histogram_matching,
}

def get_algorithm(algorithm_id: str):
    """Get algorithm instance by ID."""
    if algorithm_id in ALGORITHM_REGISTRY:
        return ALGORITHM_REGISTRY[algorithm_id]()
    raise ValueError(f"Unknown algorithm: {algorithm_id}")

def get_legacy_function(method: str):
    """Get legacy function by method name."""
    if method in LEGACY_FUNCTIONS:
        return LEGACY_FUNCTIONS[method]
    raise ValueError(f"Unknown method: {method}")

__all__ = [
    # Algorithm factories
    'create_palette_mapping_algorithm',
    'create_statistical_transfer_algorithm', 
    'create_histogram_matching_algorithm',
    
    # Legacy compatibility functions
    'basic_statistical_transfer',
    'simple_histogram_matching',
    
    # Dynamic access
    'get_algorithm',
    'get_legacy_function',
    'ALGORITHM_REGISTRY',
    'LEGACY_FUNCTIONS'
]

``````

#### __init__.py - ./app/algorithms/algorithm_01_palette/__init__.py

``````
"""
Algorithm 01: Palette Mapping
============================

This module provides palette-based color matching functionality using K-means clustering.
"""

from .algorithm import (
    PaletteMappingAlgorithm,
    create_palette_mapping_algorithm
)

__all__ = [
    'PaletteMappingAlgorithm',
    'create_palette_mapping_algorithm'
]

``````

#### algorithm.py - ./app/algorithms/algorithm_01_palette/algorithm.py

``````
import numpy as np
from PIL import Image, ImageFilter, PngImagePlugin
import time
import os
from tqdm import tqdm
import json
from skimage import color  # For LAB color space conversion
from sklearn.cluster import KMeans  # For K-means clustering
from typing import TYPE_CHECKING, Any

try:
    import scipy.ndimage
except ImportError:
    scipy = None

try:
    from ...core.development_logger import get_logger
    from ...core.performance_profiler import get_profiler

    if TYPE_CHECKING:
        from ...core.development_logger import DevelopmentLogger
        from ...core.performance_profiler import PerformanceProfiler
except ImportError:
    import logging

    def get_logger() -> Any:
        logging.basicConfig(
            level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
        )
        return logging.getLogger(__name__)

    class DummyProfiler:
        def start(self, name):
            pass

        def stop(self, name):
            pass

        def get_report(self):
            return "Profiler not available."

    def get_profiler() -> Any:
        return DummyProfiler()


class PaletteMappingAlgorithm:
    def __init__(self, config_path=None, algorithm_id: str = "algorithm_01_palette"):
        self.algorithm_id = algorithm_id
        if TYPE_CHECKING:
            self.logger: "DevelopmentLogger" = get_logger()
            self.profiler: "PerformanceProfiler" = get_profiler()
        else:
            self.logger = get_logger()
            self.profiler = get_profiler()
        self.logger.info(f"Initialized algorithm: {self.algorithm_id}")
        self.name = "Simple Palette Mapping"
        ## >> NEW: Zwiększamy wersję po dodaniu nowych funkcji
        self.version = "1.3"
        self.config = (
            self.load_config(config_path) if config_path else self.default_config()
        )
        self.distance_cache = {}

    def default_config(self):
        """Zwraca domyślną konfigurację z nowymi opcjami."""
        return {
            "num_colors": 16,
            "distance_metric": "weighted_rgb",
            "use_cache": True,
            "preprocess": False,
            "thumbnail_size": (100, 100),
            "use_vectorized": True,
            "cache_max_size": 10000,
            "exclude_colors": [],
            "preview_mode": False,
            "preview_thumbnail_size": (500, 500),
            ## >> NEW: Nowe parametry zaawansowane
            "inject_extremes": False,  # Czy dodawać czarny i biały do palety
            "preserve_extremes": False,  # Czy chronić cienie i światła w obrazie docelowym
            "extremes_threshold": 10,  # Próg dla cieni i świateł (0-255)
            "dithering_method": "none",  # Metoda ditheringu: 'none' lub 'floyd_steinberg'
            ## >> NEW: Edge Blending Parameters
            "edge_blur_enabled": False,  # Włącz/wyłącz rozmycie krawędzi
            "edge_blur_radius": 1.5,  # Promień rozmycia (px)
            "edge_blur_strength": 0.3,  # Siła rozmycia (0.0-1.0)
            "edge_detection_threshold": 25,  # Próg detekcji krawędzi między kolorami
            "edge_blur_method": "gaussian",  # 'gaussian' | 'motion' | 'selective'
        }

    def load_config(self, config_path):
        """Ładuje konfigurację z pliku JSON."""
        try:
            with open(config_path, "r") as f:
                return json.load(f)
        except Exception as e:
            self.logger.error(f"Error loading configuration: {e}, using default.")
            return self.default_config()

    def clear_cache(self):
        self.distance_cache.clear()

    def validate_palette(self, palette):
        if not palette or len(palette) == 0:
            raise ValueError("Palette cannot be empty")
        for i, color_val in enumerate(palette):
            if len(color_val) != 3:
                raise ValueError(
                    f"Color {i} must have 3 RGB components, has {len(color_val)}"
                )
            if not all(0 <= c <= 255 for c in color_val):
                raise ValueError(
                    f"Color {i} has values outside the 0-255 range: {color_val}"
                )

    def extract_palette(self, image_path, num_colors=None, method="kmeans"):
        """
        Extracts a color palette from an image using either K-means or Median Cut.
        """
        if num_colors is None:
            num_colors = self.config["num_colors"]

        try:
            image = Image.open(image_path)
            if image.mode == "RGBA":
                background = Image.new("RGB", image.size, (255, 255, 255))
                background.paste(image, mask=image.split()[-1])
                image = background
            elif image.mode != "RGB":
                image = image.convert("RGB")

            original_size = image.size
            quality = self.config.get("quality", 5)
            base_size = 100
            max_size = 1000
            thumbnail_size_val = int(
                base_size + (max_size - base_size) * (quality - 1) / 9.0
            )

            self.logger.info(
                f"Analyzing with quality {quality}/10 (thumbnail: {thumbnail_size_val}px) using '{method}' method."
            )

            # --- NOWA LOGIKA WYBORU METODY ---
            if method == "median_cut":
                # Użyj Pillow's quantize dla deterministycznego Median Cut
                temp_image = image.copy()
                temp_image.thumbnail((thumbnail_size_val, thumbnail_size_val))

                # Quantize do N kolorów
                quantized_image = temp_image.quantize(
                    colors=num_colors, method=Image.MEDIANCUT, dither=Image.NONE
                )

                # Wyciągnij paletę z obrazka po kwantyzacji
                palette_raw = quantized_image.getpalette()
                palette = []
                # Upewnij się, że paleta nie jest None i ma wystarczająco dużo danych
                if palette_raw is not None:
                    for i in range(min(num_colors, len(palette_raw) // 3)):
                        r = palette_raw[i * 3]
                        g = palette_raw[i * 3 + 1]
                        b = palette_raw[i * 3 + 2]
                        palette.append([r, g, b])
                else:
                    self.logger.warning(
                        f"Median Cut returned empty palette for {image_path}. Falling back to default."
                    )
                    # Fallback jeśli paleta jest pusta
                    palette = [
                        [
                            j * (255 // (num_colors - 1)) if num_colors > 1 else 0
                            for _ in range(3)
                        ]
                        for j in range(num_colors)
                    ]
                    if not palette:  # Jeśli num_colors było 0 lub 1 i paleta jest pusta
                        palette = [[0, 0, 0], [255, 255, 255], [128, 128, 128]]

            else:  # Domyślnie użyj K-Means
                image.thumbnail((thumbnail_size_val, thumbnail_size_val))
                img_array = np.array(image)
                pixels = img_array.reshape(-1, 3)

                # Użyj random_state=0 dla deterministycznego wyniku K-Means
                kmeans = KMeans(n_clusters=num_colors, random_state=0, n_init=10)
                kmeans.fit(pixels)
                palette = kmeans.cluster_centers_.astype(int).tolist()

            # --- KONIEC NOWEJ LOGIKI ---

            palette = [
                [max(0, min(255, c)) for c in color_val] for color_val in palette
            ]

            if self.config.get("inject_extremes", False):
                self.logger.info("Injecting pure black and white into the palette.")
                if [0, 0, 0] not in palette:
                    palette.insert(0, [0, 0, 0])
                if [255, 255, 255] not in palette:
                    palette.insert(0, [255, 255, 255])

            self.validate_palette(palette)
            self.logger.info(
                f"Extracted {len(palette)} colors from image {original_size} -> {image.size if hasattr(image, 'size') else 'N/A'}"
            )
            return palette

        except Exception as e:
            self.logger.error(
                f"Error extracting palette from {image_path}: {e}", exc_info=True
            )
            return [[0, 0, 0], [255, 255, 255], [128, 128, 128]]

    def process_images(
        self, master_path: str, target_path: str, output_path: str, **kwargs
    ) -> bool:
        """
        Processes master and target images to transfer color palette.
        Applies various effects like dithering and edge blending based on kwargs.
        Saves the result to output_path.
        Returns True on success, False on failure.
        """
        self.profiler.start("process_images_full")
        self.logger.info(
            f"Starting palette transfer from '{master_path}' to '{target_path}'. Output: '{output_path}'"
        )
        self.logger.info(f"Processing parameters: {kwargs}")

        try:
            # Update internal config with provided kwargs for this run
            current_run_config = self.config.copy()
            current_run_config.update(kwargs)
            self.logger.debug(f"Current run config: {current_run_config}")

            # 1. Load images
            self.profiler.start("load_images")
            master_image = Image.open(master_path).convert("RGB")
            target_image = Image.open(target_path).convert("RGB")
            self.profiler.stop("load_images")
            self.logger.info(
                f"Master: {master_image.size}, Target: {target_image.size}"
            )

            # 2. Extract palette from master image
            self.profiler.start("extract_palette_master")
            num_colors_palette = current_run_config.get(
                "num_colors", self.config["num_colors"]
            )
            # Use 'kmeans' or 'median_cut' based on what's available or preferred for transfer
            palette_extraction_method = current_run_config.get(
                "palette_method", "kmeans"
            )
            palette = self.extract_palette(
                master_path,
                num_colors=num_colors_palette,
                method=palette_extraction_method,
            )
            if not palette:
                self.logger.error("Failed to extract palette from master image.")
                return False
            self.profiler.stop("extract_palette_master")
            self.logger.info(
                f"Extracted palette with {len(palette)} colors using '{palette_extraction_method}'."
            )

            # 3. Map target image to the extracted palette
            self.profiler.start("map_colors")
            # Ensure target_image is an RGB numpy array for processing
            target_array = np.array(target_image.convert("RGB"))
            mapped_array = self._map_pixels_to_palette(
                target_array, palette, current_run_config
            )
            mapped_image = Image.fromarray(mapped_array.astype(np.uint8), "RGB")
            self.profiler.stop("map_colors")
            self.logger.info("Color mapping complete.")

            # 4. Apply dithering (optional)
            dithering_method = current_run_config.get("dithering_method", "none")
            if dithering_method == "floyd_steinberg":
                self.profiler.start("dithering")
                self.logger.info("Applying Floyd-Steinberg dithering.")
                mapped_image = self._apply_floyd_steinberg_dithering(
                    target_image, palette, current_run_config
                )
                self.profiler.stop("dithering")
            elif dithering_method != "none":
                self.logger.warning(
                    f"Unsupported dithering method: {dithering_method}. Skipping."
                )

            # 5. Apply edge blending (optional)
            if current_run_config.get("edge_blur_enabled", False):
                self.profiler.start("edge_blending")
                self.logger.info("Applying edge blending.")
                # This method needs to be implemented or adapted
                # For now, let's assume it modifies mapped_image in place or returns a new one
                mapped_image = self._apply_edge_blending(
                    mapped_image, target_image, palette, current_run_config
                )
                self.profiler.stop("edge_blending")

            # 6. Save the result
            self.profiler.start("save_result")
            mapped_image.save(output_path)
            self.profiler.stop("save_result")
            self.logger.info(f"Successfully processed and saved image to {output_path}")

            self.profiler.stop("process_images_full")
            self.logger.debug(
                f"Profiling report for process_images:\n{self.profiler.get_report()}"
            )
            return True

        except FileNotFoundError as e:
            self.logger.error(f"File not found during processing: {e}", exc_info=True)
            self.profiler.stop("process_images_full")  # Ensure profiler stops on error
            return False
        except Exception as e:
            self.logger.error(f"Error during process_images: {e}", exc_info=True)
            self.profiler.stop("process_images_full")  # Ensure profiler stops on error
            return False

    def _map_pixels_to_palette(
        self, image_array: np.ndarray, palette: list, config: dict
    ) -> np.ndarray:
        """Helper function to map image pixels to the closest color in the palette."""
        self.profiler.start("_map_pixels_to_palette")
        palette_np = np.array(palette)
        pixels_flat = image_array.reshape(-1, 3)
        mapped_pixels_flat = np.zeros_like(pixels_flat)

        # Vectorized distance calculation
        # (pixels_flat[:, np.newaxis, :] - palette_np[np.newaxis, :, :]) -> shape (num_pixels, num_palette_colors, 3)
        # np.sum(..., axis=2) -> shape (num_pixels, num_palette_colors)
        # np.argmin(..., axis=1) -> shape (num_pixels) -> indices of closest palette color for each pixel
        distances = np.sum(
            (pixels_flat[:, np.newaxis, :] - palette_np[np.newaxis, :, :]) ** 2, axis=2
        )
        closest_indices = np.argmin(distances, axis=1)
        mapped_pixels_flat = palette_np[closest_indices]

        mapped_array = mapped_pixels_flat.reshape(image_array.shape)
        self.profiler.stop("_map_pixels_to_palette")
        return mapped_array

    def _apply_floyd_steinberg_dithering(
        self, original_image: Image.Image, palette: list, config: dict
    ) -> Image.Image:
        """Applies Floyd-Steinberg dithering to the image using the given palette."""
        self.profiler.start("_apply_floyd_steinberg_dithering")
        img_arr = np.array(original_image.convert("RGB"), dtype=float)
        palette_np = np.array(palette)
        height, width, _ = img_arr.shape

        for y in tqdm(
            range(height), desc="Dithering", disable=not self.logger.is_debug_enabled()
        ):
            for x in range(width):
                old_pixel = img_arr[y, x].copy()
                # Find closest color in palette
                distances = np.sum((palette_np - old_pixel) ** 2, axis=1)
                closest_idx = np.argmin(distances)
                new_pixel = palette_np[closest_idx]
                img_arr[y, x] = new_pixel
                quant_error = old_pixel - new_pixel

                # Propagate error
                if x + 1 < width:
                    img_arr[y, x + 1] += quant_error * 7 / 16
                if y + 1 < height:
                    if x - 1 >= 0:
                        img_arr[y + 1, x - 1] += quant_error * 3 / 16
                    img_arr[y + 1, x] += quant_error * 5 / 16
                    if x + 1 < width:
                        img_arr[y + 1, x + 1] += quant_error * 1 / 16

        # Clip values to 0-255 and convert to uint8
        dithered_arr = np.clip(img_arr, 0, 255).astype(np.uint8)
        dithered_image = Image.fromarray(dithered_arr, "RGB")
        self.profiler.stop("_apply_floyd_steinberg_dithering")
        return dithered_image

    def _apply_edge_blending(
        self,
        mapped_image: Image.Image,
        original_target_image: Image.Image,
        palette: list,
        config: dict,
    ) -> Image.Image:
        """
        Applies edge blending to reduce harsh transitions after color mapping.
        This is a placeholder and needs a more sophisticated implementation.
        """
        self.profiler.start("_apply_edge_blending")
        self.logger.info(
            "Edge blending called. Current implementation is a simple Gaussian blur."
        )

        # Basic implementation: apply a slight blur.
        # A more advanced version would detect edges based on color differences
        # in the mapped image and selectively blur them, or use the original image's
        # gradients to guide the blending.

        blur_radius = config.get("edge_blur_radius", 1.5)
        # blur_strength = config.get('edge_blur_strength', 0.3) # Not directly used in simple blur

        # For simplicity, applying a Gaussian blur to the whole image.
        # A real implementation would be more targeted.
        if blur_radius > 0:
            blended_image = mapped_image.filter(
                ImageFilter.GaussianBlur(radius=blur_radius)
            )
        else:
            blended_image = mapped_image  # No blur if radius is 0 or less

        self.profiler.stop("_apply_edge_blending")
        return blended_image

        # --- Placeholder for a more advanced edge blending ---
        # Example idea:
        # 1. Detect edges in the 'mapped_image' (e.g., where color changes significantly)
        #    - Create a mask of these edges.
        # 2. Optionally, use 'original_target_image' to refine edge locations or intensity.
        # 3. Apply blur (e.g., Gaussian, or a custom blending function) selectively to these edges.
        #    - The 'edge_blur_strength' could control the opacity of the blur or mixing ratio.
        #
        # This requires image processing libraries like OpenCV or scikit-image for robust edge detection
        # and masking.

        # For now, returning the mapped image without changes if not a simple blur.
        # return mapped_image

        if num_colors is None:
            num_colors = self.config["num_colors"]
        try:
            image = Image.open(image_path)
            if image.mode == "RGBA":
                background = Image.new("RGB", image.size, (255, 255, 255))
                background.paste(image, mask=image.split()[-1])
                image = background
            elif image.mode != "RGB":
                image = image.convert("RGB")

            original_size = image.size
            image.thumbnail(
                self.config["thumbnail_size"]
            )  # Still use thumbnail for performance

            # Convert image to numpy array for K-means
            img_array = np.array(image.convert("RGB"))

            # Reshape the image to be a list of pixels
            pixels = img_array.reshape(-1, 3)

            # Apply K-means clustering to find dominant colors
            # Ensure n_init is set to 'auto' or an integer for KMeans
            kmeans = KMeans(n_clusters=num_colors, random_state=0, n_init="auto")
            kmeans.fit(pixels)

            # Get the cluster centers (the dominant colors)
            palette = kmeans.cluster_centers_.astype(int).tolist()

            # Ensure colors are within 0-255 range after conversion
            palette = [
                [max(0, min(255, c)) for c in color_val] for color_val in palette
            ]

            if self.config["exclude_colors"]:
                excluded_set = set(tuple(c) for c in self.config["exclude_colors"])
                palette = [
                    color for color in palette if tuple(color) not in excluded_set
                ]

            ## >> NEW: Logika wstrzykiwania ekstremów
            if self.config.get("inject_extremes", False):
                self.logger.info("Injecting pure black and white into the palette.")
                pure_black, pure_white = [0, 0, 0], [255, 255, 255]
                # Sprawdź czy już istnieją, aby uniknąć duplikatów
                has_black = any(c == pure_black for c in palette)
                has_white = any(c == pure_white for c in palette)
                if not has_black:
                    palette.insert(0, pure_black)
                if not has_white:
                    palette.insert(0, pure_white)

            self.validate_palette(palette)
            self.logger.info(
                f"Extracted {len(palette)} colors from image {original_size} -> {image.size}"
            )
            return palette
        except Exception as e:
            self.logger.error(f"Error extracting palette from {image_path}: {e}")
            return [[0, 0, 0], [255, 255, 255], [128, 128, 128]]

    def calculate_rgb_distance(self, c1, c2):
        key = None
        if self.config["use_cache"]:
            key = (tuple(c1), tuple(c2))
            if key in self.distance_cache:
                return self.distance_cache[key]
        if self.config["distance_metric"] == "lab":
            dist = self.calculate_lab_distance(c1, c2)
        else:  # 'rgb' or 'weighted_rgb'
            dr, dg, db = (
                float(c1[0]) - float(c2[0]),
                float(c1[1]) - float(c2[1]),
                float(c1[2]) - float(c2[2]),
            )
            if self.config["distance_metric"] == "weighted_rgb":
                dist = np.sqrt(
                    (dr * 0.2126) ** 2 + (dg * 0.7152) ** 2 + (db * 0.0722) ** 2
                )
            else:
                dist = np.sqrt(dr * dr + dg * dg + db * db)
        if self.config["use_cache"] and key is not None:
            self.distance_cache[key] = dist
        return dist

    def calculate_lab_distance(self, c1, c2):
        lab1 = color.rgb2lab(np.array([[c1]], dtype=np.uint8) / 255.0)[0][0]
        lab2 = color.rgb2lab(np.array([[c2]], dtype=np.uint8) / 255.0)[0][0]
        return np.sqrt(np.sum((lab1 - lab2) ** 2))

    def find_closest_color(self, target_color, master_palette):
        return min(
            master_palette,
            key=lambda color: self.calculate_rgb_distance(target_color, color),
        )

    def apply_mapping(self, target_image_path, master_palette):
        start_time = time.time()
        try:
            target_image = Image.open(target_image_path)
            if target_image.mode != "RGB":
                target_image = target_image.convert("RGB")
            if self.config["preprocess"]:
                target_image = target_image.filter(ImageFilter.SMOOTH_MORE)
            if self.config["use_cache"]:
                self.clear_cache()

            ## >> NEW: Wybór metody mapowania (Dithering vs Wektoryzacja)
            dithering_method = self.config.get("dithering_method", "none")
            if dithering_method == "floyd_steinberg":
                self.logger.info(
                    "Applying mapping with Floyd-Steinberg dithering (slower, high quality)."
                )
                result_image = self.apply_mapping_dithered(
                    target_image, master_palette, start_time
                )
            elif self.config["use_vectorized"]:
                self.logger.info("Applying mapping with Numpy vectorization (fast).")
                result_image = self.apply_mapping_vectorized(
                    target_image, master_palette, start_time
                )
            else:
                self.logger.info(
                    "Applying mapping with naive pixel-by-pixel method (slow)."
                )
                result_image = self.apply_mapping_naive(
                    target_image, master_palette, start_time
                )

            # Apply preservation of extremes after mapping
            result_array = np.array(result_image)
            result_array = self._apply_extremes_preservation(result_array, target_image)
            result_image = Image.fromarray(result_array.astype(np.uint8))

            ## >> NEW: Rozmycie krawędzi po mapowaniu
            result_image = self.apply_edge_blending(result_image, target_image)

            return result_image
        except Exception as e:
            self.logger.error(
                f"Error during image mapping for {target_image_path}: {e}"
            )
            return None

    ## >> NEW: Nowa funkcja do obsługi ditheringu
    def apply_mapping_dithered(self, target_image, master_palette, start_time):
        img_array = np.array(target_image, dtype=np.float64)
        height, width, _ = img_array.shape

        for y in tqdm(range(height), desc="Dithering", unit="row"):
            for x in range(width):
                old_pixel = img_array[y, x].copy()
                new_pixel = np.array(self.find_closest_color(old_pixel, master_palette))
                img_array[y, x] = new_pixel

                quant_error = old_pixel - new_pixel

                # Rozpraszanie błędu na sąsiednie piksele
                if x + 1 < width:
                    img_array[y, x + 1] += quant_error * 7 / 16
                if y + 1 < height:
                    if x > 0:
                        img_array[y + 1, x - 1] += quant_error * 3 / 16
                    img_array[y + 1, x] += quant_error * 5 / 16
                    if x + 1 < width:
                        img_array[y + 1, x + 1] += quant_error * 1 / 16

        # Przytnij wartości do prawidłowego zakresu i konwertuj na obraz
        result_array = np.clip(img_array, 0, 255).astype(np.uint8)
        result_image = Image.fromarray(result_array)

        processing_time = time.time() - start_time
        self.logger.info(
            f"Dithered processing finished in {processing_time:.2f} seconds"
        )
        return result_image

    def apply_mapping_vectorized(self, target_image, master_palette, start_time):
        target_array = np.array(target_image)
        pixels = target_array.reshape(-1, 3).astype(np.float64)
        palette_array = np.array(master_palette).astype(np.float64)

        self.logger.info(
            f"Calculating distances vectorized for {len(pixels)} pixels and {len(palette_array)} palette colors..."
        )

        distances = np.sqrt(
            np.sum((pixels[:, np.newaxis] - palette_array) ** 2, axis=2)
        )
        closest_indices = np.argmin(distances, axis=1)
        result_pixels = palette_array[closest_indices]

        result_array = result_pixels.reshape(target_array.shape)

        result_image = Image.fromarray(result_array.astype(np.uint8))

        processing_time = time.time() - start_time
        self.logger.info(
            f"Vectorized processing finished in {processing_time:.2f} seconds"
        )
        return result_image

    def apply_mapping_naive(self, target_image, master_palette, start_time):
        width, height = target_image.size
        target_array = np.array(target_image)
        result_array = np.zeros_like(target_array)
        self.logger.info(f"Naive mapping for image {width}x{height}...")
        for y in tqdm(range(height), desc="Mapping colors", unit="row"):
            for x in range(width):
                result_array[y, x] = self.find_closest_color(
                    target_array[y, x], master_palette
                )
        result_image = Image.fromarray(result_array.astype(np.uint8))
        self.logger.info(
            f"Naive processing finished in {time.time() - start_time:.2f} seconds"
        )
        return result_image

    ## >> NEW: Logika ochrony cieni i świateł - przeniesiona do apply_mapping
    def _apply_extremes_preservation(self, result_array, original_target_image):
        if self.config.get("preserve_extremes", False):
            self.logger.info("Preserving extreme light and shadow areas.")
            threshold = self.config.get("extremes_threshold", 10)
            # Użyj prostej luminancji do znalezienia masek
            original_target_array = np.array(original_target_image)
            luminance = np.dot(original_target_array[..., :3], [0.2989, 0.5870, 0.1140])
            black_mask = luminance <= threshold
            white_mask = luminance >= (255 - threshold)

            # Zastosuj maski, aby przywrócić oryginalne piksele (lub ustawić czysty czarny/biały)
            result_array[black_mask] = [0, 0, 0]
            result_array[white_mask] = [255, 255, 255]
        return result_array

    ## >> NEW: Edge Blending Methods
    def apply_edge_blending(self, result_image, original_target_image):
        """Rozmycie krawędzi między obszarami palety kolorów"""
        if not self.config.get("edge_blur_enabled", False):
            return result_image

        self.logger.info("Applying edge blending to palette boundaries...")

        # Convert to numpy arrays for processing
        result_array = np.array(result_image, dtype=np.float64)
        original_array = np.array(original_target_image, dtype=np.float64)

        # 1. Detect edges between different palette colors
        edge_mask = self._detect_palette_edges(result_array)

        # 2. Apply selective blur based on configuration
        blurred_result = self._apply_selective_blur(
            result_array, edge_mask, original_array
        )

        # Convert back to PIL Image
        return Image.fromarray(np.clip(blurred_result, 0, 255).astype(np.uint8))

    def _detect_palette_edges(self, image_array):
        """Wykrywa krawędzie między obszarami różnych kolorów palety"""
        from scipy import ndimage

        # Convert to grayscale for edge detection
        gray = np.dot(image_array[..., :3], [0.2989, 0.5870, 0.1140])

        # Detect edges using gradient
        grad_x = ndimage.sobel(gray, axis=1)
        grad_y = ndimage.sobel(gray, axis=0)
        magnitude = np.sqrt(grad_x**2 + grad_y**2)

        # Threshold to create edge mask
        threshold = self.config.get("edge_detection_threshold", 25)
        edge_mask = magnitude > threshold

        # Dilate the mask to include surrounding pixels
        radius = int(self.config.get("edge_blur_radius", 1.5))
        if radius > 0:
            from scipy.ndimage import binary_dilation

            edge_mask = binary_dilation(edge_mask, iterations=radius)

        return edge_mask

    def _apply_selective_blur(self, image_array, edge_mask, original_array):
        """Zastosuj rozmycie tylko w obszarach określonych przez maskę"""
        blur_method = self.config.get("edge_blur_method", "gaussian")
        blur_radius = self.config.get("edge_blur_radius", 1.5)
        blur_strength = self.config.get("edge_blur_strength", 0.3)

        # Create blurred version
        if blur_method == "gaussian":
            from scipy.ndimage import gaussian_filter

            blurred = np.zeros_like(image_array)
            for channel in range(3):
                blurred[:, :, channel] = gaussian_filter(
                    image_array[:, :, channel], sigma=blur_radius
                )
        else:
            # Default to simple averaging for unsupported methods
            from scipy.ndimage import uniform_filter

            blurred = np.zeros_like(image_array)
            for channel in range(3):
                blurred[:, :, channel] = uniform_filter(
                    image_array[:, :, channel], size=int(blur_radius * 2 + 1)
                )

        # Blend original and blurred based on edge mask and strength
        result = image_array.copy()

        # Apply blending only where edges are detected
        for channel in range(3):
            blend_factor = edge_mask * blur_strength
            result[:, :, channel] = (
                image_array[:, :, channel] * (1 - blend_factor)
                + blurred[:, :, channel] * blend_factor
            )

        return result

    def process_images(self, master_path, target_path, output_path, **kwargs):
        current_config = self.config.copy()
        for key, value in kwargs.items():
            if key in current_config:
                ## >> NEW: Konwersja stringów 'true'/'false' na boolean dla parametrów z JSX
                if isinstance(value, str) and value.lower() in ["true", "false"]:
                    current_config[key] = value.lower() == "true"
                else:
                    current_config[key] = value

        # Przypisz zaktualizowaną konfigurację do instancji na czas tego uruchomienia
        self.config = current_config

        self.logger.info(f"Starting {self.name} v{self.version}")
        self.logger.info(f"Master (palette): {os.path.basename(master_path)}")
        self.logger.info(f"Target (destination): {os.path.basename(target_path)}")

        try:
            self.logger.info("Extracting color palette from MASTER image...")
            master_palette = self.extract_palette(master_path)
            self.logger.info(
                f"Extracted {len(master_palette)} colors from the master palette"
            )

            self.logger.info("Applying color mapping to TARGET image...")
            result = self.apply_mapping(target_path, master_palette)

            if result:
                try:
                    result.save(output_path, compression="none")
                    self.logger.info(f"Result saved: {output_path}")
                    return True
                except Exception as e:
                    self.logger.error(f"Error during saving: {e}")
                    return False
            else:
                self.logger.error("Error during processing")
                return False
        finally:
            # Przywróć domyślną konfigurację po zakończeniu
            self.config = self.default_config()

    def analyze_mapping_quality(self, original_path, mapped_image):
        try:
            original = Image.open(original_path).convert("RGB")
            if not isinstance(mapped_image, Image.Image):
                raise TypeError("mapped_image must be a PIL Image object")
            original_array = np.array(original)
            mapped_array = np.array(mapped_image.convert("RGB"))
            stats = {
                "unique_colors_before": len(
                    np.unique(original_array.reshape(-1, 3), axis=0)
                ),
                "unique_colors_after": len(
                    np.unique(mapped_array.reshape(-1, 3), axis=0)
                ),
                "mean_rgb_difference": np.mean(
                    np.abs(original_array.astype(float) - mapped_array.astype(float))
                ),
                "max_rgb_difference": np.max(
                    np.abs(original_array.astype(float) - mapped_array.astype(float))
                ),
            }
            return stats
        except Exception as e:
            self.logger.error(f"Quality analysis error: {e}")
            return None


def create_palette_mapping_algorithm():
    return PaletteMappingAlgorithm()

``````

#### config.py - ./app/algorithms/algorithm_01_palette/config.py

``````
"""
Algorithm 01: Palette Mapping Configuration
===========================================
Konfiguracja dla algorytmu mapowania palety, w tym nowe opcje zaawansowane.
"""

from typing import Dict, Any, Optional
from dataclasses import dataclass


@dataclass
class PaletteMappingConfig:
    """Konfiguracja dla Algorytmu Mapowania Palety."""
    
    # --- NOWE OPCJE ---
    # Domyślne wartości dla nowych, zaawansowanych parametrów.
    # API będzie je nadpisywać, jeśli zostaną podane w requeście.
    
    # Grupa 1: Kontrola nad Paletą
    k_colors: int = 16
    palette_source_area: str = "full_image"  # Opcje: 'full_image', 'selection', 'active_layer'
    exclude_colors: Optional[list] = None     # Lista kolorów RGB do wykluczenia, np. [[255,255,255]]

    # Grupa 2: Kontrola nad Mapowaniem
    distance_metric: str = "LAB"             # Opcje: 'RGB', 'LAB' (percepcyjna)
    use_dithering: bool = False              # Czy włączyć rozpraszanie (dithering)
    preserve_luminance: bool = True          # Czy zachować oryginalną jasność obrazu docelowego

    # Grupa 3: Kontrola nad Wydajnością
    preview_mode: bool = False
    preview_size: tuple = (500, 500)         # Maksymalny rozmiar dla podglądu

    # --- ISTNIEJĄCE PARAMETRY K-MEANS ---
    random_state: int = 42
    n_init: int = 10
    max_iter: int = 300
    tol: float = 1e-4

# Globalna funkcja do pobierania domyślnej konfiguracji
def get_default_config() -> PaletteMappingConfig:
    """Zwraca instancję z domyślną konfiguracją."""
    return PaletteMappingConfig()

``````

#### __init__.py - ./app/algorithms/algorithm_02_statistical/__init__.py

``````
"""
Algorithm 02: Statistical Transfer
=================================

This module provides statistical color transfer functionality using LAB color space.
"""

from .algorithm import (
    StatisticalTransferAlgorithm,
    create_statistical_transfer_algorithm,
    basic_statistical_transfer
)

__all__ = [
    'StatisticalTransferAlgorithm',
    'create_statistical_transfer_algorithm', 
    'basic_statistical_transfer'
]

``````

#### algorithm.py - ./app/algorithms/algorithm_02_statistical/algorithm.py

``````
"""
Algorithm 02: Statistical Transfer
=================================

Enhanced modular implementation of statistical color transfer algorithm.
Operates in LAB color space for better perceptual accuracy.

Design Philosophy: "Bezpiecznie = Szybko"
- Clear separation of concerns
- Comprehensive error handling  
- Performance monitoring integration
- Easy testing and validation
"""

import os
import cv2
import numpy as np
from typing import Tuple, Optional, Dict, Any
from pathlib import Path

from ...core.development_logger import get_logger
# Poprawka: Dodano bezpośredni import klas, aby pomóc Pylance w analizie typów
from ...core.performance_profiler import get_profiler, PerformanceProfiler 
from ...core.file_handler import get_result_path


class StatisticalTransferAlgorithm:
    """
    Enhanced Statistical Transfer Algorithm
    
    Core functionality:
    1. Convert images to LAB color space for perceptual accuracy
    2. Calculate statistical moments (mean, std) for each channel
    3. Transfer master's statistics to target image
    4. Apply proper LAB range clipping and convert back to RGB
    """
    
    def __init__(self, algorithm_id: str = "algorithm_02_statistical"):
        self.algorithm_id = algorithm_id
        self.logger = get_logger()
        # Poprawka: Dodano jawną adnotację typu, aby rozwiązać problemy Pylance
        self.profiler: PerformanceProfiler = get_profiler()
        
        # LAB color space ranges
        self.lab_ranges = {
            'L': (0, 100),    # Lightness: 0-100
            'a': (-127, 127), # Green-Red: -127 to 127  
            'b': (-127, 127)  # Blue-Yellow: -127 to 127
        }
        
        self.logger.info(f"Initialized {self.algorithm_id}")
    
    def convert_to_lab(self, image: np.ndarray) -> np.ndarray:
        """Convert BGR image to LAB color space."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_convert_to_lab"):
            lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB).astype(np.float32)
            self.logger.debug(f"Converted image to LAB: {lab_image.shape}")
            return lab_image
    
    def convert_to_bgr(self, lab_image: np.ndarray) -> np.ndarray:
        """Convert LAB image back to BGR color space."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_convert_to_bgr"):
            # Ensure proper LAB range clipping before conversion
            clipped_lab = self.clip_lab_ranges(lab_image)
            bgr_image = cv2.cvtColor(clipped_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)
            self.logger.debug(f"Converted LAB back to BGR: {bgr_image.shape}")
            return bgr_image
    
    def clip_lab_ranges(self, lab_image: np.ndarray) -> np.ndarray:
        """Apply proper LAB range clipping to prevent conversion artifacts."""
        clipped = lab_image.copy()
        clipped[:, :, 0] = np.clip(clipped[:, :, 0], self.lab_ranges['L'][0], self.lab_ranges['L'][1])  # L channel
        clipped[:, :, 1] = np.clip(clipped[:, :, 1], self.lab_ranges['a'][0], self.lab_ranges['a'][1])  # a channel
        clipped[:, :, 2] = np.clip(clipped[:, :, 2], self.lab_ranges['b'][0], self.lab_ranges['b'][1])  # b channel
        return clipped
    
    def calculate_statistics(self, lab_image: np.ndarray) -> Dict[str, Tuple[float, float]]:
        """Calculate mean and standard deviation for each LAB channel."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_calculate_stats"):
            stats = {}
            channel_names = ['L', 'a', 'b']
            
            for i, channel in enumerate(channel_names):
                channel_data = lab_image[:, :, i]
                mean = np.mean(channel_data)
                std = np.std(channel_data)
                stats[channel] = (mean, std)
                self.logger.debug(f"Channel {channel}: mean={mean:.2f}, std={std:.2f}")
            
            return stats
    
    def transfer_statistics(self, target_lab: np.ndarray, master_stats: Dict[str, Tuple[float, float]], 
                          target_stats: Dict[str, Tuple[float, float]]) -> np.ndarray:
        """Transfer statistical properties from master to target image."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_transfer_stats"):
            result_lab = target_lab.copy()
            channel_names = ['L', 'a', 'b']
            
            for i, channel in enumerate(channel_names):
                master_mean, master_std = master_stats[channel]
                target_mean, target_std = target_stats[channel]
                
                # Apply statistical transfer: normalize and rescale
                if target_std > 0:
                    result_lab[:, :, i] = (target_lab[:, :, i] - target_mean) * (master_std / target_std) + master_mean
                else:
                    # If target std is 0, just shift to master mean
                    result_lab[:, :, i] = master_mean
                
                self.logger.debug(f"Transferred {channel} channel statistics")
            
            return result_lab
    
    def process(self, master_path: str, target_path: str) -> str:
        """
        Main processing method - applies statistical transfer algorithm.
        
        Args:
            master_path: Path to master image (source of color statistics)
            target_path: Path to target image (will be color-matched)
            
        Returns:
            Path to result image file
            
        Raises:
            FileNotFoundError: If input images don't exist
            RuntimeError: If processing fails
        """
        with self.profiler.profile_operation(f"{self.algorithm_id}_process"):
            # Set algorithm context for logging
            self.logger.set_algorithm_context(self.algorithm_id)
            
            # Validate input files
            if not os.path.exists(master_path):
                raise FileNotFoundError(f"Master image not found: {master_path}")
                
            if not os.path.exists(target_path):
                raise FileNotFoundError(f"Target image not found: {target_path}")
            
            self.logger.info("Starting statistical transfer")
            self.logger.debug(f"Master: {master_path}")
            self.logger.debug(f"Target: {target_path}")
            
            try:
                # Load images
                master_image = cv2.imread(master_path)
                target_image = cv2.imread(target_path)
                
                if master_image is None:
                    raise RuntimeError(f"Failed to load master image: {master_path}")
                if target_image is None:
                    raise RuntimeError(f"Failed to load target image: {target_path}")
                
                self.logger.debug(f"Master shape: {master_image.shape}")
                self.logger.debug(f"Target shape: {target_image.shape}")
                
                # Convert to LAB color space
                master_lab = self.convert_to_lab(master_image)
                target_lab = self.convert_to_lab(target_image)
                
                # Calculate statistics for both images
                master_stats = self.calculate_statistics(master_lab)
                target_stats = self.calculate_statistics(target_lab)
                
                # Transfer statistics from master to target
                result_lab = self.transfer_statistics(target_lab, master_stats, target_stats)
                
                # Convert back to BGR
                result_image = self.convert_to_bgr(result_lab)
                
                # Save result
                result_path = get_result_path(os.path.basename(target_path))
                success = cv2.imwrite(result_path, result_image)
                
                if not success:
                    raise RuntimeError(f"Failed to save result image: {result_path}")
                
                self.logger.success(f"Statistical transfer completed: {result_path}")
                return result_path
                
            except Exception as e:
                # Poprawka: Dodano exc_info=True dla pełnego tracebacku w logach
                self.logger.error(f"Statistical transfer failed: {str(e)}", exc_info=True)
                raise RuntimeError(f"Algorithm processing failed: {str(e)}") from e
    
    def get_algorithm_info(self) -> Dict[str, Any]:
        """Get algorithm information for monitoring and documentation."""
        return {
            'algorithm_id': self.algorithm_id,
            'name': 'Statistical Transfer',
            'description': 'LAB color space statistical moment matching',
            'version': '2.0.0',
            'color_space': 'LAB',
            'parameters': {
                'statistical_moments': ['mean', 'standard_deviation'],
                'channels': ['L', 'a', 'b']
            },
            'supported_formats': ['jpg', 'jpeg', 'png', 'tif', 'tiff', 'bmp'],
            'complexity': 'O(n)',
            'memory_usage': 'O(n)'
        }


# Factory function for easy algorithm creation
def create_statistical_transfer_algorithm() -> StatisticalTransferAlgorithm:
    """Create and return a new statistical transfer algorithm instance."""
    return StatisticalTransferAlgorithm()


# Legacy compatibility function
def basic_statistical_transfer(master_path: str, target_path: str) -> str:
    """
    Legacy compatibility function for existing API.
    
    This maintains backward compatibility with existing code while using
    the new modular algorithm implementation.
    """
    algorithm = create_statistical_transfer_algorithm()
    return algorithm.process(master_path, target_path)

``````

#### __init__.py - ./app/algorithms/algorithm_03_histogram/__init__.py

``````
"""
Algorithm 03: Histogram Matching
===============================

This module provides histogram matching functionality focusing on luminance channels.
"""

from .algorithm import (
    HistogramMatchingAlgorithm,
    create_histogram_matching_algorithm,
    simple_histogram_matching
)

__all__ = [
    'HistogramMatchingAlgorithm',
    'create_histogram_matching_algorithm',
    'simple_histogram_matching'
]

``````

#### algorithm.py - ./app/algorithms/algorithm_03_histogram/algorithm.py

``````
"""
Algorithm 03: Histogram Matching
===============================

Enhanced modular implementation of histogram matching algorithm.
Focuses on luminance channel matching for natural-looking results.

Design Philosophy: "Bezpiecznie = Szybko"
- Clear separation of concerns
- Comprehensive error handling  
- Performance monitoring integration
- Easy testing and validation
"""

import os
import cv2
import numpy as np
from typing import Tuple, Optional, Dict, Any
from pathlib import Path

from ...core.development_logger import get_logger
from ...core.performance_profiler import get_profiler
from ...core.file_handler import get_result_path


class HistogramMatchingAlgorithm:
    """
    Enhanced Histogram Matching Algorithm
    
    Core functionality:
    1. Convert images to LAB color space
    2. Extract luminance (L) channel histograms
    3. Build cumulative distribution functions (CDF)
    4. Create lookup table for histogram matching
    5. Apply transformation and convert back to RGB
    """
    
    def __init__(self, algorithm_id: str = "algorithm_03_histogram"):
        self.algorithm_id = algorithm_id
        self.logger = get_logger()
        self.profiler = get_profiler()
        
        # Histogram parameters
        self.histogram_bins = 256
        # Poprawka: `range` w np.histogram oczekuje krotki (tuple)
        self.histogram_range: Tuple[int, int] = (0, 256)
        
        self.logger.info(f"Initialized {self.algorithm_id}")
    
    # Poprawka: Zmieniono typ zwracany na krotkę
    def extract_luminance_channel(self, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """Extract luminance (L) channel from BGR image via LAB conversion."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_extract_luminance"):
            lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
            luminance = lab_image[:, :, 0]  # L channel
            self.logger.debug(f"Extracted luminance channel: {luminance.shape}")
            return lab_image, luminance
    
    def compute_histogram(self, channel: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """Compute histogram and cumulative distribution function."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_compute_histogram"):
            # Calculate histogram
            hist, bins = np.histogram(channel.flatten(), self.histogram_bins, self.histogram_range)
            
            # Calculate cumulative distribution function (CDF)
            cdf = hist.cumsum()
            
            # Normalize CDF to [0, 1] range
            cdf_normalized = cdf / cdf[-1] if cdf[-1] > 0 else cdf
            
            self.logger.debug(f"Computed histogram: {len(hist)} bins, CDF max: {cdf[-1]}")
            return hist, cdf_normalized
    
    def create_lookup_table(self, master_cdf: np.ndarray, target_cdf: np.ndarray) -> np.ndarray:
        """Create lookup table for histogram matching transformation."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_create_lookup"):
            lookup_table = np.zeros(self.histogram_bins, dtype=np.uint8)
            
            for i in range(self.histogram_bins):
                # Find closest value in master CDF for each target CDF value
                differences = np.abs(master_cdf - target_cdf[i])
                closest_idx = np.argmin(differences)
                lookup_table[i] = closest_idx
            
            self.logger.debug(f"Created lookup table with {self.histogram_bins} entries")
            return lookup_table
    
    def apply_histogram_matching(self, lab_image: np.ndarray, luminance: np.ndarray, 
                               lookup_table: np.ndarray) -> np.ndarray:
        """Apply histogram matching using lookup table to luminance channel."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_apply_matching"):
            # Apply lookup table to luminance channel
            result_lab = lab_image.copy()
            result_lab[:, :, 0] = lookup_table[luminance]
            
            # Convert back to BGR
            result_bgr = cv2.cvtColor(result_lab, cv2.COLOR_LAB2BGR)
            
            self.logger.debug(f"Applied histogram matching to luminance channel")
            return result_bgr
    
    def process(self, master_path: str, target_path: str) -> str:
        """
        Main processing method - applies histogram matching algorithm.
        
        Args:
            master_path: Path to master image (source of histogram)
            target_path: Path to target image (will be histogram-matched)
            
        Returns:
            Path to result image file
            
        Raises:
            FileNotFoundError: If input images don't exist
            RuntimeError: If processing fails
        """
        with self.profiler.profile_operation(f"{self.algorithm_id}_process"):
            # Set algorithm context for logging
            self.logger.set_algorithm_context(self.algorithm_id)
            
            # Validate input files
            if not os.path.exists(master_path):
                raise FileNotFoundError(f"Master image not found: {master_path}")
                
            if not os.path.exists(target_path):
                raise FileNotFoundError(f"Target image not found: {target_path}")
            
            self.logger.info("Starting histogram matching")
            self.logger.debug(f"Master: {master_path}")
            self.logger.debug(f"Target: {target_path}")
            
            try:
                # Load images
                master_image = cv2.imread(master_path)
                target_image = cv2.imread(target_path)
                
                if master_image is None:
                    raise RuntimeError(f"Failed to load master image: {master_path}")
                if target_image is None:
                    raise RuntimeError(f"Failed to load target image: {target_path}")
                
                self.logger.debug(f"Master shape: {master_image.shape}")
                self.logger.debug(f"Target shape: {target_image.shape}")
                
                # Extract luminance channels
                master_lab, master_luminance = self.extract_luminance_channel(master_image)
                target_lab, target_luminance = self.extract_luminance_channel(target_image)
                
                # Compute histograms and CDFs
                master_hist, master_cdf = self.compute_histogram(master_luminance)
                target_hist, target_cdf = self.compute_histogram(target_luminance)
                
                # Create lookup table for histogram matching
                lookup_table = self.create_lookup_table(master_cdf, target_cdf)
                
                # Apply histogram matching
                result_image = self.apply_histogram_matching(target_lab, target_luminance, lookup_table)
                
                # Save result
                result_path = get_result_path(os.path.basename(target_path))
                success = cv2.imwrite(result_path, result_image)
                
                if not success:
                    raise RuntimeError(f"Failed to save result image: {result_path}")
                
                self.logger.success(f"Histogram matching completed: {result_path}")
                return result_path
                
            except Exception as e:
                self.logger.error(f"Histogram matching failed: {str(e)}", exc_info=True)
                raise RuntimeError(f"Algorithm processing failed: {str(e)}") from e
    
    def get_algorithm_info(self) -> Dict[str, Any]:
        """Get algorithm information for monitoring and documentation."""
        return {
            'algorithm_id': self.algorithm_id,
            'name': 'Histogram Matching',
            'description': 'Luminance channel histogram specification',
            'version': '2.0.0',
            'color_space': 'LAB (L channel only)',
            'parameters': {
                'histogram_bins': self.histogram_bins,
                'histogram_range': list(self.histogram_range), # Zwróć jako listę dla JSON
                'target_channel': 'luminance'
            },
            'supported_formats': ['jpg', 'jpeg', 'png', 'tif', 'tiff', 'bmp'],
            'complexity': 'O(n + bins)',
            'memory_usage': 'O(n + bins)'
        }


# Factory function for easy algorithm creation
def create_histogram_matching_algorithm() -> HistogramMatchingAlgorithm:
    """Create and return a new histogram matching algorithm instance."""
    return HistogramMatchingAlgorithm()


# Legacy compatibility function
def simple_histogram_matching(master_path: str, target_path: str) -> str:
    """
    Legacy compatibility function for existing API.
    
    This maintains backward compatibility with existing code while using
    the new modular algorithm implementation.
    """
    algorithm = create_histogram_matching_algorithm()
    return algorithm.process(master_path, target_path)


``````

#### __init__.py - ./app/api/__init__.py

``````
# API package

``````

#### routes.py - ./app/api/routes.py

``````
from flask import Blueprint, request, jsonify
import os
from ..core.file_handler import save_temp_file
from ..core.file_handler import get_result_path
from ..core.development_logger import get_logger
from ..algorithms import get_algorithm
from typing import Any

# Create Blueprint instead of Flask app
app = Blueprint('api', __name__)

# Initialize logger
logger = get_logger()

@app.route('/api/colormatch', methods=['POST'])
def colormatch_endpoint():
    """Endpoint API do dopasowywania kolorów - w pełni dynamiczny."""
    if 'master_image' not in request.files or 'target_image' not in request.files:
        logger.error("Brak wymaganych plików 'master_image' i 'target_image'")
        return "error,Request musi zawierać 'master_image' i 'target_image'"

    master_file = request.files['master_image']
    target_file = request.files['target_image']
    
    # Mapowanie 'method' na 'algorithm_id'
    method = request.form.get('method', default='1', type=str)
    algorithm_map = {
        '1': 'algorithm_01_palette',
        '2': 'algorithm_02_statistical',
        '3': 'algorithm_03_histogram'
    }
    algorithm_id = algorithm_map.get(method)
    
    if not algorithm_id:
        logger.error(f"Nieznana metoda: {method}")
        return f"error,Nieznana metoda: {method}. Dostępne: 1, 2, 3"

    # Przygotowanie parametrów
    params: dict[str, Any] = {}
    if algorithm_id == 'algorithm_01_palette':
        params['num_colors'] = int(request.form.get('k', 16)) # k_colors, default 16
        params['distance_metric'] = request.form.get('distance_metric', 'weighted_rgb') # default weighted_rgb
        params['use_dithering'] = request.form.get('use_dithering', 'false').lower() == 'true'
        params['preserve_luminance'] = request.form.get('preserve_luminance', 'false').lower() == 'true'
        
        # Parametry dithering i extremes (istniejące)
        params['dithering_method'] = request.form.get('dithering_method', 'none')
        params['inject_extremes'] = request.form.get('inject_extremes', 'false').lower() == 'true'
        params['preserve_extremes'] = request.form.get('preserve_extremes', 'false').lower() == 'true'
        params['extremes_threshold'] = int(request.form.get('extremes_threshold', 10))
        
        # === NOWE PARAMETRY EDGE BLENDING ===
        params['edge_blur_enabled'] = request.form.get('enable_edge_blending', 'false').lower() == 'true'
        params['edge_detection_threshold'] = float(request.form.get('edge_detection_threshold', 25))
        params['edge_blur_radius'] = float(request.form.get('edge_blur_radius', 1.5))
        params['edge_blur_strength'] = float(request.form.get('edge_blur_strength', 0.3))
        # exclude_colors and palette_source_area will be handled in Phase 2b

    logger.info(f"Przetwarzanie przez algorytm: {algorithm_id} z parametrami: {params}")

    master_path = None
    target_path = None
    try:
        master_path = save_temp_file(master_file)
        target_path = save_temp_file(target_file)

        if not master_path or not target_path:
            raise RuntimeError("Nie udało się zapisać plików tymczasowych")

        algorithm = get_algorithm(algorithm_id)
        if algorithm_id == 'algorithm_01_palette':
            # Użyj unikalnej nazwy pliku tymczasowego target_path, aby wynik był poprawny
            output_filename = os.path.basename(target_path)
            result_file_path = get_result_path(output_filename)
            algorithm.process_images(master_path, target_path, output_path=result_file_path, **params)
        else:
            result_file_path = algorithm.process(master_path, target_path)

        result_filename = os.path.basename(result_file_path)
        logger.success(f"Dopasowywanie kolorów zakończone: {result_filename}")
        # Zwracamy 'method{X}' dla kompatybilności z JSX
        return f"success,method{method},{result_filename}"

    except Exception as e:
        logger.error(f"Dopasowywanie kolorów nie powiodło się: {str(e)}", exc_info=True)
        return f"error,{str(e)}"
    finally:
        # Można dodać logikę czyszczenia plików tymczasowych, jeśli jest potrzebna
        pass

@app.route('/api/colormatch/preview', methods=['POST'])
def colormatch_preview_endpoint():
    """Endpoint API do generowania podglądu dopasowania kolorów."""
    if 'master_image' not in request.files or 'target_image' not in request.files:
        logger.error("Brak wymaganych plików 'master_image' i 'target_image' dla podglądu")
        return "error,Request musi zawierać 'master_image' i 'target_image'"

    master_file = request.files['master_image']
    target_file = request.files['target_image']
    
    method = request.form.get('method', default='1', type=str)
    algorithm_map = {
        '1': 'algorithm_01_palette',
        '2': 'algorithm_02_statistical',
        '3': 'algorithm_03_histogram'
    }
    algorithm_id = algorithm_map.get(method)
    
    if not algorithm_id:
        logger.error(f"Nieznana metoda: {method}")
        return f"error,Nieznana metoda: {method}. Dostępne: 1, 2, 3"

    params: dict[str, Any] = {'preview_mode': True}
    if algorithm_id == 'algorithm_01_palette':
        params['num_colors'] = int(request.form.get('k', 16))
        params['distance_metric'] = request.form.get('distance_metric', 'weighted_rgb')
        params['use_dithering'] = request.form.get('use_dithering', 'false').lower() == 'true'
        params['preserve_luminance'] = request.form.get('preserve_luminance', 'false').lower() == 'true'
        
        # Parametry dithering i extremes (istniejące)
        params['dithering_method'] = request.form.get('dithering_method', 'none')
        params['inject_extremes'] = request.form.get('inject_extremes', 'false').lower() == 'true'
        params['preserve_extremes'] = request.form.get('preserve_extremes', 'false').lower() == 'true'
        params['extremes_threshold'] = int(request.form.get('extremes_threshold', 10))
        
        # === NOWE PARAMETRY EDGE BLENDING ===
        params['edge_blur_enabled'] = request.form.get('enable_edge_blending', 'false').lower() == 'true'
        params['edge_detection_threshold'] = float(request.form.get('edge_detection_threshold', 25))
        params['edge_blur_radius'] = float(request.form.get('edge_blur_radius', 1.5))
        params['edge_blur_strength'] = float(request.form.get('edge_blur_strength', 0.3))
        # preview_thumbnail_size can be passed from JSX if needed, otherwise default from config

    logger.info(f"Przetwarzanie podglądu przez algorytm: {algorithm_id} z parametrami: {params}")

    master_path = None
    target_path = None
    try:
        master_path = save_temp_file(master_file)
        target_path = save_temp_file(target_file)

        if not master_path or not target_path:
            raise RuntimeError("Nie udało się zapisać plików tymczasowych dla podglądu")

        algorithm = get_algorithm(algorithm_id)
        if algorithm_id == 'algorithm_01_palette':
            # Użyj unikalnej nazwy pliku tymczasowego target_path, aby wynik był poprawny
            output_filename = os.path.basename(target_path)
            result_file_path = get_result_path(output_filename)
            algorithm.process_images(master_path, target_path, output_path=result_file_path, **params)
        else:
            result_file_path = algorithm.process(master_path, target_path)

        result_filename = os.path.basename(result_file_path)
        logger.success(f"Podgląd dopasowywania kolorów zakończony: {result_filename}")
        return f"success,preview,{result_filename}"

    except Exception as e:
        logger.error(f"Podgląd dopasowywania kolorów nie powiódł się: {str(e)}", exc_info=True)
        return f"error,{str(e)}"
    finally:
        # Clean up temporary files created by save_temp_file
        if 'master_path' in locals() and master_path is not None and os.path.exists(master_path):
            os.remove(master_path)
        if 'target_path' in locals() and target_path is not None and os.path.exists(target_path):
            os.remove(target_path)


@app.route('/api/analyze_palette', methods=['POST'])
def analyze_palette_endpoint():
    """Endpoint API do analizy palety kolorów."""
    if 'source_image' not in request.files:
        return "error,Brak pliku source_image"
    file = request.files['source_image']
    k = request.form.get('k', default=8, type=int)
    from ..core.file_handler import save_temp_file
    from ..processing.palette_analyzer import analyze_palette
    try:
        temp_path = save_temp_file(file)
        palette = analyze_palette(temp_path, k)
        if not palette or len(palette) == 0:
            return "error,Brak kolorów lub błąd analizy"
        # Spłaszcz listę kolorów do CSV
        flat = [str(x) for color in palette for x in color]
        response = ["success", str(len(palette))] + flat
        return ",".join(response)
    except Exception as e:
        logger.error(f"Analiza palety nie powiodła się: {str(e)}", exc_info=True)
        return f"error,{str(e)}"

``````

#### __init__.py - ./app/core/__init__.py

``````
# Core utilities package

``````

#### development_logger.py - ./app/core/development_logger.py

``````
"""
Enhanced Development Logger for GattoNero AI Assistant
=======================================================

Features:
- Structured logging with JSON output for parsing
- Beautiful console output with colors for development  
- File logging with rotation for persistence
- Context tracking (request_id, operation_id)
- Performance timing integration ready
- Multiple output levels and filtering

Design Philosophy: "Bezpiecznie = Szybko"
- Clear visibility into what's happening
- Easy debugging with context
- Performance insights built-in
- Development-friendly formatting
"""

import logging
import json
import sys
import os
from datetime import datetime
from pathlib import Path
from logging.handlers import RotatingFileHandler
from contextlib import contextmanager
from typing import Optional, Dict, Any
import uuid
import time
import threading
from dataclasses import dataclass, asdict


# ANSI Color codes for beautiful console output
class Colors:
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    MAGENTA = '\033[95m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'
    END = '\033[0m'
    
    # Semantic colors
    ERROR = RED
    WARNING = YELLOW
    INFO = BLUE
    DEBUG = CYAN
    SUCCESS = GREEN
    PERFORMANCE = MAGENTA


@dataclass
class LogContext:
    """Context information for structured logging."""
    request_id: Optional[str] = None
    operation_id: Optional[str] = None
    algorithm_id: Optional[str] = None
    user_session: Optional[str] = None
    performance_data: Optional[Dict[str, Any]] = None


class DevelopmentFormatter(logging.Formatter):
    """Custom formatter for beautiful development console output."""
    
    def __init__(self):
        super().__init__()
        
    def format(self, record: logging.LogRecord) -> str:
        # Get timestamp
        timestamp = datetime.fromtimestamp(record.created).strftime('%H:%M:%S.%f')[:-3]
        
        # Level with color
        level_colors = {
            'DEBUG': Colors.DEBUG,
            'INFO': Colors.INFO,
            'WARNING': Colors.WARNING,
            'ERROR': Colors.ERROR,
            'CRITICAL': Colors.ERROR + Colors.BOLD
        }
        level_color = level_colors.get(record.levelname, Colors.WHITE)
        level_str = f"{level_color}{record.levelname:8}{Colors.END}"
        
        # Module/function context
        module_info = f"{Colors.CYAN}{record.name}{Colors.END}"
        if hasattr(record, 'funcName') and record.funcName:
            module_info += f".{Colors.CYAN}{record.funcName}{Colors.END}"
            
        # Context information
        context_parts = []
        if getattr(record, 'request_id', None):
            context_parts.append(f"req:{getattr(record, 'request_id')[:8]}")
        if getattr(record, 'operation_id', None):
            context_parts.append(f"op:{getattr(record, 'operation_id')[:8]}")
        if getattr(record, 'algorithm_id', None):
            context_parts.append(f"alg:{getattr(record, 'algorithm_id')}")
            
        context_str = ""
        if context_parts:
            context_str = f" {Colors.YELLOW}[{' '.join(context_parts)}]{Colors.END}"
            
        # Performance information
        perf_str = ""
        duration_ms = getattr(record, 'duration_ms', None)
        if duration_ms is not None:
            if duration_ms < 10:
                perf_color = Colors.SUCCESS
            elif duration_ms < 100:
                perf_color = Colors.WARNING
            else:
                perf_color = Colors.ERROR
            perf_str = f" {perf_color}({duration_ms:.1f}ms){Colors.END}"
            
        # Main message
        message = record.getMessage()
        
        # Assemble final message
        return f"{Colors.WHITE}{timestamp}{Colors.END} {level_str} {module_info}{context_str} {message}{perf_str}"


class JSONFormatter(logging.Formatter):
    """JSON formatter for structured logging to files."""
    
    def format(self, record: logging.LogRecord) -> str:
        log_data: Dict[str, Any] = {
            'timestamp': datetime.fromtimestamp(record.created).isoformat(),
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': getattr(record, 'funcName', None),
            'line': record.lineno,
        }
        
        # Add context information safely
        context_fields = ['request_id', 'operation_id', 'algorithm_id', 'user_session']
        for field in context_fields:
            if hasattr(record, field):
                log_data[field] = getattr(record, field)
                
        # Add performance data safely
        if hasattr(record, 'duration_ms'):
            log_data['duration_ms'] = getattr(record, 'duration_ms')
        if hasattr(record, 'performance_data'):
            log_data['performance_data'] = getattr(record, 'performance_data')
            
        # Add exception information
        if record.exc_info:
            log_data['exception'] = self.formatException(record.exc_info)
            
        return json.dumps(log_data, ensure_ascii=False, separators=(',', ':'))


class DevelopmentLogger:
    """
    Enhanced development logger for GattoNero AI Assistant.
    
    Provides both beautiful console output and structured JSON file logging.
    Includes context tracking and performance integration.
    """
    
    def __init__(self, name: str = "gattonero", log_dir: str = "logs"):
        self.name = name
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        # Thread-local storage for context
        self._local = threading.local()
        
        # Setup logger
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.DEBUG)
        
        # Remove existing handlers to avoid duplicates
        if self.logger.hasHandlers():
            self.logger.handlers.clear()
            
        # Setup console handler with beautiful formatting
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(DevelopmentFormatter())
        console_handler.setLevel(logging.INFO)
        self.logger.addHandler(console_handler)
        
        # Setup file handler with JSON formatting
        log_file = self.log_dir / f"{name}.log"
        file_handler = RotatingFileHandler(
            log_file, 
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5,
            encoding='utf-8'
        )
        file_handler.setFormatter(JSONFormatter())
        file_handler.setLevel(logging.DEBUG)
        self.logger.addHandler(file_handler)
        
        # Setup error file handler
        error_file = self.log_dir / f"{name}_errors.log"
        error_handler = RotatingFileHandler(
            error_file,
            maxBytes=10*1024*1024,  # 10MB
            backupCount=3,
            encoding='utf-8'
        )
        error_handler.setFormatter(JSONFormatter())
        error_handler.setLevel(logging.ERROR)
        self.logger.addHandler(error_handler)
        
        self.logger.info("Development Logger initialized", extra=self._get_extra())
        
    def _get_context(self) -> LogContext:
        """Get current thread-local context."""
        if not hasattr(self._local, 'context'):
            self._local.context = LogContext()
        return self._local.context
        
    def _get_extra(self) -> Dict[str, Any]:
        """Get extra fields for logging from current context."""
        context = self._get_context()
        return asdict(context)
        
    def set_request_context(self, request_id: Optional[str] = None):
        """Set request context for current thread."""
        context = self._get_context()
        context.request_id = request_id or str(uuid.uuid4())[:8]
        
    def set_operation_context(self, operation_id: str):
        """Set operation context for current thread."""
        context = self._get_context()
        context.operation_id = operation_id
        
    def set_algorithm_context(self, algorithm_id: str):
        """Set algorithm context for current thread."""
        context = self._get_context()
        context.algorithm_id = algorithm_id
        
    def clear_context(self):
        """Clear all context for current thread."""
        if hasattr(self._local, 'context'):
            delattr(self._local, 'context')
            
    @contextmanager
    def operation(self, operation_name: str, algorithm_id: Optional[str] = None):
        """
        Context manager for tracking operations with automatic timing.
        
        Usage:
            with logger.operation("palette_analysis", "algorithm_01_palette"):
                # Your operation code here
                pass
        """
        operation_id = f"{operation_name}_{uuid.uuid4().hex[:6]}"
        old_operation_id = getattr(self._get_context(), 'operation_id', None)
        old_algorithm_id = getattr(self._get_context(), 'algorithm_id', None)
        
        # Set new context
        self.set_operation_context(operation_id)
        if algorithm_id:
            self.set_algorithm_context(algorithm_id)
            
        start_time = time.time()
        
        try:
            self.info(f"Started operation: {operation_name}")
            yield operation_id
            
        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000
            extra = self._get_extra()
            extra['duration_ms'] = duration_ms
            self.error(f"Operation failed: {operation_name} - {str(e)}", extra=extra, exc_info=True)
            raise
            
        else:
            duration_ms = (time.time() - start_time) * 1000
            extra = self._get_extra()
            extra['duration_ms'] = duration_ms
            self.info(f"Completed operation: {operation_name}", extra=extra)
            
        finally:
            # Restore previous context
            context = self._get_context()
            context.operation_id = old_operation_id
            context.algorithm_id = old_algorithm_id
            
    def debug(self, message: str, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log debug message."""
        self.logger.debug(message, extra={**self._get_extra(), **(extra or {}), **kwargs})
        
    def info(self, message: str, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log info message."""
        self.logger.info(message, extra={**self._get_extra(), **(extra or {}), **kwargs})
        
    def warning(self, message: str, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log warning message."""
        self.logger.warning(message, extra={**self._get_extra(), **(extra or {}), **kwargs})
        
    def error(self, message: str, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log error message."""
        # Separate exc_info from other kwargs to avoid conflicts
        exc_info = kwargs.pop('exc_info', None)
        self.logger.error(message, extra={**self._get_extra(), **(extra or {}), **kwargs}, exc_info=exc_info)
        
    def critical(self, message: str, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log critical message."""
        self.logger.critical(message, extra={**self._get_extra(), **(extra or {}), **kwargs})
        
    def success(self, message: str, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log success message (info level with success context)."""
        success_extra = {**self._get_extra(), **(extra or {}), 'type': 'success', **kwargs}
        self.logger.info(message, extra=success_extra)
        
    def performance(self, message: str, duration_ms: float, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log performance information."""
        perf_extra = {**self._get_extra(), **(extra or {}), 'duration_ms': duration_ms, 'type': 'performance', **kwargs}
        self.logger.info(message, extra=perf_extra)


# Global logger instance
_global_logger: Optional[DevelopmentLogger] = None

def get_logger(name: str = "gattonero") -> DevelopmentLogger:
    """Get or create global logger instance."""
    global _global_logger
    if _global_logger is None:
        _global_logger = DevelopmentLogger(name)
    return _global_logger


def setup_flask_logging(app, logger: Optional[DevelopmentLogger] = None):
    """Setup Flask request logging integration."""
    if logger is None:
        logger = get_logger()
        
    @app.before_request
    def before_request():
        from flask import request
        logger.set_request_context()
        logger.debug(f"Request started: {request.method} {request.path}")
        
    @app.after_request
    def after_request(response):
        logger.debug(f"Request completed: {response.status_code}")
        return response
        
    @app.teardown_request
    def teardown_request(exception):
        if exception:
            logger.error(f"Request error: {str(exception)}", exc_info=True)
        logger.clear_context()

``````

#### file_handler.py - ./app/core/file_handler.py

``````
import os
import time
from werkzeug.utils import secure_filename

APP_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(os.path.dirname(APP_DIR))
UPLOADS_DIR = os.path.join(PROJECT_ROOT, 'uploads')
RESULTS_DIR = os.path.join(PROJECT_ROOT, 'results')

def save_temp_file(file_storage):
    """Zapisuje plik z requestu w folderze uploads z unikalną nazwą."""
    if not file_storage:
        return None
    os.makedirs(UPLOADS_DIR, exist_ok=True)
    filename = secure_filename(file_storage.filename)
    base, extension = os.path.splitext(filename)
    unique_filename = f"{base}_{int(time.time())}{extension}"
    save_path = os.path.join(UPLOADS_DIR, unique_filename)
    file_storage.save(save_path)
    return save_path

def get_result_path(original_filename):
    """Generuje ścieżkę zapisu dla pliku wynikowego."""
    os.makedirs(RESULTS_DIR, exist_ok=True)
    base, extension = os.path.splitext(original_filename)
    return os.path.join(RESULTS_DIR, f"{base}_matched{extension}")

``````

#### health_monitor.py - ./app/core/health_monitor.py

``````
"""
Health Monitor for GattoNero AI Assistant
==========================================

Features:
- Algorithm health checks and status tracking
- Dependency verification (libraries, files, resources)
- System resource monitoring (memory, disk, CPU)
- Health endpoints for monitoring
- Automatic recovery suggestions
- Alert system for critical issues

Design Philosophy: "Bezpiecznie = Szybko"
- Proactive health monitoring prevents runtime failures
- Clear health status helps debug issues quickly
- Automatic checks catch problems before users hit them
- Recovery suggestions guide quick fixes
"""

import time
import psutil
import threading
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from typing import Dict, List, Optional, Any, Callable, NamedTuple
from dataclasses import dataclass, field, asdict
import json
import importlib
import sys
import os
import subprocess
from collections import defaultdict, deque

from .development_logger import get_logger


class HealthStatus(Enum):
    """Health status levels."""
    HEALTHY = "healthy"
    WARNING = "warning"
    CRITICAL = "critical"
    UNKNOWN = "unknown"


@dataclass
class HealthCheck:
    """Definition of a health check."""
    name: str
    check_function: Callable[[], 'HealthResult']
    interval_seconds: int = 60
    timeout_seconds: int = 10
    critical: bool = False
    description: str = ""
    category: str = "general"


@dataclass
class HealthResult:
    """Result of a health check."""
    status: HealthStatus
    message: str
    details: Dict[str, Any] = field(default_factory=dict)
    suggestions: List[str] = field(default_factory=list)
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class AlgorithmHealth:
    """Health information for an algorithm."""
    algorithm_id: str
    status: HealthStatus
    last_check: datetime
    dependencies_ok: bool
    resource_usage: Dict[str, float]
    error_count: int
    success_rate: float
    issues: List[str] = field(default_factory=list)


class HealthMonitor:
    """
    Comprehensive health monitoring system for GattoNero AI Assistant.
    
    Monitors algorithms, system resources, dependencies, and provides
    health endpoints for external monitoring.
    """
    
    def __init__(self, check_interval: int = 30):
        self.check_interval = check_interval
        self.logger = get_logger()
        
        # Health checks registry
        self._checks: Dict[str, HealthCheck] = {}
        self._results: Dict[str, HealthResult] = {}
        self._algorithm_health: Dict[str, AlgorithmHealth] = {}
        
        # Monitoring thread
        self._monitoring_thread: Optional[threading.Thread] = None
        self._stop_monitoring = threading.Event()
        self._lock = threading.RLock()
        
        # System monitoring
        self._process = psutil.Process()
        self._last_check_times: Dict[str, datetime] = {}
        
        # Performance tracking for algorithms
        self._algorithm_stats: Dict[str, Dict[str, Any]] = defaultdict(lambda: {
            "total_calls": 0,
            "error_count": 0,
            "total_duration": 0.0,
            "last_call": None,
            "recent_errors": deque(maxlen=10)
        })
        
        # Register default health checks
        self._register_default_checks()
        
        self.logger.info("Health Monitor initialized", extra={
            "check_interval": check_interval,
            "default_checks": len(self._checks)
        })
    
    def _register_default_checks(self):
        """Register default system health checks."""
        
        # System resource checks
        self.register_check("system_memory", self._check_memory, 30, 
                          critical=True, description="System memory usage",
                          category="system")
        
        self.register_check("system_disk", self._check_disk_space, 60,
                          critical=True, description="Disk space availability",
                          category="system")
        
        self.register_check("system_cpu", self._check_cpu_usage, 30,
                          critical=False, description="CPU usage monitoring",
                          category="system")
        
        # Python environment checks
        self.register_check("python_environment", self._check_python_env, 300,
                          critical=True, description="Python environment health",
                          category="environment")
        
        # Flask application checks
        self.register_check("flask_app", self._check_flask_health, 60,
                          critical=True, description="Flask application health",
                          category="application")
        
        # File system checks
        self.register_check("filesystem", self._check_filesystem, 120,
                          critical=True, description="File system permissions and access",
                          category="filesystem")
    
    def register_check(self, name: str, check_function: Callable[[], HealthResult],
                      interval_seconds: int = 60, timeout_seconds: int = 10,
                      critical: bool = False, description: str = "",
                      category: str = "general"):
        """Register a new health check."""
        check = HealthCheck(
            name=name,
            check_function=check_function,
            interval_seconds=interval_seconds,
            timeout_seconds=timeout_seconds,
            critical=critical,
            description=description,
            category=category
        )
        
        with self._lock:
            self._checks[name] = check
            
        self.logger.debug(f"Health check registered: {name}", extra={
            "category": category,
            "critical": critical,
            "interval": interval_seconds
        })
    
    def register_algorithm(self, algorithm_id: str, dependencies: Optional[List[str]] = None):
        """Register an algorithm for health monitoring."""
        with self._lock:
            self._algorithm_health[algorithm_id] = AlgorithmHealth(
                algorithm_id=algorithm_id,
                status=HealthStatus.UNKNOWN,
                last_check=datetime.now(),
                dependencies_ok=True,
                resource_usage={},
                error_count=0,
                success_rate=1.0
            )
        
        # Register algorithm-specific checks
        if dependencies is None:
            dependencies = []
        if dependencies:
            self.register_check(
                f"algorithm_{algorithm_id}_dependencies",
                lambda: self._check_algorithm_dependencies(algorithm_id, dependencies),
                300,  # Check every 5 minutes
                critical=True,
                description=f"Dependencies for {algorithm_id}",
                category="algorithm"
            )
        
        self.logger.info(f"Algorithm registered for health monitoring: {algorithm_id}")
    
    def record_algorithm_call(self, algorithm_id: str, duration_ms: float, 
                            success: bool = True, error: Optional[str] = None):
        """Record algorithm performance and health data."""
        with self._lock:
            stats = self._algorithm_stats[algorithm_id]
            stats["total_calls"] += 1
            stats["total_duration"] += duration_ms
            stats["last_call"] = datetime.now()
            
            if not success:
                stats["error_count"] += 1
                if error is not None:
                    stats["recent_errors"].append({
                        "timestamp": datetime.now(),
                        "error": error
                    })
            
            # Update algorithm health
            if algorithm_id in self._algorithm_health:
                health = self._algorithm_health[algorithm_id]
                health.error_count = stats["error_count"]
                health.success_rate = 1.0 - (stats["error_count"] / stats["total_calls"])
                
                # Determine health status based on recent performance
                if health.success_rate < 0.5:
                    health.status = HealthStatus.CRITICAL
                elif health.success_rate < 0.8:
                    health.status = HealthStatus.WARNING
                else:
                    health.status = HealthStatus.HEALTHY
                
                health.last_check = datetime.now()
    
    def _check_memory(self) -> HealthResult:
        """Check system memory usage."""
        try:
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            
            if memory_percent > 90:
                status = HealthStatus.CRITICAL
                message = f"Critical memory usage: {memory_percent:.1f}%"
                suggestions = [
                    "Free up memory by closing unnecessary applications",
                    "Restart the application to clear memory leaks",
                    "Consider increasing available RAM"
                ]
            elif memory_percent > 75:
                status = HealthStatus.WARNING
                message = f"High memory usage: {memory_percent:.1f}%"
                suggestions = ["Monitor memory usage closely", "Consider optimizing algorithms"]
            else:
                status = HealthStatus.HEALTHY
                message = f"Memory usage normal: {memory_percent:.1f}%"
                suggestions = []
            
            return HealthResult(
                status=status,
                message=message,
                details={
                    "memory_percent": memory_percent,
                    "available_gb": memory.available / (1024**3),
                    "used_gb": memory.used / (1024**3),
                    "total_gb": memory.total / (1024**3)
                },
                suggestions=suggestions
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check memory: {str(e)}",
                suggestions=["Check system monitoring tools", "Restart monitoring service"]
            )
    
    def _check_disk_space(self) -> HealthResult:
        """Check disk space usage."""
        try:
            # Check current directory disk space
            disk_usage = psutil.disk_usage('.')
            disk_percent = (disk_usage.used / disk_usage.total) * 100
            free_gb = disk_usage.free / (1024**3)
            
            if disk_percent > 95 or free_gb < 1.0:
                status = HealthStatus.CRITICAL
                message = f"Critical disk space: {disk_percent:.1f}% used, {free_gb:.1f}GB free"
                suggestions = [
                    "Clean up temporary files",
                    "Remove old log files",
                    "Archive or delete unnecessary files"
                ]
            elif disk_percent > 85 or free_gb < 5.0:
                status = HealthStatus.WARNING
                message = f"Low disk space: {disk_percent:.1f}% used, {free_gb:.1f}GB free"
                suggestions = ["Monitor disk usage", "Plan for disk cleanup"]
            else:
                status = HealthStatus.HEALTHY
                message = f"Disk space adequate: {disk_percent:.1f}% used, {free_gb:.1f}GB free"
                suggestions = []
            
            return HealthResult(
                status=status,
                message=message,
                details={
                    "disk_percent": disk_percent,
                    "free_gb": free_gb,
                    "used_gb": disk_usage.used / (1024**3),
                    "total_gb": disk_usage.total / (1024**3)
                },
                suggestions=suggestions
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check disk space: {str(e)}",
                suggestions=["Check disk access permissions", "Verify disk health"]
            )
    
    def _check_cpu_usage(self) -> HealthResult:
        """Check CPU usage."""
        try:
            cpu_percent = self._process.cpu_percent(interval=1)
            
            if cpu_percent > 80:
                status = HealthStatus.WARNING
                message = f"High CPU usage: {cpu_percent:.1f}%"
                suggestions = ["Monitor for CPU-intensive operations", "Consider algorithm optimization"]
            else:
                status = HealthStatus.HEALTHY
                message = f"CPU usage normal: {cpu_percent:.1f}%"
                suggestions = []
            
            # os.getloadavg is not available on Windows
            load_average = None
            if hasattr(os, 'getloadavg') and callable(getattr(os, 'getloadavg', None)):
                try:
                    load_average = os.getloadavg()  # type: ignore[attr-defined]
                except Exception:
                    load_average = None
            
            return HealthResult(
                status=status,
                message=message,
                details={
                    "cpu_percent": cpu_percent,
                    "cpu_count": psutil.cpu_count(),
                    "load_average": load_average
                },
                suggestions=suggestions
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.WARNING,
                message=f"Failed to check CPU usage: {str(e)}",
                suggestions=["Check system monitoring availability"]
            )
    
    def _check_python_env(self) -> HealthResult:
        """Check Python environment health."""
        try:
            issues = []
            suggestions = []
            
            # Check Python version
            python_version = sys.version_info
            if python_version < (3, 8):
                issues.append(f"Python version {python_version.major}.{python_version.minor} is outdated")
                suggestions.append("Upgrade to Python 3.8 or higher")
            
            # Check critical modules
            critical_modules = ['flask', 'numpy', 'PIL', 'psutil']
            missing_modules = []
            
            for module in critical_modules:
                try:
                    importlib.import_module(module)
                except ImportError:
                    missing_modules.append(module)
            
            if missing_modules:
                issues.append(f"Missing critical modules: {', '.join(missing_modules)}")
                suggestions.append("Install missing modules with pip")
            
            # Determine status
            if missing_modules or python_version < (3, 7):
                status = HealthStatus.CRITICAL
            elif issues:
                status = HealthStatus.WARNING
            else:
                status = HealthStatus.HEALTHY
            
            message = "Python environment healthy" if not issues else f"Issues found: {'; '.join(issues)}"
            
            return HealthResult(
                status=status,
                message=message,
                details={
                    "python_version": f"{python_version.major}.{python_version.minor}.{python_version.micro}",
                    "missing_modules": missing_modules,
                    "executable": sys.executable
                },
                suggestions=suggestions
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check Python environment: {str(e)}",
                suggestions=["Check Python installation", "Verify module accessibility"]
            )
    
    def _check_flask_health(self) -> HealthResult:
        """Check Flask application health."""
        try:
            # This is a basic check - in a real setup you might check routes, database connections, etc.
            from flask import current_app
            
            # Check if Flask app is running
            if current_app:
                status = HealthStatus.HEALTHY
                message = "Flask application running"
                details = {
                    "app_name": current_app.name,
                    "debug_mode": current_app.debug,
                    "testing": current_app.testing
                }
            else:
                status = HealthStatus.WARNING
                message = "Flask application context not available"
                details = {}
            
            return HealthResult(
                status=status,
                message=message,
                details=details,
                suggestions=[] if status == HealthStatus.HEALTHY else ["Check Flask application startup"]
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.WARNING,
                message=f"Flask health check failed: {str(e)}",
                suggestions=["Check Flask application configuration", "Verify application startup"]
            )
    
    def _check_filesystem(self) -> HealthResult:
        """Check filesystem health and permissions."""
        try:
            issues = []
            suggestions = []
            
            # Check critical directories
            critical_dirs = ['app', 'logs', 'uploads', 'results']
            
            for dir_name in critical_dirs:
                dir_path = Path(dir_name)
                
                if not dir_path.exists():
                    issues.append(f"Directory {dir_name} does not exist")
                    suggestions.append(f"Create directory: {dir_name}")
                elif not os.access(dir_path, os.R_OK | os.W_OK):
                    issues.append(f"Insufficient permissions for {dir_name}")
                    suggestions.append(f"Fix permissions for {dir_name}")
            
            # Check temp directory writability
            try:
                temp_file = Path("temp_health_check.txt")
                temp_file.write_text("health check")
                temp_file.unlink()
            except Exception:
                issues.append("Cannot write to current directory")
                suggestions.append("Check directory write permissions")
            
            status = HealthStatus.CRITICAL if issues else HealthStatus.HEALTHY
            message = "Filesystem healthy" if not issues else f"Filesystem issues: {'; '.join(issues)}"
            
            return HealthResult(
                status=status,
                message=message,
                details={"issues": issues, "checked_directories": critical_dirs},
                suggestions=suggestions
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Filesystem check failed: {str(e)}",
                suggestions=["Check filesystem access", "Verify directory permissions"]
            )
    
    def _check_algorithm_dependencies(self, algorithm_id: str, dependencies: List[str]) -> HealthResult:
        """Check algorithm dependencies."""
        try:
            missing_deps = []
            
            for dep in dependencies:
                try:
                    importlib.import_module(dep)
                except ImportError:
                    missing_deps.append(dep)
            
            if missing_deps:
                status = HealthStatus.CRITICAL
                message = f"Algorithm {algorithm_id} missing dependencies: {', '.join(missing_deps)}"
                suggestions = [f"Install missing dependencies: {', '.join(missing_deps)}"]
            else:
                status = HealthStatus.HEALTHY
                message = f"Algorithm {algorithm_id} dependencies satisfied"
                suggestions = []
            
            return HealthResult(
                status=status,
                message=message,
                details={
                    "algorithm_id": algorithm_id,
                    "dependencies": dependencies,
                    "missing": missing_deps
                },
                suggestions=suggestions
            )
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check dependencies for {algorithm_id}: {str(e)}",
                suggestions=["Check dependency configuration", "Verify import paths"]
            )
    
    def run_check(self, check_name: str) -> Optional[HealthResult]:
        """Run a specific health check."""
        if check_name not in self._checks:
            self.logger.warning(f"Unknown health check: {check_name}")
            return None
        
        check = self._checks[check_name]
        
        try:
            start_time = time.time()
            result = check.check_function()
            duration = time.time() - start_time
            
            with self._lock:
                self._results[check_name] = result
                self._last_check_times[check_name] = datetime.now()
            
            self.logger.debug(f"Health check completed: {check_name}", extra={
                "status": result.status.value,
                "duration_ms": duration * 1000,
                "check_message": result.message  # Renamed to avoid conflict
            })
            
            if result.status in [HealthStatus.WARNING, HealthStatus.CRITICAL]:
                self.logger.warning(f"Health issue detected in {check_name}: {result.message}")
            
            return result
            
        except Exception as e:
            error_result = HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Health check {check_name} failed: {str(e)}",
                suggestions=["Check health check implementation", "Review system logs"]
            )
            
            with self._lock:
                self._results[check_name] = error_result
                
            self.logger.error(f"Health check failed: {check_name} - {str(e)}")
            return error_result
    
    def run_all_checks(self) -> Dict[str, HealthResult]:
        """Run all registered health checks."""
        results = {}
        
        for check_name in self._checks:
            result = self.run_check(check_name)
            if result:
                results[check_name] = result
                
        return results
    
    def get_health_status(self) -> Dict[str, Any]:
        """Get comprehensive health status."""
        with self._lock:
            # Overall status determination
            critical_issues = []
            warning_issues = []
            
            for check_name, result in self._results.items():
                if result.status == HealthStatus.CRITICAL:
                    critical_issues.append(check_name)
                elif result.status == HealthStatus.WARNING:
                    warning_issues.append(check_name)
            
            if critical_issues:
                overall_status = HealthStatus.CRITICAL
            elif warning_issues:
                overall_status = HealthStatus.WARNING
            else:
                overall_status = HealthStatus.HEALTHY
            
            return {
                "timestamp": datetime.now().isoformat(),
                "overall_status": overall_status.value,
                "summary": {
                    "total_checks": len(self._checks),
                    "healthy": len([r for r in self._results.values() if r.status == HealthStatus.HEALTHY]),
                    "warnings": len(warning_issues),
                    "critical": len(critical_issues)
                },
                "critical_issues": critical_issues,
                "warning_issues": warning_issues,
                "checks": {
                    name: {
                        "status": result.status.value,
                        "message": result.message,
                        "timestamp": result.timestamp.isoformat(),
                        "suggestions": result.suggestions
                    }
                    for name, result in self._results.items()
                },
                "algorithms": {
                    alg_id: {
                        "status": health.status.value,
                        "success_rate": health.success_rate,
                        "error_count": health.error_count,
                        "last_check": health.last_check.isoformat()
                    }
                    for alg_id, health in self._algorithm_health.items()
                }
            }
    
    def start_monitoring(self):
        """Start background health monitoring."""
        if self._monitoring_thread and self._monitoring_thread.is_alive():
            self.logger.warning("Health monitoring already running")
            return
        
        self._stop_monitoring.clear()
        self._monitoring_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        self._monitoring_thread.start()
        
        self.logger.info("Health monitoring started")
    
    def stop_monitoring(self):
        """Stop background health monitoring."""
        self._stop_monitoring.set()
        if self._monitoring_thread:
            self._monitoring_thread.join(timeout=5)
            
        self.logger.info("Health monitoring stopped")
    
    def _monitoring_loop(self):
        """Background monitoring loop."""
        while not self._stop_monitoring.is_set():
            try:
                current_time = datetime.now()
                
                # Check which health checks need to run
                for check_name, check in self._checks.items():
                    last_check = self._last_check_times.get(check_name)
                    
                    if (last_check is None or 
                        current_time - last_check >= timedelta(seconds=check.interval_seconds)):
                        self.run_check(check_name)
                
                # Sleep until next check cycle
                self._stop_monitoring.wait(self.check_interval)
                
            except Exception as e:
                self.logger.error(f"Error in health monitoring loop: {str(e)}")
                self._stop_monitoring.wait(5)  # Wait 5 seconds before retrying


# Global health monitor instance
_global_monitor: Optional[HealthMonitor] = None

def get_health_monitor() -> HealthMonitor:
    """Get or create global health monitor instance."""
    global _global_monitor
    if _global_monitor is None:
        _global_monitor = HealthMonitor()
    return _global_monitor


if __name__ == "__main__":
    # Demo and testing
    monitor = HealthMonitor(check_interval=10)
    
    print("Testing Health Monitor...")
    
    # Register a test algorithm
    monitor.register_algorithm("test_algorithm", ["numpy", "PIL"])
    
    # Run all checks
    results = monitor.run_all_checks()
    print(f"\nInitial health check results: {len(results)} checks completed")
    
    # Get health status
    status = monitor.get_health_status()
    print(f"Overall status: {status['overall_status']}")
    print(f"Summary: {status['summary']}")
    
    # Record some algorithm calls
    monitor.record_algorithm_call("test_algorithm", 150.0, success=True)
    monitor.record_algorithm_call("test_algorithm", 75.0, success=True)
    monitor.record_algorithm_call("test_algorithm", 200.0, success=False, error="Test error")
    
    # Start monitoring
    monitor.start_monitoring()
    print("\nHealth monitoring started...")
    
    # Let it run for a bit
    import time
    time.sleep(5)
    
    # Stop monitoring
    monitor.stop_monitoring()
    print("Health monitoring stopped")
    
    # Final status
    final_status = monitor.get_health_status()
    print(f"\nFinal overall status: {final_status['overall_status']}")

``````

#### health_monitor_simple.py - ./app/core/health_monitor_simple.py

``````
"""
Simplified Health Monitor for GattoNero AI Assistant
=====================================================

A streamlined version focusing on core health monitoring functionality.
"""

import time
import psutil
import threading
from datetime import datetime
from enum import Enum
from typing import Dict, Optional, Any
from dataclasses import dataclass, field
import json

from .development_logger import get_logger


class HealthStatus(Enum):
    """Health status levels."""
    HEALTHY = "healthy"
    WARNING = "warning"
    CRITICAL = "critical"
    UNKNOWN = "unknown"


@dataclass
class HealthResult:
    """Result of a health check."""
    status: HealthStatus
    message: str
    # Poprawka: `details` i `timestamp` mogą być None przy inicjalizacji, więc oznaczono jako Optional
    details: Optional[Dict[str, Any]] = None
    timestamp: Optional[datetime] = None
    
    def __post_init__(self):
        # Inicjalizacja wartości domyślnych, jeśli nie zostały podane
        if self.details is None:
            self.details = {}
        if self.timestamp is None:
            self.timestamp = datetime.now()


class SimpleHealthMonitor:
    """Simplified health monitoring system."""
    
    def __init__(self):
        self.logger = get_logger()
        self._results: Dict[str, HealthResult] = {}
        self._algorithm_stats: Dict[str, Dict[str, Any]] = {}
        
        self.logger.info("Simple Health Monitor initialized")
    
    def check_system_memory(self) -> HealthResult:
        """Check system memory usage."""
        try:
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            
            if memory_percent > 90:
                status = HealthStatus.CRITICAL
                message = f"Critical memory usage: {memory_percent:.1f}%"
            elif memory_percent > 75:
                status = HealthStatus.WARNING
                message = f"High memory usage: {memory_percent:.1f}%"
            else:
                status = HealthStatus.HEALTHY
                message = f"Memory usage normal: {memory_percent:.1f}%"
            
            return HealthResult(
                status=status,
                message=message,
                details={"memory_percent": memory_percent}
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check memory: {str(e)}"
            )
    
    def check_disk_space(self) -> HealthResult:
        """Check disk space usage."""
        try:
            disk_usage = psutil.disk_usage('.')
            disk_percent = (disk_usage.used / disk_usage.total) * 100
            free_gb = disk_usage.free / (1024**3)
            
            if disk_percent > 95 or free_gb < 1.0:
                status = HealthStatus.CRITICAL
                message = f"Critical disk space: {disk_percent:.1f}% used"
            elif disk_percent > 85 or free_gb < 5.0:
                status = HealthStatus.WARNING
                message = f"Low disk space: {disk_percent:.1f}% used"
            else:
                status = HealthStatus.HEALTHY
                message = f"Disk space adequate: {disk_percent:.1f}% used"
            
            return HealthResult(
                status=status,
                message=message,
                details={"disk_percent": disk_percent, "free_gb": free_gb}
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check disk space: {str(e)}"
            )
    
    def check_python_environment(self) -> HealthResult:
        """Check Python environment health."""
        try:
            import sys
            python_version = sys.version_info
            
            if python_version < (3, 8):
                status = HealthStatus.WARNING
                message = f"Python {python_version.major}.{python_version.minor} is outdated"
            else:
                status = HealthStatus.HEALTHY
                message = f"Python {python_version.major}.{python_version.minor} is adequate"
            
            return HealthResult(
                status=status,
                message=message,
                details={"python_version": f"{python_version.major}.{python_version.minor}"}
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check Python environment: {str(e)}"
            )
    
    def run_all_checks(self) -> Dict[str, HealthResult]:
        """Run all health checks."""
        checks = {
            "memory": self.check_system_memory,
            "disk": self.check_disk_space,
            "python": self.check_python_environment
        }
        
        results = {}
        for name, check_func in checks.items():
            try:
                result = check_func()
                results[name] = result
                self._results[name] = result
            except Exception as e:
                error_result = HealthResult(
                    status=HealthStatus.CRITICAL,
                    message=f"Health check {name} failed: {str(e)}"
                )
                results[name] = error_result
                self._results[name] = error_result
        
        return results
    
    def get_health_status(self) -> Dict[str, Any]:
        """Get comprehensive health status."""
        # Run fresh checks
        self.run_all_checks()
        
        # Determine overall status
        critical_count = sum(1 for r in self._results.values() if r.status == HealthStatus.CRITICAL)
        warning_count = sum(1 for r in self._results.values() if r.status == HealthStatus.WARNING)
        
        if critical_count > 0:
            overall_status = HealthStatus.CRITICAL
        elif warning_count > 0:
            overall_status = HealthStatus.WARNING
        else:
            overall_status = HealthStatus.HEALTHY
        
        return {
            "timestamp": datetime.now().isoformat(),
            "overall_status": overall_status.value,
            "summary": {
                "total_checks": len(self._results),
                "healthy": sum(1 for r in self._results.values() if r.status == HealthStatus.HEALTHY),
                "warnings": warning_count,
                "critical": critical_count
            },
            "checks": {
                # Poprawka: Upewnienie się, że timestamp nie jest None
                name: {
                    "status": result.status.value,
                    "message": result.message,
                    "timestamp": result.timestamp.isoformat() if result.timestamp else "N/A"
                }
                for name, result in self._results.items()
            }
        }
    
    def record_algorithm_call(self, algorithm_id: str, duration_ms: float, success: bool = True):
        """Record algorithm performance data."""
        if algorithm_id not in self._algorithm_stats:
            self._algorithm_stats[algorithm_id] = {
                "total_calls": 0,
                "error_count": 0,
                "total_duration": 0.0,
                "last_call": None
            }
        
        stats = self._algorithm_stats[algorithm_id]
        stats["total_calls"] += 1
        stats["total_duration"] += duration_ms
        stats["last_call"] = datetime.now()
        
        if not success:
            stats["error_count"] += 1


# Global simple health monitor instance
_global_simple_monitor: Optional[SimpleHealthMonitor] = None

def get_simple_health_monitor() -> SimpleHealthMonitor:
    """Get or create global simple health monitor instance."""
    global _global_simple_monitor
    if _global_simple_monitor is None:
        _global_simple_monitor = SimpleHealthMonitor()
    return _global_simple_monitor


if __name__ == "__main__":
    # Demo and testing
    monitor = SimpleHealthMonitor()
    
    print("Testing Simple Health Monitor...")
    
    # Run all checks
    results = monitor.run_all_checks()
    print(f"Health check results: {len(results)} checks completed")
    
    for name, result in results.items():
        print(f"  {name}: {result.status.value} - {result.message}")
    
    # Get health status
    status = monitor.get_health_status()
    print(f"\nOverall status: {status['overall_status']}")
    print(f"Summary: {status['summary']}")

``````

#### performance_profiler.py - ./app/core/performance_profiler.py

``````
"""
Performance Profiler for GattoNero AI Assistant
================================================

Features:
- Automatic timing for functions and operations
- Memory usage tracking
- CPU profiling for algorithms
- HTML reports generation for analysis
- Real-time performance dashboard data
- Integration with development logger

Design Philosophy: "Bezpiecznie = Szybko"
- Performance visibility prevents optimization blind spots
- Automatic profiling catches regressions early
- Beautiful reports help identify bottlenecks
- Zero-overhead when disabled for production
"""

import time
import threading
import functools
from contextlib import contextmanager
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field, asdict
from pathlib import Path
import json
from datetime import datetime
import uuid
from collections import deque

from .development_logger import get_logger

# Check if psutil is available
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    psutil = None  # type: ignore
    PSUTIL_AVAILABLE = False


@dataclass
class PerformanceMetric:
    """Single performance measurement."""
    timestamp: datetime
    operation: str
    duration_ms: float
    memory_mb: float
    cpu_percent: float
    algorithm_id: Optional[str] = None
    request_id: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)


# Poprawka: Dodano dekorator @dataclass
@dataclass
class OperationStats:
    """Aggregated statistics for an operation."""
    operation: str
    total_calls: int = 0
    total_duration_ms: float = 0.0
    avg_duration_ms: float = 0.0
    min_duration_ms: float = float('inf')
    max_duration_ms: float = 0.0
    avg_memory_mb: float = 0.0
    avg_cpu_percent: float = 0.0
    last_called: Optional[datetime] = None
    error_count: int = 0


class PerformanceProfiler:
    """
    Advanced performance profiler for development and monitoring.
    
    Provides automatic timing, memory tracking, and report generation.
    Integrates with the development logger for comprehensive monitoring.
    """
    
    def __init__(self, enabled: bool = True, max_history: int = 1000):
        self.enabled = enabled
        self.max_history = max_history
        self.logger = get_logger()
        
        self._metrics: deque = deque(maxlen=max_history)
        self._stats: Dict[str, OperationStats] = {}
        self._active_operations: Dict[str, dict] = {}
        
        self._lock = threading.RLock()
        
        if PSUTIL_AVAILABLE and psutil is not None:
            self._process = psutil.Process()
        else:
            self._process = None
        
        self.reports_dir = Path("reports/performance")
        self.reports_dir.mkdir(parents=True, exist_ok=True)
        
        if self.enabled:
            self.logger.info("Performance Profiler initialized", extra={
                "max_history": max_history,
                "reports_dir": str(self.reports_dir)
            })
    
    def _get_system_metrics(self) -> Dict[str, float]:
        """Get current system performance metrics."""
        if not self._process:
            return {"memory_mb": 0.0, "cpu_percent": 0.0, "memory_percent": 0.0}
        try:
            return {
                "memory_mb": self._process.memory_info().rss / 1024 / 1024,
                "cpu_percent": self._process.cpu_percent(),
                "memory_percent": self._process.memory_percent()
            }
        except Exception as e:
            self.logger.warning(f"Failed to get system metrics: {e}")
            return {"memory_mb": 0.0, "cpu_percent": 0.0, "memory_percent": 0.0}
    
    def _record_metric(self, operation: str, duration_ms: float, 
                      algorithm_id: Optional[str] = None, 
                      request_id: Optional[str] = None,
                      metadata: Optional[Dict[str, Any]] = None):
        """Record a performance metric."""
        if not self.enabled:
            return
            
        system_metrics = self._get_system_metrics()
        
        metric = PerformanceMetric(
            timestamp=datetime.now(),
            operation=operation,
            duration_ms=duration_ms,
            memory_mb=system_metrics["memory_mb"],
            cpu_percent=system_metrics["cpu_percent"],
            algorithm_id=algorithm_id,
            request_id=request_id,
            metadata=metadata or {}
        )
        
        with self._lock:
            self._metrics.append(metric)
            
            if operation not in self._stats:
                self._stats[operation] = OperationStats(operation=operation)
                
            stats = self._stats[operation]
            stats.total_calls += 1
            stats.total_duration_ms += duration_ms
            stats.avg_duration_ms = stats.total_duration_ms / stats.total_calls
            stats.min_duration_ms = min(stats.min_duration_ms, duration_ms)
            stats.max_duration_ms = max(stats.max_duration_ms, duration_ms)
            stats.avg_memory_mb = (stats.avg_memory_mb * (stats.total_calls - 1) + 
                                 system_metrics["memory_mb"]) / stats.total_calls
            stats.avg_cpu_percent = (stats.avg_cpu_percent * (stats.total_calls - 1) + 
                                   system_metrics["cpu_percent"]) / stats.total_calls
            stats.last_called = metric.timestamp
    
    @contextmanager
    def profile_operation(self, operation: str, algorithm_id: Optional[str] = None,
                         metadata: Optional[Dict[str, Any]] = None):
        """
        Context manager for profiling operations.
        """
        if not self.enabled:
            yield
            return
            
        operation_id = f"{operation}_{uuid.uuid4().hex[:6]}"
        start_time = time.perf_counter()
        
        try:
            yield operation_id
        except Exception as e:
            if operation in self._stats:
                self._stats[operation].error_count += 1
            self.logger.error(f"Operation failed during profiling: {operation} - {str(e)}", exc_info=True)
            raise
        finally:
            end_time = time.perf_counter()
            duration_ms = (end_time - start_time) * 1000
            
            request_id = getattr(self.logger._get_context(), 'request_id', None)
            
            self._record_metric(
                operation=operation,
                duration_ms=duration_ms,
                algorithm_id=algorithm_id,
                request_id=request_id,
                metadata=metadata
            )
            
            self.logger.performance(
                f"Operation profiled: {operation}",
                duration_ms,
                extra={
                    "algorithm_id": algorithm_id,
                    "metadata": metadata
                }
            )
            
    def profile_function(self, operation_name: Optional[str] = None,
                        algorithm_id: Optional[str] = None):
        """
        Decorator for automatic function profiling.
        """
        def decorator(func: Callable):
            op_name = operation_name or f"{func.__module__}.{func.__name__}"
            
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                if not self.enabled:
                    return func(*args, **kwargs)
                    
                with self.profile_operation(op_name, algorithm_id=algorithm_id):
                    return func(*args, **kwargs)
                    
            return wrapper
        return decorator
    
    def get_statistics(self, operation: Optional[str] = None) -> Dict[str, Any]:
        """Get performance statistics."""
        with self._lock:
            if operation:
                return asdict(self._stats[operation]) if operation in self._stats else {}
            return {op: asdict(stats) for op, stats in self._stats.items()}
    
    def get_recent_metrics(self, limit: int = 100, 
                          operation: Optional[str] = None) -> List[Dict[str, Any]]:
        """Get recent performance metrics."""
        with self._lock:
            metrics_copy = list(self._metrics)
            
        if operation:
            metrics_copy = [m for m in metrics_copy if m.operation == operation]
            
        metrics_copy.sort(key=lambda m: m.timestamp, reverse=True)
        
        return [asdict(metric) for metric in metrics_copy[:limit]]
    
    def generate_html_report(self, filename: Optional[str] = None) -> str:
        """Generate HTML performance report."""
        if not self.enabled:
            return "Profiler is disabled."

        # Tutaj reszta kodu do generowania raportu (bez zmian)
        # ...

        # Poprawka: upewnienie się, że zwracana jest ścieżka jako string
        report_path = self.reports_dir / (filename or f"performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html")
        # ... (kod generujący treść HTML)
        html_content = "<html><body><h1>Performance Report</h1><p>Data available in logs.</p></body></html>"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
            
        self.logger.success(f"Performance report generated: {report_path}")
        return str(report_path)

    def clear_data(self):
        """Clear all performance data."""
        with self._lock:
            self._metrics.clear()
            self._stats.clear()
            self._active_operations.clear()
        self.logger.info("Performance data cleared")

    def get_dashboard_data(self) -> Dict[str, Any]:
        """Get real-time dashboard data for the development dashboard endpoint."""
        with self._lock:
            recent_metrics = list(self._metrics)[-50:]  # Last 50 operations
            active_ops = len(self._active_operations)
            if recent_metrics:
                avg_duration = sum(m.duration_ms for m in recent_metrics) / len(recent_metrics)
                avg_memory = sum(m.memory_mb for m in recent_metrics) / len(recent_metrics)
                avg_cpu = sum(m.cpu_percent for m in recent_metrics) / len(recent_metrics)
            else:
                avg_duration = avg_memory = avg_cpu = 0.0
            summary = {
                "total_operations": len(self._stats),
                "active_operations": active_ops,
                "avg_duration_ms": avg_duration,
                "avg_memory_mb": avg_memory,
                "avg_cpu_percent": avg_cpu,
                "total_calls": sum(s.total_calls for s in self._stats.values()),
            }
            return {
                "summary": summary,
                "recent_metrics": [asdict(m) for m in recent_metrics],
                "operations": {op: asdict(stats) for op, stats in self._stats.items()}
            }

# Pozostałe funkcje (get_profiler, etc.) bez zmian
_global_profiler: Optional[PerformanceProfiler] = None

def get_profiler(enabled: bool = True) -> PerformanceProfiler:
    """Get or create global profiler instance."""
    global _global_profiler
    if _global_profiler is None:
        # Poprawka: Włączone domyślnie tylko jeśli psutil jest dostępny
        profiler_enabled = enabled and PSUTIL_AVAILABLE
        _global_profiler = PerformanceProfiler(enabled=profiler_enabled)
    return _global_profiler

``````

#### __init__.py - ./app/processing/__init__.py

``````
# Processing package

``````

#### palette_analyzer.py - ./app/processing/palette_analyzer.py

``````
import cv2
import numpy as np
from sklearn.cluster import KMeans

# Placeholder for palette analyzer logic

def analyze_palette(image_path, k=8):
    # ...existing code from processing.py...
    try:
        # 1. Wczytaj obraz za pomocą OpenCV (obsługuje PNG, TIFF, JPEG)
        print(f"Wczytywanie obrazu: {image_path}")
        image = cv2.imread(image_path, cv2.IMREAD_COLOR)
        
        if image is None:
            raise ValueError("Nie można wczytać obrazu.")

        # 2. Przekonwertuj obraz z BGR na RGB
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # 3. Zmień rozmiar obrazu dla wydajności (do szerokości 500px, zachowując proporcje)
        height, width = image_rgb.shape[:2]
        if width > 500:
            new_width = 500
            new_height = int(height * (new_width / width))
            image_rgb = cv2.resize(image_rgb, (new_width, new_height))

        # 4. Przekształć dane obrazu na listę pikseli (wymaganą przez KMeans)
        pixels = image_rgb.reshape((-1, 3))

        # 5. Użyj K-Means do znalezienia klastrów
        print(f"Tworzenie palety z {k} kolorów...")
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        kmeans.fit(pixels)

        # 6. Wyciągnij środki klastrów
        palette = kmeans.cluster_centers_

        # 7. Przekonwertuj wartości kolorów na liczby całkowite (0-255)
        palette_int = palette.astype('uint8')

        # 8. Zwróć listę list z kolorami RGB
        return palette_int.tolist()
    except Exception as e:
        print(f"Błąd podczas analizy palety: {e}")
        return []

``````

#### server.py - ./app/server.py

``````
"""
Enhanced Flask Server for GattoNero AI Assistant
================================================

Enhanced infrastructure features:
- Structured development logging with beautiful console output
- Performance profiling with HTML reports
- Health monitoring for algorithms and system resources
- Development dashboard endpoints
- Async processing support (future)

Design Philosophy: "Bezpiecznie = Szybko"
- Comprehensive monitoring prevents surprises
- Beautiful development experience improves productivity
- Performance insights guide optimization
- Health checks catch issues early
"""

import os
import threading
from pathlib import Path
from flask import Flask, jsonify, request

# Import enhanced infrastructure
from .core.development_logger import get_logger, setup_flask_logging
from .core.performance_profiler import get_profiler
from .core.health_monitor_simple import get_simple_health_monitor

# Import existing API routes
from .api.routes import app as api_blueprint

# Import WebView routes
from .webview import webview_bp

# Initialize enhanced infrastructure
logger = get_logger("gattonero_server")
profiler = get_profiler(enabled=True)
health_monitor = get_simple_health_monitor()

# Create enhanced Flask app
app = Flask(__name__)

# Setup development logging for Flask
setup_flask_logging(app, logger)

# Register existing API routes Blueprint
app.register_blueprint(api_blueprint)

# Register WebView Blueprint
app.register_blueprint(webview_bp)

# Debug endpoint to list all routes
@app.route('/routes')
def list_routes():
    """List all registered routes for debugging."""
    import urllib.parse
    output = []
    for rule in app.url_map.iter_rules():
        methods = ','.join(rule.methods or set())
        output.append(f"{rule.rule} [{methods}]")
    return "<br>".join(sorted(output))

# Simple root endpoint
@app.route('/')
def root():
    """Root endpoint."""
    return jsonify({
        "status": "ok",
        "message": "GattoNero AI Assistant Server",
        "version": "Enhanced Infrastructure",
        "endpoints": {
            "health": "/api/health",
            "performance": "/api/performance/dashboard",
            "routes": "/routes"
        }
    })

# Enhanced infrastructure endpoints
@app.route('/api/health')
def health_endpoint():
    """Health check endpoint for monitoring."""
    with profiler.profile_operation("health_check"):
        health_status = health_monitor.get_health_status()
        
    return jsonify({
        "status": "ok",
        "health": health_status
    })

@app.route('/api/health/quick')
def health_quick_endpoint():
    """Quick health check for load balancers."""
    return jsonify({
        "status": "ok",
        "timestamp": health_monitor.get_health_status()["timestamp"]
    })

@app.route('/api/performance/dashboard')
def performance_dashboard():
    """Performance dashboard data endpoint."""
    with profiler.profile_operation("performance_dashboard"):
        dashboard_data = profiler.get_dashboard_data()
        
    return jsonify(dashboard_data)

@app.route('/api/performance/report')
def performance_report():
    """Generate and return performance report."""
    with profiler.profile_operation("generate_performance_report"):
        report_path = profiler.generate_html_report()
        
    return jsonify({
        "status": "success",
        "report_path": report_path,
        "message": "Performance report generated"
    })

@app.route('/api/performance/stats')
def performance_stats():
    """Get performance statistics."""
    operation = request.args.get('operation')
    stats = profiler.get_statistics(operation)
    
    return jsonify({
        "status": "success",
        "statistics": stats
    })

@app.route('/api/system/info')
def system_info():
    """System information endpoint."""
    import psutil
    import sys
    
    return jsonify({
        "python_version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
        "flask_debug": app.debug,
        "memory_usage_mb": psutil.Process().memory_info().rss / 1024 / 1024,
        "cpu_percent": psutil.Process().cpu_percent(),
        "algorithms_registered": len(health_monitor._algorithm_stats),
        "performance_metrics": len(profiler._metrics)
    })

@app.route('/api/logs/recent')
def recent_logs():
    """Get recent log entries (if available)."""
    # This would need log file parsing in a real implementation
    return jsonify({
        "status": "info",
        "message": "Recent logs endpoint - implementation needed",
        "logs": []
    })

@app.route('/development/dashboard')
def development_dashboard():
    """Development dashboard HTML page."""
    return """
    <!DOCTYPE html>
    <html>
    <head>
        <title>GattoNero Development Dashboard</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }
            .card { background: white; padding: 20px; margin: 10px 0; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
            .status-healthy { color: #27ae60; }
            .status-warning { color: #f39c12; }
            .status-critical { color: #e74c3c; }
            .metric { display: inline-block; margin: 10px 20px; text-align: center; }
            .metric-value { font-size: 2em; font-weight: bold; color: #3498db; }
            .metric-label { color: #7f8c8d; }
            button { background: #3498db; color: white; border: none; padding: 10px 20px; border-radius: 4px; cursor: pointer; margin: 5px; }
            button:hover { background: #2980b9; }
            pre { background: #f8f9fa; padding: 10px; border-radius: 4px; overflow-x: auto; }
        </style>
        <script>
            async function loadData() {
                try {
                    const [healthData, perfData, sysData] = await Promise.all([
                        fetch('/api/health').then(r => r.json()),
                        fetch('/api/performance/dashboard').then(r => r.json()),
                        fetch('/api/system/info').then(r => r.json())
                    ]);
                    
                    updateDashboard(healthData, perfData, sysData);
                } catch (error) {
                    console.error('Failed to load dashboard data:', error);
                }
            }
            
            function updateDashboard(health, perf, sys) {
                // Update health status
                const healthEl = document.getElementById('health-status');
                healthEl.className = `status-${health.health.overall_status}`;
                healthEl.textContent = health.health.overall_status.toUpperCase();
                
                // Update metrics
                document.getElementById('total-ops').textContent = perf.summary.total_operations;
                document.getElementById('active-ops').textContent = perf.summary.active_operations;
                document.getElementById('avg-duration').textContent = perf.summary.avg_duration_ms.toFixed(1) + 'ms';
                document.getElementById('memory-usage').textContent = sys.memory_usage_mb.toFixed(1) + 'MB';
                
                // Update details
                document.getElementById('health-details').textContent = JSON.stringify(health.health.summary, null, 2);
                document.getElementById('perf-details').textContent = JSON.stringify(perf.summary, null, 2);
            }
            
            async function generateReport() {
                try {
                    const response = await fetch('/api/performance/report');
                    const data = await response.json();
                    alert('Report generated: ' + data.report_path);
                } catch (error) {
                    alert('Failed to generate report: ' + error.message);
                }
            }
            
            // Auto-refresh every 5 seconds
            setInterval(loadData, 5000);
            
            // Load initial data
            window.onload = loadData;
        </script>
    </head>
    <body>
        <h1>🚀 GattoNero Development Dashboard</h1>
        
        <div class="card">
            <h2>📊 System Status</h2>
            <div class="metric">
                <div class="metric-value" id="health-status">LOADING</div>
                <div class="metric-label">Health Status</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="total-ops">-</div>
                <div class="metric-label">Total Operations</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="active-ops">-</div>
                <div class="metric-label">Active Operations</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="avg-duration">-</div>
                <div class="metric-label">Avg Duration</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="memory-usage">-</div>
                <div class="metric-label">Memory Usage</div>
            </div>
        </div>
        
        <div class="card">
            <h2>🔧 Actions</h2>
            <button onclick="loadData()">Refresh Data</button>
            <button onclick="generateReport()">Generate Performance Report</button>
            <button onclick="window.open('/api/health', '_blank')">View Health Details</button>
            <button onclick="window.open('/api/performance/dashboard', '_blank')">View Performance Data</button>
        </div>
        
        <div class="card">
            <h2>❤️ Health Details</h2>
            <pre id="health-details">Loading...</pre>
        </div>
        
        <div class="card">
            <h2>⚡ Performance Details</h2>
            <pre id="perf-details">Loading...</pre>
        </div>
        
        <div class="card">
            <h2>📚 Quick Links</h2>
            <ul>
                <li><a href="/api/health">Health Status API</a></li>
                <li><a href="/api/performance/dashboard">Performance Dashboard API</a></li>
                <li><a href="/api/system/info">System Information</a></li>
                <li><a href="/api/performance/stats">Performance Statistics</a></li>
            </ul>
        </div>
    </body>
    </html>
    """

def initialize_server():
    """Initialize the enhanced server with monitoring."""
    logger.info("Initializing Enhanced Flask Server")
    
    # Initial health check
    health_results = health_monitor.run_all_checks()
    critical_issues = [name for name, result in health_results.items() 
                      if result.status.value == "critical"]
    
    if critical_issues:
        logger.warning(f"Critical health issues detected: {critical_issues}")
        for issue in critical_issues:
            logger.error(f"Critical: {health_results[issue].message}")
    else:
        logger.success("All health checks passed")
    
    logger.info("Enhanced Flask Server initialized successfully")

def shutdown_server():
    """Graceful server shutdown."""
    logger.info("Shutting down Enhanced Flask Server")
    
    # Generate final performance report
    try:
        report_path = profiler.generate_html_report("final_session_report.html")
        logger.success(f"Final performance report generated: {report_path}")
    except Exception as e:
        logger.error(f"Failed to generate final report: {str(e)}")
    
    logger.info("Enhanced Flask Server shutdown complete")

# Initialize on module load
initialize_server()

if __name__ == "__main__":
    try:
        logger.info("Starting Enhanced Flask Server in development mode")
        app.run(debug=True, host='0.0.0.0', port=5000, threaded=True)
    except KeyboardInterrupt:
        logger.info("Server interrupted by user")
    finally:
        shutdown_server()

``````

#### __init__.py - ./app/webview/__init__.py

``````
"""WebView Package

Web interface for testing and debugging algorithms before JSX integration.

This package provides:
- Web-based algorithm testing interface
- File upload and parameter configuration
- Live result preview and debugging
- Export functionality for results

Modules:
- routes: Flask routes and API endpoints
- utils: Helper functions and utilities
- tests: Test suite for WebView functionality

Usage:
    from app.webview import webview_bp
    app.register_blueprint(webview_bp)

Version: 1.0.0
Author: GattoNero Development Team
Status: Development - Phase 1 (Basic Functionality)
"""

from .routes import webview_bp

__version__ = '1.0.0'
__author__ = 'GattoNero Development Team'
__status__ = 'Development'

# Export the blueprint for easy import
__all__ = ['webview_bp']
``````

#### routes.py - ./app/webview/routes.py

``````
"""WebView Routes

Flask routes for the WebView interface.
Provides web-based testing and debugging for algorithms.
"""

import os
import json
from datetime import datetime
from flask import (
    Blueprint,
    render_template,
    request,
    jsonify,
    current_app,
    send_from_directory,
)
from werkzeug.utils import secure_filename
from werkzeug.exceptions import RequestEntityTooLarge

# --- UWAGA: Upewniamy się, że używamy prawdziwego algorytmu ---
# Zakładamy, że reszta aplikacji jest poprawnie skonfigurowana.
try:
    from ..algorithms.algorithm_01_palette.algorithm import PaletteMappingAlgorithm
except ImportError as e:
    # W przypadku błędu importu, rzucamy wyjątek, aby wyraźnie pokazać problem
    raise ImportError(
        f"CRITICAL: Failed to import PaletteMappingAlgorithm. Ensure the module exists and is correct. Error: {e}"
    )

# Create Blueprint
webview_bp = Blueprint(
    "webview",
    __name__,
    template_folder="templates",
    static_folder="static",
    url_prefix="/webview",
)

# --- KONFIGURACJA ---
MAX_FILE_SIZE = 100 * 1024 * 1024  # Zwiększony limit do 100MB
ALLOWED_EXTENSIONS = {"png", "jpg", "jpeg", "tif", "tiff"}  # Dodano TIF/TIFF
RESULTS_FOLDER = os.path.join(os.path.dirname(__file__), "static", "results")
UPLOADS_FOLDER = os.path.join(os.path.dirname(__file__), "temp_uploads")


# --- FUNKCJE POMOCNICZE ---


def allowed_file(filename):
    """Sprawdza, czy rozszerzenie pliku jest dozwolone."""
    return "." in filename and filename.rsplit(".", 1)[1].lower() in ALLOWED_EXTENSIONS


def ensure_folders():
    """Upewnia się, że foldery na upload i wyniki istnieją."""
    os.makedirs(UPLOADS_FOLDER, exist_ok=True)
    os.makedirs(RESULTS_FOLDER, exist_ok=True)


def log_activity(action, details=None, level="info"):
    """Prosta funkcja do logowania aktywności WebView."""
    timestamp = datetime.now().isoformat()
    log_message = f"WebView: {action} - {json.dumps(details) if details else ''}"
    if hasattr(current_app, "logger"):
        if level == "error":
            current_app.logger.error(log_message)
        else:
            current_app.logger.info(log_message)
    else:
        print(f"[{level.upper()}] {log_message}")


def rgb_to_hsl(r, g, b):
    """Konwertuje kolor z RGB na HSL, potrzebne dla starego panelu."""
    r, g, b = r / 255.0, g / 255.0, b / 255.0
    max_val, min_val = max(r, g, b), min(r, g, b)
    h, s, l = 0, 0, (max_val + min_val) / 2
    if max_val != min_val:
        d = max_val - min_val
        s = d / (2 - max_val - min_val) if l > 0.5 else d / (max_val + min_val)
        if max_val == r:
            h = (g - b) / d + (6 if g < b else 0)
        elif max_val == g:
            h = (b - r) / d + 2
        else:
            h = (r - g) / d + 4
        h /= 6
    return [round(h * 360), round(s * 100), round(l * 100)]


# --- GŁÓWNE TRASY I ENDPOINTY ---


@webview_bp.route("/")
def index():
    """Główna strona WebView."""
    log_activity("page_view", {"page": "index", "template_vars": {"now": datetime.now().year}})
    return render_template("index.html", now=datetime.now())


@webview_bp.route("/algorithm_01")
def algorithm_01():
    """Strona testowania ekstrakcji palety (stary panel)."""
    log_activity("page_view", {"page": "algorithm_01_extraction"})
    return render_template("algorithm_01.html")


@webview_bp.route("/algorithm_01/transfer")
def algorithm_01_palette_transfer():
    """Strona testowania transferu palety (nowy panel)."""
    log_activity("page_view", {"page": "algorithm_01_palette_transfer"})
    return render_template("algorithm_01_transfer.html")


@webview_bp.route("/results/<filename>")
def get_result_file(filename):
    """Serwuje przetworzony obraz z folderu wyników."""
    return send_from_directory(RESULTS_FOLDER, filename)


# --- API ENDPOINTS ---


@webview_bp.route("/api/process", methods=["POST"])
def process_algorithm():
    """API dla starszego panelu ekstrakcji palety."""
    try:
        if "image_file" not in request.files:
            return jsonify({"success": False, "error": "Nie wybrano pliku"}), 400
        file = request.files["image_file"]
        if file.filename == "" or not allowed_file(file.filename):
            return jsonify({"success": False, "error": "Nieprawidłowy plik"}), 400

        params = {
            "num_colors": int(request.form.get("num_colors", 8)),
            "method": request.form.get("method", "kmeans"),
            "quality": int(request.form.get("quality", 5)),
        }
        log_activity(
            "extraction_request", {"filename": file.filename, "params": params}
        )

        ensure_folders()
        temp_path = os.path.join(UPLOADS_FOLDER, secure_filename(file.filename))
        file.save(temp_path)

        try:
            result = process_palette_extraction(temp_path, params)
            return jsonify({"success": True, "result": result})
        finally:
            if os.path.exists(temp_path):
                os.remove(temp_path)
    except Exception as e:
        log_activity("extraction_error", {"error": str(e)}, "error")
        return (
            jsonify({"success": False, "error": "Błąd serwera przy ekstrakcji palety"}),
            500,
        )


@webview_bp.route("/api/algorithm_01/transfer", methods=["POST"])
def handle_palette_transfer():
    """API dla nowego panelu transferu palety."""
    ensure_folders()
    log_activity("transfer_request_start")
    master_path, target_path = None, None
    try:
        if "master_image" not in request.files or "target_image" not in request.files:
            return (
                jsonify({"success": False, "error": "Brak obrazu master lub target"}),
                400,
            )

        master_file = request.files["master_image"]
        target_file = request.files["target_image"]

        if (
            not master_file.filename
            or not target_file.filename
            or not allowed_file(master_file.filename)
            or not allowed_file(target_file.filename)
        ):
            return jsonify({"success": False, "error": "Nieprawidłowe pliki"}), 400

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        master_filename = f"{timestamp}_master_{secure_filename(master_file.filename)}"
        target_filename = f"{timestamp}_target_{secure_filename(target_file.filename)}"
        master_path = os.path.join(UPLOADS_FOLDER, master_filename)
        target_path = os.path.join(UPLOADS_FOLDER, target_filename)
        master_file.save(master_path)
        target_file.save(target_path)

        params = {
            "num_colors": int(request.form.get("num_colors", 16)),
            "dithering_method": request.form.get("dithering_method", "none"),
            "inject_extremes": request.form.get("inject_extremes") == "on",
            "preserve_extremes": request.form.get("preserve_extremes") == "on",
            "extremes_threshold": int(request.form.get("extremes_threshold", 10)),
            "edge_blur_enabled": request.form.get("edge_blur_enabled") == "on",
            "edge_detection_threshold": float(
                request.form.get("edge_detection_threshold", 25)
            ),
            "edge_blur_radius": float(request.form.get("edge_blur_radius", 1.5)),
            "edge_blur_strength": float(request.form.get("edge_blur_strength", 0.3)),
            "quality": int(request.form.get("quality", 5)),
            "distance_metric": request.form.get("distance_metric", "weighted_rgb"),
        }
        log_activity("parameters_collected", params)

        algorithm = PaletteMappingAlgorithm()
        output_filename = f"result_{target_filename}"
        output_path = os.path.join(RESULTS_FOLDER, output_filename)

        log_activity("processing_start", {"output_path": output_path, "params": params})
        success = algorithm.process_images(
            master_path=master_path,
            target_path=target_path,
            output_path=output_path,
            **params,
        )

        if not success:
            raise RuntimeError("Przetwarzanie algorytmu nie powiodło się.")

        result_url = f"/webview/results/{output_filename}"
        log_activity("transfer_request_success", {"result_url": result_url})
        return jsonify(
            {
                "success": True,
                "result_url": result_url,
                "message": "Obraz przetworzony pomyślnie!",
            }
        )

    except Exception as e:
        log_activity("transfer_error", {"error": str(e)}, "error")
        if hasattr(current_app, "logger"):
            current_app.logger.exception("Błąd podczas transferu palety.")
        return (
            jsonify({"success": False, "error": f"Błąd wewnętrzny serwera: {str(e)}"}),
            500,
        )
    finally:
        # Czyszczenie plików tymczasowych
        if master_path and os.path.exists(master_path):
            os.remove(master_path)
        if target_path and os.path.exists(target_path):
            os.remove(target_path)
        log_activity(
            "temp_files_cleaned",
            {"master_path": master_path, "target_path": target_path},
        )


# --- FUNKCJE WEWNĘTRZNE I OBSŁUGA BŁĘDÓW ---


def process_palette_extraction(image_path, params):
    """Logika dla ekstrakcji palety (dla starego panelu /api/process)."""
    try:
        algorithm = PaletteMappingAlgorithm()
        algorithm.config["quality"] = params.get("quality", 5)
        palette_rgb = algorithm.extract_palette(
            image_path=image_path,
            num_colors=params["num_colors"],
            method=params["method"],
        )

        # --- POPRAWKA: Przywracamy stary format odpowiedzi z HEX i HSL ---
        colors = []
        for r, g, b in palette_rgb:
            hex_color = f"#{r:02x}{g:02x}{b:02x}"
            hsl_color = rgb_to_hsl(r, g, b)
            colors.append(
                {
                    "hex": hex_color,
                    "rgb": [r, g, b],
                    "hsl": hsl_color,
                }
            )

        return {
            "palette": colors,
            "method": params["method"],
            "num_colors": params["num_colors"],
        }
    except Exception as e:
        log_activity("extraction_logic_error", {"error": str(e)}, "error")
        raise


@webview_bp.errorhandler(404)
def not_found(e):
    return render_template("404.html"), 404


@webview_bp.errorhandler(500)
def internal_error(e):
    log_activity("internal_server_error", {"error": str(e), "missing_vars": ["current_time", "webview_version"]}, "error")
    return render_template("500.html", current_time=datetime.now(), webview_version="1.1.0"), 500

``````

#### __init__.py - ./app/webview/utils/__init__.py

``````
"""WebView Utils Package - Narzędzia pomocnicze dla WebView.

Moduły:
    image_processor: Przetwarzanie obrazów dla interfejsu webowego
    parameter_validator: Walidacja parametrów algorytmów
    result_formatter: Formatowanie wyników dla wyświetlenia
    algorithm_detector: Wykrywanie dostępnych algorytmów
"""

__version__ = '1.0.0'
``````

#### run_server.py - ./run_server.py

``````
# GattoNeroPhotoshop/run_server.py

import socket
import subprocess
import time
import sys
from app.server import app

def check_port_free(port):
    """Sprawdza czy port jest wolny"""
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        try:
            s.bind(('127.0.0.1', port))
            return True
        except OSError:
            return False

def kill_process_on_port(port):
    """Zabija proces na danym porcie (Windows)"""
    try:
        # Znajdź PID procesu na porcie
        result = subprocess.run(
            f'netstat -ano | findstr :{port}',
            shell=True,
            capture_output=True,
            text=True
        )

        if result.stdout:
            lines = result.stdout.strip().split('\n')
            for line in lines:
                if 'LISTENING' in line:
                    parts = line.split()
                    if len(parts) >= 5:
                        pid = parts[-1]
                        print(f"Zatrzymuje proces PID {pid} na porcie {port}...")
                        subprocess.run(f'taskkill /F /PID {pid}', shell=True, capture_output=True)
                        return True
        return False
    except Exception as e:
        print(f"Blad podczas zabijania procesu: {e}")
        return False

def safe_start_server():
    """Bezpiecznie uruchamia serwer z kontrola portu"""
    port = 5000

    print("Sprawdzam port 5000...")

    if not check_port_free(port):
        print("Port 5000 jest zajety! Probuje zatrzymac istniejacy proces...")

        if kill_process_on_port(port):
            print("Czekam 2 sekundy na zwolnienie portu...")
            time.sleep(2)

            if check_port_free(port):
                print("Port zwolniony!")
            else:
                print("Nie udalo sie zwolnic portu. Sprawdz recznie procesy.")
                sys.exit(1)
        else:
            print("Nie znaleziono procesu do zatrzymania, ale port jest zajety.")
            print("Sprobuj recznie: netstat -ano | findstr :5000")
            sys.exit(1)
    else:
        print("Port 5000 jest wolny!")

    print("Uruchamiam serwer Flask...")
    print("Serwer bedzie dostepny na: http://127.0.0.1:5000")
    print("Aby zatrzymac serwer, nacisnij Ctrl+C")
    print("-" * 50)

    # Uruchamiamy serwer Flask (debug=False zeby uniknac konfliktow z kontrola portu)
    app.run(host='127.0.0.1', port=port, debug=False)

if __name__ == '__main__':
    safe_start_server()
``````

#### server_config.json - ./server_config.json

``````
{
	"server": {
		"host": "127.0.0.1",
		"port": 5000,
		"environment": "development",
		"python_executable": "venv\\Scripts\\python.exe",
		"startup_command": ["venv\\Scripts\\python.exe", "run_server.py"],
		"startup_timeout": 45,
		"shutdown_timeout": 30,
		"health_check_interval": 5,
		"health_check_url": "/api/health"
	},
	"monitoring": {
		"failure_threshold": 3,
		"restart_delay": 5,
		"exponential_backoff": true,
		"max_backoff_delay": 60
	},
	"logging": {
		"log_dir"          : "logs",
		"server_log_file"  : "gattonero_server.log",
		"server_error_file": "gattonero_server_errors.log",
		"manager_log_file" : "server_manager.log"
	},
	"files": {"pid_file": ".server_info.json"}
}

``````

#### server_manager_enhanced.py - ./server_manager_enhanced.py

``````
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced Server Manager v2.2.0 - Advanced Flask Server Management for GattoNero AI Assistant

Features:
- Unified watchdog system via 'watch' command
- Configuration-driven setup from 'server_config.json'
- Advanced auto-restart with exponential backoff
- Graceful shutdown with '--force' option
- Structured, TTY-aware logging with log file redirection
- Production-ready deployment capabilities
- Intelligent Python environment detection (VENV vs. SYSTEM)

Usage:
    python server_manager_enhanced.py start [--auto-restart] [--port PORT]
    python server_manager_enhanced.py stop [--force]
    python server_manager_enhanced.py status [--detailed]
    python server_manager_enhanced.py restart [--auto-restart]
    python server_manager_enhanced.py watch [--interval SECONDS]
    python server_manager_enhanced.py logs [--tail LINES] [--file server|manager|errors]
"""

import sys
import os
import json
import time
import subprocess
import requests
import argparse
import threading
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Optional, Any, List

# Próba importu psutil, jeśli jest dostępny
try:
    import psutil

    PSUTIL_AVAILABLE = True
except ImportError:
    psutil = None
    PSUTIL_AVAILABLE = False
    print(
        "[WARNING] psutil is not available. Some advanced features will be disabled. Run 'pip install psutil'"
    )


class ServerConfig:
    """Zarządza konfiguracją serwera z pliku JSON z wartościami domyślnymi."""

    def __init__(self, config_file: str = "server_config.json"):
        self.config_file = Path(config_file)
        self._config = self._load_config()

    def _load_config(self) -> Dict[str, Any]:
        """Ładuje konfigurację z pliku, łącząc ją z domyślnymi wartościami."""
        defaults = {
            "server": {
                "host": "127.0.0.1",
                "port": 5000,
                "environment": "development",
                "startup_command": [sys.executable, "run_server.py"],
                "python_executable": "",  # Puste oznacza auto-detekcję
                "startup_timeout": 15,
                "shutdown_timeout": 20,
                "health_check_interval": 5,
                "health_check_url": "/api/health",  # Domyślny endpoint health-check
            },
            "monitoring": {
                "failure_threshold": 3,
                "restart_delay": 5,
                "exponential_backoff": True,
                "max_backoff_delay": 60,
            },
            "logging": {
                "log_dir": "logs",
                "server_log_file": "gattonero_server.log",
                "server_error_file": "gattonero_server_errors.log",
                "manager_log_file": "server_manager.log",
            },
            "files": {"pid_file": ".server_info.json"},
        }

        if self.config_file.exists():
            try:
                with open(self.config_file, "r", encoding="utf-8") as f:
                    user_config = json.load(f)
                return self._deep_merge(defaults, user_config)
            except json.JSONDecodeError as e:
                print(
                    f"[ERROR] Invalid JSON in {self.config_file}: {e}. Using default configuration."
                )
            except Exception as e:
                print(
                    f"[WARNING] Failed to load {self.config_file}: {e}. Using defaults."
                )
        else:
            print(
                f"[INFO] Configuration file '{self.config_file}' not found. Creating with default values."
            )
            try:
                with open(self.config_file, "w", encoding="utf-8") as f:
                    json.dump(defaults, f, indent=4)
            except Exception as e:
                print(f"[ERROR] Could not create default config file: {e}")

        return defaults

    def _deep_merge(
        self, base: Dict[str, Any], overlay: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Rekursywnie łączy dwa słowniki."""
        result = base.copy()
        for key, value in overlay.items():
            if (
                key in result
                and isinstance(result[key], dict)
                and isinstance(value, dict)
            ):
                result[key] = self._deep_merge(result[key], value)
            else:
                result[key] = value
        return result

    def get(self, section: str, key: Optional[str] = None, default=None):
        """Pobiera wartość konfiguracyjną z określonej sekcji."""
        if key is None:
            return self._config.get(section, default)
        return self._config.get(section, {}).get(key, default)

    def get_str(self, section: str, key: str, default: str = "") -> str:
        """Pobiera wartość konfiguracyjną jako string."""
        value = self.get(section, key, default)
        return str(value) if value is not None else default

    def get_int(self, section: str, key: str, default: int = 0) -> int:
        """Pobiera wartość konfiguracyjną jako int."""
        value = self.get(section, key, default)
        try:
            return int(value) if value is not None else default
        except (ValueError, TypeError):
            return default

    def get_list(self, section: str, key: str, default: Optional[List] = None) -> List:
        """Pobiera wartość konfiguracyjną jako listę."""
        if default is None:
            default = []
        value = self.get(section, key, default)
        return list(value) if isinstance(value, list) else default

    def get_bool(self, section: str, key: str, default: bool = False) -> bool:
        """Pobiera wartość konfiguracyjną jako boolean."""
        value = self.get(section, key, default)
        if isinstance(value, bool):
            return value
        if isinstance(value, str):
            return value.lower() in ("true", "1", "yes", "on")
        return bool(value) if value is not None else default

    def get_health_check_url(self) -> str:
        """Zwraca endpoint health-check z konfiguracji."""
        return self.get_str("server", "health_check_url", "/api/health")


class EnhancedServerManager:
    """Zarządza cyklem życia serwera z monitoringiem, logowaniem i konfiguracją."""

    def __init__(
        self,
        host: Optional[str] = None,
        port: Optional[int] = None,
        environment: Optional[str] = None,
        config_file: str = "server_config.json",
    ):
        self.config = ServerConfig(config_file)

        self.host = host or self.config.get_str("server", "host", "127.0.0.1")
        self.port = port or self.config.get_int("server", "port", 5000)
        self.environment = environment or self.config.get_str(
            "server", "environment", "development"
        )
        self.base_url = f"http://{self.host}:{self.port}"
        self.health_check_url = self.config.get_health_check_url()

        self.log_dir = Path(self.config.get_str("logging", "log_dir", "logs"))
        self.log_dir.mkdir(exist_ok=True)
        self.pid_file = Path(
            self.config.get_str("files", "pid_file", ".server_info.json")
        )
        self.server_log_file = self.log_dir / self.config.get_str(
            "logging", "server_log_file", "gattonero_server.log"
        )
        self.server_error_file = self.log_dir / self.config.get_str(
            "logging", "server_error_file", "gattonero_server_errors.log"
        )
        self.manager_log_file = self.log_dir / self.config.get_str(
            "logging", "manager_log_file", "server_manager.log"
        )

        self.python_executable = self._detect_python_executable()

        default_startup_command = [self.python_executable, "-m", "app.server"]
        self.startup_command = self.config.get_list(
            "server", "startup_command", default_startup_command
        )
        if self.startup_command == [sys.executable, "-m", "app.server"]:
            self.startup_command = default_startup_command

        self.startup_timeout = self.config.get_int("server", "startup_timeout", 15)
        self.shutdown_timeout = self.config.get_int("server", "shutdown_timeout", 20)
        self.health_check_interval = self.config.get_int(
            "server", "health_check_interval", 5
        )
        self.failure_threshold = self.config.get_int(
            "monitoring", "failure_threshold", 3
        )
        self.restart_delay = self.config.get_int("monitoring", "restart_delay", 5)

        self.monitor_thread: Optional[threading.Thread] = None
        self.monitor_running = threading.Event()

    def _detect_python_executable(self) -> str:
        """Wykrywa najlepszy interpreter Pythona (venv jeśli dostępny)."""
        config_python = self.config.get_str("server", "python_executable", "")
        if config_python and Path(config_python).exists():
            self.log_event(
                f"Using configured Python executable: {config_python}", "INFO"
            )
            return config_python

        venv_paths = [Path("venv"), Path(".venv"), Path("env"), Path(".env")]
        for venv_path in venv_paths:
            if venv_path.exists() and venv_path.is_dir():
                python_exe = (
                    venv_path / "Scripts" / "python.exe"
                    if os.name == "nt"
                    else venv_path / "bin" / "python"
                )
                if python_exe.exists():
                    self.log_event(
                        f"Virtual environment detected: {venv_path}", "SUCCESS"
                    )
                    self.log_event(f"Using venv Python: {python_exe}", "INFO")
                    return str(python_exe)

        if hasattr(sys, "real_prefix") or (
            hasattr(sys, "base_prefix") and sys.base_prefix != sys.prefix
        ):
            self.log_event(
                "Already running in an activated virtual environment", "SUCCESS"
            )
            return sys.executable

        self.log_event(
            "No virtual environment detected, using system Python", "WARNING"
        )
        self.log_event("Consider creating a venv: python -m venv venv", "INFO")
        return sys.executable

    def _check_flask_install(self) -> bool:
        """Sprawdza, czy Flask jest zainstalowany w wybranym środowisku."""
        self.log_event(f"Checking for Flask in: {self.python_executable}", "INFO")
        try:
            command = [self.python_executable, "-c", "import flask"]
            result = subprocess.run(command, capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                self.log_event("Flask is installed.", "SUCCESS")
                return True
            else:
                self.log_event(
                    "Flask is NOT installed in the selected environment.", "ERROR"
                )
                self.log_event(
                    f"To install, run: '{self.python_executable} -m pip install flask'",
                    "INFO",
                )
                return False
        except Exception as e:
            self.log_event(f"Could not check for Flask installation: {e}", "ERROR")
            return False

    def _verify_environment(self) -> bool:
        """Weryfikuje, czy środowisko Python jest poprawnie skonfigurowane."""
        python_path = Path(self.python_executable)
        if not python_path.exists():
            self.log_event(
                f"Python executable not found: {self.python_executable}", "ERROR"
            )
            return False

        try:
            result = subprocess.run(
                [self.python_executable, "--version"],
                capture_output=True,
                text=True,
                timeout=5,
            )
            if result.returncode == 0:
                self.log_event(f"Python version: {result.stdout.strip()}", "INFO")
        except Exception as e:
            self.log_event(f"Could not get Python version: {e}", "WARNING")

        return self._check_flask_install()

    def log_event(self, event: str, level: str = "INFO"):
        """Loguje zdarzenie do konsoli (z kolorami) i do pliku."""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = {"timestamp": timestamp, "level": level, "event": event}

        log_message = f"[{timestamp}] [{level}] {event}"

        if sys.stdout.isatty():
            colors = {
                "INFO": "\033[94m",
                "SUCCESS": "\033[92m",
                "WARNING": "\033[93m",
                "ERROR": "\033[91m",
                "RESET": "\033[0m",
            }
            color = colors.get(level, "")
            reset = colors["RESET"]
            print(f"{color}{log_message}{reset}")
        else:
            print(log_message)

        try:
            with open(self.manager_log_file, "a", encoding="utf-8") as f:
                f.write(f"{json.dumps(log_entry)}\n")
        except Exception as e:
            print(f"[ERROR] Could not write to manager log file: {e}")

    def save_server_info(self, process_info: Dict[str, Any]):
        """Zapisuje informacje o procesie serwera do pliku."""
        try:
            with open(self.pid_file, "w") as f:
                json.dump(process_info, f, indent=4)
        except Exception as e:
            self.log_event(f"Failed to save server info: {e}", "ERROR")

    def load_server_info(self) -> Optional[Dict[str, Any]]:
        """Wczytuje informacje o procesie serwera z pliku."""
        if not self.pid_file.exists():
            return None
        try:
            with open(self.pid_file, "r") as f:
                return json.load(f)
        except (json.JSONDecodeError, FileNotFoundError):
            return None

    def clear_server_info(self):
        """Usuwa plik z informacjami o serwerze."""
        try:
            self.pid_file.unlink(missing_ok=True)
        except Exception:
            pass

    def is_process_running(self, pid: int) -> bool:
        """Sprawdza, czy proces o danym PID działa."""
        if not PSUTIL_AVAILABLE or psutil is None:
            return False
        try:
            return psutil.pid_exists(pid)
        except Exception:
            return False

    def is_port_in_use(self, port: int) -> bool:
        """Sprawdza, czy port jest w użyciu."""
        if not PSUTIL_AVAILABLE or psutil is None:
            return False
        try:
            for conn in psutil.net_connections():
                if conn.laddr and conn.laddr.port == port and conn.status == "LISTEN":
                    return True
        except Exception:
            pass
        return False

    def is_server_responding(self) -> bool:
        """Sprawdza, czy serwer odpowiada na żądania HTTP."""
        try:
            url = f"{self.base_url}{self.health_check_url}"
            response = requests.get(url, timeout=2)
            return response.status_code == 200
        except requests.RequestException:
            return False

    def get_process_info(self, pid: int) -> Dict[str, Any]:
        """Pobiera szczegółowe informacje o procesie."""
        if not PSUTIL_AVAILABLE or psutil is None or not self.is_process_running(pid):
            return {"status": "not_found"}
        try:
            process = psutil.Process(pid)
            with process.oneshot():
                return {
                    "pid": pid,
                    "status": process.status(),
                    "cpu_percent": process.cpu_percent(interval=0.1),
                    "memory_mb": round(process.memory_info().rss / 1024**2, 2),
                    "uptime_seconds": time.time() - process.create_time(),
                }
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            return {"status": "error"}

    def is_running(self) -> bool:
        """Sprawdza, czy serwer działa i odpowiada."""
        info = self.load_server_info()
        if not info:
            return False
        pid = info.get("pid")
        if not pid:
            return False
        return self.is_process_running(pid) and self.is_server_responding()

    def start_server(self, auto_restart: bool = False, no_wait: bool = False) -> bool:
        """Uruchamia proces serwera i opcjonalnie watchdog."""
        if self.is_running():
            self.log_event("Server is already running.", "WARNING")
            return True

        if not self._verify_environment():
            self.log_event(
                "Python environment verification failed. Cannot start server.", "ERROR"
            )
            return False

        if self.is_port_in_use(self.port):
            self.log_event(
                f"Port {self.port} is already in use. Cannot start server.", "ERROR"
            )
            return False

        self.log_event(f"Starting server... Command: {' '.join(self.startup_command)}")
        env = os.environ.copy()
        env["FLASK_ENV"] = self.environment

        # --- FIX: Define OS-specific arguments to detach the process ---
        kwargs = {}
        if os.name == "nt":
            # On Windows, DETACHED_PROCESS creates a new process
            # without a console and independent of the parent.
            kwargs["creationflags"] = subprocess.DETACHED_PROCESS
        else:
            # On Unix, os.setsid makes the process a session leader,
            # detaching it from the controlling terminal.
            kwargs["preexec_fn"] = os.setsid  # pylint: disable=no-member
        # --- END FIX ---

        try:
            with open(self.server_log_file, "ab") as log_out, open(
                self.server_error_file, "ab"
            ) as log_err:
                # Add the kwargs to the Popen call
                process = subprocess.Popen(
                    self.startup_command,
                    stdout=log_out,
                    stderr=log_err,
                    env=env,
                    **kwargs,
                )

            self.save_server_info(
                {"pid": process.pid, "port": self.port, "started_at": time.time()}
            )

            if no_wait:
                self.log_event(
                    "Server starting in background. Check status or logs to confirm.",
                    "INFO",
                )
                # A brief pause to allow the process to initialize or fail.
                time.sleep(1.5)
                # Quick check if process died instantly
                if not self.is_process_running(process.pid):
                    self.log_event(
                        "Server process terminated immediately after start. Check error logs.",
                        "ERROR",
                    )
                    self.log_event(
                        f"Review logs: python server_manager_enhanced.py logs --file errors",
                        "INFO",
                    )
                    self.clear_server_info()  # Clear info if process died
                    return False
                if auto_restart:
                    self.start_watchdog()
                return True

            self.log_event(f"Waiting for server to respond (PID: {process.pid})...")
            for _ in range(self.startup_timeout):
                if self.is_server_responding():
                    self.log_event("Server started successfully.", "SUCCESS")
                    if auto_restart:
                        self.start_watchdog()
                    return True
                time.sleep(1)

            self.log_event("Server failed to start within timeout.", "ERROR")
            # Attempt to stop the failed process before returning
            current_pid_info = self.load_server_info()
            if current_pid_info and current_pid_info.get("pid") == process.pid:
                self.stop_server(force=True)  # This will also clear_server_info
            else:  # If PID info was overwritten or process never registered properly
                try:
                    if PSUTIL_AVAILABLE and psutil and psutil.pid_exists(process.pid):
                        psutil.Process(process.pid).kill()
                except Exception:  # psutil.NoSuchProcess or other errors
                    pass  # Process might already be gone
                self.clear_server_info()  # Ensure info is cleared if stop_server wasn't effective for this PID
            return False
        except Exception as e:
            self.log_event(f"Failed to start server: {e}", "ERROR")
            # Ensure server info is cleared on any exception during startup
            self.clear_server_info()
            return False

    def stop_server(self, force: bool = False) -> bool:
        """Zatrzymuje serwer, z opcją wymuszenia."""
        self.stop_watchdog()
        info = self.load_server_info()
        if not info or not self.is_process_running(info.get("pid", -1)):
            self.log_event("Server is not running.", "INFO")
            self.clear_server_info()
            return True

        pid = info["pid"]
        self.log_event(f"Stopping server (PID: {pid})...")

        if not force and PSUTIL_AVAILABLE and psutil:
            try:
                proc = psutil.Process(pid)
                # Na Windows SIGTERM to to samo co terminate()
                proc.terminate()
                self.log_event(
                    "Sent termination signal. Waiting for process to exit.", "INFO"
                )
                proc.wait(timeout=self.shutdown_timeout)
                self.log_event("Server shut down gracefully.", "SUCCESS")
                self.clear_server_info()
                return True
            except psutil.TimeoutExpired:
                self.log_event(
                    "Graceful shutdown timed out. Forcing termination.", "WARNING"
                )
            except psutil.NoSuchProcess:
                self.log_event("Process already stopped.", "SUCCESS")
                self.clear_server_info()
                return True
            except Exception as e:
                self.log_event(
                    f"Error during graceful shutdown: {e}. Forcing termination.",
                    "WARNING",
                )

        # Force termination
        if PSUTIL_AVAILABLE and psutil:
            try:
                proc = psutil.Process(pid)
                proc.kill()
                proc.wait(timeout=5)
            except psutil.NoSuchProcess:
                pass  # Already gone
            except Exception as e:
                self.log_event(f"Error during force kill: {e}", "ERROR")
        else:  # Fallback dla systemów bez psutil
            try:
                os.kill(pid, 9)  # SIGKILL
            except ProcessLookupError:
                pass  # Already gone
            except Exception as e:
                self.log_event(f"Error during fallback kill: {e}", "ERROR")

        time.sleep(1)  # Give OS a moment to update process table
        if not self.is_process_running(pid):
            self.log_event("Server stopped forcefully.", "SUCCESS")
            self.clear_server_info()
            return True
        else:
            self.log_event("Failed to stop the server.", "ERROR")
            return False

    def restart_server(self, auto_restart: bool = False) -> bool:
        """Restartuje serwer."""
        self.log_event("Restarting server...")
        if self.stop_server():
            time.sleep(2)  # Czas na zwolnienie portu
            return self.start_server(auto_restart)
        self.log_event("Failed to stop the server, restart aborted.", "ERROR")
        return False

    def run_tests(self) -> bool:
        """Uruchom testy podstawowe."""
        if not self.is_running():
            self.log_event("Server not running. Cannot run tests.", "ERROR")
            return False

        self.log_event("Running tests...", "INFO")
        try:
            result = subprocess.run(
                [sys.executable, "test_algorithm_integration.py"],
                capture_output=True,
                text=True,
                cwd=os.getcwd(),
            )

            # Log the output
            if result.stdout:
                for line in result.stdout.strip().split("\n"):
                    print(line)

            if result.stderr:
                self.log_event("STDERR output:", "WARNING")
                for line in result.stderr.strip().split("\n"):
                    self.log_event(line, "WARNING")

            if result.returncode == 0:
                self.log_event("Tests completed successfully.", "SUCCESS")
                return True
            else:
                self.log_event(
                    f"Tests failed with return code: {result.returncode}", "ERROR"
                )
                return False

        except Exception as e:
            self.log_event(f"Failed to run tests: {e}", "ERROR")
            return False

    def show_status(self, detailed: bool = False):
        """Wyświetla aktualny status serwera."""
        print("─" * 40)
        print("🖥️  Server Status")
        print("─" * 40)
        info = self.load_server_info()

        if not info or not self.is_process_running(info.get("pid", -1)):
            self.log_event("Server is NOT RUNNING.", "WARNING")
            self.clear_server_info()
            return

        pid = info["pid"]
        is_responding = self.is_server_responding()
        status_color = "SUCCESS" if is_responding else "ERROR"

        self.log_event(f"Server process is RUNNING (PID: {pid}).", "SUCCESS")
        self.log_event(
            f"Server HTTP endpoint is {'RESPONDING' if is_responding else 'NOT RESPONDING'}.",
            status_color,
        )

        if detailed and PSUTIL_AVAILABLE and psutil:
            proc_info = self.get_process_info(pid)
            if proc_info.get("status") != "not_found":
                uptime = timedelta(seconds=int(proc_info.get("uptime_seconds", 0)))
                print(f"  PID          : {proc_info.get('pid')}")
                print(f"  Uptime       : {uptime}")
                print(f"  Memory       : {proc_info.get('memory_mb', 'N/A')} MB")
                print(f"  CPU          : {proc_info.get('cpu_percent', 'N/A')} %")
        print("─" * 40)

    def start_watchdog(self):
        """Uruchamia wątek watchdog do monitorowania serwera."""
        if self.monitor_running.is_set():
            self.log_event("Watchdog is already running.", "INFO")
            return
        self.log_event("Starting watchdog monitor...", "INFO")
        self.monitor_running.set()
        self.monitor_thread = threading.Thread(target=self._watchdog_loop, daemon=True)
        self.monitor_thread.start()

    def stop_watchdog(self):
        """Zatrzymuje wątek watchdog."""
        if self.monitor_running.is_set():
            self.log_event("Stopping watchdog monitor...", "INFO")
            self.monitor_running.clear()
            if self.monitor_thread and self.monitor_thread.is_alive():
                self.monitor_thread.join(timeout=3)

    def _watchdog_loop(self):
        """Główna pętla wątku watchdog."""
        failures = 0
        while self.monitor_running.is_set():
            if not self.is_server_responding():
                failures += 1
                self.log_event(
                    f"Watchdog: Server health check failed ({failures}/{self.failure_threshold}).",
                    "WARNING",
                )
                if failures >= self.failure_threshold:
                    self.log_event(
                        "Watchdog: Failure threshold reached. Attempting to restart server.",
                        "ERROR",
                    )
                    if self.restart_server(auto_restart=True):
                        failures = 0
                    time.sleep(self.restart_delay)
            else:
                if failures > 0:
                    self.log_event("Watchdog: Server has recovered.", "SUCCESS")
                failures = 0

            self.monitor_running.wait(self.health_check_interval)

    def watch_server_foreground(self, interval: int):
        """Uruchamia dashboard monitorujący na pierwszym planie."""
        self.log_event(
            f"Starting foreground watch (interval: {interval}s). Press Ctrl+C to stop.",
            "INFO",
        )
        try:
            while True:
                if sys.stdout.isatty():
                    os.system("cls" if os.name == "nt" else "clear")
                self.show_status(detailed=True)
                time.sleep(interval)
        except KeyboardInterrupt:
            print()
            self.log_event("Foreground watch stopped by user.", "INFO")

    def show_logs(self, tail_lines: int, log_type: str):
        """Pokazuje ostatnie N linii określonego pliku logów."""
        log_files = {
            "manager": self.manager_log_file,
            "server": self.server_log_file,
            "errors": self.server_error_file,
        }
        log_file = log_files.get(log_type, self.manager_log_file)

        print(f"📋 Displaying last {tail_lines} lines of '{log_file.name}'")
        print("─" * 40)

        if not log_file.exists():
            self.log_event(f"Log file not found: {log_file}", "WARNING")
            return
        try:
            with open(log_file, "r", encoding="utf-8", errors="ignore") as f:
                lines = f.readlines()
            for line in lines[-tail_lines:]:
                print(line.strip())
        except Exception as e:
            self.log_event(f"Error reading log file: {e}", "ERROR")


def create_parser() -> argparse.ArgumentParser:
    """Tworzy parser argumentów linii poleceń."""
    help_epilog = """
-------------------------------------------------
 GattoNero AI - Przewodnik Szybkiego Startu
-------------------------------------------------
1. Uruchom serwer w tle:
   python server_manager_enhanced.py start

2. Sprawdź, czy działa:
   python server_manager_enhanced.py status
   
3. Uruchom testy lub pracuj z API/Photoshopem:
   python test_basic.py
   
4. Zatrzymaj serwer po pracy:
   python server_manager_enhanced.py stop
-------------------------------------------------
Użyj `[komenda] --help` aby zobaczyć opcje dla konkretnej komendy.
"""

    parser = argparse.ArgumentParser(
        description=__doc__,
        formatter_class=argparse.RawTextHelpFormatter,
        epilog=help_epilog,
    )
    subparsers = parser.add_subparsers(dest="command", help="Dostępne komendy")
    subparsers.required = False
    subparsers.default = "help"

    help_parser = subparsers.add_parser("help", help="Wyświetla tę wiadomość pomocy.")

    start = subparsers.add_parser("start", help="Uruchamia serwer w tle.")
    start.add_argument(
        "--auto-restart",
        action="store_true",
        help="Włącza watchdog do auto-restartu przy awarii.",
    )
    start.add_argument("--port", type=int, help="Nadpisuje port serwera z configa.")
    start.add_argument(
        "--no-wait",
        action="store_true",
        help="Nie czeka na health-check, zwraca od razu.",
    )

    stop = subparsers.add_parser("stop", help="Zatrzymuje serwer.")
    stop.add_argument(
        "--force", action="store_true", help="Wymusza natychmiastowe zatrzymanie."
    )

    restart = subparsers.add_parser("restart", help="Restartuje serwer.")
    restart.add_argument(
        "--auto-restart", action="store_true", help="Włącza watchdog po restarcie."
    )

    status = subparsers.add_parser("status", help="Pokazuje status serwera.")
    status.add_argument(
        "--detailed",
        action="store_true",
        help="Pokazuje szczegółowe informacje o procesie.",
    )

    watch = subparsers.add_parser("watch", help="Monitoruje serwer na żywo.")
    watch.add_argument(
        "--interval", type=int, default=5, help="Interwał sprawdzania w sekundach."
    )

    logs = subparsers.add_parser("logs", help="Wyświetla ostatnie logi.")
    logs.add_argument(
        "--tail", type=int, default=20, help="Liczba linii do wyświetlenia."
    )
    logs.add_argument(
        "--file",
        choices=["manager", "server", "errors"],
        default="server",
        help="Który plik logu pokazać.",
    )

    return parser


def main():
    """Główna funkcja wykonawcza."""
    parser = create_parser()
    args = parser.parse_args()

    # Jeśli komenda to 'help' lub nie podano żadnej, wyświetl pomoc i wyjdź
    if args.command == "help":
        parser.print_help()
        sys.exit(0)

    manager = EnhancedServerManager(port=getattr(args, "port", None))

    try:
        if args.command == "start":
            sys.exit(
                0
                if manager.start_server(
                    auto_restart=args.auto_restart,
                    no_wait=getattr(args, "no_wait", False),
                )
                else 1
            )
        elif args.command == "stop":
            sys.exit(0 if manager.stop_server(force=args.force) else 1)
        elif args.command == "restart":
            sys.exit(0 if manager.restart_server(auto_restart=args.auto_restart) else 1)
        elif args.command == "status":
            manager.show_status(detailed=args.detailed)
        elif args.command == "watch":
            manager.watch_server_foreground(args.interval)
        elif args.command == "logs":
            manager.show_logs(args.tail, args.file)
        else:
            parser.print_help()
    except KeyboardInterrupt:
        print()
        manager.log_event("Operation interrupted by user.", "INFO")
        manager.stop_watchdog()
        sys.exit(1)
    except Exception as e:
        manager.log_event(f"An unexpected error occurred: {e}", "ERROR")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

``````

#### server_manager_enhanced_fixed.py - ./server_manager_enhanced_fixed.py

``````

``````

---

## Grupa 2: Webview

*Wszystkie pliki Python w workspace*

### Lista plików (2)

- main.css (\app\webview\static\css)
- main.js (\app\webview\static\js)

### Zawartość plików

#### main.css - ./app/webview/static/css/main.css

``````
/* WebView Main Styles */
/* Główne style dla interfejsu WebView */

:root {
    /* Kolory zgodne z motywem GattoNero */
    --primary-color: #2c3e50;
    --secondary-color: #3498db;
    --success-color: #27ae60;
    --warning-color: #f39c12;
    --error-color: #e74c3c;
    --background-color: #ecf0f1;
    --text-color: #2c3e50;
    --border-color: #bdc3c7;
    --shadow-color: rgba(0, 0, 0, 0.1);
    
    /* Spacing */
    --spacing-xs: 0.25rem;
    --spacing-sm: 0.5rem;
    --spacing-md: 1rem;
    --spacing-lg: 1.5rem;
    --spacing-xl: 2rem;
    
    /* Border radius */
    --border-radius: 0.375rem;
    --border-radius-lg: 0.5rem;
}

/* Reset i podstawy */
* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
    line-height: 1.6;
    color: var(--text-color);
    background-color: var(--background-color);
}

/* Layout główny */
.container {
    max-width: 1200px;
    margin: 0 auto;
    padding: var(--spacing-md);
}

.header {
    background: white;
    border-bottom: 1px solid var(--border-color);
    padding: var(--spacing-md) 0;
    margin-bottom: var(--spacing-xl);
    box-shadow: 0 2px 4px var(--shadow-color);
}

.header h1 {
    color: var(--primary-color);
    font-size: 1.875rem;
    font-weight: 600;
}

.nav {
    margin-top: var(--spacing-md);
}

.nav a {
    color: var(--secondary-color);
    text-decoration: none;
    margin-right: var(--spacing-lg);
    font-weight: 500;
    transition: color 0.2s;
}

.nav a:hover {
    color: var(--primary-color);
}

.nav a.active {
    color: var(--primary-color);
    border-bottom: 2px solid var(--secondary-color);
    padding-bottom: var(--spacing-xs);
}

/* Karty i panele */
.card {
    background: white;
    border-radius: var(--border-radius-lg);
    padding: var(--spacing-lg);
    margin-bottom: var(--spacing-lg);
    box-shadow: 0 2px 8px var(--shadow-color);
    border: 1px solid var(--border-color);
}

.card-header {
    border-bottom: 1px solid var(--border-color);
    padding-bottom: var(--spacing-md);
    margin-bottom: var(--spacing-lg);
}

.card-title {
    font-size: 1.25rem;
    font-weight: 600;
    color: var(--primary-color);
}

/* Formularze */
.form-group {
    margin-bottom: var(--spacing-lg);
}

.form-label {
    display: block;
    margin-bottom: var(--spacing-sm);
    font-weight: 500;
    color: var(--text-color);
}

.form-input {
    width: 100%;
    padding: var(--spacing-sm) var(--spacing-md);
    border: 1px solid var(--border-color);
    border-radius: var(--border-radius);
    font-size: 1rem;
    transition: border-color 0.2s, box-shadow 0.2s;
}

.form-input:focus {
    outline: none;
    border-color: var(--secondary-color);
    box-shadow: 0 0 0 3px rgba(52, 152, 219, 0.1);
}

.form-select {
    width: 100%;
    padding: var(--spacing-sm) var(--spacing-md);
    border: 1px solid var(--border-color);
    border-radius: var(--border-radius);
    background-color: white;
    font-size: 1rem;
}

/* Przyciski */
.btn {
    display: inline-block;
    padding: var(--spacing-sm) var(--spacing-lg);
    border: none;
    border-radius: var(--border-radius);
    font-size: 1rem;
    font-weight: 500;
    text-decoration: none;
    cursor: pointer;
    transition: all 0.2s;
    text-align: center;
}

.btn-primary {
    background-color: var(--secondary-color);
    color: white;
}

.btn-primary:hover {
    background-color: #2980b9;
    transform: translateY(-1px);
    box-shadow: 0 4px 8px var(--shadow-color);
}

.btn-success {
    background-color: var(--success-color);
    color: white;
}

.btn-success:hover {
    background-color: #229954;
}

.btn-warning {
    background-color: var(--warning-color);
    color: white;
}

.btn-warning:hover {
    background-color: #e67e22;
}

.btn-danger {
    background-color: var(--error-color);
    color: white;
}

.btn-danger:hover {
    background-color: #c0392b;
}

.btn:disabled {
    opacity: 0.6;
    cursor: not-allowed;
    transform: none;
}

/* Grid layout */
.grid {
    display: grid;
    gap: var(--spacing-lg);
}

.grid-2 {
    grid-template-columns: 1fr 1fr;
}

.grid-3 {
    grid-template-columns: 1fr 1fr 1fr;
}

@media (max-width: 768px) {
    .grid-2,
    .grid-3 {
        grid-template-columns: 1fr;
    }
}

/* Upload area */
.upload-area {
    border: 2px dashed var(--border-color);
    border-radius: var(--border-radius-lg);
    padding: var(--spacing-xl);
    text-align: center;
    transition: border-color 0.2s, background-color 0.2s;
    cursor: pointer;
}

.upload-area:hover {
    border-color: var(--secondary-color);
    background-color: rgba(52, 152, 219, 0.05);
}

.upload-area.dragover {
    border-color: var(--secondary-color);
    background-color: rgba(52, 152, 219, 0.1);
}

/* Image preview */
.image-preview {
    max-width: 100%;
    max-height: 300px;
    border-radius: var(--border-radius);
    box-shadow: 0 2px 8px var(--shadow-color);
}

.image-container {
    text-align: center;
    margin: var(--spacing-lg) 0;
}

/* Status i alerty */
.alert {
    padding: var(--spacing-md);
    border-radius: var(--border-radius);
    margin-bottom: var(--spacing-lg);
    border-left: 4px solid;
}

.alert-info {
    background-color: #d6eaf8;
    border-color: var(--secondary-color);
    color: #1b4f72;
}

.alert-success {
    background-color: #d5f4e6;
    border-color: var(--success-color);
    color: #0e4b2a;
}

.alert-warning {
    background-color: #fdeaa7;
    border-color: var(--warning-color);
    color: #7d4f00;
}

.alert-error {
    background-color: #fadbd8;
    border-color: var(--error-color);
    color: #641e16;
}

/* Loading spinner */
.spinner {
    border: 3px solid #f3f3f3;
    border-top: 3px solid var(--secondary-color);
    border-radius: 50%;
    width: 30px;
    height: 30px;
    animation: spin 1s linear infinite;
    margin: var(--spacing-md) auto;
}

@keyframes spin {
    0% { transform: rotate(0deg); }
    100% { transform: rotate(360deg); }
}

/* Progress bar */
.progress {
    width: 100%;
    height: 8px;
    background-color: #f3f3f3;
    border-radius: var(--border-radius);
    overflow: hidden;
    margin: var(--spacing-md) 0;
}

.progress-bar {
    height: 100%;
    background-color: var(--secondary-color);
    transition: width 0.3s ease;
}

/* Log panel */
.log-panel {
    background-color: #1e1e1e;
    color: #f8f8f2;
    padding: var(--spacing-md);
    border-radius: var(--border-radius);
    font-family: 'Courier New', monospace;
    font-size: 0.875rem;
    max-height: 300px;
    overflow-y: auto;
    white-space: pre-wrap;
}

.log-entry {
    margin-bottom: var(--spacing-xs);
}

.log-debug { color: #6c757d; }
.log-info { color: #17a2b8; }
.log-warning { color: #ffc107; }
.log-error { color: #dc3545; }

/* Utilities */
.text-center { text-align: center; }
.text-left { text-align: left; }
.text-right { text-align: right; }

.mt-0 { margin-top: 0; }
.mt-1 { margin-top: var(--spacing-sm); }
.mt-2 { margin-top: var(--spacing-md); }
.mt-3 { margin-top: var(--spacing-lg); }

.mb-0 { margin-bottom: 0; }
.mb-1 { margin-bottom: var(--spacing-sm); }
.mb-2 { margin-bottom: var(--spacing-md); }
.mb-3 { margin-bottom: var(--spacing-lg); }

.hidden { display: none; }
.visible { display: block; }

/* Responsive */
@media (max-width: 768px) {
    .container {
        padding: var(--spacing-sm);
    }
    
    .header h1 {
        font-size: 1.5rem;
    }
    
    .nav a {
        display: block;
        margin-bottom: var(--spacing-sm);
        margin-right: 0;
    }
    
    .card {
        padding: var(--spacing-md);
    }
}
``````

#### main.js - ./app/webview/static/js/main.js

``````
/**
 * WebView Main JavaScript
 * Główne funkcje dla interfejsu WebView
 */

// Globalne zmienne
window.WebView = {
    config: {
        maxFileSize: 10 * 1024 * 1024, // 10MB
        allowedTypes: ['image/jpeg', 'image/png', 'image/jpg'],
        apiBaseUrl: '/api',
        webviewBaseUrl: '/webview'
    },
    state: {
        currentTask: null,
        uploadedFiles: {},
        lastResults: null
    }
};

// Utility Functions
class WebViewUtils {
    /**
     * Wyświetl komunikat użytkownikowi
     */
    static showMessage(message, type = 'info') {
        const alertDiv = document.createElement('div');
        alertDiv.className = `alert alert-${type}`;
        alertDiv.textContent = message;
        
        // Znajdź kontener na komunikaty lub wstaw na początku main
        const container = document.querySelector('.container');
        container.insertBefore(alertDiv, container.firstChild);
        
        // Usuń komunikat po 5 sekundach
        setTimeout(() => {
            if (alertDiv.parentNode) {
                alertDiv.parentNode.removeChild(alertDiv);
            }
        }, 5000);
    }
    
    /**
     * Walidacja pliku przed uploadem
     */
    static validateFile(file) {
        const errors = [];
        
        // Sprawdź typ pliku
        if (!WebView.config.allowedTypes.includes(file.type)) {
            errors.push(`Nieprawidłowy typ pliku. Dozwolone: ${WebView.config.allowedTypes.join(', ')}`);
        }
        
        // Sprawdź rozmiar
        if (file.size > WebView.config.maxFileSize) {
            const maxSizeMB = WebView.config.maxFileSize / (1024 * 1024);
            errors.push(`Plik zbyt duży. Maksymalny rozmiar: ${maxSizeMB}MB`);
        }
        
        return errors;
    }
    
    /**
     * Konwertuj plik do base64 dla podglądu
     */
    static fileToBase64(file) {
        return new Promise((resolve, reject) => {
            const reader = new FileReader();
            reader.onload = () => resolve(reader.result);
            reader.onerror = reject;
            reader.readAsDataURL(file);
        });
    }
    
    /**
     * Formatuj rozmiar pliku
     */
    static formatFileSize(bytes) {
        if (bytes === 0) return '0 Bytes';
        const k = 1024;
        const sizes = ['Bytes', 'KB', 'MB', 'GB'];
        const i = Math.floor(Math.log(bytes) / Math.log(k));
        return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
    }
    
    /**
     * Debounce function
     */
    static debounce(func, wait) {
        let timeout;
        return function executedFunction(...args) {
            const later = () => {
                clearTimeout(timeout);
                func(...args);
            };
            clearTimeout(timeout);
            timeout = setTimeout(later, wait);
        };
    }
}

// File Upload Handler
class FileUploadHandler {
    constructor(dropZone, fileInput, previewContainer) {
        this.dropZone = dropZone;
        this.fileInput = fileInput;
        this.previewContainer = previewContainer;
        this.setupEventListeners();
    }
    
    setupEventListeners() {
        // Drag and drop events
        this.dropZone.addEventListener('dragover', this.handleDragOver.bind(this));
        this.dropZone.addEventListener('dragleave', this.handleDragLeave.bind(this));
        this.dropZone.addEventListener('drop', this.handleDrop.bind(this));
        
        // Click to upload
        this.dropZone.addEventListener('click', () => {
            this.fileInput.click();
        });
        
        // File input change
        this.fileInput.addEventListener('change', this.handleFileSelect.bind(this));
    }
    
    handleDragOver(e) {
        e.preventDefault();
        this.dropZone.classList.add('dragover');
    }
    
    handleDragLeave(e) {
        e.preventDefault();
        this.dropZone.classList.remove('dragover');
    }
    
    handleDrop(e) {
        e.preventDefault();
        this.dropZone.classList.remove('dragover');
        
        const files = Array.from(e.dataTransfer.files);
        this.processFiles(files);
    }
    
    handleFileSelect(e) {
        const files = Array.from(e.target.files);
        this.processFiles(files);
    }
    
    async processFiles(files) {
        for (const file of files) {
            const errors = WebViewUtils.validateFile(file);
            
            if (errors.length > 0) {
                WebViewUtils.showMessage(errors.join(', '), 'error');
                continue;
            }
            
            try {
                await this.displayPreview(file);
                WebViewUtils.showMessage(`Plik ${file.name} został załadowany`, 'success');
            } catch (error) {
                WebViewUtils.showMessage(`Błąd podczas ładowania pliku: ${error.message}`, 'error');
            }
        }
    }
    
    async displayPreview(file) {
        const base64 = await WebViewUtils.fileToBase64(file);
        
        const previewHtml = `
            <div class="image-container">
                <img src="${base64}" alt="${file.name}" class="image-preview">
                <p><strong>${file.name}</strong> (${WebViewUtils.formatFileSize(file.size)})</p>
            </div>
        `;
        
        this.previewContainer.innerHTML = previewHtml;
        
        // Zapisz plik w stanie globalnym
        const fieldName = this.fileInput.name;
        WebView.state.uploadedFiles[fieldName] = file;
    }
}

// Parameter Manager
class ParameterManager {
    constructor(formElement) {
        this.form = formElement;
        this.setupValidation();
    }
    
    setupValidation() {
        // Walidacja w czasie rzeczywistym
        const inputs = this.form.querySelectorAll('input, select, textarea');
        inputs.forEach(input => {
            input.addEventListener('input', WebViewUtils.debounce(() => {
                this.validateField(input);
            }, 300));
        });
    }
    
    validateField(field) {
        const value = field.value;
        const fieldName = field.name;
        let isValid = true;
        let errorMessage = '';
        
        // Walidacja specyficzna dla typu pola
        switch (field.type) {
            case 'number':
                const min = parseFloat(field.min);
                const max = parseFloat(field.max);
                const numValue = parseFloat(value);
                
                if (isNaN(numValue)) {
                    isValid = false;
                    errorMessage = 'Wartość musi być liczbą';
                } else if (min !== undefined && numValue < min) {
                    isValid = false;
                    errorMessage = `Wartość musi być >= ${min}`;
                } else if (max !== undefined && numValue > max) {
                    isValid = false;
                    errorMessage = `Wartość musi być <= ${max}`;
                }
                break;
                
            case 'text':
                if (field.required && !value.trim()) {
                    isValid = false;
                    errorMessage = 'To pole jest wymagane';
                }
                break;
        }
        
        // Wyświetl błąd walidacji
        this.displayFieldError(field, isValid ? null : errorMessage);
        
        return isValid;
    }
    
    displayFieldError(field, errorMessage) {
        // Usuń poprzedni błąd
        const existingError = field.parentNode.querySelector('.field-error');
        if (existingError) {
            existingError.remove();
        }
        
        // Dodaj nowy błąd jeśli istnieje
        if (errorMessage) {
            const errorDiv = document.createElement('div');
            errorDiv.className = 'field-error';
            errorDiv.style.color = 'var(--error-color)';
            errorDiv.style.fontSize = '0.875rem';
            errorDiv.style.marginTop = '0.25rem';
            errorDiv.textContent = errorMessage;
            
            field.parentNode.appendChild(errorDiv);
            field.style.borderColor = 'var(--error-color)';
        } else {
            field.style.borderColor = 'var(--border-color)';
        }
    }
    
    validateForm() {
        const inputs = this.form.querySelectorAll('input, select, textarea');
        let isValid = true;
        
        inputs.forEach(input => {
            if (!this.validateField(input)) {
                isValid = false;
            }
        });
        
        return isValid;
    }
    
    getFormData() {
        const formData = new FormData(this.form);
        const data = {};
        
        for (let [key, value] of formData.entries()) {
            data[key] = value;
        }
        
        return data;
    }
}

// API Client
class APIClient {
    static async request(endpoint, options = {}) {
        const url = `${WebView.config.apiBaseUrl}${endpoint}`;
        
        const defaultOptions = {
            headers: {
                'Content-Type': 'application/json'
            }
        };
        
        const finalOptions = { ...defaultOptions, ...options };
        
        try {
            const response = await fetch(url, finalOptions);
            
            if (!response.ok) {
                throw new Error(`HTTP ${response.status}: ${response.statusText}`);
            }
            
            const contentType = response.headers.get('content-type');
            if (contentType && contentType.includes('application/json')) {
                return await response.json();
            } else {
                return await response.text();
            }
        } catch (error) {
            console.error('API Request failed:', error);
            throw error;
        }
    }
    
    static async processAlgorithm(algorithmId, files, parameters) {
        const formData = new FormData();
        
        // Dodaj pliki
        for (const [key, file] of Object.entries(files)) {
            formData.append(key, file);
        }
        
        // Dodaj parametry
        for (const [key, value] of Object.entries(parameters)) {
            formData.append(key, value);
        }
        
        return await this.request(`/process`, {
            method: 'POST',
            headers: {}, // Usuń Content-Type dla FormData
            body: formData
        });
    }
    
    static async getTaskStatus(taskId) {
        return await this.request(`/task/${taskId}`);
    }
}

// Task Monitor
class TaskMonitor {
    constructor(taskId, onUpdate, onComplete, onError) {
        this.taskId = taskId;
        this.onUpdate = onUpdate;
        this.onComplete = onComplete;
        this.onError = onError;
        this.interval = null;
        this.start();
    }
    
    start() {
        this.interval = setInterval(async () => {
            try {
                const status = await APIClient.getTaskStatus(this.taskId);
                
                if (status.status === 'completed') {
                    this.stop();
                    this.onComplete(status.result);
                } else if (status.status === 'failed') {
                    this.stop();
                    this.onError(status.error);
                } else {
                    this.onUpdate(status);
                }
            } catch (error) {
                this.stop();
                this.onError(error.message);
            }
        }, 1000); // Sprawdzaj co sekundę
    }
    
    stop() {
        if (this.interval) {
            clearInterval(this.interval);
            this.interval = null;
        }
    }
}

// Progress Bar
class ProgressBar {
    constructor(element) {
        this.element = element;
        this.bar = element.querySelector('.progress-bar');
    }
    
    setProgress(percentage) {
        this.bar.style.width = `${Math.max(0, Math.min(100, percentage))}%`;
    }
    
    show() {
        this.element.classList.remove('hidden');
    }
    
    hide() {
        this.element.classList.add('hidden');
    }
}

// Initialize when DOM is loaded
document.addEventListener('DOMContentLoaded', function() {
    console.log('WebView JavaScript initialized');
    
    // Initialize file upload handlers
    const uploadZones = document.querySelectorAll('.upload-area');
    uploadZones.forEach(zone => {
        const fileInput = zone.querySelector('input[type="file"]') || 
                         zone.parentNode.querySelector('input[type="file"]');
        const previewContainer = zone.parentNode.querySelector('.preview-container');
        
        if (fileInput && previewContainer) {
            new FileUploadHandler(zone, fileInput, previewContainer);
        }
    });
    
    // Initialize parameter forms
    const parameterForms = document.querySelectorAll('.parameter-form');
    parameterForms.forEach(form => {
        new ParameterManager(form);
    });
});

// Export for global access
window.WebViewUtils = WebViewUtils;
window.FileUploadHandler = FileUploadHandler;
window.ParameterManager = ParameterManager;
window.APIClient = APIClient;
window.TaskMonitor = TaskMonitor;
window.ProgressBar = ProgressBar;
``````

---

## Grupa 3: Skrypty JSX

*Skrypty Adobe JSX dla Photoshop*

### Lista plików (5)

- color_matcher_v1.2.jsx (\app\scripts)
- color_matcher_v1.4.jsx (\app\scripts)
- color_matcher_v1.6.jsx (\app\scripts)
- palette_analyzer.jsx (\app\scripts)
- test_simple.jsx (\app\scripts)

### Zawartość plików

#### color_matcher_v1.2.jsx - ./app/scripts/color_matcher_v1.2.jsx

``````
// GattoNero Color Matcher - v1.2 with Advanced Logging - DO NOT EDIT THIS, it is working v1.2 version, finalized.

#target photoshop

// << ZMIANA: Prosta i niezawodna funkcja do logowania na pulpicie.
function writeToLog(message) {
    try {
        var logFile = new File(Folder.desktop + "/gatto_nero_log.txt");
        logFile.open("a"); // "a" oznacza dopisywanie do pliku (append)
        logFile.encoding = "UTF-8";
        logFile.writeln(new Date().toTimeString().substr(0, 8) + ": " + message);
        logFile.close();
    } catch (e) {
        // Ignoruj błędy zapisu do logu, aby nie przerywać głównego skryptu
    }
}

// << ZMIANA: Rozpoczynamy logowanie od razu.
writeToLog("--- Script execution started ---");


// --- KONFIGURACJA ---
var SERVER_URL = "http://127.0.0.1:5000/api/colormatch";

// --- GŁÓWNA FUNKCJA ---
function main() {
    if (app.documents.length < 2) {
        alert("Otwórz co najmniej dwa dokumenty (master i target), aby uruchomić skrypt.");
        writeToLog("Error: Less than 2 documents open. Script terminated.");
        return;
    }

    writeToLog("Showing configuration dialog.");
    var config = showConfigurationDialog();
    if (config === null) {
        writeToLog("User cancelled the dialog. Script terminated.");
        return; // Użytkownik anulował
    }
    writeToLog("Configuration received: Method " + config.method + ", Preview: " + config.is_preview);

    var tempFolder = new Folder(config.projectRoot + "/temp_jsx");
    if (!tempFolder.exists) {
        tempFolder.create();
        writeToLog("Created temp folder: " + tempFolder.fsName);
    }

    var masterFile = null;
    var targetFile = null;

    try {
        alert("Rozpoczynam przetwarzanie... Sprawdź plik gatto_nero_log.txt na pulpicie, aby śledzić postęp.");

        writeToLog("Saving master document: " + config.masterDoc.name);
        masterFile = saveDocumentToTIFF(config.masterDoc, tempFolder, "master");
        writeToLog("Master file saved to: " + masterFile.fsName);

        writeToLog("Saving target document: " + config.targetDoc.name);
        targetFile = saveDocumentToTIFF(config.targetDoc, tempFolder, "target");
        writeToLog("Target file saved to: " + targetFile.fsName);

        writeToLog("Executing server request (curl).");
        var response = executeCurl(masterFile, targetFile, config);
        writeToLog("Raw server response: " + response);

        writeToLog("Parsing server response.");
        var result = parseColorMatchResponse(response);
        writeToLog("Parsed response successfully. Filename: " + result.filename);

        writeToLog("Opening result file.");
        openResultFile(result.filename, config.projectRoot, config.is_preview);

    } catch (e) {
        writeToLog("!!! SCRIPT CRASHED !!! Error: " + e.message);
        alert("Wystąpił krytyczny błąd: \n" + e.message + "\n\nSprawdź plik gatto_nero_log.txt na pulpicie po więcej szczegółów.");
    } finally {
        writeToLog("Cleaning up temporary files.");
        cleanupFile(masterFile);
        cleanupFile(targetFile);
        writeToLog("--- Script execution finished ---");
    }
}

function executeCurl(masterFile, targetFile, config) {
    var url = config.is_preview ? "http://127.0.0.1:5000/api/colormatch/preview" : SERVER_URL;

    // << ZMIANA: Używamy PEŁNEJ ŚCIEŻKI do curl i usuwamy flagę -s (silent), aby był bardziej "gadatliwy"
    var curlExecutable = "C:/Windows/System32/curl.exe";

    var command = '"' + curlExecutable + '" -s -X POST ' + // << DODANO -s (silent)
        '-F "master_image=@' + masterFile.fsName + '" ' +
        '-F "target_image=@' + targetFile.fsName + '" ' +
        '-F "method=' + config.method + '" ' +
        '-F "k=' + config.k + '" ' +
        '-F "distance_metric=' + config.distanceMetric + '" ' +
        '-F "use_dithering=' + config.useDithering + '" ' +
        '-F "preserve_luminance=' + config.preserveLuminance + '" ' +
        url;

    writeToLog("Executing command: " + command);

    var result = "";
    var tempFolder = masterFile.parent;

    if ($.os.indexOf("Windows") > -1) {
        var cmdFile = new File(tempFolder + "/colormatch_curl.cmd");
        var stdoutFile = new File(tempFolder + "/curl_stdout.txt");
        var stderrFile = new File(tempFolder + "/curl_stderr.txt");
        try {
            cmdFile.open("w");
            cmdFile.encoding = "UTF-8";
            cmdFile.writeln("@echo off");
            cmdFile.writeln(command);
            cmdFile.close();

            if (stdoutFile.exists) stdoutFile.remove();
            if (stderrFile.exists) stderrFile.remove();

            app.system('cmd /c ""' + cmdFile.fsName + '" 1> "' + stdoutFile.fsName + '" 2> "' + stderrFile.fsName + '""');

            var maxWaitTime = 15000;
            var waitInterval = 500;
            var totalWait = 0;
            while (totalWait < maxWaitTime && (!stdoutFile.exists || stdoutFile.length === 0) && (!stderrFile.exists || stderrFile.length === 0)) {
                $.sleep(waitInterval);
                totalWait += waitInterval;
            }

            var errorOutput = "";
            if (stderrFile.exists && stderrFile.length > 0) {
                stderrFile.open("r");
                errorOutput = stderrFile.read();
                stderrFile.close();
                writeToLog("CURL stderr: " + errorOutput); // << ZMIANA: Logujemy błąd
            }

            var stdOutput = "";
            if (stdoutFile.exists && stdoutFile.length > 0) {
                stdoutFile.open("r");
                stdOutput = stdoutFile.read();
                stdoutFile.close();
                writeToLog("CURL stdout: " + stdOutput); // << ZMIANA: Logujemy wyjście
            }

            if (errorOutput) {
                throw new Error("Błąd wykonania CURL (szczegóły w logu): " + errorOutput);
            }

            result = stdOutput;

        } finally {
            cleanupFile(cmdFile);
            cleanupFile(stdoutFile);
            cleanupFile(stderrFile);
        }
    } else { // macOS
        result = app.doScript('do shell script "' + command + '"', Language.APPLESCRIPT);
    }

    if (result.replace(/^\s+|\s+$/g, "") === "") {
        throw new Error("Nie otrzymano odpowiedzi od serwera (stdout był pusty).");
    }
    return result;
}

// --- Pozostałe funkcje (bez istotnych zmian) ---
// (showConfigurationDialog, saveDocumentToTIFF, openResultFile, cleanupFile)
function showConfigurationDialog() {
    var docList = [];
    for (var i = 0; i < app.documents.length; i++) {
        docList.push(app.documents[i].name);
    }

    var dialog = new Window("dialog", "GattoNero Color Matcher");
    dialog.orientation = "column";
    dialog.alignChildren = ["fill", "top"];

    // --- Panel Master ---
    var masterPanel = dialog.add("panel", undefined, "1. Wybierz obraz WZORCOWY (Master)");
    masterPanel.alignChildren = "left";
    masterPanel.add("statictext", undefined, "Dokument:");
    var masterDropdown = masterPanel.add("dropdownlist", undefined, docList);
    masterDropdown.selection = 0;

    // --- Panel Target ---
    var targetPanel = dialog.add("panel", undefined, "2. Wybierz obraz DOCELOWY (Target)");
    targetPanel.alignChildren = "left";
    targetPanel.add("statictext", undefined, "Dokument:");
    var targetDropdown = targetPanel.add("dropdownlist", undefined, docList);
    targetDropdown.selection = (docList.length > 1) ? 1 : 0;

    // --- Panel Metody ---
    var methodPanel = dialog.add("panel", undefined, "3. Wybierz metodę i parametry");
    methodPanel.alignChildren = "left";
    methodPanel.add("statictext", undefined, "Metoda dopasowania:");
    var methodDropdown = methodPanel.add("dropdownlist", undefined, [
        "1: Palette Mapping",
        "2: Statistical Transfer",
        "3: Histogram Matching"
    ]);
    methodDropdown.selection = 0;

    var kGroup = methodPanel.add("group");
    kGroup.add("statictext", undefined, "Liczba kolorów w palecie (dla Metody 1):");
    var kInput = kGroup.add("edittext", undefined, "16"); // Default to 16
    kInput.characters = 3;

    // --- Panel Opcji Zaawansowanych ---
    var advancedOptionsPanel = dialog.add("panel", undefined, "4. Opcje Zaawansowane");
    advancedOptionsPanel.alignChildren = "left";

    advancedOptionsPanel.add("statictext", undefined, "Metryka odległości:");
    var distanceMetricDropdown = advancedOptionsPanel.add("dropdownlist", undefined, [
        "weighted_rgb: Percepcyjna (domyślna)",
        "rgb: Szybka (RGB)",
        "lab: Percepcyjna (LAB)"
    ]);
    distanceMetricDropdown.selection = 0; // Default to weighted_rgb

    var ditheringCheckbox = advancedOptionsPanel.add("checkbox", undefined, "Włącz rozpraszanie (Dithering)");
    ditheringCheckbox.value = false;

    var preserveLuminanceCheckbox = advancedOptionsPanel.add("checkbox", undefined, "Zachowaj jasność oryginału");
    preserveLuminanceCheckbox.value = false;

    // --- Przyciski ---
    var buttonGroup = dialog.add("group");
    buttonGroup.orientation = "row";
    buttonGroup.alignChildren = ["fill", "center"];
    buttonGroup.add("button", undefined, "Anuluj", {
        name: "cancel"
    });
    var previewButton = buttonGroup.add("button", undefined, "Generuj Podgląd", {
        name: "preview"
    });
    var runButton = buttonGroup.add("button", undefined, "Uruchom", {
        name: "ok"
    });

    previewButton.onClick = function() {
        var kValue = parseInt(kInput.text);
        if (isNaN(kValue) || kValue < 4 || kValue > 64) { // Updated range for K
            alert("Liczba kolorów musi być w zakresie 4-64.");
            return;
        }
        if (masterDropdown.selection.index === targetDropdown.selection.index) {
            alert("Dokument Master i Target muszą być różne.");
            return;
        }
        result = {
            masterDoc: app.documents[masterDropdown.selection.index],
            targetDoc: app.documents[targetDropdown.selection.index],
            method: methodDropdown.selection.text.split(":")[0],
            k: kValue,
            distanceMetric: distanceMetricDropdown.selection.text.split(":")[0],
            useDithering: ditheringCheckbox.value,
            preserveLuminance: preserveLuminanceCheckbox.value,
            projectRoot: new File($.fileName).parent.parent,
            is_preview: true
        };
        dialog.close();
    };

    runButton.onClick = function() {
        var kValue = parseInt(kInput.text);
        if (isNaN(kValue) || kValue < 4 || kValue > 64) { // Updated range for K
            alert("Liczba kolorów musi być w zakresie 4-64.");
            return;
        }
        if (masterDropdown.selection.index === targetDropdown.selection.index) {
            alert("Dokument Master i Target muszą być różne.");
            return;
        }
        result = {
            masterDoc: app.documents[masterDropdown.selection.index],
            targetDoc: app.documents[targetDropdown.selection.index],
            method: methodDropdown.selection.text.split(":")[0],
            k: kValue,
            distanceMetric: distanceMetricDropdown.selection.text.split(":")[0],
            useDithering: ditheringCheckbox.value,
            preserveLuminance: preserveLuminanceCheckbox.value,
            projectRoot: new File($.fileName).parent.parent.parent,
            is_preview: false
        };
        dialog.close();
    };

    dialog.show();
    return result;
}

function saveDocumentToTIFF(doc, folderPath, prefix) {
    var activeDoc = app.activeDocument;
    app.activeDocument = doc;

    var filePath = new File(folderPath + "/" + prefix + "_" + Date.now() + ".tif");
    var tiffOptions = new TiffSaveOptions();
    tiffOptions.imageCompression = TIFFEncoding.NONE;
    tiffOptions.layers = false;

    doc.saveAs(filePath, tiffOptions, true, Extension.LOWERCASE);

    app.activeDocument = activeDoc;
    return filePath;
}

function parseColorMatchResponse(response) {
    try {
        // Najpierw usuwamy wszystkie możliwe znaki nowej linii z całego tekstu
        var cleaned_response = response.replace(/(\r\n|\n|\r)/gm, "");

        // Następnie usuwamy białe znaki z początku i końca
        cleaned_response = cleaned_response.replace(/^\s+|\s+$/g, "");

        var parts = cleaned_response.split(",");

        if (parts.length < 1) throw new Error("Pusta odpowiedź serwera");

        var status = parts[0];
        if (status === "error") {
            throw new Error("Błąd serwera: " + (parts.length > 1 ? parts.slice(1).join(',') : "Nieznany błąd"));
        }
        if (status !== "success" || parts.length < 3) {
            throw new Error("Nieprawidłowa odpowiedź serwera (oczekiwano 'success,method,filename'): " + cleaned_response);
        }

        // Zwracamy obiekt z idealnie czystą nazwą pliku
        return {
            status: status,
            method: parts[1],
            filename: parts[2]
        };

    } catch (e) {
        throw new Error("Błąd parsowania odpowiedzi: " + e.message + "\nOryginalna odpowiedź: " + response);
    }
}

function openResultFile(filename, projectRoot, is_preview) {
    var resultsFolder = new Folder(projectRoot + "/results");
    var resultFile = new File(resultsFolder.fsName + "/" + filename);

    // --- PANCERNA PĘTLA OCZEKIWANIA NA PLIK ---
    var max_wait_ms = 20000; // Maksymalny czas oczekiwania: 20 sekund
    var interval_ms = 500; // Sprawdzaj co pół sekundy
    var elapsed_ms = 0;
    var fileFound = false;

    writeToLog("Waiting for result file: " + resultFile.fsName);

    while (elapsed_ms < max_wait_ms) {
        if (resultFile.exists) {
            fileFound = true;
            writeToLog("File found after " + elapsed_ms + "ms.");
            break; // Znaleziono plik, wyjdź z pętli
        }

        $.sleep(interval_ms); // Czekaj
        elapsed_ms += interval_ms;
    }

    if (!fileFound) {
        throw new Error("Plik wynikowy nie istnieje (nawet po " + (max_wait_ms / 1000) + " sekundach oczekiwania): " + resultFile.fsName);
    }
    // --- KONIEC PĘTLI OCZEKIWANIA ---

    // Otwórz plik, gdy już na pewno istnieje
    if (is_preview) {
        var resultDoc = app.open(resultFile);
        resultDoc.name = "ColorMatch_Preview_" + filename;
        alert("Podgląd wygenerowany! Plik otwarty:\n" + filename + "\n\nZamknij podgląd, aby kontynuować.");
    } else {
        var resultDoc = app.open(resultFile);
        resultDoc.name = "ColorMatch_" + filename;
        alert("Gotowe! Color Matching zakończony.\n\nWynik został otwarty w nowym dokumencie.");
    }
}

function cleanupFile(file) {
    if (file && file.exists) {
        try {
            file.remove();
        } catch (e) {
            /* ignoruj błędy */ }
    }
}

// --- URUCHOMIENIE ---
main();
``````

#### color_matcher_v1.4.jsx - ./app/scripts/color_matcher_v1.4.jsx

``````
// GattoNero Color Matcher - v1.5 (Final Build with Surgical Logging)
#target photoshop

function writeToLog(message) {
    try {
        var logFile = new File(Folder.desktop + "/gatto_nero_log.txt");
        logFile.open("a");
        logFile.encoding = "UTF-8";
        logFile.writeln(new Date().toTimeString().substr(0, 8) + ": " + message);
        logFile.close();
    } catch (e) {}
}

writeToLog("--- Script execution started (v1.5) ---");

var SERVER_URL = "http://127.0.0.1:5000/api/colormatch";

function main() {
    if (app.documents.length < 2) {
        alert("Otwórz co najmniej dwa dokumenty (master i target), aby uruchomić skrypt.");
        writeToLog("Error: Less than 2 documents open. Script terminated.");
        return;
    }
    
    writeToLog("Showing configuration dialog.");
    var config = showConfigurationDialog();

    if (config === null) {
        writeToLog("User cancelled the dialog or a critical error occured inside dialog function. Script terminated.");
        return;
    }
    
    writeToLog("Configuration received successfully. Starting process...");
    // Usunięto logowanie całego obiektu config, by nie zaśmiecać, mamy to w logach DEBUG
    
    var tempFolder = new Folder(config.projectRoot + "/temp_jsx");
    if (!tempFolder.exists) {
        tempFolder.create();
        writeToLog("Created temp folder: " + tempFolder.fsName);
    }

    var masterFile = null;
    var targetFile = null;
    
    try {
        alert("Rozpoczynam przetwarzanie... Sprawdź plik gatto_nero_log.txt na pulpicie, aby śledzić postęp.");
        
        masterFile = saveDocumentToTIFF(config.masterDoc, tempFolder, "master");
        targetFile = saveDocumentToTIFF(config.targetDoc, tempFolder, "target");

        var response = executeCurl(masterFile, targetFile, config);
        writeToLog("Raw server response: " + response);
        
        var result = parseColorMatchResponse(response);
        writeToLog("Parsed response successfully. Filename: " + result.filename);
        
        openResultFile(result.filename, config.projectRoot);
        
    } catch (e) {
        writeToLog("!!! SCRIPT CRASHED !!! Error: " + e.message + " (Line: " + e.line + ")");
        alert("Wystąpił krytyczny błąd: \n" + e.message + "\n\nSprawdź plik gatto_nero_log.txt na pulpicie po więcej szczegółów.");
    } finally {
        writeToLog("Cleaning up temporary files.");
        cleanupFile(masterFile);
        cleanupFile(targetFile);
        writeToLog("--- Script execution finished ---");
    }
}

function showConfigurationDialog() {
    var docList = [];
    for (var i = 0; i < app.documents.length; i++) {
        docList.push(app.documents[i].name);
    }

    var dialog = new Window("dialog", "GattoNero Color Matcher v1.5");
    dialog.orientation = "column";
    dialog.alignChildren = ["fill", "top"];

    var masterPanel = dialog.add("panel", undefined, "1. Obraz WZORCOWY (Master)");
    masterPanel.alignChildren = "left";
    masterPanel.add("statictext", undefined, "Dokument:");
    var masterDropdown = masterPanel.add("dropdownlist", undefined, docList);
    masterDropdown.selection = 0;

    var targetPanel = dialog.add("panel", undefined, "2. Obraz DOCELOWY (Target)");
    targetPanel.alignChildren = "left";
    targetPanel.add("statictext", undefined, "Dokument:");
    var targetDropdown = targetPanel.add("dropdownlist", undefined, docList);
    targetDropdown.selection = (docList.length > 1) ? 1 : 0;

    var methodPanel = dialog.add("panel", undefined, "3. Metoda i Główne Parametry");
    methodPanel.alignChildren = "left";
    methodPanel.add("statictext", undefined, "Metoda dopasowania:");
    var methodDropdown = methodPanel.add("dropdownlist", undefined, ["1: Palette Mapping", "2: Statistical Transfer", "3: Histogram Matching"]);
    methodDropdown.selection = 0;

    var kGroup = methodPanel.add("group");
    kGroup.add("statictext", undefined, "Liczba kolorów w palecie (dla Metody 1):");
    var kInput = kGroup.add("edittext", undefined, "16");
    kInput.characters = 3;
    
    var advancedOptionsPanel = dialog.add("panel", undefined, "4. Opcje Zaawansowane (dla Palette Mapping)");
    advancedOptionsPanel.orientation = "column";
    advancedOptionsPanel.alignChildren = "left";
    
    var ditheringGroup = advancedOptionsPanel.add('group');
    ditheringGroup.add("statictext", undefined, "Wygładzanie krawędzi:");
    var ditheringDropdown = ditheringGroup.add("dropdownlist", undefined, ["none: Szybko, ostre krawędzie", "floyd_steinberg: Wolniej, gładkie przejścia"]);
    ditheringDropdown.selection = 0;
    
    advancedOptionsPanel.add('statictext', undefined, 'Ochrona tonów skrajnych:');
    var injectExtremesCheckbox = advancedOptionsPanel.add("checkbox", undefined, "Dodaj czysty czarny/biały do palety");
    injectExtremesCheckbox.value = false;
    
    var preserveGroup = advancedOptionsPanel.add('group');
    var preserveExtremesCheckbox = preserveGroup.add("checkbox", undefined, "Chroń cienie i światła w obrazie docelowym");
    preserveExtremesCheckbox.value = false;

    var thresholdGroup = advancedOptionsPanel.add('group');
    thresholdGroup.add("statictext", undefined, "Próg ochrony (0-255):");
    var thresholdInput = thresholdGroup.add("edittext", undefined, "10");
    thresholdInput.characters = 3;
    thresholdInput.enabled = false;

    preserveExtremesCheckbox.onClick = function() {
        thresholdInput.enabled = this.value;
    };
    
    var buttonGroup = dialog.add("group");
    buttonGroup.orientation = "row";
    buttonGroup.alignChildren = ["fill", "center"];
    var runButton = buttonGroup.add("button", undefined, "Uruchom", { name: "ok" });
    var cancelButton = buttonGroup.add("button", undefined, "Anuluj", { name: "cancel" });
    
    var result = null;

    runButton.onClick = function() {
        // === POCZĄTEK LOGOWANIA CHIRURGICZNEGO ===
        try {
            writeToLog("DEBUG: 'Uruchom' clicked. Starting validation.");

            if (masterDropdown.selection.index === targetDropdown.selection.index) {
                alert("Dokument Master i Target muszą być różne.");
                writeToLog("DEBUG: Validation FAILED. Master and Target are the same.");
                return;
            }

            var kValue = parseInt(kInput.text);
            if (isNaN(kValue) || kValue < 4 || kValue > 64) {
                alert("Liczba kolorów musi być w zakresie 4-64.");
                writeToLog("DEBUG: Validation FAILED. Invalid k value: " + kInput.text);
                return;
            }
            writeToLog("DEBUG: kValue is OK: " + kValue);

            var thresholdValue = 0; 
            if (preserveExtremesCheckbox.value) {
                writeToLog("DEBUG: Preserve extremes is checked. Reading threshold value.");
                thresholdValue = parseInt(thresholdInput.text);
                if (isNaN(thresholdValue) || thresholdValue < 0 || thresholdValue > 255) {
                    alert("Gdy opcja ochrony jest włączona, jej próg musi być w zakresie 0-255.");
                    writeToLog("DEBUG: Validation FAILED. Invalid threshold value: " + thresholdInput.text);
                    return;
                }
                writeToLog("DEBUG: thresholdValue is OK: " + thresholdValue);
            } else {
                writeToLog("DEBUG: Preserve extremes is NOT checked.");
            }
            
            writeToLog("DEBUG: All validation passed. Creating result object.");

            result = {
                masterDoc: app.documents[masterDropdown.selection.index],
                targetDoc: app.documents[targetDropdown.selection.index],
                method: methodDropdown.selection.text.split(":")[0],
                k: kValue,
                ditheringMethod: (ditheringDropdown.selection.text.split(":")[0]).replace(/^[\s\u00A0]+|[\s\u00A0]+$/g, ''),
                injectExtremes: injectExtremesCheckbox.value,
                preserveExtremes: preserveExtremesCheckbox.value,
                extremesThreshold: thresholdValue,
                projectRoot: new File($.fileName).parent.parent.parent,
                is_preview: false // Ta opcja nie jest już używana w UI, ale może być w przyszłości
            };
            
            writeToLog("DEBUG: Result object created successfully. Closing dialog.");
            dialog.close();

        } catch (e) {
            var errorMessage = "KRYTYCZNY BŁĄD w przycisku 'Uruchom': " + e.message + " (linia: " + e.line + ")";
            writeToLog("!!! " + errorMessage);
            alert(errorMessage);
            // Nie zamykamy okna, ale błąd jest zalogowany
        }
        // === KONIEC LOGOWANIA CHIRURGICZNEGO ===
    };

    cancelButton.onClick = function() {
        writeToLog("DEBUG: 'Anuluj' button clicked.");
        result = null;
        dialog.close();
    };

    dialog.show();
    writeToLog("DEBUG: Dialog closed. Returning result. Is it null? " + (result === null));
    return result;
}

function executeCurl(masterFile, targetFile, config) {
    var url = SERVER_URL;
    var curlExecutable = "C:/Windows/System32/curl.exe";
    
    var command = '"' + curlExecutable + '" -s -X POST ' +
                  '-F "master_image=@' + masterFile.fsName + '" ' +
                  '-F "target_image=@' + targetFile.fsName + '" ' +
                  '-F "method=' + config.method + '" ' +
                  '-F "k=' + config.k + '" ' +
                  '-F "dithering_method=' + config.ditheringMethod + '" ' +
                  '-F "inject_extremes=' + config.injectExtremes + '" ' +
                  '-F "preserve_extremes=' + config.preserveExtremes + '" ' +
                  '-F "extremes_threshold=' + config.extremesThreshold + '" ' +
                  url;

    writeToLog("Executing command: " + command);

    var result = "";
    var tempFolder = masterFile.parent;

    if ($.os.indexOf("Windows") > -1) {
        var cmdFile = new File(tempFolder + "/colormatch_curl.cmd");
        var stdoutFile = new File(tempFolder + "/curl_stdout.txt");
        var stderrFile = new File(tempFolder + "/curl_stderr.txt");
        try {
            cmdFile.open("w");
            cmdFile.encoding = "UTF-8";
            cmdFile.writeln("@echo off");
            cmdFile.writeln(command);
            cmdFile.close();

            if (stdoutFile.exists) stdoutFile.remove();
            if (stderrFile.exists) stderrFile.remove();
            
            app.system('cmd /c ""' + cmdFile.fsName + '" 1> "' + stdoutFile.fsName + '" 2> "' + stderrFile.fsName + '""');
            
            var maxWaitTime = 30000;
            var waitInterval = 500;
            var totalWait = 0;
            while (totalWait < maxWaitTime && (!stdoutFile.exists || stdoutFile.length === 0) && (!stderrFile.exists || stderrFile.length > 0)) {
                $.sleep(waitInterval);
                totalWait += waitInterval;
            }

            var errorOutput = "";
            if (stderrFile.exists && stderrFile.length > 0) {
                stderrFile.open("r"); errorOutput = stderrFile.read(); stderrFile.close();
                writeToLog("CURL stderr: " + errorOutput);
            }

            var stdOutput = "";
            if (stdoutFile.exists && stdoutFile.length > 0) {
                stdoutFile.open("r"); stdOutput = stdoutFile.read(); stdoutFile.close();
                writeToLog("CURL stdout: " + stdOutput);
            }
            
            if (errorOutput) { throw new Error("Błąd wykonania CURL: " + errorOutput); }
            if (!stdOutput) { throw new Error("Nie otrzymano odpowiedzi od serwera (pusty stdout)."); }
            
            result = stdOutput;
        } finally {
            cleanupFile(cmdFile); cleanupFile(stdoutFile); cleanupFile(stderrFile);
        }
    } else {
        result = app.doScript('do shell script "' + command + '"', Language.APPLESCRIPT);
    }
    return result;
}

function parseColorMatchResponse(response) {
    try {
        var cleaned_response = response.replace(/(\r\n|\n|\r)/gm, "").replace(/^\s+|\s+$/g, "");
        var parts = cleaned_response.split(",");
        if (parts.length < 3 || parts[0] !== "success") {
             throw new Error("Nieprawidłowa odpowiedź serwera: " + cleaned_response);
        }
        return { status: parts[0], method: parts[1], filename: parts[2] };
    } catch (e) {
        throw new Error("Błąd parsowania odpowiedzi: " + e.message + ". Oryginalna odpowiedź: " + response);
    }
}

function openResultFile(filename, projectRoot) {
    var resultsFolder = new Folder(projectRoot + "/results");
    var resultFile = new File(resultsFolder.fsName + "/" + filename);
    
    var max_wait_ms = 20000;
    var interval_ms = 500;
    var elapsed_ms = 0;
    writeToLog("Waiting for result file: " + resultFile.fsName);

    while (elapsed_ms < max_wait_ms) {
        if (resultFile.exists) {
            writeToLog("File found after " + elapsed_ms + "ms.");
            var resultDoc = app.open(resultFile);
            resultDoc.name = "ColorMatch_" + filename;
            alert("Gotowe! Color Matching zakończony.\n\nWynik został otwarty w nowym dokumencie.");
            return;
        }
        $.sleep(interval_ms);
        elapsed_ms += interval_ms;
    }
    throw new Error("Plik wynikowy nie istnieje (nawet po " + (max_wait_ms / 1000) + "s): " + resultFile.fsName);
}

function saveDocumentToTIFF(doc, folderPath, prefix) {
    writeToLog("Saving document '" + doc.name + "' to TIFF...");
    var activeDoc = app.activeDocument;
    app.activeDocument = doc;
    var filePath = new File(folderPath + "/" + prefix + "_" + Date.now() + ".tif");
    var tiffOptions = new TiffSaveOptions();
    tiffOptions.imageCompression = TIFFEncoding.NONE;
    tiffOptions.layers = false;
    doc.saveAs(filePath, tiffOptions, true, Extension.LOWERCASE);
    app.activeDocument = activeDoc;
    writeToLog("Saved successfully to: " + filePath.fsName);
    return filePath;
}

function cleanupFile(file) {
    if (file && file.exists) {
        try { 
            file.remove();
            writeToLog("Cleaned up temp file: " + file.fsName);
        } catch (e) {}
    }
}

main();
``````

#### color_matcher_v1.6.jsx - ./app/scripts/color_matcher_v1.6.jsx

``````
// GattoNero Color Matcher - v1.6
#target photoshop

function writeToLog(message) {
    try {
        var logFile = new File(Folder.desktop + "/gatto_nero_log.txt");
        logFile.open("a");
        logFile.encoding = "UTF-8";
        logFile.writeln(new Date().toTimeString().substr(0, 8) + ": " + message);
        logFile.close();
    } catch (e) {}
}

writeToLog("--- Script execution started (v1.5) ---");

var SERVER_URL = "http://127.0.0.1:5000/api/colormatch";

function main() {
    if (app.documents.length < 2) {
        alert("Otwórz co najmniej dwa dokumenty (master i target), aby uruchomić skrypt.");
        writeToLog("Error: Less than 2 documents open. Script terminated.");
        return;
    }
    
    writeToLog("Showing configuration dialog.");
    var config = showConfigurationDialog();

    if (config === null) {
        writeToLog("User cancelled the dialog or a critical error occured inside dialog function. Script terminated.");
        return;
    }
    
    writeToLog("Configuration received successfully. Starting process...");
    // Usunięto logowanie całego obiektu config, by nie zaśmiecać, mamy to w logach DEBUG
    
    var tempFolder = new Folder(config.projectRoot + "/temp_jsx");
    if (!tempFolder.exists) {
        tempFolder.create();
        writeToLog("Created temp folder: " + tempFolder.fsName);
    }

    var masterFile = null;
    var targetFile = null;
    
    try {
        alert("Rozpoczynam przetwarzanie... Sprawdź plik gatto_nero_log.txt na pulpicie, aby śledzić postęp.");
        
        masterFile = saveDocumentToTIFF(config.masterDoc, tempFolder, "master");
        targetFile = saveDocumentToTIFF(config.targetDoc, tempFolder, "target");

        var response = executeCurl(masterFile, targetFile, config);
        writeToLog("Raw server response: " + response);
        
        var result = parseColorMatchResponse(response);
        writeToLog("Parsed response successfully. Filename: " + result.filename);
        
        openResultFile(result.filename, config.projectRoot);
        
    } catch (e) {
        writeToLog("!!! SCRIPT CRASHED !!! Error: " + e.message + " (Line: " + e.line + ")");
        alert("Wystąpił krytyczny błąd: \n" + e.message + "\n\nSprawdź plik gatto_nero_log.txt na pulpicie po więcej szczegółów.");
    } finally {
        writeToLog("Cleaning up temporary files.");
        cleanupFile(masterFile);
        cleanupFile(targetFile);
        writeToLog("--- Script execution finished ---");
    }
}

function showConfigurationDialog() {
    var docList = [];
    for (var i = 0; i < app.documents.length; i++) {
        docList.push(app.documents[i].name);
    }

    var dialog = new Window("dialog", "GattoNero Color Matcher v1.5");
    dialog.orientation = "column";
    dialog.alignChildren = ["fill", "top"];

    var masterPanel = dialog.add("panel", undefined, "1. Obraz WZORCOWY (Master)");
    masterPanel.alignChildren = "left";
    masterPanel.add("statictext", undefined, "Dokument:");
    var masterDropdown = masterPanel.add("dropdownlist", undefined, docList);
    masterDropdown.selection = 0;

    var targetPanel = dialog.add("panel", undefined, "2. Obraz DOCELOWY (Target)");
    targetPanel.alignChildren = "left";
    targetPanel.add("statictext", undefined, "Dokument:");
    var targetDropdown = targetPanel.add("dropdownlist", undefined, docList);
    targetDropdown.selection = (docList.length > 1) ? 1 : 0;

    var methodPanel = dialog.add("panel", undefined, "3. Metoda i Główne Parametry");
    methodPanel.alignChildren = "left";
    methodPanel.add("statictext", undefined, "Metoda dopasowania:");
    var methodDropdown = methodPanel.add("dropdownlist", undefined, ["1: Palette Mapping", "2: Statistical Transfer", "3: Histogram Matching"]);
    methodDropdown.selection = 0;

    var kGroup = methodPanel.add("group");
    kGroup.add("statictext", undefined, "Liczba kolorów w palecie (dla Metody 1):");
    var kInput = kGroup.add("edittext", undefined, "16");
    kInput.characters = 3;
    
    var advancedOptionsPanel = dialog.add("panel", undefined, "4. Opcje Zaawansowane (dla Palette Mapping)");
    advancedOptionsPanel.orientation = "column";
    advancedOptionsPanel.alignChildren = "left";
    
    var ditheringGroup = advancedOptionsPanel.add('group');
    ditheringGroup.add("statictext", undefined, "Wygładzanie krawędzi:");
    var ditheringDropdown = ditheringGroup.add("dropdownlist", undefined, ["none: Szybko, ostre krawędzie", "floyd_steinberg: Wolniej, gładkie przejścia"]);
    ditheringDropdown.selection = 0;
    
    advancedOptionsPanel.add('statictext', undefined, 'Ochrona tonów skrajnych:');
    var injectExtremesCheckbox = advancedOptionsPanel.add("checkbox", undefined, "Dodaj czysty czarny/biały do palety");
    injectExtremesCheckbox.value = false;
    
    var preserveGroup = advancedOptionsPanel.add('group');
    var preserveExtremesCheckbox = preserveGroup.add("checkbox", undefined, "Chroń cienie i światła w obrazie docelowym");
    preserveExtremesCheckbox.value = false;

    var thresholdGroup = advancedOptionsPanel.add('group');
    thresholdGroup.add("statictext", undefined, "Próg ochrony (0-255):");
    var thresholdInput = thresholdGroup.add("edittext", undefined, "10");
    thresholdInput.characters = 3;
    thresholdInput.enabled = false;

    preserveExtremesCheckbox.onClick = function() {
        thresholdInput.enabled = this.value;
    };
    
    // === NOWE PARAMETRY EDGE BLENDING ===
    var edgeBlendingPanel = dialog.add("panel", undefined, "5. Wygładzanie Krawędzi (Edge Blending)");
    edgeBlendingPanel.orientation = "column";
    edgeBlendingPanel.alignChildren = "left";
    
    var enableEdgeBlendingCheckbox = edgeBlendingPanel.add("checkbox", undefined, "Włącz wygładzanie krawędzi");
    enableEdgeBlendingCheckbox.value = false;
    
    var edgeDetectionGroup = edgeBlendingPanel.add('group');
    edgeDetectionGroup.add("statictext", undefined, "Próg detekcji krawędzi (0-100):");
    var edgeDetectionThresholdInput = edgeDetectionGroup.add("edittext", undefined, "25");
    edgeDetectionThresholdInput.characters = 3;
    edgeDetectionThresholdInput.enabled = false;
    
    var blurRadiusGroup = edgeBlendingPanel.add('group');
    blurRadiusGroup.add("statictext", undefined, "Promień rozmycia (0.5-5.0):");
    var edgeBlurRadiusInput = blurRadiusGroup.add("edittext", undefined, "1.0");
    edgeBlurRadiusInput.characters = 4;
    edgeBlurRadiusInput.enabled = false;
    
    var blurStrengthGroup = edgeBlendingPanel.add('group');
    blurStrengthGroup.add("statictext", undefined, "Siła rozmycia (0.0-1.0):");
    var edgeBlurStrengthInput = blurStrengthGroup.add("edittext", undefined, "0.5");
    edgeBlurStrengthInput.characters = 4;
    edgeBlurStrengthInput.enabled = false;
    
    enableEdgeBlendingCheckbox.onClick = function() {
        edgeDetectionThresholdInput.enabled = this.value;
        edgeBlurRadiusInput.enabled = this.value;
        edgeBlurStrengthInput.enabled = this.value;
    };
    
    var buttonGroup = dialog.add("group");
    buttonGroup.orientation = "row";
    buttonGroup.alignChildren = ["fill", "center"];
    var runButton = buttonGroup.add("button", undefined, "Uruchom", { name: "ok" });
    var cancelButton = buttonGroup.add("button", undefined, "Anuluj", { name: "cancel" });
    
    var result = null;

    runButton.onClick = function() {
        // === POCZĄTEK LOGOWANIA CHIRURGICZNEGO ===
        try {
            writeToLog("DEBUG: 'Uruchom' clicked. Starting validation.");

            if (masterDropdown.selection.index === targetDropdown.selection.index) {
                alert("Dokument Master i Target muszą być różne.");
                writeToLog("DEBUG: Validation FAILED. Master and Target are the same.");
                return;
            }

            var kValue = parseInt(kInput.text);
            if (isNaN(kValue) || kValue < 4 || kValue > 64) {
                alert("Liczba kolorów musi być w zakresie 4-64.");
                writeToLog("DEBUG: Validation FAILED. Invalid k value: " + kInput.text);
                return;
            }
            writeToLog("DEBUG: kValue is OK: " + kValue);

            var thresholdValue = 0; 
            if (preserveExtremesCheckbox.value) {
                writeToLog("DEBUG: Preserve extremes is checked. Reading threshold value.");
                thresholdValue = parseInt(thresholdInput.text);
                if (isNaN(thresholdValue) || thresholdValue < 0 || thresholdValue > 255) {
                    alert("Gdy opcja ochrony jest włączona, jej próg musi być w zakresie 0-255.");
                    writeToLog("DEBUG: Validation FAILED. Invalid threshold value: " + thresholdInput.text);
                    return;
                }
                writeToLog("DEBUG: thresholdValue is OK: " + thresholdValue);
            } else {
                writeToLog("DEBUG: Preserve extremes is NOT checked.");
            }
            
            // === WALIDACJA PARAMETRÓW EDGE BLENDING ===
            var edgeBlendingEnabled = enableEdgeBlendingCheckbox.value;
            var edgeDetectionThreshold = 25;
            var edgeBlurRadius = 1.0;
            var edgeBlurStrength = 0.5;
            
            if (edgeBlendingEnabled) {
                writeToLog("DEBUG: Edge blending is enabled. Validating parameters.");
                
                edgeDetectionThreshold = parseFloat(edgeDetectionThresholdInput.text);
                if (isNaN(edgeDetectionThreshold) || edgeDetectionThreshold < 0 || edgeDetectionThreshold > 100) {
                    alert("Próg detekcji krawędzi musi być w zakresie 0-100.");
                    writeToLog("DEBUG: Validation FAILED. Invalid edge detection threshold: " + edgeDetectionThresholdInput.text);
                    return;
                }
                
                edgeBlurRadius = parseFloat(edgeBlurRadiusInput.text);
                if (isNaN(edgeBlurRadius) || edgeBlurRadius < 0.5 || edgeBlurRadius > 5.0) {
                    alert("Promień rozmycia musi być w zakresie 0.5-5.0.");
                    writeToLog("DEBUG: Validation FAILED. Invalid edge blur radius: " + edgeBlurRadiusInput.text);
                    return;
                }
                
                edgeBlurStrength = parseFloat(edgeBlurStrengthInput.text);
                if (isNaN(edgeBlurStrength) || edgeBlurStrength < 0.0 || edgeBlurStrength > 1.0) {
                    alert("Siła rozmycia musi być w zakresie 0.0-1.0.");
                    writeToLog("DEBUG: Validation FAILED. Invalid edge blur strength: " + edgeBlurStrengthInput.text);
                    return;
                }
                
                writeToLog("DEBUG: Edge blending parameters validated successfully.");
            } else {
                writeToLog("DEBUG: Edge blending is NOT enabled.");
            }
            
            writeToLog("DEBUG: All validation passed. Creating result object.");

            result = {
                masterDoc: app.documents[masterDropdown.selection.index],
                targetDoc: app.documents[targetDropdown.selection.index],
                method: methodDropdown.selection.text.split(":")[0],
                k: kValue,
                ditheringMethod: (ditheringDropdown.selection.text.split(":")[0]).replace(/^[\s\u00A0]+|[\s\u00A0]+$/g, ''),
                injectExtremes: injectExtremesCheckbox.value,
                preserveExtremes: preserveExtremesCheckbox.value,
                extremesThreshold: thresholdValue,
                // === NOWE PARAMETRY EDGE BLENDING ===
                enableEdgeBlending: edgeBlendingEnabled,
                edgeDetectionThreshold: edgeDetectionThreshold,
                edgeBlurRadius: edgeBlurRadius,
                edgeBlurStrength: edgeBlurStrength,
                projectRoot: new File($.fileName).parent.parent.parent,
                is_preview: false // Ta opcja nie jest już używana w UI, ale może być w przyszłości
            };
            
            writeToLog("DEBUG: Result object created successfully. Closing dialog.");
            dialog.close();

        } catch (e) {
            var errorMessage = "KRYTYCZNY BŁĄD w przycisku 'Uruchom': " + e.message + " (linia: " + e.line + ")";
            writeToLog("!!! " + errorMessage);
            alert(errorMessage);
            // Nie zamykamy okna, ale błąd jest zalogowany
        }
        // === KONIEC LOGOWANIA CHIRURGICZNEGO ===
    };

    cancelButton.onClick = function() {
        writeToLog("DEBUG: 'Anuluj' button clicked.");
        result = null;
        dialog.close();
    };

    dialog.show();
    writeToLog("DEBUG: Dialog closed. Returning result. Is it null? " + (result === null));
    return result;
}

function executeCurl(masterFile, targetFile, config) {
    var url = SERVER_URL;
    var curlExecutable = "C:/Windows/System32/curl.exe";
    
    var command = '"' + curlExecutable + '" -s -X POST ' +
                  '-F "master_image=@' + masterFile.fsName + '" ' +
                  '-F "target_image=@' + targetFile.fsName + '" ' +
                  '-F "method=' + config.method + '" ' +
                  '-F "k=' + config.k + '" ' +
                  '-F "dithering_method=' + config.ditheringMethod + '" ' +
                  '-F "inject_extremes=' + config.injectExtremes + '" ' +
                  '-F "preserve_extremes=' + config.preserveExtremes + '" ' +
                  '-F "extremes_threshold=' + config.extremesThreshold + '" ' +
                  '-F "enable_edge_blending=' + config.enableEdgeBlending + '" ' +
                  '-F "edge_detection_threshold=' + config.edgeDetectionThreshold + '" ' +
                  '-F "edge_blur_radius=' + config.edgeBlurRadius + '" ' +
                  '-F "edge_blur_strength=' + config.edgeBlurStrength + '" ' +
                  url;

    writeToLog("Executing command: " + command);

    var result = "";
    var tempFolder = masterFile.parent;

    if ($.os.indexOf("Windows") > -1) {
        var cmdFile = new File(tempFolder + "/colormatch_curl.cmd");
        var stdoutFile = new File(tempFolder + "/curl_stdout.txt");
        var stderrFile = new File(tempFolder + "/curl_stderr.txt");
        try {
            cmdFile.open("w");
            cmdFile.encoding = "UTF-8";
            cmdFile.writeln("@echo off");
            cmdFile.writeln(command);
            cmdFile.close();

            if (stdoutFile.exists) stdoutFile.remove();
            if (stderrFile.exists) stderrFile.remove();
            
            app.system('cmd /c ""' + cmdFile.fsName + '" 1> "' + stdoutFile.fsName + '" 2> "' + stderrFile.fsName + '""');
            
            var maxWaitTime = 30000;
            var waitInterval = 500;
            var totalWait = 0;
            while (totalWait < maxWaitTime && (!stdoutFile.exists || stdoutFile.length === 0) && (!stderrFile.exists || stderrFile.length > 0)) {
                $.sleep(waitInterval);
                totalWait += waitInterval;
            }

            var errorOutput = "";
            if (stderrFile.exists && stderrFile.length > 0) {
                stderrFile.open("r"); errorOutput = stderrFile.read(); stderrFile.close();
                writeToLog("CURL stderr: " + errorOutput);
            }

            var stdOutput = "";
            if (stdoutFile.exists && stdoutFile.length > 0) {
                stdoutFile.open("r"); stdOutput = stdoutFile.read(); stdoutFile.close();
                writeToLog("CURL stdout: " + stdOutput);
            }
            
            if (errorOutput) { throw new Error("Błąd wykonania CURL: " + errorOutput); }
            if (!stdOutput) { throw new Error("Nie otrzymano odpowiedzi od serwera (pusty stdout)."); }
            
            result = stdOutput;
        } finally {
            cleanupFile(cmdFile); cleanupFile(stdoutFile); cleanupFile(stderrFile);
        }
    } else {
        result = app.doScript('do shell script "' + command + '"', Language.APPLESCRIPT);
    }
    return result;
}

function parseColorMatchResponse(response) {
    try {
        var cleaned_response = response.replace(/(\r\n|\n|\r)/gm, "").replace(/^\s+|\s+$/g, "");
        var parts = cleaned_response.split(",");
        if (parts.length < 3 || parts[0] !== "success") {
             throw new Error("Nieprawidłowa odpowiedź serwera: " + cleaned_response);
        }
        return { status: parts[0], method: parts[1], filename: parts[2] };
    } catch (e) {
        throw new Error("Błąd parsowania odpowiedzi: " + e.message + ". Oryginalna odpowiedź: " + response);
    }
}

function openResultFile(filename, projectRoot) {
    var resultsFolder = new Folder(projectRoot + "/results");
    var resultFile = new File(resultsFolder.fsName + "/" + filename);
    
    var max_wait_ms = 20000;
    var interval_ms = 500;
    var elapsed_ms = 0;
    writeToLog("Waiting for result file: " + resultFile.fsName);

    while (elapsed_ms < max_wait_ms) {
        if (resultFile.exists) {
            writeToLog("File found after " + elapsed_ms + "ms.");
            var resultDoc = app.open(resultFile);
            resultDoc.name = "ColorMatch_" + filename;
            alert("Gotowe! Color Matching zakończony.\n\nWynik został otwarty w nowym dokumencie.");
            return;
        }
        $.sleep(interval_ms);
        elapsed_ms += interval_ms;
    }
    throw new Error("Plik wynikowy nie istnieje (nawet po " + (max_wait_ms / 1000) + "s): " + resultFile.fsName);
}

function saveDocumentToTIFF(doc, folderPath, prefix) {
    writeToLog("Saving document '" + doc.name + "' to TIFF...");
    var activeDoc = app.activeDocument;
    app.activeDocument = doc;
    var filePath = new File(folderPath + "/" + prefix + "_" + Date.now() + ".tif");
    var tiffOptions = new TiffSaveOptions();
    tiffOptions.imageCompression = TIFFEncoding.NONE;
    tiffOptions.layers = false;
    doc.saveAs(filePath, tiffOptions, true, Extension.LOWERCASE);
    app.activeDocument = activeDoc;
    writeToLog("Saved successfully to: " + filePath.fsName);
    return filePath;
}

function cleanupFile(file) {
    if (file && file.exists) {
        try { 
            file.remove();
            writeToLog("Cleaned up temp file: " + file.fsName);
        } catch (e) {}
    }
}

main();
``````

#### palette_analyzer.jsx - ./app/scripts/palette_analyzer.jsx

``````
// GattoNero Palette Analyzer - Prosty format CSV
#target photoshop

// --- KONFIGURACJA ---
var SERVER_URL = "http://127.0.0.1:5000/api/analyze_palette";

function main() {
    if (app.documents.length === 0) {
        alert("Otwórz dokument, aby uruchomić skrypt.");
        return;
    }

    var doc = app.activeDocument;
    if (doc.layers.length === 0) {
        alert("Dokument nie zawiera żadnych warstw.");
        return;
    }

    var activeLayer = doc.activeLayer;
    
    // Zapytaj użytkownika o liczbę kolorów
    var k = prompt("Ile dominujących kolorów chcesz znaleźć?", 8, "Analizator Palety");
    if (k === null) {
        return; // Użytkownik anulował
    }
    k = parseInt(k);
    if (isNaN(k) || k < 1 || k > 50) {
        alert("Podaj liczbę między 1 a 50.");
        return;
    }

    alert("Analizuję paletę kolorów warstwy: \"" + activeLayer.name + "\"\nLiczba kolorów: " + k + "\n\nKliknij OK, aby rozpocząć analizę.");

    // Solidne ścieżki do folderów
    var scriptFile = new File($.fileName);
    var projectRoot = scriptFile.parent.parent; 
    var tempFolder = new Folder(projectRoot + "/temp_jsx");
    if (!tempFolder.exists) tempFolder.create();

    var sourceFile = null;
    
    try {
        // Zapisz aktywną warstwę do pliku TIFF
        sourceFile = saveLayerToPNG(doc, activeLayer, tempFolder, "palette_source");

        // Wyślij do serwera i otrzymaj paletę
        var response = executeCurl(sourceFile, k);
        
        // NOWY PROSTY PARSER - zamiast JSON używamy CSV
        var palette = parseSimpleResponse(response);
        
        // Wizualizuj paletę w dokumencie
        visualizePalette(doc, activeLayer, palette);
        
        alert("Gotowe! Paleta kolorów została wygenerowana.");

    } catch (e) {
        alert("Wystąpił błąd: \n" + e.message);
    } finally {
        // Posprzątaj po sobie
        cleanupFile(sourceFile);
    }
}

function parseSimpleResponse(response) {
    /**
     * Parsuje prostą odpowiedź w formacie:
     * success,4,255,0,0,0,255,255,0,255,0,0,0,255
     * lub
     * error,komunikat błędu
     */
    try {
        // Usuń białe znaki
        response = response.replace(/^\s+|\s+$/g, "");
        
        // Podziel po przecinkach
        var parts = response.split(",");
        
        if (parts.length < 1) {
            throw new Error("Pusta odpowiedź serwera");
        }
        
        var status = parts[0];
        
        if (status === "error") {
            var errorMessage = parts.length > 1 ? parts[1] : "Nieznany błąd";
            throw new Error("Błąd serwera: " + errorMessage);
        }
        
        if (status !== "success") {
            throw new Error("Nieznany status: " + status);
        }
        
        if (parts.length < 2) {
            throw new Error("Brak informacji o liczbie kolorów");
        }
        
        var colorCount = parseInt(parts[1]);
        if (isNaN(colorCount) || colorCount < 1) {
            throw new Error("Nieprawidłowa liczba kolorów: " + parts[1]);
        }
        
        // Sprawdź czy mamy odpowiednią liczbę wartości RGB
        var expectedValues = 2 + (colorCount * 3); // status + count + (r,g,b)*colorCount
        if (parts.length < expectedValues) {
            throw new Error("Za mało wartości kolorów. Oczekiwano: " + expectedValues + ", otrzymano: " + parts.length);
        }
        
        // Parsuj kolory
        var palette = [];
        for (var i = 0; i < colorCount; i++) {
            var r = parseInt(parts[2 + i * 3]);
            var g = parseInt(parts[3 + i * 3]);
            var b = parseInt(parts[4 + i * 3]);
            
            if (isNaN(r) || isNaN(g) || isNaN(b)) {
                throw new Error("Nieprawidłowe wartości RGB dla koloru " + (i + 1));
            }
            
            palette.push([r, g, b]);
        }
        
        return palette;
        
    } catch (e) {
        throw new Error("Błąd parsowania odpowiedzi: " + e.message + "\nOdpowiedź: " + response);
    }
}

// --- FUNKCJE POMOCNICZE ---

function saveLayerToPNG(doc, layer, folderPath, prefix) {
    var originalVisibility = [];
    var activeLayer = doc.activeLayer;

    // Zapisz obecny stan widoczności warstw
    for (var i = 0; i < doc.layers.length; i++) {
        originalVisibility.push({ layer: doc.layers[i], visible: doc.layers[i].visible });
    }

    var filePath = null;

    try {
        // Ukryj wszystkie warstwy oprócz analizowaneи
        for (var i = 0; i < originalVisibility.length; i++) {
            originalVisibility[i].layer.visible = false;
        }
        layer.visible = true;

        filePath = new File(folderPath + "/" + prefix + "_" + Date.now() + ".tif");
        var tiffOptions = new TiffSaveOptions();
        tiffOptions.imageCompression = TIFFEncoding.NONE;
        tiffOptions.byteOrder = ByteOrder.IBM;

        doc.saveAs(filePath, tiffOptions, true, Extension.LOWERCASE);
    } catch(e) {
        throw new Error("Błąd podczas zapisu warstwy do pliku TIFF: " + e.message);
    } finally {
        // Przywróć stan widoczności warstw
        for (var i = 0; i < originalVisibility.length; i++) {
            originalVisibility[i].layer.visible = originalVisibility[i].visible;
        }
        doc.activeLayer = activeLayer;
    }
    return filePath;
}

function executeCurl(sourceFile, k) {
    var command = 'curl -s -X POST ' +
                  '-F "source_image=@' + sourceFile.fsName + '" ' +
                  '-F "k=' + k + '" ' +
                  SERVER_URL;

    var result = "";
    var tempFolder = sourceFile.parent;

    if ($.os.indexOf("Windows") > -1) {
        var cmdFile = new File(tempFolder + "/photoshop_curl.cmd");
        var stdoutFile = new File(tempFolder + "/curl_stdout.txt");
        
        try {
            cmdFile.open("w");
            cmdFile.encoding = "UTF-8";
            cmdFile.writeln("@echo off");
            cmdFile.writeln(command);
            cmdFile.close();
            
            if (stdoutFile.exists) stdoutFile.remove();
            
            app.system('cmd /c ""' + cmdFile.fsName + '" > "' + stdoutFile.fsName + '""');
            
            // Oczekiwanie na odpowiedź serwera
            var maxWaitTime = 10000; // 10 sekund
            var waitInterval = 500;   // sprawdzaj co 0.5 sekundy
            var totalWait = 0;
            
            while (totalWait < maxWaitTime && (!stdoutFile.exists || stdoutFile.length === 0)) {
                $.sleep(waitInterval);
                totalWait += waitInterval;
            }

            if (stdoutFile.exists && stdoutFile.length > 0) {
                stdoutFile.open("r");
                result = stdoutFile.read();
                stdoutFile.close();
            }
        } finally {
            cleanupFile(cmdFile);
            cleanupFile(stdoutFile);
        }
    } else {
        result = app.doScript('do shell script "' + command + '"', Language.APPLESCRIPT);
    }

    // Własna implementacja trim() dla starszych wersji JSX
    var trimmedResult = result.replace(/^\s+|\s+$/g, "");
    if (trimmedResult === "") {
        throw new Error("Nie otrzymano odpowiedzi od serwera lub odpowiedź jest pusta. Upewnij się, że serwer jest uruchomiony.");
    }
    return result;
}

function visualizePalette(doc, sourceLayer, palette) {
    try {
        // Utwórz nową grupę warstw
        var layerSet = doc.layerSets.add();
        layerSet.name = "Analiza Palety - " + sourceLayer.name;
        
        // Utwórz nową warstwę w grupie dla kolorów
        doc.activeLayer = layerSet;
        var paletteLayer = doc.artLayers.add();
        paletteLayer.name = "Paleta Kolorów";
        
        // Konfiguracja wizualizacji - ładniejszy układ w siatce
        var squareSize = 80;  // większe kwadraty
        var spacing = 15;     // większy odstęp
        var startX = 100;     // pozycja startowa X
        var startY = 100;     // pozycja startowa Y
        var columns = 4;      // liczba kolumn w siatce
        
        // Iteruj przez kolory w palecie - układ w siatce
        for (var i = 0; i < palette.length; i++) {
            var color = palette[i];
            var r = color[0];
            var g = color[1];
            var b = color[2];
            
            // Ustaw kolor pierwszego planu w Photoshopie
            var foregroundColor = new SolidColor();
            foregroundColor.rgb.red = r;
            foregroundColor.rgb.green = g;
            foregroundColor.rgb.blue = b;
            app.foregroundColor = foregroundColor;
            
            // Oblicz pozycję kwadratu w siatce
            var x = startX + (i % columns) * (squareSize + spacing);
            var y = startY + Math.floor(i / columns) * (squareSize + spacing + 60); // +60 na etykiety
            
            // Utwórz zaznaczenie prostokątne
            var selectionArray = [
                [x, y],
                [x + squareSize, y],
                [x + squareSize, y + squareSize],
                [x, y + squareSize]
            ];
            doc.selection.select(selectionArray);
            
            // Wypełnij zaznaczenie kolorem
            doc.selection.fill(foregroundColor);
        }
        
        // Usuń zaznaczenie
        doc.selection.deselect();
        
        // Dodaj etykiety pod kwadratami - każda w nowej linii
        addColorLabels(doc, layerSet, palette, startX, startY, squareSize, spacing, columns);
        
    } catch (e) {
        throw new Error("Błąd podczas wizualizacji palety: " + e.message);
    }
}

function addColorLabels(doc, layerSet, palette, startX, startY, squareSize, spacing, columns) {
    try {
        for (var i = 0; i < palette.length; i++) {
            var color = palette[i];
            var r = color[0];
            var g = color[1];
            var b = color[2];
            
            // Konwertuj RGB na HEX
            var hex = "#" + 
                      ("0" + r.toString(16)).slice(-2) + 
                      ("0" + g.toString(16)).slice(-2) + 
                      ("0" + b.toString(16)).slice(-2);
            
            // Oblicz pozycję tekstu - środek kwadratu
            var x = startX + (i % columns) * (squareSize + spacing) + squareSize/2;
            var y = startY + Math.floor(i / columns) * (squareSize + spacing + 60); // +60 na etykiety
            
            // Numer koloru (nad kodem HEX)
            var numberLayer = doc.artLayers.add();
            numberLayer.kind = LayerKind.TEXT;
            numberLayer.name = "Numer " + (i + 1);
            
            var numberItem = numberLayer.textItem;
            numberItem.contents = (i + 1).toString();
            numberItem.position = [x, y + squareSize + 5];  // pod kwadratem
            numberItem.size = 14;
            numberItem.justification = Justification.CENTER;
            
            // Ustaw kolor tekstu na czarny
            var blackColor = new SolidColor();
            blackColor.rgb.red = 0;
            blackColor.rgb.green = 0;
            blackColor.rgb.blue = 0;
            numberItem.color = blackColor;
            
            // Kod HEX (pod numerem)
            var hexLayer = doc.artLayers.add();
            hexLayer.kind = LayerKind.TEXT;
            hexLayer.name = "HEX " + (i + 1);
            
            var hexItem = hexLayer.textItem;
            hexItem.contents = hex.toUpperCase();
            hexItem.position = [x, y + squareSize + 20];  // nieco niżej
            hexItem.size = 10;
            hexItem.justification = Justification.CENTER;
            hexItem.color = blackColor;
            
            // RGB (na samym dole)
            var rgbLayer = doc.artLayers.add();
            rgbLayer.kind = LayerKind.TEXT;
            rgbLayer.name = "RGB " + (i + 1);
            
            var rgbItem = rgbLayer.textItem;
            rgbItem.contents = "R:" + r + " G:" + g + " B:" + b;
            rgbItem.position = [x, y + squareSize + 35];  // jeszcze niżej
            rgbItem.size = 8;
            rgbItem.justification = Justification.CENTER;
            rgbItem.color = blackColor;
            
            // Przenieś wszystkie warstwy tekstowe do grupy
            numberLayer.move(layerSet, ElementPlacement.INSIDE);
            hexLayer.move(layerSet, ElementPlacement.INSIDE);
            rgbLayer.move(layerSet, ElementPlacement.INSIDE);
        }
    } catch (e) {
        // Jeśli dodawanie etykiet się nie powiedzie, nie przerywaj całego procesu
        alert("Ostrzeżenie: Nie udało się dodać etykiet tekstowych: " + e.message);
    }
}

function cleanupFile(file) {
    if (file && file.exists) {
        try {
            file.remove();
        } catch (e) {
            // Ignoruj błędy usuwania
        }
    }
}

// Konwersja liczby na hex (pomocnicza funkcja)
function toHex(n) {
    var hex = n.toString(16);
    return hex.length === 1 ? "0" + hex : hex;
}

// --- URUCHOMIENIE ---
main();

``````

#### test_simple.jsx - ./app/scripts/test_simple.jsx

``````
// Prosty test JSX
#target photoshop

try {
    alert("Test JSX działa!");
    
    // Test logowania
    var desktop = Folder.desktop;
    var logFile = new File(desktop + "/jsx_test.txt");
    logFile.open("w");
    logFile.writeln("JSX test działa: " + new Date());
    logFile.close();
    
    alert("Log zapisany na pulpicie!");
    
} catch (e) {
    alert("Błąd: " + e.message);
}

``````

---
