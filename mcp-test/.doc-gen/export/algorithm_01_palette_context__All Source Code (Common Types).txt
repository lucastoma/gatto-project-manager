Collected context from directory: D:\projects\gatto-ps-ai\app\algorithms\algorithm_01_palette
Filter used: All Source Code (Common Types)
Patterns: ['*.py', '*.js', '*.java', '*.c', '*.cpp', '*.h', '*.hpp', '*.cs', '*.go', '*.rb', '*.php', '*.swift', '*.kt', '*.kts', '*.rs', '*.scala', '*.sh', '*.ps1']
Total files processed: 25
================================================================================

--- File: algorithm.py ---
import logging
import numpy as np
from PIL import Image, ImageFilter
import time
import json
from skimage import color
from sklearn.cluster import KMeans
from typing import TYPE_CHECKING, Any, Dict, List

# --- Lepsza obsługa opcjonalnych zależności ---
try:
    from tqdm import tqdm
except ImportError:
    tqdm = lambda x, **kwargs: x

try:
    from scipy.spatial import KDTree
    from scipy import ndimage

    SCIPY_AVAILABLE = True
except ImportError:
    KDTree, ndimage = None, None
    SCIPY_AVAILABLE = False
# --- Koniec obsługi zależności ---

try:
    from ...core.development_logger import get_logger
    from ...core.performance_profiler import get_profiler

    if TYPE_CHECKING:
        from ...core.development_logger import DevelopmentLogger
        from ...core.performance_profiler import PerformanceProfiler
except ImportError:

    def get_logger() -> Any:
        logging.basicConfig(
            level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
        )
        return logging.getLogger(__name__)

    class DummyProfiler:
        def start(self, name):
            pass

        def stop(self, name):
            pass

        def get_report(self):
            return "Profiler not available."

        def profile_operation(self, *args, **kwargs):
            import contextlib

            return contextlib.nullcontext()

    def get_profiler() -> Any:
        return DummyProfiler()


class PaletteMappingAlgorithm:
    def __init__(
        self, config_path: str = None, algorithm_id: str = "algorithm_01_palette"
    ):
        self.algorithm_id = algorithm_id
        if TYPE_CHECKING:
            self.logger: "DevelopmentLogger" = get_logger()
            self.profiler: "PerformanceProfiler" = get_profiler()
        else:
            self.logger = get_logger()
            self.profiler = get_profiler()

        self.logger.info(f"Initialized algorithm: {self.algorithm_id}")
        self.name = "Palette Mapping Refactored"
        self.version = "2.5-ColorFocus"
        self.default_config_values = self._get_default_config()
        self.config = (
            self.load_config(config_path)
            if config_path
            else self.default_config_values.copy()
        )
        if not SCIPY_AVAILABLE:
            self.logger.warning(
                "Scipy not installed. Advanced features (KDTree, Edge Blending) are disabled."
            )

        self.bayer_matrix_8x8 = np.array(
            [
                [0, 32, 8, 40, 2, 34, 10, 42],
                [48, 16, 56, 24, 50, 18, 58, 26],
                [12, 44, 4, 36, 14, 46, 6, 38],
                [60, 28, 52, 20, 62, 30, 54, 22],
                [3, 35, 11, 43, 1, 33, 9, 41],
                [51, 19, 59, 27, 49, 17, 57, 25],
                [15, 47, 7, 39, 13, 45, 5, 37],
                [63, 31, 55, 23, 61, 29, 53, 21],
            ]
        )

    def _get_default_config(self) -> Dict[str, Any]:
        return {
            "num_colors": 16,
            "palette_method": "kmeans",
            "quality": 5,
            "distance_metric": "weighted_hsv",
            "hue_weight": 3.0,
            "use_color_focus": False,
            "focus_ranges": [],  # Lista obiektów definiujących zakresy
            "dithering_method": "none",
            "dithering_strength": 8.0,
            "inject_extremes": False,
            "preserve_extremes": False,
            "extremes_threshold": 10,
            "edge_blur_enabled": False,
            "edge_blur_radius": 1.5,
            "edge_blur_strength": 0.3,
            "edge_detection_threshold": 25,
            "postprocess_median_filter": False,
        }

    # --- Backward compatibility helper ---
    def default_config(self) -> Dict[str, Any]:
        """Zachowana dla kompatybilności wstecznej (stare testy)."""
        return self.default_config_values

    # ... (metody load_config, validate_palette, extract_palette pozostają bez zmian) ...
    def load_config(self, config_path: str) -> Dict[str, Any]:
        config = self.default_config_values.copy()
        try:
            with open(config_path, "r", encoding="utf-8") as f:
                user_config = json.load(f)
            config.update(user_config)
            return config
        except Exception as e:
            self.logger.error(f"Error loading configuration: {e}, using default.")
            return config

    def validate_palette(self, palette: List[List[int]]):
        if not palette:
            raise ValueError("Palette cannot be empty")
        for i, color_val in enumerate(palette):
            if len(color_val) != 3:
                raise ValueError(f"Color {i} must have 3 components")
            if not all(0 <= c <= 255 for c in color_val):
                raise ValueError(f"Color {i} has values outside 0-255")

    def extract_palette(
        self,
        image_path: str,
        num_colors: int,
        method: str,
        quality: int,
        inject_extremes: bool,
    ) -> List[List[int]]:
        with self.profiler.profile_operation(
            "extract_palette", algorithm_id=self.algorithm_id
        ):
            try:
                image = Image.open(image_path)
                if image.mode == "RGBA":
                    background = Image.new("RGB", image.size, (255, 255, 255))
                    background.paste(image, mask=image.split()[-1])
                    image = background
                elif image.mode != "RGB":
                    image = image.convert("RGB")

                base_size, max_size = 100, 1000
                thumbnail_size_val = int(
                    base_size + (max_size - base_size) * (quality - 1) / 9.0
                )
                image.thumbnail((thumbnail_size_val, thumbnail_size_val))
                self.logger.info(
                    f"Analyzing palette (quality: {quality}/10, size: {thumbnail_size_val}px, method: '{method}')"
                )

                if method == "median_cut":
                    quantized_image = image.quantize(
                        colors=num_colors, method=Image.MEDIANCUT, dither=Image.NONE
                    )
                    palette_raw = quantized_image.getpalette()
                    num_actual_colors = len(palette_raw) // 3
                    palette = [
                        list(palette_raw[i * 3 : i * 3 + 3])
                        for i in range(num_actual_colors)
                    ]
                else:
                    img_array = np.array(image)
                    pixels = img_array.reshape(-1, 3)
                    kmeans = KMeans(n_clusters=num_colors, random_state=42, n_init=10)
                    kmeans.fit(pixels)
                    palette = kmeans.cluster_centers_.astype(int).tolist()

                palette = [
                    [max(0, min(255, c)) for c in color_val] for color_val in palette
                ]
                if inject_extremes:
                    if [0, 0, 0] not in palette:
                        palette.insert(0, [0, 0, 0])
                    if [255, 255, 255] not in palette:
                        palette.append([255, 255, 255])
                self.validate_palette(palette)
                self.logger.info(f"Extracted {len(palette)} colors.")
                return palette
            except Exception as e:
                self.logger.error(f"Error extracting palette: {e}", exc_info=True)
                return [[0, 0, 0], [128, 128, 128], [255, 255, 255]]

    def _calculate_hsv_distance_sq(self, pixels_hsv, palette_hsv, weights):
        """Oblicza kwadrat ważonej odległości w HSV, używając tablicy wag."""
        delta_sv = pixels_hsv[:, np.newaxis, 1:] - palette_hsv[np.newaxis, :, 1:]
        delta_h_abs = np.abs(
            pixels_hsv[:, np.newaxis, 0] - palette_hsv[np.newaxis, :, 0]
        )
        delta_h = np.minimum(delta_h_abs, 1.0 - delta_h_abs)

        # Tworzenie pełnej macierzy delty
        delta_hsv = np.concatenate((delta_h[..., np.newaxis], delta_sv), axis=2)

        # Zastosowanie wag (broadcasting)
        # weights mają kształt (N, 3), delta_hsv ma (N, M, 3) -> weights[:, np.newaxis, :] ma (N, 1, 3)
        weighted_delta_hsv = delta_hsv * weights[:, np.newaxis, :]

        return np.sum(weighted_delta_hsv**2, axis=2)

    def _map_pixels_to_palette(
        self, image_array: np.ndarray, palette: List[List[int]], config: Dict[str, Any]
    ) -> np.ndarray:
        with self.profiler.profile_operation(
            "map_pixels_to_palette", algorithm_id=self.algorithm_id
        ):
            metric = config.get("distance_metric")
            palette_np = np.array(palette, dtype=np.float32)
            pixels_flat = image_array.reshape(-1, 3).astype(np.float32)

            if "hsv" in metric:
                pixels_hsv = color.rgb2hsv(pixels_flat / 255.0)
                palette_hsv = color.rgb2hsv(palette_np / 255.0)

                # Ustawienie domyślnych wag
                weights = np.full(
                    (pixels_hsv.shape[0], 3), [config.get("hue_weight", 3.0), 1.0, 1.0]
                )

                distances_sq = self._calculate_hsv_distance_sq(
                    pixels_hsv, palette_hsv, weights
                )  # POPRAWIONA LOGIKA "Color Focus"
                self.logger.info(
                    f"COLOR FOCUS DEBUG: use_color_focus = {config.get('use_color_focus', False)}"
                )
                self.logger.info(
                    f"COLOR FOCUS DEBUG: focus_ranges = {config.get('focus_ranges', [])}"
                )
                if config.get("use_color_focus", False) and config.get("focus_ranges"):
                    self.logger.info(
                        f"Using Color Focus with {len(config['focus_ranges'])} range(s)."
                    )

                    # Dla każdego focus range
                    for i, focus in enumerate(config["focus_ranges"]):
                        target_h = focus["target_hsv"][0] / 360.0
                        target_s = focus["target_hsv"][1] / 100.0
                        target_v = focus["target_hsv"][2] / 100.0

                        range_h = focus["range_h"] / 360.0
                        range_s = focus["range_s"] / 100.0
                        range_v = focus["range_v"] / 100.0

                        # Sprawdź które KOLORY Z PALETY pasują do focus range
                        palette_h_dist = np.abs(palette_hsv[:, 0] - target_h)
                        palette_hue_mask = np.minimum(
                            palette_h_dist, 1.0 - palette_h_dist
                        ) <= (range_h / 2.0)
                        palette_sat_mask = np.abs(palette_hsv[:, 1] - target_s) <= (
                            range_s / 2.0
                        )
                        palette_val_mask = np.abs(palette_hsv[:, 2] - target_v) <= (
                            range_v / 2.0
                        )

                        palette_final_mask = (
                            palette_hue_mask & palette_sat_mask & palette_val_mask
                        )

                        if np.sum(palette_final_mask) > 0:
                            # APLIKUJ COLOR FOCUS: zmniejsz odległości do preferowanych kolorów palety
                            boost = focus.get("boost_factor", 1.0)
                            distances_sq[:, palette_final_mask] /= boost
                            self.logger.info(
                                f"Color Focus applied: boosted {np.sum(palette_final_mask)} palette colors by factor {boost}"
                            )
                        else:
                            self.logger.warning(
                                f"Color Focus range {i+1}: no palette colors matched the specified range"
                            )

                closest_indices = np.argmin(distances_sq, axis=1)

            elif metric == "lab" and SCIPY_AVAILABLE:
                palette_lab = color.rgb2lab(palette_np / 255.0)
                kdtree = KDTree(palette_lab)
                pixels_lab = color.rgb2lab(pixels_flat / 255.0)
                _, closest_indices = kdtree.query(pixels_lab)
            else:
                if metric == "lab":
                    self.logger.warning(
                        "LAB metric used without Scipy. Falling back to slow calculation."
                    )
                weights = (
                    np.array([0.2126, 0.7152, 0.0722])
                    if metric == "weighted_rgb"
                    else np.array([1.0, 1.0, 1.0])
                )
                distances = np.sqrt(
                    np.sum(
                        (
                            (
                                pixels_flat[:, np.newaxis, :]
                                - palette_np[np.newaxis, :, :]
                            )
                            * weights
                        )
                        ** 2,
                        axis=2,
                    )
                )
                closest_indices = np.argmin(distances, axis=1)

            return palette_np[closest_indices].reshape(image_array.shape)

    def _apply_ordered_dithering(
        self, image_array: np.ndarray, strength: float
    ) -> np.ndarray:
        with self.profiler.profile_operation(
            "apply_ordered_dithering", algorithm_id=self.algorithm_id
        ):
            self.logger.info(
                f"Applying fast ordered dithering with strength {strength}."
            )
            h, w, _ = image_array.shape
            bayer_norm = self.bayer_matrix_8x8 / 64.0 - 0.5
            tiled_bayer = np.tile(bayer_norm, (h // 8 + 1, w // 8 + 1))[:h, :w]
            # Scale pattern by 255 so max strength=1.0 adds roughly ±127 intensity,
            # strength=0.5 adds ±64 etc.  This yields visible difference and ensures
            # variance grows monotonically with strength.
            dither_pattern = tiled_bayer[:, :, np.newaxis] * (strength * 255.0)

            dithered_image = np.clip(
                image_array.astype(np.float32) + dither_pattern, 0.0, 255.0
            )
            return dithered_image

    def _apply_edge_blending(
        self, mapped_image: Image.Image, config: Dict[str, Any]
    ) -> Image.Image:
        # ... (bez zmian)
        with self.profiler.profile_operation(
            "apply_edge_blending", algorithm_id=self.algorithm_id
        ):
            if not SCIPY_AVAILABLE:
                self.logger.warning(
                    "Scipy not installed. Falling back to simple Gaussian blur for edge blending."
                )
                return mapped_image.filter(
                    ImageFilter.GaussianBlur(radius=config["edge_blur_radius"])
                )

            self.logger.info("Applying advanced edge blending.")
            mapped_array = np.array(mapped_image, dtype=np.float64)
            gray = np.dot(mapped_array[..., :3], [0.2989, 0.5870, 0.1140])
            grad_x = ndimage.sobel(gray, axis=1)
            grad_y = ndimage.sobel(gray, axis=0)
            magnitude = np.sqrt(grad_x**2 + grad_y**2)
            edge_mask = magnitude > config["edge_detection_threshold"]

            radius = int(config["edge_blur_radius"])
            if radius > 0:
                edge_mask = ndimage.binary_dilation(edge_mask, iterations=radius)

            blurred_array = mapped_array.copy()
            for channel in range(3):
                blurred_array[:, :, channel] = ndimage.gaussian_filter(
                    mapped_array[:, :, channel], sigma=config["edge_blur_radius"]
                )

            blend_factor = (edge_mask * config["edge_blur_strength"])[:, :, np.newaxis]
            result_array = (
                mapped_array * (1 - blend_factor) + blurred_array * blend_factor
            )

            return Image.fromarray(np.clip(result_array, 0, 255).astype(np.uint8))

    def _preserve_extremes(
        self, mapped_array: np.ndarray, original_array: np.ndarray, threshold: int
    ) -> np.ndarray:
        with self.profiler.profile_operation(
            "preserve_extremes", algorithm_id=self.algorithm_id
        ):
            self.logger.info("Preserving extreme light and shadow areas.")
            luminance = np.dot(original_array[..., :3], [0.2989, 0.5870, 0.1140])
            black_mask = luminance <= threshold
            white_mask = luminance >= (255 - threshold)
            mapped_array[black_mask] = [0, 0, 0]
            mapped_array[white_mask] = [255, 255, 255]
            return mapped_array

    def process_images(
        self, master_path: str, target_path: str, output_path: str, **kwargs
    ) -> bool:
        with self.profiler.profile_operation(
            "process_images_full", algorithm_id=self.algorithm_id
        ):
            # Handle distance cache flag transparently for CPU implementation
            kwargs.pop("distance_cache_enabled", None)
            run_config = self.default_config_values.copy()
            run_config.update(kwargs)

            self.logger.info(f"Processing with effective config: {run_config}")

            try:
                target_image = Image.open(target_path).convert("RGB")
                target_array = np.array(target_image)
                self.logger.info(f"Target: {target_image.size}")

                palette = self.extract_palette(
                    master_path,
                    num_colors=run_config["num_colors"],
                    method=run_config["palette_method"],
                    quality=run_config["quality"],
                    inject_extremes=run_config["inject_extremes"],
                )

                array_to_map = target_array
                # Auto-enable ordered dithering if strength > 0 but method is 'none'
                if (
                    run_config["dithering_method"] == "none"
                    and run_config.get("dithering_strength", 0.0) > 0.0
                ):
                    self.logger.info(
                        "Dithering strength > 0 but method 'none'; switching to 'ordered'."
                    )
                    run_config["dithering_method"] = "ordered"

                if run_config["dithering_method"] == "ordered":
                    array_to_map = self._apply_ordered_dithering(
                        target_array, run_config["dithering_strength"]
                    )

                mapped_array = self._map_pixels_to_palette(
                    array_to_map, palette, run_config
                )

                if run_config["preserve_extremes"]:
                    mapped_array = self._preserve_extremes(
                        mapped_array, target_array, run_config["extremes_threshold"]
                    )

                mapped_image = Image.fromarray(
                    np.clip(mapped_array, 0, 255).astype(np.uint8), "RGB"
                )

                if run_config["edge_blur_enabled"]:
                    mapped_image = self._apply_edge_blending(mapped_image, run_config)

                if run_config["postprocess_median_filter"] and SCIPY_AVAILABLE:
                    self.logger.info(
                        "Applying post-process median filter to reduce noise."
                    )
                    filtered_array = ndimage.median_filter(
                        np.array(mapped_image), size=3
                    )
                    mapped_image = Image.fromarray(filtered_array)

                mapped_image.save(output_path)
                self.logger.success(
                    f"Successfully processed and saved image to {output_path}"
                )
                return True

            except FileNotFoundError as e:
                self.logger.error(f"File not found: {e}", exc_info=True)
                return False
            except Exception as e:
                self.logger.error(
                    f"An unexpected error occurred during image processing: {e}",
                    exc_info=True,
                )
                return False


def create_palette_mapping_algorithm():
    return PaletteMappingAlgorithm()

--- File: algorithm_gpu.py ---
import numpy as np
import pyopencl as cl
from PIL import Image, ImageFilter
import logging
import time
import threading
import os
from typing import Any, Dict, List, Optional

# Logika pomocnicza i fallbacki
from . import algorithm_gpu_utils as utils
from . import algorithm_gpu_cpu_fallback as cpu
from . import algorithm_gpu_exceptions as err
from . import algorithm_gpu_config as cfg

# Zależności
try:
    from scipy import ndimage
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False


class OpenCLManager:
    _instance = None
    _lock = threading.Lock()

    def __new__(cls):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super(OpenCLManager, cls).__new__(cls)
                cls._instance._initialized = False
                cls._instance.ctx: Optional[cl.Context] = None
                cls._instance.queue: Optional[cl.CommandQueue] = None
                cls._instance.prg: Optional[cl.Program] = None
                cls._instance.logger = utils.get_logger()
        return cls._instance

    def ensure_initialized(self):
        if self._initialized:
            return
        with self._lock:
            if self._initialized:
                return
            self.logger.info("OpenCLManager: Rozpoczynam leniwą inicjalizację...")
            try:
                platforms = cl.get_platforms()
                if not platforms:
                    raise RuntimeError("Nie znaleziono platform OpenCL. Sprawdź sterowniki.")
                gpu_devices = []
                for p in platforms:
                    try:
                        gpu_devices.extend(p.get_devices(device_type=cl.device_type.GPU))
                    except cl.LogicError:
                        continue
                if not gpu_devices:
                    self.logger.warning("Nie znaleziono GPU, próbuję użyć CPU jako urządzenia OpenCL.")
                    cpu_devices = []
                    for p in platforms:
                        try:
                            cpu_devices.extend(p.get_devices(device_type=cl.device_type.CPU))
                        except cl.LogicError:
                            continue
                    if not cpu_devices:
                        raise RuntimeError("Nie znaleziono żadnych urządzeń OpenCL (ani GPU, ani CPU).")
                    device = cpu_devices[0]
                else:
                    device = gpu_devices[0]
                self.ctx = cl.Context([device])
                self.queue = cl.CommandQueue(self.ctx)
                self.logger.info(f"Zainicjalizowano OpenCL na urządzeniu: {device.name}")
                self._compile_kernel_from_file()
                self._initialized = True
                self.logger.info("OpenCLManager: Leniwa inicjalizacja zakończona pomyślnie.")
            except Exception as e:
                self.logger.error(f"KRYTYCZNY BŁĄD: Inicjalizacja OpenCL nie powiodła się: {e}", exc_info=True)
                self.ctx = None
                self.queue = None
                self.prg = None
                self._initialized = False
                raise err.GPUProcessingError(f"Inicjalizacja OpenCL nie powiodła się: {e}") from e

    def _compile_kernel_from_file(self):
        try:
            kernel_file_path = os.path.join(os.path.dirname(__file__), 'palette_mapping.cl')
            with open(kernel_file_path, 'r', encoding='utf-8') as kernel_file:
                kernel_code = kernel_file.read()
            self.prg = cl.Program(self.ctx, kernel_code).build()
        except cl.LogicError as e:
            self.logger.error(f"Błąd kompilacji kernela OpenCL: {e}")
            raise err.GPUProcessingError(f"Błąd kompilacji kernela: {e}")
        except FileNotFoundError:
            self.logger.error(f"Plik kernela 'palette_mapping.cl' nie został znaleziony.")
            raise err.GPUProcessingError("Nie znaleziono pliku kernela OpenCL.")

    def get_context(self) -> cl.Context:
        self.ensure_initialized()
        if not self.ctx:
            raise err.GPUProcessingError("Kontekst OpenCL jest niedostępny.")
        return self.ctx

    def get_queue(self) -> cl.CommandQueue:
        self.ensure_initialized()
        if not self.queue:
            raise err.GPUProcessingError("Kolejka poleceń OpenCL jest niedostępna.")
        return self.queue

    def get_program(self) -> cl.Program:
        self.ensure_initialized()
        if not self.prg:
            raise err.GPUProcessingError("Program kernela OpenCL jest niedostępny.")
        return self.prg



class PaletteMappingAlgorithmGPU:
    def __init__(self, config_path: str = None, algorithm_id: str = "algorithm_01_palette_production"):
        self.algorithm_id = algorithm_id
        self.logger = utils.get_logger()
        self.profiler = utils.get_profiler()
        self.name = "Palette Mapping (OpenCL Production)"
        self.version = "12.0-Final"
        self.default_config = cfg.get_default_config()
        self.config = cfg.load_config(config_path, self.default_config) if config_path else self.default_config.copy()
        self.bayer_matrix_8x8 = np.array([[0,32,8,40,2,34,10,42],[48,16,56,24,50,18,58,26],[12,44,4,36,14,46,6,38],[60,28,52,20,62,30,54,22],[3,35,11,43,1,33,9,41],[51,19,59,27,49,17,57,25],[15,47,7,39,13,45,5,37],[63,31,55,23,61,29,53,21]])

    def _apply_ordered_dithering(self, image_array: np.ndarray, strength: float) -> np.ndarray:
        """Zoptymalizowana, wektorowa implementacja ditheringu."""
        self.logger.info(f"Stosuję dithering z siłą {strength}.")
        h, w, _ = image_array.shape
        bayer_norm = self.bayer_matrix_8x8 / 64.0 - 0.5
        tiled_bayer = np.tile(bayer_norm, (h // 8 + 1, w // 8 + 1))[:h, :w]
        dither_pattern = tiled_bayer[:, :, np.newaxis] * strength
        return np.clip(image_array.astype(np.float32) + dither_pattern, 0, 255)

    def _preserve_extremes(self, mapped_array: np.ndarray, original_array: np.ndarray, threshold: int) -> np.ndarray:
        """Ulepszona wersja oparta na luminancji."""
        self.logger.info("Zachowuję skrajne wartości czerni i bieli.")
        luminance = np.dot(original_array[..., :3], [0.2989, 0.5870, 0.1140])
        black_mask = luminance <= threshold
        white_mask = luminance >= (255 - threshold)
        mapped_array[black_mask] = [0, 0, 0]
        mapped_array[white_mask] = [255, 255, 255]
        return mapped_array

    def _gaussian_weights(self, radius: int) -> np.ndarray:
        sigma = max(radius / 2.0, 0.1)
        offsets = np.arange(-radius, radius + 1, dtype=np.float32)
        weights = np.exp(-offsets ** 2 / (2 * sigma * sigma))
        weights /= weights.sum()
        return weights.astype(np.float32)

    def _blur_image_gpu_gauss(self, image_array: np.ndarray, radius: int) -> Optional[np.ndarray]:
        """Separable Gaussian blur on GPU using two 1-D passes."""
        if radius <= 0:
            return image_array
        h, w, _ = image_array.shape
        flat = image_array.astype(np.uint8).reshape(-1)
        weights = self._gaussian_weights(radius)
        try:
            cl_mgr = OpenCLManager()
            ctx = cl_mgr.get_context()
            queue = cl_mgr.get_queue()
            prg = cl_mgr.get_program()
            mf = cl.mem_flags
            buf_in = cl.Buffer(ctx, mf.READ_WRITE | mf.COPY_HOST_PTR, hostbuf=flat)
            buf_temp = cl.Buffer(ctx, mf.READ_WRITE, flat.nbytes)
            buf_out = cl.Buffer(ctx, mf.READ_WRITE, flat.nbytes)
            buf_w = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=weights)

            global_size = (h * w,)
            # horizontal pass
            prg.gaussian_blur_h(queue, global_size, None,
                                buf_in, buf_temp, buf_w,
                                np.int32(radius), np.int32(w), np.int32(h))
            # vertical pass
            prg.gaussian_blur_v(queue, global_size, None,
                                buf_temp, buf_out, buf_w,
                                np.int32(radius), np.int32(w), np.int32(h))

            cl.enqueue_copy(queue, flat, buf_out).wait()
            for b in (buf_in, buf_temp, buf_out, buf_w):
                b.release()
            return flat.reshape((h, w, 3))
        except Exception as e:
            self.logger.warning(f"GPU gaussian blur nie powiódł się: {e}. Użycie CPU jako fallback (jeśli zaimplementowano).")
            return None

    def _apply_edge_blending(self, mapped_image: Image.Image, config: Dict[str, Any]) -> Image.Image:
        if not SCIPY_AVAILABLE:
            # brak Scipy; spróbuj GPU box blur bez maski krawędzi? potrzebujemy ndimage do maski
            self.logger.warning("Scipy niedostępne – nie mogę wygenerować maski krawędzi. Pomijam edge blur.")
            return mapped_image
        self.logger.info("Stosuję zaawansowane wygładzanie krawędzi.")
        mapped_array = np.array(mapped_image, dtype=np.float64)
        gray = np.dot(mapped_array[..., :3], [0.2989, 0.5870, 0.1140])
        from scipy import ndimage  # import lokalny, jeśli dostępny
        grad_x = ndimage.sobel(gray, axis=1); grad_y = ndimage.sobel(gray, axis=0)
        magnitude = np.sqrt(grad_x**2 + grad_y**2)
        edge_mask = magnitude > config["edge_detection_threshold"]
        radius = int(config["edge_blur_radius"])
        if radius > 0:
            edge_mask = ndimage.binary_dilation(edge_mask, iterations=radius)
        
        use_gpu = config.get("edge_blur_device", "auto").lower() != "cpu" and not config.get("force_cpu")

        blurred_array = None
        device_used = "none"
        start_t = time.perf_counter()

        if radius > 0 and use_gpu:
            blurred_array = self._blur_image_gpu_gauss(mapped_array.astype(np.uint8), radius)
            if blurred_array is not None:
                device_used = "gpu"

        if blurred_array is None:
            # fallback CPU Gauss
            blurred_array = mapped_array.copy()
            for channel in range(3):
                blurred_array[:, :, channel] = ndimage.gaussian_filter(mapped_array[:, :, channel], sigma=radius)
            device_used = "cpu"

        elapsed_ms = (time.perf_counter() - start_t) * 1000.0
        self._log_blur_benchmark(device_used, radius, elapsed_ms, mapped_array.shape[1], mapped_array.shape[0])

        blend_factor = (edge_mask * config["edge_blur_strength"])[:, :, np.newaxis]
        result_array = (mapped_array * (1 - blend_factor) + blurred_array * blend_factor)
        return Image.fromarray(np.clip(result_array, 0, 255).astype(np.uint8))

    def _map_pixels_to_palette_opencl(self, image_array: np.ndarray, palette: List[List[int]], config: Dict[str, Any]) -> np.ndarray:
        with self.profiler.profile_operation("map_pixels_to_palette_opencl", algorithm_id=self.algorithm_id):
            start_time = time.perf_counter()
            cl_mgr = OpenCLManager()
            ctx = cl_mgr.get_context()
            queue = cl_mgr.get_queue()
            prg = cl_mgr.get_program()
            palette_np_rgb = np.array(palette, dtype=np.float32)
            palette_np_hsv = cpu.rgb2hsv(palette_np_rgb / 255.0).astype(np.float32).flatten()
            pixels_flat = image_array.reshape(-1, 3).astype(np.float32)
            mf = cl.mem_flags
            pixels_g, palette_hsv_g, output_g = None, None, None
            try:
                pixels_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=pixels_flat)
                palette_hsv_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=palette_np_hsv)
                output_g = cl.Buffer(ctx, mf.WRITE_ONLY, pixels_flat.shape[0] * 4)
                local_size = (64,)
                global_size_raw = pixels_flat.shape[0]
                rounded_global_size = (global_size_raw + local_size[0] - 1) // local_size[0] * local_size[0]
                global_size = (rounded_global_size,)
                prg.map_palette(
                    queue, global_size, local_size,
                    pixels_g, palette_hsv_g, output_g,
                    np.int32(len(palette)), np.float32(config.get('hue_weight', 3.0))
                )
                closest_indices = np.empty(pixels_flat.shape[0], dtype=np.int32)
                cl.enqueue_copy(queue, closest_indices, output_g).wait()
                result_array = np.array(palette, dtype=np.uint8)[closest_indices].reshape(image_array.shape)
                self.logger.info(f"Przetworzono na GPU (OpenCL) {pixels_flat.shape[0]:,} pikseli w {(time.perf_counter() - start_time) * 1000:.1f}ms")
                return result_array
            except Exception as e:
                self.logger.error(f"Błąd podczas wykonywania kernela OpenCL: {e}", exc_info=True)
                raise err.GPUProcessingError(f"Błąd wykonania OpenCL: {e}")
            finally:
                if pixels_g: pixels_g.release()
                if palette_hsv_g: palette_hsv_g.release()
                if output_g: output_g.release()
    
    def _map_pixels_to_palette(self, image_array: np.ndarray, palette: List[List[int]], config: Dict[str, Any]) -> np.ndarray:
        """Dispatcher wybierający między GPU a CPU."""
        try:
            if image_array.size > 100_000 and not config.get('force_cpu'):
                return self._map_pixels_to_palette_opencl(image_array, palette, config)
        except err.GPUProcessingError as e:
            self.logger.warning(f"Przetwarzanie GPU nie powiodło się ({e}). Przełączam na CPU.")
        
        self.logger.info("Używam ścieżki CPU (obraz zbyt mały lub błąd GPU).")
        return cpu.map_pixels_to_palette_cpu(image_array, palette, config, self.logger)

    def process_images(self, master_path: str, target_path: str, output_path: str, **kwargs) -> bool:
        """Pełny potok przetwarzania, od ekstrakcji palety po finalny zapis."""
        run_config = self.default_config.copy()
        run_config.update(kwargs)
        
        try:
            # Konwersja typów, aby uniknąć błędów
            for key in ['hue_weight', 'dithering_strength', 'edge_blur_radius', 'edge_blur_strength']:
                if key in run_config: run_config[key] = float(run_config[key])
            for key in ['num_colors', 'quality', 'extremes_threshold', 'edge_detection_threshold', 'gpu_batch_size']:
                 if key in run_config: run_config[key] = int(run_config[key])
            if 'edge_blur_device' in run_config:
                run_config['edge_blur_device'] = str(run_config['edge_blur_device']).lower()
        except (ValueError, TypeError) as e:
            self.logger.error(f"Błąd konwersji typów w konfiguracji: {e}", exc_info=True)
            return False

        try:
            # Używamy cpu.extract_palette z `algorithm_gpu_cpu_fallback.py`
            master_image = cpu.safe_image_load(master_path, self.logger)
            # Pamiętaj, że ta wersja `extract_palette` nie przyjmuje `method`
            palette = cpu.extract_palette(
                image=master_image, 
                num_colors=run_config['num_colors'],
                quality=run_config['quality'],
                inject_extremes=run_config['inject_extremes'],
                max_palette_size=self.default_config.get('_max_palette_size', 256),
                logger=self.logger
            )

            target_image_pil = Image.open(target_path).convert("RGB")
            target_array = np.array(target_image_pil)
            array_to_map = target_array

            if run_config.get("dithering_method") == "ordered":
                array_to_map = self._apply_ordered_dithering(array_to_map, run_config.get("dithering_strength", 8.0))

            mapped_array = self._map_pixels_to_palette(array_to_map, palette, run_config)
            
            if run_config.get("preserve_extremes"):
                mapped_array = self._preserve_extremes(mapped_array, target_array, run_config.get("extremes_threshold", 10))

            mapped_image = Image.fromarray(mapped_array, "RGB")

            if run_config.get("edge_blur_enabled"):
                mapped_image = self._apply_edge_blending(mapped_image, run_config)
            
            mapped_image.save(output_path, quality=95)
            self.logger.info(f"Obraz pomyślnie zapisany w: {output_path}")
            return True
        except Exception as e:
            self.logger.error(f"Główny proces przetwarzania nie powiódł się: {e}", exc_info=True)
            return False

    def _log_blur_benchmark(self, device: str, radius: int, elapsed_ms: float, width: int, height: int):
        """Loguje wynik benchmarku do CSV w folderze logs."""
        try:
            logs_dir = os.path.join(os.path.dirname(__file__), "..", "..", "logs")
            os.makedirs(logs_dir, exist_ok=True)
            csv_path = os.path.join(logs_dir, "edge_blur_benchmarks.csv")
            header_needed = not os.path.exists(csv_path)
            import csv, datetime
            with open(csv_path, "a", newline="", encoding="utf-8") as f:
                writer = csv.writer(f)
                if header_needed:
                    writer.writerow(["timestamp", "device", "radius", "elapsed_ms", "width", "height"])
                writer.writerow([
                    datetime.datetime.now().isoformat(), device, radius, f"{elapsed_ms:.2f}", width, height
                ])
        except Exception:
            # nie blokuj głównego procesu w razie problemów z logiem
            pass

def create_palette_mapping_algorithm_gpu():
    return PaletteMappingAlgorithmGPU()

--- File: algorithm_gpu_config.py ---
# /app/algorithms/algorithm_01_palette/algorithm-gpu-config.py
# Moduł odpowiedzialny za zarządzanie konfiguracją algorytmu.

import json
from typing import Any, Dict

def get_default_config() -> Dict[str, Any]:
    """Zwraca słownik z domyślnymi wartościami konfiguracji algorytmu."""
    return {
        "num_colors": 8,
        "palette_method": "kmeans",
        "quality": 5,
        "distance_metric": "weighted_hsv",
        "hue_weight": 3.0,
        "saturation_weight": 1.0,
        "value_weight": 1.0,
        "use_color_focus": False,
        "focus_ranges": [],
        "dithering_method": "none",
        "dithering_strength": 8.0,
        "inject_extremes": True,
        "preserve_extremes": False,
        "extremes_threshold": 10,
        "edge_blur_enabled": False,
        "edge_blur_radius": 1.5,
        "edge_blur_strength": 0.3,
        "edge_detection_threshold": 25,
        "edge_blur_device": "auto",  # auto|gpu|cpu
        "postprocess_median_filter": False,
        # Opcje specyficzne dla GPU
        "force_cpu": False,
        "gpu_batch_size": 2_000_000,
        "enable_kernel_fusion": True,
        "gpu_memory_cleanup": True,
        "use_64bit_indices": False,  # Dla bardzo dużych obrazów
        "_max_palette_size": 256,    # Dodane dla pełnej spójności konfiguracji
    }

def validate_run_config(config: Dict[str, Any], max_palette_size: int = 256):
    """
    Waliduje i normalizuje parametry konfiguracyjne w locie.
    Modyfikuje przekazany słownik `config`.
    """
    if "hue_weight" in config:
        config["hue_weight"] = max(0.1, min(10.0, float(config["hue_weight"])))
    if "gpu_batch_size" in config:
        config["gpu_batch_size"] = max(100_000, min(10_000_000, int(config["gpu_batch_size"])))
    if "num_colors" in config:
        config["num_colors"] = max(2, min(max_palette_size, int(config["num_colors"])))
    if "quality" in config:
        config["quality"] = max(1, min(10, int(config["quality"])))
    if "dithering_strength" in config:
        config["dithering_strength"] = max(0.0, min(16.0, float(config["dithering_strength"])))
    if "extremes_threshold" in config:
        config["extremes_threshold"] = max(0, min(50, int(config["extremes_threshold"])))
    if "edge_blur_radius" in config:
        config["edge_blur_radius"] = max(0.0, min(5.0, float(config["edge_blur_radius"])))
    if "edge_blur_strength" in config:
        config["edge_blur_strength"] = max(0.0, min(1.0, float(config["edge_blur_strength"])))
    if "edge_detection_threshold" in config:
        config["edge_detection_threshold"] = max(0, min(200, int(config["edge_detection_threshold"])))
    if "saturation_weight" in config:
        config["saturation_weight"] = max(0.1, min(5.0, float(config["saturation_weight"])))
    if "value_weight" in config:
        config["value_weight"] = max(0.1, min(5.0, float(config["value_weight"])))

def load_config(config_path: str, default_config: Dict[str, Any]) -> Dict[str, Any]:
    """
    Wczytuje konfigurację z pliku JSON, waliduje ją i łączy z konfiguracją domyślną.
    """
    config = default_config.copy()
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            user_config = json.load(f)
        
        # Walidacja wczytanych wartości
        validate_run_config(user_config, default_config.get("_max_palette_size", 256))
        
        config.update(user_config)
    except Exception as e:
        # W przypadku błędu, logowanie powinno odbywać się w klasie, która ma logger.
        # Tutaj zwracamy tylko domyślną konfigurację.
        print(f"Warning: Error loading configuration from {config_path}: {e}. Using defaults.")
        return default_config
        
    return config

--- File: algorithm_gpu_cpu_fallback.py ---
import time
from pathlib import Path
from typing import Any, Dict, List
import numpy as np
from PIL import Image
from .algorithm_gpu_exceptions import ImageProcessingError

try:
    from skimage import color as skimage_color
    # Poprawnie definiujemy rgb2hsv do użytku w całym module
    rgb2hsv = skimage_color.rgb2hsv
    from sklearn.cluster import KMeans
    SCIPY_SKLEARN_AVAILABLE = True
except ImportError:
    SCIPY_SKLEARN_AVAILABLE = False
    def rgb2hsv(x): raise NotImplementedError("scikit-image is not installed")

def safe_image_load(image_path: str, logger: Any) -> Image.Image:
    try:
        path_obj = Path(image_path)
        if not path_obj.exists(): raise ImageProcessingError(f"Image file not found: {image_path}")
        if not path_obj.is_file(): raise ImageProcessingError(f"Path is not a file: {image_path}")
        if path_obj.stat().st_size == 0: raise ImageProcessingError(f"Image file is empty: {image_path}")
        if path_obj.stat().st_size > 500 * 1024 * 1024:
            logger.warning(f"Very large image file: {path_obj.stat().st_size / 1024**2:.1f}MB")
        image = Image.open(image_path)
        if image.mode != "RGB":
            image = image.convert("RGB")
        return image
    except Exception as e:
        raise ImageProcessingError(f"Failed to load image {image_path}: {e}")

def extract_palette(image: Image.Image, num_colors: int, quality: int, inject_extremes: bool, max_palette_size: int, logger: Any) -> List[List[int]]:
    if not SCIPY_SKLEARN_AVAILABLE:
        logger.error("Scikit-learn is required for palette extraction.")
        return [[0,0,0], [255,255,255]]
    base_size, max_size = 100, 1000
    thumbnail_size = int(base_size + (max_size - base_size) * (quality - 1) / 9.0)
    image.thumbnail((thumbnail_size, thumbnail_size))
    pixels = np.array(image).reshape(-1, 3)
    if len(pixels) < num_colors:
        num_colors = len(pixels)
    kmeans = KMeans(n_clusters=num_colors, random_state=42, n_init=10)
    kmeans.fit(pixels)
    palette = kmeans.cluster_centers_.astype(int).tolist()
    if inject_extremes:
        if [0, 0, 0] not in palette and len(palette) < max_palette_size: palette.insert(0, [0, 0, 0])
        if [255, 255, 255] not in palette and len(palette) < max_palette_size: palette.append([255, 255, 255])
    return palette

def map_pixels_to_palette_cpu(image_array: np.ndarray, palette: List[List[int]], config: Dict[str, Any], logger: Any) -> np.ndarray:
    if not SCIPY_SKLEARN_AVAILABLE:
        logger.error("Scikit-image is required for CPU color conversion.")
        return image_array
    
    start_time = time.perf_counter()
    pixel_count = image_array.shape[0] * image_array.shape[1]
    palette_np = np.array(palette, dtype=np.float32)
    pixels_flat = image_array.reshape(-1, 3).astype(np.float32)
    
    # --- NAPRAWA BŁĘDU ---
    # Używamy bezpośrednio funkcji `rgb2hsv` zamiast błędnej nazwy `color.rgb2hsv`
    pixels_hsv = rgb2hsv(pixels_flat / 255.0)
    palette_hsv = rgb2hsv(palette_np / 255.0)
    # --- KONIEC NAPRAWY ---
    
    delta_h = np.abs(pixels_hsv[:, np.newaxis, 0] - palette_hsv[np.newaxis, :, 0])
    delta_h = np.minimum(delta_h, 1.0 - delta_h)
    
    hue_weight = float(config.get('hue_weight', 3.0))
    distances_sq = (
        (hue_weight * delta_h)**2 +
        (pixels_hsv[:, np.newaxis, 1] - palette_hsv[np.newaxis, :, 1])**2 +
        (pixels_hsv[:, np.newaxis, 2] - palette_hsv[np.newaxis, :, 2])**2
    )
    
    closest_indices = np.argmin(distances_sq, axis=1)
    result = palette_np[closest_indices].reshape(image_array.shape)
    
    logger.info(f"CPU processed {pixel_count:,} pixels in {(time.perf_counter() - start_time) * 1000:.1f}ms")
    
    # Zwracamy tablicę jako uint8, tak jak robi to ścieżka GPU
    return np.clip(result, 0, 255).astype(np.uint8)

--- File: algorithm_gpu_exceptions.py ---
# /app/algorithms/algorithm_01_palette/algorithm_gpu_exceptions.py
# Module containing custom exceptions for the GPU algorithm.

class GPUProcessingError(Exception):
    """Custom exception for GPU processing errors."""
    pass

class GPUMemoryError(GPUProcessingError):
    """Specific exception for GPU memory issues."""
    pass

class ImageProcessingError(Exception):
    """Exception for image loading and processing errors."""
    pass

--- File: algorithm_gpu_utils.py ---
# /app/algorithms/algorithm_01_palette/algorithm-gpu-utils.py
# Moduł zawierający podstawowe, współdzielone komponenty i definicje.

import logging
import numpy as np
from enum import Enum
from typing import Any, TYPE_CHECKING, Tuple, List

# --- Project Imports with Fallbacks ---
# Umożliwia działanie modułu nawet poza główną strukturą projektu.
try:
    if TYPE_CHECKING:
        from ...core.development_logger import DevelopmentLogger
except ImportError:
    # Definicje zastępcze, jeśli główne moduły nie są dostępne
    DevelopmentLogger = logging.Logger
    
    class PerformanceProfiler:
        def profile_operation(self, *args, **kwargs):
            import contextlib
            return contextlib.nullcontext()

# --- Fallback Logger and Profiler ---

def get_logger() -> Any:
    """Zwraca instancję loggera, zapewniając fallback, jeśli główny system logowania jest niedostępny."""
    try:
        from ...core.development_logger import get_logger as get_core_logger
        return get_core_logger()
    except ImportError:
        logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
        return logging.getLogger("fallback_logger")

def get_profiler() -> Any:
    """Zwraca instancję profilera, zapewniając fallback."""
    try:
        from ...core.performance_profiler import get_profiler as get_core_profiler
        return get_core_profiler()
    except ImportError:
        return PerformanceProfiler()

# --- Enhanced Custom Exceptions ---

# --- Validation Utilities ---

def validate_image_array(image_array):
    """Validates input image array and returns its dimensions.
    
    Args:
        image_array: Input image as numpy array
        
    Returns:
        Tuple of (height, width, channels)
        
    Raises:
        ValueError: If validation fails
    """
    if not isinstance(image_array, np.ndarray):
        raise ValueError("Input must be a numpy array")
    
    if image_array.dtype != np.uint8:
        raise ValueError("Input array must have dtype uint8")
    
    if len(image_array.shape) != 3 or image_array.shape[2] != 3:
        raise ValueError("Input must be a 3D array with shape (H,W,3)")
    
    return image_array.shape

def validate_palette(palette):
    """Validates palette and converts it to numpy array.
    
    Args:
        palette: List of [R,G,B] colors with values 0-255
        
    Returns:
        numpy.ndarray: Palette as float32 array with values 0-1
        
    Raises:
        ValueError: If validation fails
    """
    if not palette or not all(isinstance(c, (list, tuple)) and len(c) == 3 for c in palette):
        raise ValueError("Palette must be a non-empty list of [R,G,B] lists")
    
    palette_np = np.array(palette, dtype=np.float32)
    
    if np.any((palette_np < 0) | (palette_np > 255)):
        raise ValueError("Palette values must be in range [0, 255]")
    
    return palette_np / 255.0

# --- Acceleration Strategy Enum ---

class AccelerationStrategy(Enum):
    """Definiuje strategię wyboru backendu do przetwarzania."""
    CPU = 0
    GPU_SMALL = 1    # Małe palety, prosty algorytm
    GPU_MEDIUM = 2   # Średnia złożoność
    GPU_LARGE = 3    # Pełny potok GPU z przetwarzaniem wsadowym

--- File: config.py ---
"""
Algorithm 01: Palette Mapping Configuration
===========================================
Konfiguracja dla algorytmu mapowania palety, w tym nowe opcje zaawansowane.
"""

from typing import Dict, Any, Optional
from dataclasses import dataclass


@dataclass
class PaletteMappingConfig:
    """Konfiguracja dla Algorytmu Mapowania Palety."""
    
    # --- NOWE OPCJE ---
    # Domyślne wartości dla nowych, zaawansowanych parametrów.
    # API będzie je nadpisywać, jeśli zostaną podane w requeście.
    
    # Grupa 1: Kontrola nad Paletą
    k_colors: int = 16
    palette_source_area: str = "full_image"  # Opcje: 'full_image', 'selection', 'active_layer'
    exclude_colors: Optional[list] = None     # Lista kolorów RGB do wykluczenia, np. [[255,255,255]]

    # Grupa 2: Kontrola nad Mapowaniem
    distance_metric: str = "LAB"             # Opcje: 'RGB', 'LAB' (percepcyjna)
    use_dithering: bool = False              # Czy włączyć rozpraszanie (dithering)
    preserve_luminance: bool = True          # Czy zachować oryginalną jasność obrazu docelowego

    # Grupa 3: Kontrola nad Wydajnością
    preview_mode: bool = False
    preview_size: tuple = (500, 500)         # Maksymalny rozmiar dla podglądu

    # --- ISTNIEJĄCE PARAMETRY K-MEANS ---
    random_state: int = 42
    n_init: int = 10
    max_iter: int = 300
    tol: float = 1e-4

# Globalna funkcja do pobierania domyślnej konfiguracji
def get_default_config() -> PaletteMappingConfig:
    """Zwraca instancję z domyślną konfiguracją."""
    return PaletteMappingConfig()

--- File: __init__.py ---
from .algorithm import PaletteMappingAlgorithm
from .algorithm import create_palette_mapping_algorithm
PaletteMappingAlgorithmCPU = PaletteMappingAlgorithm
create_palette_mapping_algorithm_cpu = create_palette_mapping_algorithm

try:
    from .algorithm_gpu import PaletteMappingAlgorithmGPU
    from .algorithm_gpu import create_palette_mapping_algorithm_gpu
    OPENCL_AVAILABLE = True
except (ImportError, RuntimeError):
    PaletteMappingAlgorithmGPU = None
    create_palette_mapping_algorithm_gpu = None
    OPENCL_AVAILABLE = False
    
__all__ = [
    'PaletteMappingAlgorithm',
    'create_palette_mapping_algorithm',
    'PaletteMappingAlgorithmCPU',
    'create_palette_mapping_algorithm_cpu',
]
if OPENCL_AVAILABLE:
    __all__.extend([
        'PaletteMappingAlgorithmGPU',
        'create_palette_mapping_algorithm_gpu',
    ])
--- File: tests\conftest.py ---
import pytest
import numpy as np
from PIL import Image
import tempfile
from pathlib import Path

# ----------------- GPU availability helpers -----------------
try:
    import pyopencl as cl
    def gpu_available() -> bool:
        try:
            return any(
                d.type == cl.device_type.GPU
                for p in cl.get_platforms() for d in p.get_devices()
            )
        except Exception:
            return False
except Exception:
    # pyopencl not installed or misconfigured -> no GPU
    def gpu_available() -> bool:
        return False

# ----------------- SESSION-level fixtures -----------------

@pytest.fixture(scope="session", autouse=False)
def gpu():
    """Skip entire test module if no GPU available."""
    if not gpu_available():
        pytest.skip("OpenCL GPU not available", allow_module_level=True)


# ----------------- Utility fixtures -----------------

@pytest.fixture
def synthetic_image(tmp_path):
    """Return a callable that creates and returns a synthetic RGB image path."""
    def _create(name: str = "synthetic.tif", size=(256, 256)) -> str:
        arr = (np.random.rand(size[1], size[0], 3) * 255).astype(np.uint8)
        path = Path(tmp_path) / name
        Image.fromarray(arr).save(path)
        return str(path)
    return _create

# ------------- Additional common fixtures (CPU tests) -------------

@pytest.fixture(scope="function")
def gradient_image(tmp_path):
    """Create horizontal RGB gradient, return path."""
    arr = np.zeros((100, 100, 3), dtype=np.uint8)
    for i in range(100):
        arr[:, i, 0] = int(i * 2.55)
        arr[:, i, 1] = 128
        arr[:, i, 2] = 255 - int(i * 2.55)
    path = tmp_path / "gradient.png"
    Image.fromarray(arr).save(path)
    return str(path)

@pytest.fixture(scope="function")
def noise_image(tmp_path):
    """Random noise RGB image (200x200) with deterministic content."""
    rng = np.random.RandomState(42)
    arr = (rng.rand(200, 200, 3) * 255).astype(np.uint8)
    path = tmp_path / "noise.png"
    Image.fromarray(arr).save(path)
    return str(path)

@pytest.fixture
def checkerboard(tmp_path):
    """Create a 64×64 checkerboard image and return its path."""
    arr = np.zeros((64, 64, 3), dtype=np.uint8)
    arr[0:32, 0:32] = [255, 0, 0]   # Red
    arr[0:32, 32:64] = [0, 0, 255]  # Blue
    arr[32:64, 0:32] = [0, 255, 0]  # Green
    arr[32:64, 32:64] = [255, 255, 0]  # Yellow
    path = tmp_path / "checkerboard.png"
    Image.fromarray(arr).save(path)
    return str(path)

from app.algorithms.algorithm_01_palette.algorithm import PaletteMappingAlgorithm

@pytest.fixture
def algorithm_cpu():
    """Return CPU PaletteMappingAlgorithm instance."""
    return PaletteMappingAlgorithm()

# ----------------- Auto-skip for gpu marker -----------------

def pytest_runtest_setup(item):
    if 'gpu' in item.keywords and not gpu_available():
        pytest.skip("OpenCL GPU not available")

--- File: tests\__init__.py ---
# -*- coding: utf-8 -*-
"""
Test package for algorithm_01_palette

This package contains all tests related to the PaletteMappingAlgorithm,
including unit tests, parameter tests, and integration tests.
"""
--- File: tests\gpu\test_dithering_strength.py ---
import numpy as np
from PIL import Image
import pytest

from app.algorithms.algorithm_01_palette.algorithm_gpu import PaletteMappingAlgorithmGPU


@pytest.mark.gpu
def test_dithering_strength_effect(gpu, tmp_path, synthetic_image):
    alg = PaletteMappingAlgorithmGPU()
    master = synthetic_image("master_dither.tif")

    out_none = tmp_path / "dither_none.jpg"
    out_high = tmp_path / "dither_high.jpg"

    # No dithering
    assert alg.process_images(master, master, str(out_none),
                              dithering_method="none", dithering_strength=0.0)

    # Ordered dithering with strong strength
    assert alg.process_images(master, master, str(out_high),
                              dithering_method="ordered", dithering_strength=8.0)

    img_none = np.array(Image.open(out_none))
    img_high = np.array(Image.open(out_high))
    assert not np.array_equal(img_none, img_high)

--- File: tests\gpu\test_edge_blur.py ---
import numpy as np
from PIL import Image
import pytest
from pathlib import Path

from app.algorithms.algorithm_01_palette.algorithm_gpu import PaletteMappingAlgorithmGPU


@pytest.mark.gpu
def test_edge_blur_effect(gpu, tmp_path, synthetic_image):
    """Ensure edge_blur config alters the GPU output."""
    alg = PaletteMappingAlgorithmGPU()
    master = synthetic_image("master_edge_blur.tif")

    out_none = tmp_path / "blur_none.jpg"
    out_blur = tmp_path / "blur_on.jpg"

    base_cfg = dict(edge_blur_radius=2.0, edge_blur_strength=0.5)

    assert alg.process_images(master, master, str(out_none), edge_blur_enabled=False, **base_cfg)
    assert alg.process_images(master, master, str(out_blur), edge_blur_enabled=True, **base_cfg)

    img_none = np.array(Image.open(out_none))
    img_blur = np.array(Image.open(out_blur))
    assert not np.array_equal(img_none, img_blur)

--- File: tests\gpu\test_hue_weight.py ---
import numpy as np
from PIL import Image
import pytest

from app.algorithms.algorithm_01_palette.algorithm_gpu import PaletteMappingAlgorithmGPU


@pytest.mark.gpu
def test_hue_weight_effect(gpu, tmp_path, synthetic_image):
    alg = PaletteMappingAlgorithmGPU()
    master = synthetic_image("master_hue.tif")

    out_low = tmp_path / "hue_low.jpg"
    out_high = tmp_path / "hue_high.jpg"

    assert alg.process_images(master, master, str(out_low), hue_weight=1.0)
    assert alg.process_images(master, master, str(out_high), hue_weight=5.0)

    img_low = np.array(Image.open(out_low))
    img_high = np.array(Image.open(out_high))
    assert not np.array_equal(img_low, img_high)

--- File: tests\gpu\test_preserve_extremes.py ---
import numpy as np
from PIL import Image
import pytest

from app.algorithms.algorithm_01_palette.algorithm_gpu import PaletteMappingAlgorithmGPU


@pytest.mark.gpu
def test_preserve_extremes_effect(gpu, tmp_path, synthetic_image):
    alg = PaletteMappingAlgorithmGPU()
    master = synthetic_image("master_extremes.tif")

    off_cfg = dict(preserve_extremes=False, extremes_threshold=0)
    on_cfg = dict(preserve_extremes=True, extremes_threshold=15)

    out_off = tmp_path / "extremes_off.jpg"
    out_on = tmp_path / "extremes_on.jpg"

    assert alg.process_images(master, master, str(out_off), **off_cfg)
    assert alg.process_images(master, master, str(out_on), **on_cfg)

    img_off = np.array(Image.open(out_off))
    img_on = np.array(Image.open(out_on))
    assert not np.array_equal(img_off, img_on)

--- File: tests\gpu\__init__.py ---

--- File: tests\integration\test_algorithm_happy_path.py ---
"""Integration test: PaletteMappingAlgorithm happy path
Checks that the full algorithm runs end-to-end and produces a plausible output.
"""
import pytest
import numpy as np
from PIL import Image
from pathlib import Path
from app.algorithms.algorithm_01_palette.algorithm import PaletteMappingAlgorithm

def test_algorithm_happy_path(tmp_path):
    # Synthetic master: noise, target: gradient
    master = (np.random.rand(100, 100, 3) * 255).astype(np.uint8)
    target = np.zeros((100, 100, 3), dtype=np.uint8)
    for i in range(100):
        target[:, i, 0] = int(i * 2.55)
        target[:, i, 1] = 128
        target[:, i, 2] = 255 - int(i * 2.55)
    master_path = tmp_path / "master.png"
    target_path = tmp_path / "target.png"
    Image.fromarray(master).save(master_path)
    Image.fromarray(target).save(target_path)

    output_path = tmp_path / "result.png"
    alg = PaletteMappingAlgorithm()
    ok = alg.process_images(
        master_path=str(master_path),
        target_path=str(target_path),
        output_path=str(output_path),
        num_colors=8,
        edge_blur_enabled=True,
        edge_blur_radius=1.0,
        edge_blur_strength=0.5,
        dithering_strength=0.5,
    )
    assert ok and output_path.exists()
    result = np.array(Image.open(output_path))
    assert result.shape == (100, 100, 3)
    # At least some quantization should occur
    assert len(np.unique(result.reshape(-1, 3), axis=0)) < 100*100

--- File: tests\parameters\test_distance_cache.py ---
"""Parameter test: distance_cache_enabled
Ensures that enabling distance cache changes algorithm runtime or at least does not break output.
This simplified check only verifies that outputs are identical regardless (functional correctness).
"""

import numpy as np
from pathlib import Path
from PIL import Image
import pytest


@pytest.mark.parametrize("distance_cache_enabled", [False, True])
def test_distance_cache_output_consistency(tmp_path, gradient_image, noise_image, algorithm_cpu, distance_cache_enabled):
    """Algorithm should produce same visual result regardless of the cache flag (quality invariant)."""
    out = Path(tmp_path) / f"res_{distance_cache_enabled}.png"
    ok = algorithm_cpu.process_images(
        master_path=noise_image,
        target_path=gradient_image,
        output_path=str(out),
        distance_cache_enabled=distance_cache_enabled,
        num_colors=16,
    )
    assert ok and out.exists()

    # Load result
    arr = np.array(Image.open(out))
    pytest.cache_imgs = getattr(pytest, "cache_imgs", {})
    pytest.cache_imgs[distance_cache_enabled] = arr


def test_distance_cache_equality():
    imgs = getattr(pytest, "cache_imgs", {})
    assert imgs and False in imgs and True in imgs, "Previous parametrized run failed"
    img_false = imgs[False]
    img_true = imgs[True]
    # Must produce identical outputs when cache enabled vs disabled
    assert img_false.shape == img_true.shape, "Output shapes differ when enabling distance cache"
    assert np.array_equal(img_false, img_true), "Image contents differ when enabling distance cache"

--- File: tests\parameters\test_dithering_strength.py ---
"""Parameter test: dithering_strength
Checks that higher dithering_strength produces noisier (more color variance) output.
Simplified heuristic: compare mean absolute difference from non-dithered result.
"""

from pathlib import Path
import numpy as np
from PIL import Image
import pytest


@pytest.mark.parametrize("d_strength", [0.0, 0.5, 1.0])
def test_dithering_strength_variation(tmp_path, gradient_image, noise_image, algorithm_cpu, d_strength):
    out = Path(tmp_path) / f"out_{d_strength}.png"
    algorithm_cpu.process_images(
        master_path=noise_image,
        target_path=gradient_image,
        output_path=str(out),
        dithering_strength=d_strength,
        num_colors=8,
    )
    arr = np.array(Image.open(out))
    # Save to session data
    pytest._dither_outputs = getattr(pytest, "_dither_outputs", {})
    pytest._dither_outputs[d_strength] = arr


def test_dithering_strength_monotone():
    data = getattr(pytest, "_dither_outputs", {})
    assert data, "Param loop missing"
    # check monotonic increase in variance with strength
    var_none = np.var(data[0.0].astype(float))
    var_mid = np.var(data[0.5].astype(float))
    var_strong = np.var(data[1.0].astype(float))
    assert var_none < var_mid < var_strong, \
        f"Variance not increasing monotonically: {var_none:.1f} !< {var_mid:.1f} !< {var_strong:.1f}"

--- File: tests\parameters\test_edge_blur_enabled.py ---
"""Behavioral parameter test: edge_blur_enabled
Checks that enabling edge blur increases color diversity on sharp-edged images.
Converted from legacy unittest to pure pytest.
"""

import numpy as np
from PIL import Image
import pytest
from pathlib import Path

from app.algorithms.algorithm_01_palette.algorithm import PaletteMappingAlgorithm


@pytest.fixture(scope="function")
def checkerboard(tmp_path):
    """Return master/target checkerboard image path (64×64, 4 colors)."""
    arr = np.zeros((64, 64, 3), dtype=np.uint8)
    arr[0:32, 0:32] = [255, 0, 0]   # Red
    arr[0:32, 32:64] = [0, 0, 255]  # Blue
    arr[32:64, 0:32] = [0, 255, 0]  # Green
    arr[32:64, 32:64] = [255, 255, 0]  # Yellow
    img_path = Path(tmp_path) / "checkerboard.png"
    Image.fromarray(arr).save(img_path)
    return str(img_path)


def _unique_colors(img_path):
    return len(np.unique(np.array(Image.open(img_path)).reshape(-1, 3), axis=0))


@pytest.mark.parametrize("edge_blur_enabled", [False, True])
def test_edge_blur_enabled_effect(tmp_path, checkerboard, edge_blur_enabled):
    alg = PaletteMappingAlgorithm()
    out = Path(tmp_path) / f"result_{edge_blur_enabled}.png"

    alg.process_images(
        master_path=checkerboard,
        target_path=checkerboard,
        output_path=str(out),
        edge_blur_enabled=edge_blur_enabled,
        edge_blur_radius=1.5,
        edge_blur_strength=0.5,
        num_colors=4,
    )

    assert out.exists()

    # Less strict assertion in parameterized loop – compute later
    # Return colors for comparison outside param loop


def test_edge_blur_enabled_increases_color_diversity(tmp_path, checkerboard):
    alg = PaletteMappingAlgorithm()
    out_disabled = Path(tmp_path) / "disabled.png"
    out_enabled = Path(tmp_path) / "enabled.png"

    alg.process_images(checkerboard, checkerboard, str(out_disabled),
                       edge_blur_enabled=False, num_colors=4)
    alg.process_images(checkerboard, checkerboard, str(out_enabled),
                       edge_blur_enabled=True, edge_blur_radius=1.5, edge_blur_strength=0.5, num_colors=4)

    colors_disabled = _unique_colors(out_disabled)
    colors_enabled = _unique_colors(out_enabled)

    assert colors_enabled != colors_disabled, "Parameter had no effect on color variety"
    assert colors_enabled > colors_disabled, "Enabling blur should increase unique colors"

--- File: tests\parameters\test_edge_blur_method.py ---
"""Parameter test: edge_blur_method
Checks that both supported methods run and produce output (no crash).
"""
from pathlib import Path
import pytest
import numpy as np
from PIL import Image

@pytest.mark.parametrize("method", ["gaussian", "none"])
def test_edge_blur_method_runs(tmp_path, checkerboard, algorithm_cpu, method):
    out = Path(tmp_path) / f"out_{method}.png"
    ok = algorithm_cpu.process_images(
        master_path=checkerboard,
        target_path=checkerboard,
        output_path=str(out),
        edge_blur_enabled=True,
        edge_blur_radius=1.5,
        edge_blur_strength=0.5,
        edge_blur_method=method,
        num_colors=4,
    )
    assert ok and out.exists()
    arr = np.array(Image.open(out))
    assert arr.shape[2] == 3

--- File: tests\parameters\test_edge_blur_radius.py ---
"""Parameter test: edge_blur_radius
Checks that increasing edge_blur_radius increases the number of unique colors (smoother blending).
"""
import numpy as np
from PIL import Image
from pathlib import Path
import pytest

@pytest.mark.parametrize("radius", [0.0, 1.0, 2.0])
def test_edge_blur_radius_effect(tmp_path, checkerboard, algorithm_cpu, radius):
    out = Path(tmp_path) / f"out_{radius}.png"
    algorithm_cpu.process_images(
        master_path=checkerboard,
        target_path=checkerboard,
        output_path=str(out),
        edge_blur_enabled=True,
        edge_blur_radius=radius,
        edge_blur_strength=0.5,
        num_colors=4,
    )
    arr = np.array(Image.open(out))
    pytest._radius_colors = getattr(pytest, "_radius_colors", {})
    pytest._radius_colors[radius] = len(np.unique(arr.reshape(-1, 3), axis=0))

def test_edge_blur_radius_monotonicity():
    data = getattr(pytest, "_radius_colors", {})
    assert data, "Param loop missing"
    assert data[0.0] <= data[1.0] <= data[2.0], "Unique color count should increase with radius"

--- File: tests\parameters\test_edge_blur_strength.py ---
"""Parameter test: edge_blur_strength
Checks that increasing edge_blur_strength increases blending effect (more unique colors).
"""
import numpy as np
from PIL import Image
from pathlib import Path
import pytest

@pytest.mark.parametrize("strength", [0.0, 0.5, 1.0])
def test_edge_blur_strength_effect(tmp_path, checkerboard, algorithm_cpu, strength):
    out = Path(tmp_path) / f"out_{strength}.png"
    algorithm_cpu.process_images(
        master_path=checkerboard,
        target_path=checkerboard,
        output_path=str(out),
        edge_blur_enabled=True,
        edge_blur_radius=1.5,
        edge_blur_strength=strength,
        num_colors=4,
    )
    arr = np.array(Image.open(out))
    pytest._strength_colors = getattr(pytest, "_strength_colors", {})
    pytest._strength_colors[strength] = len(np.unique(arr.reshape(-1, 3), axis=0))

def test_edge_blur_strength_monotonicity():
    data = getattr(pytest, "_strength_colors", {})
    assert data, "Param loop missing"
    assert data[0.0] <= data[0.5] <= data[1.0], "Unique color count should increase with strength"

--- File: tests\parameters\test_edge_detection_threshold.py ---
"""Parameter test: edge_detection_threshold
Checks that raising the threshold reduces the amount of blending (fewer unique colors).
"""
import numpy as np
from PIL import Image
from pathlib import Path
import pytest

@pytest.mark.parametrize("threshold", [0.05, 0.2, 0.5])
def test_edge_detection_threshold_effect(tmp_path, checkerboard, algorithm_cpu, threshold):
    out = Path(tmp_path) / f"out_{threshold}.png"
    algorithm_cpu.process_images(
        master_path=checkerboard,
        target_path=checkerboard,
        output_path=str(out),
        edge_blur_enabled=True,
        edge_blur_radius=1.5,
        edge_blur_strength=0.5,
        edge_detection_threshold=threshold,
        num_colors=4,
    )
    arr = np.array(Image.open(out))
    pytest._thresh_colors = getattr(pytest, "_thresh_colors", {})
    pytest._thresh_colors[threshold] = len(np.unique(arr.reshape(-1, 3), axis=0))

def test_edge_detection_threshold_inverse():
    data = getattr(pytest, "_thresh_colors", {})
    assert data, "Param loop missing"
    assert data[0.05] >= data[0.2] >= data[0.5], "Unique color count should decrease with threshold"

--- File: tests\parameters\test_num_colors.py ---
"""Parameter test: num_colors
Verifies that varying `num_colors` changes color quantization quality.
Converted to pure pytest with common fixtur es.
"""

import numpy as np
from PIL import Image
import pytest
from pathlib import Path


@pytest.mark.parametrize("num_colors", [4, 16, 64])
def test_num_colors_variation(tmp_path, gradient_image, noise_image, algorithm_cpu, num_colors):
    out = Path(tmp_path) / f"result_{num_colors}.png"

    ok = algorithm_cpu.process_images(
        master_path=noise_image,
        target_path=gradient_image,
        output_path=str(out),
        num_colors=num_colors,
    )
    assert ok and out.exists()

    result_arr = np.array(Image.open(out))
    unique_colors = len(np.unique(result_arr.reshape(-1, 3), axis=0))

    # Store result in test metadata for later comparison
    pytest.unique_colors = getattr(pytest, "unique_colors", {})
    pytest.unique_colors[num_colors] = unique_colors


def test_num_colors_monotonicity():
    """Ensure unique color count increases with num_colors and error decreases."""
    data = getattr(pytest, "unique_colors", {})
    assert data, "Previous parametrized test did not run."
    assert data[4] <= data[16] <= data[64]

--- File: tests\parameters\__init__.py ---
