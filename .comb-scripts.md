# project name: Gatto Nero Ai Manager (PY+JSX)

ROOT: d:\Unity\Projects\GattoNeroPhotoshop

---

## file tree list

### Found Files (37)
- .comb-doc.py ()
- .comb-scripts.py ()
- __init__.py (\app)
- __init__.py (\app\algorithms)
- __init__.py (\app\algorithms\algorithm_01_palette)
- algorithm.py (\app\algorithms\algorithm_01_palette)
- config.py (\app\algorithms\algorithm_01_palette)
- tests.py (\app\algorithms\algorithm_01_palette)
- __init__.py (\app\algorithms\algorithm_02_statistical)
- algorithm.py (\app\algorithms\algorithm_02_statistical)
- __init__.py (\app\algorithms\algorithm_03_histogram)
- algorithm.py (\app\algorithms\algorithm_03_histogram)
- __init__.py (\app\api)
- routes.py (\app\api)
- __init__.py (\app\core)
- development_logger.py (\app\core)
- file_handler.py (\app\core)
- health_monitor.py (\app\core)
- health_monitor_simple.py (\app\core)
- performance_profiler.py (\app\core)
- __init__.py (\app\processing)
- palette_analyzer.py (\app\processing)
- color_matcher.jsx (\app\scripts)
- palette_analyzer.jsx (\app\scripts)
- test_simple.jsx (\app\scripts)
- server.py (\app)
- run_server.py ()
- server_manager_enhanced.py ()
- server_manager_enhanced_fixed.py ()
- test_algorithm_integration.py ()
- test_basic.py ()
- test_curl.py ()
- test_runner.py ()
- test_speed.py ()
- __init__.py (\tests)
- base_test_case.py (\tests)
- test_base_case_demo.py (\tests)

---

## file content

### .comb-doc.py - ./.comb-doc.py

``````
﻿import os
from pathlib import Path

# =================================================================================
# SCRIPT FOR FILE AGGREGATION
#
# Wersja: 4.0 (Uniwersalna)
# Opis: Skrypt wyszukuje pliki pasujące do podanych wzorców (np. *.md, *.py)
#       w określonych katalogach, filtruje je na podstawie .gitignore,
#       a następnie łączy ich zawartość w jeden zbiorczy plik .md.
# =================================================================================

# --- KONFIGURACJA ---
# W tej sekcji możesz dostosować działanie skryptu do swoich potrzeb.

# Nazwa projektu, która pojawi się w nagłówku pliku wyjściowego.
PROJECT_NAME = "Gatto Nero Ai Manager (Dokumentacja)"

# Nazwa pliku, do którego zostanie zapisany wynik.
OUTPUT_FILE = ".comb-doc.md"

# ---------------------------------------------------------------------------------
# WZORCE PLIKÓW (FILE_PATTERNS)
# ---------------------------------------------------------------------------------
# Zdefiniuj, jakie pliki mają być wyszukiwane. Możesz podać jeden lub wiele wzorców.
#
# PRZYKŁADY:
# - Tylko pliki Markdown:      FILE_PATTERNS = ['*.md']
# - Pliki Python i JSX:        FILE_PATTERNS = ['*.py', '*.jsx']
# - Tylko pliki tekstowe:      FILE_PATTERNS = ['*.txt']
#
FILE_PATTERNS = ['*.md']
# ---------------------------------------------------------------------------------

# ŚCIEŻKI DO PRZESZUKANIA ($includePaths)
# Lista katalogów do przeszukania. Użyj ['all'] aby przeszukać wszystko.
INCLUDE_PATHS = ['app/algorithms/algorithm_01_palette']

# Nazwa pliku .gitignore, używanego do wykluczeń.
GITIGNORE_FILE = ".gitignore"


# =================================================================================
# --- SILNIK SKRYPTU (zazwyczaj nie wymaga modyfikacji) ---
# =================================================================================

def load_gitignore_patterns(root_path):
    """Wczytuje i przetwarza wzorce z pliku .gitignore."""
    gitignore_path = root_path / GITIGNORE_FILE
    patterns = []
    if gitignore_path.exists():
        print("Znaleziono plik .gitignore. Stosuję reguły wykluczeń.")
        with open(gitignore_path, 'r', encoding='utf-8') as f:
            for line in f:
                stripped_line = line.strip()
                if stripped_line and not stripped_line.startswith('#'):
                    patterns.append(stripped_line)
    else:
        print(".gitignore nie został znaleziony.")
    return patterns

def is_ignored(file_path, root_path, ignore_patterns):
    """Sprawdza, czy dany plik powinien być zignorowany na podstawie wzorców."""
    relative_path_str = str(file_path.relative_to(root_path).as_posix())
    for pattern in ignore_patterns:
        if pattern.endswith('/'):
            if f"/{pattern[:-1]}/" in f"/{relative_path_str}":
                return True
        elif file_path.match(pattern):
             return True
    return False

def find_files_to_process(root_path, ignore_patterns):
    """Znajduje wszystkie pliki do przetworzenia zgodnie z konfiguracją."""
    print(f"Wyszukiwanie plików pasujących do wzorców: {', '.join(FILE_PATTERNS)}...")
    all_found_files = []

    search_paths = []
    if 'all' in INCLUDE_PATHS:
        search_paths.append(root_path)
    else:
        for include_path in INCLUDE_PATHS:
            full_search_path = root_path / include_path
            if full_search_path.is_dir():
                search_paths.append(full_search_path)
            else:
                print(f"UWAGA: Ścieżka '{include_path}' nie istnieje i została pominięta.")

    for path in search_paths:
        for pattern in FILE_PATTERNS:
            # Używamy **/{pattern}, aby szukać rekursywnie
            all_found_files.extend(path.glob(f'**/{pattern}'))
    
    files_to_process = []
    for file in all_found_files:
        if file.name == OUTPUT_FILE or is_ignored(file, root_path, ignore_patterns):
            continue
        files_to_process.append(file)
            
    unique_files = sorted(list(set(files_to_process)))
    print(f"Znaleziono {len(unique_files)} unikalnych plików do przetworzenia.")
    return unique_files

def read_file_with_fallback_encoding(file_path):
    """Probuje odczytac plik jako UTF-8, a jesli sie nie uda, jako windows-1250."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except UnicodeDecodeError:
        print(f"  -> Plik '{file_path.name}' nie jest w UTF-8, próba odczytu jako windows-1250.")
        try:
            with open(file_path, 'r', encoding='windows-1250') as f:
                return f.read()
        except Exception as e:
            return f"BŁĄD ODCZYTU PLIKU {file_path.name}: {e}"
    except Exception as e:
        return f"NIEOCZEKIWANY BŁĄD ODCZYTU PLIKU {file_path.name}: {e}"

def main():
    """Główna funkcja skryptu."""
    root_path = Path.cwd()
    print(f"Rozpoczynam agregację dla projektu: {PROJECT_NAME}")

    ignore_patterns = load_gitignore_patterns(root_path)
    files_to_process = find_files_to_process(root_path, ignore_patterns)
    
    markdown_content = []
    markdown_content.append(f"# project name: {PROJECT_NAME}\n\nROOT: {root_path}\n\n---\n")
    markdown_content.append("## file tree list\n")
    if files_to_process:
        markdown_content.append(f"### Found Files ({len(files_to_process)})")
        for file in files_to_process:
            dir_path = str(file.parent.relative_to(root_path))
            dir_path = '' if dir_path == '.' else f"\\{dir_path}"
            markdown_content.append(f"- {file.name} ({dir_path})")
        markdown_content.append("")
    markdown_content.append("---\n")

    markdown_content.append("## file content\n")
    for file in files_to_process:
        relative_path = file.relative_to(root_path).as_posix()
        markdown_content.append(f"### {file.name} - ./{relative_path}\n")
        markdown_content.append('``````')
        content = read_file_with_fallback_encoding(file)
        markdown_content.append(content)
        markdown_content.append('``````\n')

    final_content = "\n".join(markdown_content)
    try:
        # Zapisujemy z 'utf-8-sig' dla najlepszej kompatybilnosci z programami na Windows
        with open(root_path / OUTPUT_FILE, 'w', encoding='utf-8-sig') as f:
            f.write(final_content)
        print(f"Gotowe! Plik '{OUTPUT_FILE}' został utworzony.")
    except Exception as e:
        print(f"BŁĄD ZAPISU PLIKU: {e}")

if __name__ == "__main__":
    main()
``````

### .comb-scripts.py - ./.comb-scripts.py

``````
﻿import os
from pathlib import Path

# =================================================================================
# SCRIPT FOR FILE AGGREGATION
#
# Wersja: 4.0 (Uniwersalna)
# Opis: Skrypt wyszukuje pliki pasujące do podanych wzorców (np. *.md, *.py)
#       w określonych katalogach, filtruje je na podstawie .gitignore,
#       a następnie łączy ich zawartość w jeden zbiorczy plik .md.
# =================================================================================

# --- KONFIGURACJA ---
# W tej sekcji możesz dostosować działanie skryptu do swoich potrzeb.

# Nazwa projektu, która pojawi się w nagłówku pliku wyjściowego.
PROJECT_NAME = "Gatto Nero Ai Manager (PY+JSX)"

# Nazwa pliku, do którego zostanie zapisany wynik.
OUTPUT_FILE = ".comb-scripts.md"

# ---------------------------------------------------------------------------------
# WZORCE PLIKÓW (FILE_PATTERNS)
# ---------------------------------------------------------------------------------
# Zdefiniuj, jakie pliki mają być wyszukiwane. Możesz podać jeden lub wiele wzorców.
#
# PRZYKŁADY:
# - Tylko pliki Markdown:      FILE_PATTERNS = ['*.md']
# - Pliki Python i JSX:        FILE_PATTERNS = ['*.py', '*.jsx']
# - Tylko pliki tekstowe:      FILE_PATTERNS = ['*.txt']
#
FILE_PATTERNS = ['*.py', '*.jsx']
# ---------------------------------------------------------------------------------

# ŚCIEŻKI DO PRZESZUKANIA ($includePaths)
# Lista katalogów do przeszukania. Użyj ['all'] aby przeszukać wszystko.
INCLUDE_PATHS = ['all']

# Nazwa pliku .gitignore, używanego do wykluczeń.
GITIGNORE_FILE = ".gitignore"


# =================================================================================
# --- SILNIK SKRYPTU (zazwyczaj nie wymaga modyfikacji) ---
# =================================================================================

def load_gitignore_patterns(root_path):
    """Wczytuje i przetwarza wzorce z pliku .gitignore."""
    gitignore_path = root_path / GITIGNORE_FILE
    patterns = []
    if gitignore_path.exists():
        print("Znaleziono plik .gitignore. Stosuję reguły wykluczeń.")
        with open(gitignore_path, 'r', encoding='utf-8') as f:
            for line in f:
                stripped_line = line.strip()
                if stripped_line and not stripped_line.startswith('#'):
                    patterns.append(stripped_line)
    else:
        print(".gitignore nie został znaleziony.")
    return patterns

def is_ignored(file_path, root_path, ignore_patterns):
    """Sprawdza, czy dany plik powinien być zignorowany na podstawie wzorców."""
    relative_path_str = str(file_path.relative_to(root_path).as_posix())
    for pattern in ignore_patterns:
        if pattern.endswith('/'):
            if f"/{pattern[:-1]}/" in f"/{relative_path_str}":
                return True
        elif file_path.match(pattern):
             return True
    return False

def find_files_to_process(root_path, ignore_patterns):
    """Znajduje wszystkie pliki do przetworzenia zgodnie z konfiguracją."""
    print(f"Wyszukiwanie plików pasujących do wzorców: {', '.join(FILE_PATTERNS)}...")
    all_found_files = []

    search_paths = []
    if 'all' in INCLUDE_PATHS:
        search_paths.append(root_path)
    else:
        for include_path in INCLUDE_PATHS:
            full_search_path = root_path / include_path
            if full_search_path.is_dir():
                search_paths.append(full_search_path)
            else:
                print(f"UWAGA: Ścieżka '{include_path}' nie istnieje i została pominięta.")

    for path in search_paths:
        for pattern in FILE_PATTERNS:
            # Używamy **/{pattern}, aby szukać rekursywnie
            all_found_files.extend(path.glob(f'**/{pattern}'))
    
    files_to_process = []
    for file in all_found_files:
        if file.name == OUTPUT_FILE or is_ignored(file, root_path, ignore_patterns):
            continue
        files_to_process.append(file)
            
    unique_files = sorted(list(set(files_to_process)))
    print(f"Znaleziono {len(unique_files)} unikalnych plików do przetworzenia.")
    return unique_files

def read_file_with_fallback_encoding(file_path):
    """Probuje odczytac plik jako UTF-8, a jesli sie nie uda, jako windows-1250."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except UnicodeDecodeError:
        print(f"  -> Plik '{file_path.name}' nie jest w UTF-8, próba odczytu jako windows-1250.")
        try:
            with open(file_path, 'r', encoding='windows-1250') as f:
                return f.read()
        except Exception as e:
            return f"BŁĄD ODCZYTU PLIKU {file_path.name}: {e}"
    except Exception as e:
        return f"NIEOCZEKIWANY BŁĄD ODCZYTU PLIKU {file_path.name}: {e}"

def main():
    """Główna funkcja skryptu."""
    root_path = Path.cwd()
    print(f"Rozpoczynam agregację dla projektu: {PROJECT_NAME}")

    ignore_patterns = load_gitignore_patterns(root_path)
    files_to_process = find_files_to_process(root_path, ignore_patterns)
    
    markdown_content = []
    markdown_content.append(f"# project name: {PROJECT_NAME}\n\nROOT: {root_path}\n\n---\n")
    markdown_content.append("## file tree list\n")
    if files_to_process:
        markdown_content.append(f"### Found Files ({len(files_to_process)})")
        for file in files_to_process:
            dir_path = str(file.parent.relative_to(root_path))
            dir_path = '' if dir_path == '.' else f"\\{dir_path}"
            markdown_content.append(f"- {file.name} ({dir_path})")
        markdown_content.append("")
    markdown_content.append("---\n")

    markdown_content.append("## file content\n")
    for file in files_to_process:
        relative_path = file.relative_to(root_path).as_posix()
        markdown_content.append(f"### {file.name} - ./{relative_path}\n")
        markdown_content.append('``````')
        content = read_file_with_fallback_encoding(file)
        markdown_content.append(content)
        markdown_content.append('``````\n')

    final_content = "\n".join(markdown_content)
    try:
        # Zapisujemy z 'utf-8-sig' dla najlepszej kompatybilnosci z programami na Windows
        with open(root_path / OUTPUT_FILE, 'w', encoding='utf-8-sig') as f:
            f.write(final_content)
        print(f"Gotowe! Plik '{OUTPUT_FILE}' został utworzony.")
    except Exception as e:
        print(f"BŁĄD ZAPISU PLIKU: {e}")

if __name__ == "__main__":
    main()
``````

### __init__.py - ./app/__init__.py

``````
# Makes 'app' a package

``````

### __init__.py - ./app/algorithms/__init__.py

``````
"""
GattoNero AI Assistant - Algorithm Modules
==========================================

This package contains modular algorithm implementations for color matching
and image processing. Each algorithm is self-contained with comprehensive
monitoring, testing, and documentation.

Available Algorithms:
- Algorithm 01: Palette Mapping (K-means based color palette extraction)
- Algorithm 02: Statistical Transfer (LAB color space statistical matching)
- Algorithm 03: Histogram Matching (Luminance channel histogram specification)
"""

# Import algorithm factories for easy access
from .algorithm_01_palette import (
    create_palette_mapping_algorithm
)
from .algorithm_02_statistical import (
    create_statistical_transfer_algorithm,
    basic_statistical_transfer
)
from .algorithm_03_histogram import (
    create_histogram_matching_algorithm,
    simple_histogram_matching
)

# Algorithm registry for dynamic access
ALGORITHM_REGISTRY = {
    'algorithm_01_palette': create_palette_mapping_algorithm,
    'algorithm_02_statistical': create_statistical_transfer_algorithm,
    'algorithm_03_histogram': create_histogram_matching_algorithm,
}

# Legacy function mapping for backward compatibility
LEGACY_FUNCTIONS = {
    'method2': basic_statistical_transfer,
    'method3': simple_histogram_matching,
}

def get_algorithm(algorithm_id: str):
    """Get algorithm instance by ID."""
    if algorithm_id in ALGORITHM_REGISTRY:
        return ALGORITHM_REGISTRY[algorithm_id]()
    raise ValueError(f"Unknown algorithm: {algorithm_id}")

def get_legacy_function(method: str):
    """Get legacy function by method name."""
    if method in LEGACY_FUNCTIONS:
        return LEGACY_FUNCTIONS[method]
    raise ValueError(f"Unknown method: {method}")

__all__ = [
    # Algorithm factories
    'create_palette_mapping_algorithm',
    'create_statistical_transfer_algorithm', 
    'create_histogram_matching_algorithm',
    
    # Legacy compatibility functions
    'basic_statistical_transfer',
    'simple_histogram_matching',
    
    # Dynamic access
    'get_algorithm',
    'get_legacy_function',
    'ALGORITHM_REGISTRY',
    'LEGACY_FUNCTIONS'
]

``````

### __init__.py - ./app/algorithms/algorithm_01_palette/__init__.py

``````
"""
Algorithm 01: Palette Mapping
============================

This module provides palette-based color matching functionality using K-means clustering.
"""

from .algorithm import (
    PaletteMappingAlgorithm,
    create_palette_mapping_algorithm
)

__all__ = [
    'PaletteMappingAlgorithm',
    'create_palette_mapping_algorithm'
]

``````

### algorithm.py - ./app/algorithms/algorithm_01_palette/algorithm.py

``````
import numpy as np
from PIL import Image, ImageFilter, PngImagePlugin
import time
import os
from tqdm import tqdm
import json
from skimage import color # For LAB color space conversion
from skimage import exposure # For dithering (match_histograms)
from typing import TYPE_CHECKING, Any
try:
    from app.core.development_logger import get_logger
    from app.core.performance_profiler import get_profiler
    if TYPE_CHECKING:
        from app.core.development_logger import DevelopmentLogger
        from app.core.performance_profiler import PerformanceProfiler
except ImportError:
    import logging
    def get_logger() -> Any:
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
        return logging.getLogger(__name__)
    class DummyProfiler:
        def start(self, name): pass
        def stop(self, name): pass
        def get_report(self): return "Profiler not available."
    def get_profiler() -> Any:
        return DummyProfiler()

class PaletteMappingAlgorithm:
    def __init__(self, config_path=None, algorithm_id: str = "algorithm_01_palette"):
        self.algorithm_id = algorithm_id
        if TYPE_CHECKING:
            self.logger: 'DevelopmentLogger' = get_logger()
            self.profiler: 'PerformanceProfiler' = get_profiler()
        else:
            self.logger = get_logger()
            self.profiler = get_profiler()
        self.logger.info(f"Initialized algorithm: {self.algorithm_id}")
        self.name = "Simple Palette Mapping"
        self.version = "1.2"
        self.config = self.load_config(config_path) if config_path else self.default_config()
        self.distance_cache = {}
        
    def default_config(self):
        """Returns the default configuration dictionary."""
        return {
            'num_colors': 16,
            'distance_metric': 'weighted_rgb', # 'rgb', 'weighted_rgb', 'lab'
            'use_cache': True,
            'preprocess': False,
            'thumbnail_size': (100, 100),
            'use_vectorized': True,
            'cache_max_size': 10000,
            'use_dithering': False,
            'preserve_luminance': False,
            'exclude_colors': [], # List of RGB tuples to exclude
            'preview_mode': False,
            'preview_thumbnail_size': (500, 500) # Max size for preview
        }
    
    def load_config(self, config_path):
        """Loads configuration from a JSON file."""
        try:
            with open(config_path, 'r') as f:
                return json.load(f)
        except Exception as e:
            self.logger.error(f"Error loading configuration: {e}, using default.")
            return self.default_config()
    
    def clear_cache(self):
        """Clears the distance cache."""
        self.distance_cache.clear()
        
    def validate_palette(self, palette):
        """Validates the color palette."""
        if not palette or len(palette) == 0:
            raise ValueError("Palette cannot be empty")
        
        for i, color_val in enumerate(palette):
            if len(color_val) != 3:
                raise ValueError(f"Color {i} must have 3 RGB components, has {len(color_val)}")
            if not all(0 <= c <= 255 for c in color_val):
                raise ValueError(f"Color {i} has values outside the 0-255 range: {color_val}")
                
    def extract_palette(self, image_path, num_colors=None):
        """
        Extracts a color palette from the master image using proper quantization.
        """
        if num_colors is None:
            num_colors = self.config['num_colors']
            
        try:
            image = Image.open(image_path)
            
            # Handle RGBA - convert to RGB with a white background
            if image.mode == 'RGBA':
                background = Image.new('RGB', image.size, (255, 255, 255))
                background.paste(image, mask=image.split()[-1])
                image = background
            elif image.mode != 'RGB':
                image = image.convert('RGB')
            
            # Resize image for faster quantization processing
            original_size = image.size
            image.thumbnail(self.config['thumbnail_size'])
            
            # Use quantize() for proper extraction of dominant colors
            quantized = image.quantize(colors=num_colors)
            palette_data = quantized.getpalette()
            
            if not palette_data:
                raise ValueError("Could not extract palette data from image.")

            # Ensure palette_data has enough elements for the requested num_colors
            palette_data = palette_data[:num_colors*3]
            
            # Convert to a list of RGB tuples
            palette = [[palette_data[i], palette_data[i+1], palette_data[i+2]] 
                       for i in range(0, len(palette_data), 3)]
            
            # Filter out excluded colors
            if self.config['exclude_colors']:
                initial_len = len(palette)
                excluded_set = set(tuple(c) for c in self.config['exclude_colors'])
                palette = [color_val for color_val in palette if tuple(color_val) not in excluded_set]
                self.logger.info(f"Excluded {initial_len - len(palette)} colors from the palette.")

            self.validate_palette(palette)
            self.logger.info(f"Extracted {len(palette)} colors from image {original_size} -> {image.size}")
            return palette
            
        except Exception as e:
            self.logger.error(f"Error extracting palette from {image_path}: {e}")
            # A better default palette with basic colors
            default_palette = [
                [0, 0, 0],       # Black
                [255, 255, 255], # White
                [255, 0, 0],     # Red
                [0, 255, 0],     # Green
                [0, 0, 255],     # Blue
                [255, 255, 0],   # Yellow
                [255, 0, 255],   # Magenta
                [0, 255, 255],   # Cyan
                [128, 128, 128], # Gray
                [192, 192, 192], # Light Gray
                [128, 0, 0],     # Maroon
                [0, 128, 0],     # Dark Green
                [0, 0, 128],     # Navy
                [128, 128, 0],   # Olive
                [128, 0, 128],   # Purple
                [0, 128, 128]    # Teal
            ]
            return default_palette[:num_colors if num_colors else 16]
    
    def calculate_rgb_distance(self, color1, color2):
        """
        Calculates the distance between two RGB colors with caching and size control.
        """
        key = None # Initialize key to None

        if self.config['use_cache']:
            # Control cache size
            if len(self.distance_cache) > self.config['cache_max_size']:
                self.clear_cache()
                
            key = (tuple(color1), tuple(color2))
            if key in self.distance_cache:
                return self.distance_cache[key]
        
        # Calculate distance regardless of caching
        if self.config['distance_metric'] == 'weighted_rgb':
            distance = self.calculate_weighted_rgb_distance(color1, color2)
        elif self.config['distance_metric'] == 'lab':
            distance = self.calculate_lab_distance(color1, color2)
        else: # default to euclidean RGB
            dr = float(color1[0]) - float(color2[0])
            dg = float(color1[1]) - float(color2[1])
            db = float(color1[2]) - float(color2[2])
            distance = np.sqrt(dr*dr + dg*dg + db*db)
        
        # Store in cache only if caching is enabled and key was defined
        if self.config['use_cache'] and key is not None:
            self.distance_cache[key] = distance
        
        return distance
    
    def calculate_weighted_rgb_distance(self, color1, color2):
        """
        Calculates weighted RGB distance based on human perception.
        Weights align with the ITU-R BT.709 standard for luminance.
        """
        # Weights based on human perception - ITU-R BT.709 standard
        r_weight = 0.2126  # Red
        g_weight = 0.7152  # Green (most important for brightness perception)
        b_weight = 0.0722  # Blue
        
        # Explicitly cast to float to prevent any potential uint8 issues
        dr = (float(color1[0]) - float(color2[0])) * r_weight
        dg = (float(color1[1]) - float(color2[1])) * g_weight
        db = (float(color1[2]) - float(color2[2])) * b_weight
        
        return np.sqrt(dr*dr + dg*dg + db*db)

    def calculate_lab_distance(self, color1, color2):
        """
        Calculates distance in LAB space.
        Converts RGB colors (0-255) to LAB, then calculates Euclidean distance.
        """
        # Convert RGB (0-255) to LAB (L:0-100, a:-128-127, b:-128-127)
        # scikit-image expects RGB in the range 0-1
        lab1 = color.rgb2lab(np.array([[color1]], dtype=np.uint8) / 255.0)[0][0]
        lab2 = color.rgb2lab(np.array([[color2]], dtype=np.uint8) / 255.0)[0][0]
        
        # Euclidean distance in LAB space
        return np.sqrt(np.sum((lab1 - lab2)**2))
    
    def find_closest_color(self, target_color, master_palette):
        """
        Finds the closest color in the master palette for a target color.
        """
        min_distance = float('inf')
        best_color = master_palette[0]
        
        for color_val in master_palette:
            distance = self.calculate_rgb_distance(target_color, color_val)
            if distance < min_distance:
                min_distance = distance
                best_color = color_val
                
        return best_color
    
    def apply_mapping(self, target_image_path, master_palette):
        """
        Main mapping function - applies the master palette to the target image.
        """
        start_time = time.time()
        
        try:
            # Load the target image
            target_image = Image.open(target_image_path)
            
            # Handle RGBA - convert to RGB with a white background
            if target_image.mode == 'RGBA':
                background = Image.new('RGB', target_image.size, (255, 255, 255))
                background.paste(target_image, mask=target_image.split()[-1])
                target_image = background
            elif target_image.mode != 'RGB':
                target_image = target_image.convert('RGB')
            
            # Optional preprocessing
            if self.config['preprocess']:
                target_image = target_image.filter(ImageFilter.SMOOTH_MORE)
                self.logger.info("Applied smoothing to the target image.")
            
            # Clear cache before processing
            if self.config['use_cache']:
                self.clear_cache()
            
            # Use the vectorized version if enabled
            if self.config['use_vectorized']:
                return self.apply_mapping_vectorized(target_image, master_palette, start_time)
            else:
                return self.apply_mapping_naive(target_image, master_palette, start_time)
                
        except Exception as e:
            self.logger.error(f"Error during image mapping for {target_image_path}: {e}")
            return None
    
    def apply_mapping_vectorized(self, target_image, master_palette, start_time):
        """
        Fast, vectorized version of mapping using NumPy.
        """
        width, height = target_image.size
        target_array = np.array(target_image)
        
        # Reshape to (height*width, 3) and convert to float64 for consistent precision
        pixels = target_array.reshape(-1, 3).astype(np.float64)
        palette_array = np.array(master_palette).astype(np.float64)
        
        self.logger.info(f"Calculating distances vectorized for {len(pixels)} pixels and {len(master_palette)} palette colors...")
        
        # Calculate all distances at once
        if self.config['distance_metric'] == 'weighted_rgb':
            # Perceptual weights according to ITU-R BT.709
            weights = np.array([0.2126, 0.7152, 0.0722], dtype=np.float64)
            distances = np.sqrt(np.sum(((pixels[:, np.newaxis] - palette_array) * weights)**2, axis=2))
        else: # Default to standard Euclidean distance
            distances = np.sqrt(np.sum((pixels[:, np.newaxis] - palette_array)**2, axis=2))
        
        # Find the closest colors
        closest_indices = np.argmin(distances, axis=1)
        result_pixels = palette_array[closest_indices]
        
        # Preserve luminance if enabled
        if self.config['preserve_luminance']:
            # Convert original image to LAB
            original_lab = color.rgb2lab(target_array / 255.0)
            # Convert result to LAB
            result_lab = color.rgb2lab(result_pixels.reshape(target_array.shape).astype(np.uint8) / 255.0)
            # Replace L channel of result with original L channel
            result_lab[:, :, 0] = original_lab[:, :, 0]
            # Convert back to RGB
            result_pixels = (color.lab2rgb(result_lab) * 255).astype(np.uint8).reshape(-1, 3)

        # Apply dithering if enabled (only for non-luminance preserved images)
        if self.config['use_dithering'] and not self.config['preserve_luminance']:
            # This is a simplified dithering
            dithered_image = Image.fromarray(result_pixels.reshape(target_array.shape).astype(np.uint8))
            dithered_image = dithered_image.convert("L").convert("RGB") # Convert to grayscale then back
            result_pixels = np.array(dithered_image).reshape(-1, 3)

        # Reshape back to image dimensions
        result_array = result_pixels.reshape(target_array.shape)
        result_image = Image.fromarray(result_array.astype(np.uint8))
        
        processing_time = time.time() - start_time
        self.logger.info(f"Vectorized processing finished in {processing_time:.2f} seconds")
        
        return result_image
    
    def apply_mapping_naive(self, target_image, master_palette, start_time):
        """
        Naive pixel-by-pixel version (for comparison and debugging).
        """
        width, height = target_image.size
        target_array = np.array(target_image)
        result_array = np.zeros_like(target_array)
        
        original_lab_array = None # Initialize to None
        # Store original luminance if preserving
        if self.config['preserve_luminance']:
            original_lab_array = color.rgb2lab(target_array / 255.0)
        
        self.logger.info(f"Naive mapping for image {width}x{height}...")
        
        # Process each pixel with a progress bar
        for y in tqdm(range(height), desc="Mapping colors", unit="row"):
            for x in range(width):
                target_color = target_array[y, x]
                mapped_color = self.find_closest_color(target_color, master_palette)
                
                # Preserve luminance if enabled
                if self.config['preserve_luminance'] and original_lab_array is not None:
                    mapped_lab = color.rgb2lab(np.array([[mapped_color]], dtype=np.uint8) / 255.0)[0][0]
                    mapped_lab[0] = original_lab_array[y, x, 0] # Replace L channel
                    mapped_color = (color.lab2rgb(np.array([mapped_lab])) * 255).astype(np.uint8)[0]

                result_array[y, x] = mapped_color
        
        # Apply dithering if enabled (only for non-luminance preserved images)
        if self.config['use_dithering'] and not self.config['preserve_luminance']:
            # This is a simplified dithering
            dithered_image = Image.fromarray(result_array.astype(np.uint8))
            dithered_image = dithered_image.convert("L").convert("RGB") # Convert to grayscale then back
            result_array = np.array(dithered_image)

        # Convert back to PIL Image
        result_image = Image.fromarray(result_array.astype(np.uint8))
        
        processing_time = time.time() - start_time
        self.logger.info(f"Naive processing finished in {processing_time:.2f} seconds")
        
        return result_image
    
    def process_images(self, master_path, target_path, output_path, **kwargs):
        """
        Complete process: extract palette from MASTER and apply to TARGET.
        
        Args:
            master_path: Path to the master image (palette source)
            target_path: Path to the target image (transformation destination)
            output_path: Path to save the result
            **kwargs: Additional parameters, including preview_mode
        """
        # Update config with kwargs for this specific process call
        current_config = self.config.copy()
        for key, value in kwargs.items():
            if key in current_config:
                current_config[key] = value
        
        self.logger.info(f"🎨 Starting {self.name} v{self.version}")
        self.logger.info(f"📁 Master (palette): {os.path.basename(master_path)}")
        self.logger.info(f"📁 Target (destination): {os.path.basename(target_path)}")
        
        # Handle preview mode
        original_target_path = target_path
        original_master_path = master_path
        
        temp_master_path, temp_target_path = None, None
        
        try:
            if current_config['preview_mode']:
                self.logger.info("🖼️ Preview mode: scaling images to a smaller resolution.")
                
                # Create temporary paths for resized images
                temp_dir = os.path.dirname(output_path)
                temp_master_path = os.path.join(temp_dir, f"temp_master_{os.path.basename(master_path)}")
                temp_target_path = os.path.join(temp_dir, f"temp_target_{os.path.basename(target_path)}")

                with Image.open(master_path) as master_image_pil:
                    master_image_pil.thumbnail(current_config['preview_thumbnail_size'])
                    master_image_pil.save(temp_master_path)
                    master_path = temp_master_path
                    self.logger.info(f"Resized master for preview: {master_image_pil.size}")

                with Image.open(target_path) as target_image_pil:
                    target_image_pil.thumbnail(current_config['preview_thumbnail_size'])
                    target_image_pil.save(temp_target_path)
                    target_path = temp_target_path
                    self.logger.info(f"Resized target for preview: {target_image_pil.size}")

            # Extract the palette from the MASTER image
            self.logger.info("🎯 Extracting color palette from MASTER image...")
            master_palette = self.extract_palette(master_path) 
            self.logger.info(f"✅ Extracted {len(master_palette)} colors from the master palette")
            
            # Show sample colors from the palette
            self.logger.info("🎨 Sample colors from master palette:")
            for i, color_val in enumerate(master_palette[:5]): # Show first 5
                self.logger.info(f"   Color {i+1}: RGB({color_val[0]}, {color_val[1]}, {color_val[2]})")
            if len(master_palette) > 5:
                self.logger.info(f"   ... and {len(master_palette)-5} more")
            
            # Apply the mapping to the TARGET image
            self.logger.info("🔄 Applying color mapping to TARGET image...")
            result = self.apply_mapping(target_path, master_palette)
            
            if result:
                # Save with metadata
                try:
                    pnginfo = PngImagePlugin.PngInfo()
                    pnginfo.add_text("Algorithm", f"{self.name} v{self.version}")
                    pnginfo.add_text("MasterFile", os.path.basename(original_master_path))
                    pnginfo.add_text("TargetFile", os.path.basename(original_target_path))
                    pnginfo.add_text("PaletteSize", str(len(master_palette)))
                    pnginfo.add_text("DistanceMetric", current_config['distance_metric'])
                    pnginfo.add_text("ProcessingDate", time.strftime("%Y-%m-%d %H:%M:%S"))
                    
                    if output_path.lower().endswith('.png'):
                        result.save(output_path, pnginfo=pnginfo)
                    else:
                        result.save(output_path)
                        
                    self.logger.info(f"💾 Result saved: {output_path}")
                    return True
                except Exception as e:
                    self.logger.error(f"❌ Error during saving: {e}")
                    return False
            else:
                self.logger.error("❌ Error during processing")
                return False
        finally:
            # Clean up temporary preview files
            if temp_master_path and os.path.exists(temp_master_path):
                os.remove(temp_master_path)
            if temp_target_path and os.path.exists(temp_target_path):
                os.remove(temp_target_path)
    
    def analyze_mapping_quality(self, original_path, mapped_image):
        """
        Analysis of mapping quality - basic statistics.
        """
        try:
            original = Image.open(original_path).convert('RGB')
            # Ensure mapped image is a PIL Image object
            if not isinstance(mapped_image, Image.Image):
                 raise TypeError("mapped_image must be a PIL Image object")

            original_array = np.array(original)
            mapped_array = np.array(mapped_image.convert('RGB'))

            # Basic statistics
            stats = {
                'unique_colors_before': len(np.unique(original_array.reshape(-1, 3), axis=0)),
                'unique_colors_after': len(np.unique(mapped_array.reshape(-1, 3), axis=0)),
                'mean_rgb_difference': np.mean(np.abs(original_array.astype(float) - mapped_array.astype(float))),
                'max_rgb_difference': np.max(np.abs(original_array.astype(float) - mapped_array.astype(float)))
            }
            return stats
        except Exception as e:
            self.logger.error(f"Quality analysis error: {e}")
            return None

# Factory function
def create_palette_mapping_algorithm():
    return PaletteMappingAlgorithm()


``````

### config.py - ./app/algorithms/algorithm_01_palette/config.py

``````
"""
Algorithm 01: Palette Mapping Configuration
===========================================
Konfiguracja dla algorytmu mapowania palety, w tym nowe opcje zaawansowane.
"""

from typing import Dict, Any, Optional
from dataclasses import dataclass


@dataclass
class PaletteMappingConfig:
    """Konfiguracja dla Algorytmu Mapowania Palety."""
    
    # --- NOWE OPCJE ---
    # Domyślne wartości dla nowych, zaawansowanych parametrów.
    # API będzie je nadpisywać, jeśli zostaną podane w requeście.
    
    # Grupa 1: Kontrola nad Paletą
    k_colors: int = 16
    palette_source_area: str = "full_image"  # Opcje: 'full_image', 'selection', 'active_layer'
    exclude_colors: Optional[list] = None     # Lista kolorów RGB do wykluczenia, np. [[255,255,255]]

    # Grupa 2: Kontrola nad Mapowaniem
    distance_metric: str = "LAB"             # Opcje: 'RGB', 'LAB' (percepcyjna)
    use_dithering: bool = False              # Czy włączyć rozpraszanie (dithering)
    preserve_luminance: bool = True          # Czy zachować oryginalną jasność obrazu docelowego

    # Grupa 3: Kontrola nad Wydajnością
    preview_mode: bool = False
    preview_size: tuple = (500, 500)         # Maksymalny rozmiar dla podglądu

    # --- ISTNIEJĄCE PARAMETRY K-MEANS ---
    random_state: int = 42
    n_init: int = 10
    max_iter: int = 300
    tol: float = 1e-4

# Globalna funkcja do pobierania domyślnej konfiguracji
def get_default_config() -> PaletteMappingConfig:
    """Zwraca instancję z domyślną konfiguracją."""
    return PaletteMappingConfig()

``````

### tests.py - ./app/algorithms/algorithm_01_palette/tests.py

``````
import unittest
import numpy as np
from PIL import Image
import os
from tests.base_test_case import BaseAlgorithmTestCase
from app.algorithms.algorithm_01_palette.algorithm import PaletteMappingAlgorithm

class TestPaletteMappingAlgorithm(BaseAlgorithmTestCase):
    def setUp(self):
        super().setUp() # Call the base class setUp to create self.test_dir
        self.mapper = PaletteMappingAlgorithm()
        
        # Stwórz testowy obraz 10x10 z znanymi kolorami
        self.test_colors = [
            [255, 0, 0],    # Czerwony
            [0, 255, 0],    # Zielony  
            [0, 0, 255],    # Niebieski
            [255, 255, 255] # Biały
        ]
        
        # Stwórz testowy obraz programowo
        # Using self.create_test_image for test image creation
        self.master_image_path = self.create_test_image(
            "master_test_image.png", 
            shape=(10, 10, 3), 
            color=[255, 0, 0] # Red
        )
        self.target_image_path = self.create_test_image(
            "target_test_image.png", 
            shape=(10, 10, 3), 
            color=[0, 0, 255] # Blue
        )

        # Create a more complex test image for palette extraction
        test_array = np.zeros((10, 10, 3), dtype=np.uint8)
        test_array[:5, :5] = [255, 0, 0]    # Lewy górny - czerwony
        test_array[:5, 5:] = [0, 255, 0]    # Prawy górny - zielony
        test_array[5:, :5] = [0, 0, 255]    # Lewy dolny - niebieski
        test_array[5:, 5:] = [255, 255, 255] # Prawy dolny - biały
        self.complex_test_image_path = os.path.join(self.test_dir, "complex_test_image.png")
        Image.fromarray(test_array).save(self.complex_test_image_path)


    def test_rgb_distance_euclidean(self):
        """Test podstawowej metryki euklidesowej"""
        self.mapper.config['distance_metric'] = 'euclidean'
        
        color1 = [255, 0, 0]  # Czerwony
        color2 = [0, 255, 0]  # Zielony
        distance = self.mapper.calculate_rgb_distance(color1, color2)
        expected = np.sqrt(255*255 + 255*255)  # ~360.6
        self.assertAlmostEqual(distance, expected, places=1)
        
    def test_rgb_distance_weighted(self):
        """Test ważonej metryki RGB"""
        self.mapper.config['distance_metric'] = 'weighted_rgb'
        
        color1 = [255, 0, 0]  # Czerwony
        color2 = [0, 255, 0]  # Zielony
        distance = self.mapper.calculate_rgb_distance(color1, color2)
        
        # Sprawdź czy używa właściwych wag
        expected = np.sqrt((255*0.2126)**2 + (255*0.7152)**2 + 0)
        self.assertAlmostEqual(distance, expected, places=1)
        
    def test_closest_color(self):
        """Test znajdowania najbliższego koloru"""
        target_color = [100, 100, 100]  # Szary
        master_palette = [[0, 0, 0], [255, 255, 255], [128, 128, 128]]
        closest = self.mapper.find_closest_color(target_color, master_palette)
        self.assertEqual(closest, [128, 128, 128])
        
    def test_palette_extraction_programmatic(self):
        """Test wyciągania palety z programowo utworzonego obrazu"""
        # Use the complex test image created in setUp
        palette = self.mapper.extract_palette(self.complex_test_image_path, num_colors=4)
        
        # Sprawdź czy paleta ma właściwą liczbę kolorów
        self.assertEqual(len(palette), 4)
        
        # Sprawdź czy wszystkie kolory są w prawidłowym formacie
        for color in palette:
            self.assertEqual(len(color), 3)
            for component in color:
                self.assertGreaterEqual(component, 0)
                self.assertLessEqual(component, 255)
                
        # Sprawdź czy wyciągnięte kolory są podobne do oczekiwanych
        # (z tolerancją na kwantyzację)
        palette_set = set(tuple(color) for color in palette)
        expected_colors = set(tuple(color) for color in self.test_colors)
        
        # Powinniśmy mieć wszystkie główne kolory (z pewną tolerancją)
        self.assertGreaterEqual(len(palette), 3)  # Przynajmniej 3 różne kolory
        
    def test_cache_functionality(self):
        """Test funkcjonalności cache"""
        self.mapper.config['use_cache'] = True
        self.mapper.clear_cache()
        
        color1 = [255, 0, 0]
        color2 = [0, 255, 0]
        
        # Pierwsze wywołanie - powinno obliczyć i zapisać do cache
        distance1 = self.mapper.calculate_rgb_distance(color1, color2)
        self.assertEqual(len(self.mapper.distance_cache), 1)
        
        # Drugie wywołanie - powinno pobrać z cache
        distance2 = self.mapper.calculate_rgb_distance(color1, color2)
        self.assertEqual(distance1, distance2)
        self.assertEqual(len(self.mapper.distance_cache), 1)
        
    def test_palette_validation(self):
        """Test walidacji palety"""
        # Poprawna paleta
        good_palette = [[255, 0, 0], [0, 255, 0], [0, 0, 255]]
        self.assertIsNone(self.mapper.validate_palette(good_palette))
        
        # Pusta paleta
        with self.assertRaises(ValueError):
            self.mapper.validate_palette([])
            
        # Nieprawidłowy format koloru
        with self.assertRaises(ValueError):
            self.mapper.validate_palette([[255, 0], [0, 255, 0]])
            
        # Wartości poza zakresem
        with self.assertRaises(ValueError):
            self.mapper.validate_palette([[256, 0, 0], [0, 255, 0]])

    def test_process_images(self):
        """Test kompletnego procesu mapowania obrazów."""
        output_path = os.path.join(self.test_dir, "result_mapped_image.png")
        
        # Ensure the master and target images are created by create_test_image
        # self.master_image_path and self.target_image_path are already created in setUp
        
        success = self.mapper.process_images(
            master_path=self.master_image_path,
            target_path=self.target_image_path,
            output_path=output_path
        )
        self.assertTrue(success)
        self.assertTrue(os.path.exists(output_path))
        
        # Optionally, load the result and check its properties
        result_image = Image.open(output_path)
        self.assertEqual(result_image.size, (10, 10))
        self.assertEqual(result_image.mode, 'RGB')

    def test_process_images_error_handling(self):
        """Test obsługi błędów w procesie mapowania obrazów."""
        output_path = os.path.join(self.test_dir, "result_mapped_image_error.png")
        
        # Test z nieistniejącymi plikami
        success = self.mapper.process_images(
            master_path="non_existent_master.png",
            target_path="non_existent_target.png",
            output_path=output_path
        )
        self.assertFalse(success)
        self.assertFalse(os.path.exists(output_path))

    def test_process_images_with_vectorized_and_naive(self):
        """Test porównujący wyniki wektoryzowanej i naiwnej wersji."""
        output_path_vec = os.path.join(self.test_dir, "result_vec.png")
        output_path_naive = os.path.join(self.test_dir, "result_naive.png")

        # Create a more diverse master image for better palette
        master_diverse_path = self.create_test_image(
            "master_diverse.png", 
            shape=(10, 10, 3), 
            color=None # Random colors
        )
        target_diverse_path = self.create_test_image(
            "target_diverse.png", 
            shape=(10, 10, 3), 
            color=None # Random colors
        )

        # Run vectorized version
        self.mapper.config['use_vectorized'] = True
        success_vec = self.mapper.process_images(
            master_path=master_diverse_path,
            target_path=target_diverse_path,
            output_path=output_path_vec
        )
        self.assertTrue(success_vec)
        self.assertTrue(os.path.exists(output_path_vec))

        # Run naive version
        self.mapper.config['use_vectorized'] = False
        success_naive = self.mapper.process_images(
            master_path=master_diverse_path,
            target_path=target_diverse_path,
            output_path=output_path_naive
        )
        self.assertTrue(success_naive)
        self.assertTrue(os.path.exists(output_path_naive))

        # Compare results (they should be identical or very close)
        img_vec = Image.open(output_path_vec)
        img_naive = Image.open(output_path_naive)
        
        arr_vec = np.array(img_vec)
        arr_naive = np.array(img_naive)

        # Assert that the arrays are identical
        np.testing.assert_array_equal(arr_vec, arr_naive)

if __name__ == '__main__':
    unittest.main()

``````

### __init__.py - ./app/algorithms/algorithm_02_statistical/__init__.py

``````
"""
Algorithm 02: Statistical Transfer
=================================

This module provides statistical color transfer functionality using LAB color space.
"""

from .algorithm import (
    StatisticalTransferAlgorithm,
    create_statistical_transfer_algorithm,
    basic_statistical_transfer
)

__all__ = [
    'StatisticalTransferAlgorithm',
    'create_statistical_transfer_algorithm', 
    'basic_statistical_transfer'
]

``````

### algorithm.py - ./app/algorithms/algorithm_02_statistical/algorithm.py

``````
"""
Algorithm 02: Statistical Transfer
=================================

Enhanced modular implementation of statistical color transfer algorithm.
Operates in LAB color space for better perceptual accuracy.

Design Philosophy: "Bezpiecznie = Szybko"
- Clear separation of concerns
- Comprehensive error handling  
- Performance monitoring integration
- Easy testing and validation
"""

import os
import cv2
import numpy as np
from typing import Tuple, Optional, Dict, Any
from pathlib import Path

from app.core.development_logger import get_logger
# Poprawka: Dodano bezpośredni import klas, aby pomóc Pylance w analizie typów
from app.core.performance_profiler import get_profiler, PerformanceProfiler 
from app.core.file_handler import get_result_path


class StatisticalTransferAlgorithm:
    """
    Enhanced Statistical Transfer Algorithm
    
    Core functionality:
    1. Convert images to LAB color space for perceptual accuracy
    2. Calculate statistical moments (mean, std) for each channel
    3. Transfer master's statistics to target image
    4. Apply proper LAB range clipping and convert back to RGB
    """
    
    def __init__(self, algorithm_id: str = "algorithm_02_statistical"):
        self.algorithm_id = algorithm_id
        self.logger = get_logger()
        # Poprawka: Dodano jawną adnotację typu, aby rozwiązać problemy Pylance
        self.profiler: PerformanceProfiler = get_profiler()
        
        # LAB color space ranges
        self.lab_ranges = {
            'L': (0, 100),    # Lightness: 0-100
            'a': (-127, 127), # Green-Red: -127 to 127  
            'b': (-127, 127)  # Blue-Yellow: -127 to 127
        }
        
        self.logger.info(f"Initialized {self.algorithm_id}")
    
    def convert_to_lab(self, image: np.ndarray) -> np.ndarray:
        """Convert BGR image to LAB color space."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_convert_to_lab"):
            lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB).astype(np.float32)
            self.logger.debug(f"Converted image to LAB: {lab_image.shape}")
            return lab_image
    
    def convert_to_bgr(self, lab_image: np.ndarray) -> np.ndarray:
        """Convert LAB image back to BGR color space."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_convert_to_bgr"):
            # Ensure proper LAB range clipping before conversion
            clipped_lab = self.clip_lab_ranges(lab_image)
            bgr_image = cv2.cvtColor(clipped_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)
            self.logger.debug(f"Converted LAB back to BGR: {bgr_image.shape}")
            return bgr_image
    
    def clip_lab_ranges(self, lab_image: np.ndarray) -> np.ndarray:
        """Apply proper LAB range clipping to prevent conversion artifacts."""
        clipped = lab_image.copy()
        clipped[:, :, 0] = np.clip(clipped[:, :, 0], self.lab_ranges['L'][0], self.lab_ranges['L'][1])  # L channel
        clipped[:, :, 1] = np.clip(clipped[:, :, 1], self.lab_ranges['a'][0], self.lab_ranges['a'][1])  # a channel
        clipped[:, :, 2] = np.clip(clipped[:, :, 2], self.lab_ranges['b'][0], self.lab_ranges['b'][1])  # b channel
        return clipped
    
    def calculate_statistics(self, lab_image: np.ndarray) -> Dict[str, Tuple[float, float]]:
        """Calculate mean and standard deviation for each LAB channel."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_calculate_stats"):
            stats = {}
            channel_names = ['L', 'a', 'b']
            
            for i, channel in enumerate(channel_names):
                channel_data = lab_image[:, :, i]
                mean = np.mean(channel_data)
                std = np.std(channel_data)
                stats[channel] = (mean, std)
                self.logger.debug(f"Channel {channel}: mean={mean:.2f}, std={std:.2f}")
            
            return stats
    
    def transfer_statistics(self, target_lab: np.ndarray, master_stats: Dict[str, Tuple[float, float]], 
                          target_stats: Dict[str, Tuple[float, float]]) -> np.ndarray:
        """Transfer statistical properties from master to target image."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_transfer_stats"):
            result_lab = target_lab.copy()
            channel_names = ['L', 'a', 'b']
            
            for i, channel in enumerate(channel_names):
                master_mean, master_std = master_stats[channel]
                target_mean, target_std = target_stats[channel]
                
                # Apply statistical transfer: normalize and rescale
                if target_std > 0:
                    result_lab[:, :, i] = (target_lab[:, :, i] - target_mean) * (master_std / target_std) + master_mean
                else:
                    # If target std is 0, just shift to master mean
                    result_lab[:, :, i] = master_mean
                
                self.logger.debug(f"Transferred {channel} channel statistics")
            
            return result_lab
    
    def process(self, master_path: str, target_path: str) -> str:
        """
        Main processing method - applies statistical transfer algorithm.
        
        Args:
            master_path: Path to master image (source of color statistics)
            target_path: Path to target image (will be color-matched)
            
        Returns:
            Path to result image file
            
        Raises:
            FileNotFoundError: If input images don't exist
            RuntimeError: If processing fails
        """
        with self.profiler.profile_operation(f"{self.algorithm_id}_process"):
            # Set algorithm context for logging
            self.logger.set_algorithm_context(self.algorithm_id)
            
            # Validate input files
            if not os.path.exists(master_path):
                raise FileNotFoundError(f"Master image not found: {master_path}")
                
            if not os.path.exists(target_path):
                raise FileNotFoundError(f"Target image not found: {target_path}")
            
            self.logger.info("Starting statistical transfer")
            self.logger.debug(f"Master: {master_path}")
            self.logger.debug(f"Target: {target_path}")
            
            try:
                # Load images
                master_image = cv2.imread(master_path)
                target_image = cv2.imread(target_path)
                
                if master_image is None:
                    raise RuntimeError(f"Failed to load master image: {master_path}")
                if target_image is None:
                    raise RuntimeError(f"Failed to load target image: {target_path}")
                
                self.logger.debug(f"Master shape: {master_image.shape}")
                self.logger.debug(f"Target shape: {target_image.shape}")
                
                # Convert to LAB color space
                master_lab = self.convert_to_lab(master_image)
                target_lab = self.convert_to_lab(target_image)
                
                # Calculate statistics for both images
                master_stats = self.calculate_statistics(master_lab)
                target_stats = self.calculate_statistics(target_lab)
                
                # Transfer statistics from master to target
                result_lab = self.transfer_statistics(target_lab, master_stats, target_stats)
                
                # Convert back to BGR
                result_image = self.convert_to_bgr(result_lab)
                
                # Save result
                result_path = get_result_path(os.path.basename(target_path))
                success = cv2.imwrite(result_path, result_image)
                
                if not success:
                    raise RuntimeError(f"Failed to save result image: {result_path}")
                
                self.logger.success(f"Statistical transfer completed: {result_path}")
                return result_path
                
            except Exception as e:
                # Poprawka: Dodano exc_info=True dla pełnego tracebacku w logach
                self.logger.error(f"Statistical transfer failed: {str(e)}", exc_info=True)
                raise RuntimeError(f"Algorithm processing failed: {str(e)}") from e
    
    def get_algorithm_info(self) -> Dict[str, Any]:
        """Get algorithm information for monitoring and documentation."""
        return {
            'algorithm_id': self.algorithm_id,
            'name': 'Statistical Transfer',
            'description': 'LAB color space statistical moment matching',
            'version': '2.0.0',
            'color_space': 'LAB',
            'parameters': {
                'statistical_moments': ['mean', 'standard_deviation'],
                'channels': ['L', 'a', 'b']
            },
            'supported_formats': ['jpg', 'jpeg', 'png', 'tif', 'tiff', 'bmp'],
            'complexity': 'O(n)',
            'memory_usage': 'O(n)'
        }


# Factory function for easy algorithm creation
def create_statistical_transfer_algorithm() -> StatisticalTransferAlgorithm:
    """Create and return a new statistical transfer algorithm instance."""
    return StatisticalTransferAlgorithm()


# Legacy compatibility function
def basic_statistical_transfer(master_path: str, target_path: str) -> str:
    """
    Legacy compatibility function for existing API.
    
    This maintains backward compatibility with existing code while using
    the new modular algorithm implementation.
    """
    algorithm = create_statistical_transfer_algorithm()
    return algorithm.process(master_path, target_path)

``````

### __init__.py - ./app/algorithms/algorithm_03_histogram/__init__.py

``````
"""
Algorithm 03: Histogram Matching
===============================

This module provides histogram matching functionality focusing on luminance channels.
"""

from .algorithm import (
    HistogramMatchingAlgorithm,
    create_histogram_matching_algorithm,
    simple_histogram_matching
)

__all__ = [
    'HistogramMatchingAlgorithm',
    'create_histogram_matching_algorithm',
    'simple_histogram_matching'
]

``````

### algorithm.py - ./app/algorithms/algorithm_03_histogram/algorithm.py

``````
"""
Algorithm 03: Histogram Matching
===============================

Enhanced modular implementation of histogram matching algorithm.
Focuses on luminance channel matching for natural-looking results.

Design Philosophy: "Bezpiecznie = Szybko"
- Clear separation of concerns
- Comprehensive error handling  
- Performance monitoring integration
- Easy testing and validation
"""

import os
import cv2
import numpy as np
from typing import Tuple, Optional, Dict, Any
from pathlib import Path

from app.core.development_logger import get_logger
from app.core.performance_profiler import get_profiler
from app.core.file_handler import get_result_path


class HistogramMatchingAlgorithm:
    """
    Enhanced Histogram Matching Algorithm
    
    Core functionality:
    1. Convert images to LAB color space
    2. Extract luminance (L) channel histograms
    3. Build cumulative distribution functions (CDF)
    4. Create lookup table for histogram matching
    5. Apply transformation and convert back to RGB
    """
    
    def __init__(self, algorithm_id: str = "algorithm_03_histogram"):
        self.algorithm_id = algorithm_id
        self.logger = get_logger()
        self.profiler = get_profiler()
        
        # Histogram parameters
        self.histogram_bins = 256
        # Poprawka: `range` w np.histogram oczekuje krotki (tuple)
        self.histogram_range: Tuple[int, int] = (0, 256)
        
        self.logger.info(f"Initialized {self.algorithm_id}")
    
    # Poprawka: Zmieniono typ zwracany na krotkę
    def extract_luminance_channel(self, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """Extract luminance (L) channel from BGR image via LAB conversion."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_extract_luminance"):
            lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
            luminance = lab_image[:, :, 0]  # L channel
            self.logger.debug(f"Extracted luminance channel: {luminance.shape}")
            return lab_image, luminance
    
    def compute_histogram(self, channel: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """Compute histogram and cumulative distribution function."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_compute_histogram"):
            # Calculate histogram
            hist, bins = np.histogram(channel.flatten(), self.histogram_bins, self.histogram_range)
            
            # Calculate cumulative distribution function (CDF)
            cdf = hist.cumsum()
            
            # Normalize CDF to [0, 1] range
            cdf_normalized = cdf / cdf[-1] if cdf[-1] > 0 else cdf
            
            self.logger.debug(f"Computed histogram: {len(hist)} bins, CDF max: {cdf[-1]}")
            return hist, cdf_normalized
    
    def create_lookup_table(self, master_cdf: np.ndarray, target_cdf: np.ndarray) -> np.ndarray:
        """Create lookup table for histogram matching transformation."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_create_lookup"):
            lookup_table = np.zeros(self.histogram_bins, dtype=np.uint8)
            
            for i in range(self.histogram_bins):
                # Find closest value in master CDF for each target CDF value
                differences = np.abs(master_cdf - target_cdf[i])
                closest_idx = np.argmin(differences)
                lookup_table[i] = closest_idx
            
            self.logger.debug(f"Created lookup table with {self.histogram_bins} entries")
            return lookup_table
    
    def apply_histogram_matching(self, lab_image: np.ndarray, luminance: np.ndarray, 
                               lookup_table: np.ndarray) -> np.ndarray:
        """Apply histogram matching using lookup table to luminance channel."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_apply_matching"):
            # Apply lookup table to luminance channel
            result_lab = lab_image.copy()
            result_lab[:, :, 0] = lookup_table[luminance]
            
            # Convert back to BGR
            result_bgr = cv2.cvtColor(result_lab, cv2.COLOR_LAB2BGR)
            
            self.logger.debug(f"Applied histogram matching to luminance channel")
            return result_bgr
    
    def process(self, master_path: str, target_path: str) -> str:
        """
        Main processing method - applies histogram matching algorithm.
        
        Args:
            master_path: Path to master image (source of histogram)
            target_path: Path to target image (will be histogram-matched)
            
        Returns:
            Path to result image file
            
        Raises:
            FileNotFoundError: If input images don't exist
            RuntimeError: If processing fails
        """
        with self.profiler.profile_operation(f"{self.algorithm_id}_process"):
            # Set algorithm context for logging
            self.logger.set_algorithm_context(self.algorithm_id)
            
            # Validate input files
            if not os.path.exists(master_path):
                raise FileNotFoundError(f"Master image not found: {master_path}")
                
            if not os.path.exists(target_path):
                raise FileNotFoundError(f"Target image not found: {target_path}")
            
            self.logger.info("Starting histogram matching")
            self.logger.debug(f"Master: {master_path}")
            self.logger.debug(f"Target: {target_path}")
            
            try:
                # Load images
                master_image = cv2.imread(master_path)
                target_image = cv2.imread(target_path)
                
                if master_image is None:
                    raise RuntimeError(f"Failed to load master image: {master_path}")
                if target_image is None:
                    raise RuntimeError(f"Failed to load target image: {target_path}")
                
                self.logger.debug(f"Master shape: {master_image.shape}")
                self.logger.debug(f"Target shape: {target_image.shape}")
                
                # Extract luminance channels
                master_lab, master_luminance = self.extract_luminance_channel(master_image)
                target_lab, target_luminance = self.extract_luminance_channel(target_image)
                
                # Compute histograms and CDFs
                master_hist, master_cdf = self.compute_histogram(master_luminance)
                target_hist, target_cdf = self.compute_histogram(target_luminance)
                
                # Create lookup table for histogram matching
                lookup_table = self.create_lookup_table(master_cdf, target_cdf)
                
                # Apply histogram matching
                result_image = self.apply_histogram_matching(target_lab, target_luminance, lookup_table)
                
                # Save result
                result_path = get_result_path(os.path.basename(target_path))
                success = cv2.imwrite(result_path, result_image)
                
                if not success:
                    raise RuntimeError(f"Failed to save result image: {result_path}")
                
                self.logger.success(f"Histogram matching completed: {result_path}")
                return result_path
                
            except Exception as e:
                self.logger.error(f"Histogram matching failed: {str(e)}", exc_info=True)
                raise RuntimeError(f"Algorithm processing failed: {str(e)}") from e
    
    def get_algorithm_info(self) -> Dict[str, Any]:
        """Get algorithm information for monitoring and documentation."""
        return {
            'algorithm_id': self.algorithm_id,
            'name': 'Histogram Matching',
            'description': 'Luminance channel histogram specification',
            'version': '2.0.0',
            'color_space': 'LAB (L channel only)',
            'parameters': {
                'histogram_bins': self.histogram_bins,
                'histogram_range': list(self.histogram_range), # Zwróć jako listę dla JSON
                'target_channel': 'luminance'
            },
            'supported_formats': ['jpg', 'jpeg', 'png', 'tif', 'tiff', 'bmp'],
            'complexity': 'O(n + bins)',
            'memory_usage': 'O(n + bins)'
        }


# Factory function for easy algorithm creation
def create_histogram_matching_algorithm() -> HistogramMatchingAlgorithm:
    """Create and return a new histogram matching algorithm instance."""
    return HistogramMatchingAlgorithm()


# Legacy compatibility function
def simple_histogram_matching(master_path: str, target_path: str) -> str:
    """
    Legacy compatibility function for existing API.
    
    This maintains backward compatibility with existing code while using
    the new modular algorithm implementation.
    """
    algorithm = create_histogram_matching_algorithm()
    return algorithm.process(master_path, target_path)


``````

### __init__.py - ./app/api/__init__.py

``````
# API package

``````

### routes.py - ./app/api/routes.py

``````
from flask import Blueprint, request, jsonify
import os
from app.core.file_handler import save_temp_file
from app.core.development_logger import get_logger
from app.algorithms import get_algorithm
from typing import Any

# Create Blueprint instead of Flask app
app = Blueprint('api', __name__)

# Initialize logger
logger = get_logger()

@app.route('/api/colormatch', methods=['POST'])
def colormatch_endpoint():
    """Endpoint API do dopasowywania kolorów - w pełni dynamiczny."""
    if 'master_image' not in request.files or 'target_image' not in request.files:
        logger.error("Brak wymaganych plików 'master_image' i 'target_image'")
        return "error,Request musi zawierać 'master_image' i 'target_image'"

    master_file = request.files['master_image']
    target_file = request.files['target_image']
    
    # Mapowanie 'method' na 'algorithm_id'
    method = request.form.get('method', default='1', type=str)
    algorithm_map = {
        '1': 'algorithm_01_palette',
        '2': 'algorithm_02_statistical',
        '3': 'algorithm_03_histogram'
    }
    algorithm_id = algorithm_map.get(method)
    
    if not algorithm_id:
        logger.error(f"Nieznana metoda: {method}")
        return f"error,Nieznana metoda: {method}. Dostępne: 1, 2, 3"

    # Przygotowanie parametrów
    params: dict[str, Any] = {}
    if algorithm_id == 'algorithm_01_palette':
        params['num_colors'] = int(request.form.get('k', 16)) # k_colors, default 16
        params['distance_metric'] = request.form.get('distance_metric', 'weighted_rgb') # default weighted_rgb
        params['use_dithering'] = request.form.get('use_dithering', 'false').lower() == 'true'
        params['preserve_luminance'] = request.form.get('preserve_luminance', 'false').lower() == 'true'
        # exclude_colors and palette_source_area will be handled in Phase 2b

    logger.info(f"Przetwarzanie przez algorytm: {algorithm_id} z parametrami: {params}")

    master_path = None
    target_path = None
    try:
        master_path = save_temp_file(master_file)
        target_path = save_temp_file(target_file)

        if not master_path or not target_path:
            raise RuntimeError("Nie udało się zapisać plików tymczasowych")

        # Dynamiczne pobranie i uruchomienie algorytmu
        algorithm = get_algorithm(algorithm_id)
        result_file_path = algorithm.process_images(master_path, target_path, output_path=None, **params) # output_path will be handled by algorithm

        result_filename = os.path.basename(result_file_path)
        logger.success(f"Dopasowywanie kolorów zakończone: {result_filename}")
        # Zwracamy 'method{X}' dla kompatybilności z JSX
        return f"success,method{method},{result_filename}"

    except Exception as e:
        logger.error(f"Dopasowywanie kolorów nie powiodło się: {str(e)}", exc_info=True)
        return f"error,{str(e)}"
    finally:
        # Można dodać logikę czyszczenia plików tymczasowych, jeśli jest potrzebna
        pass

@app.route('/api/colormatch/preview', methods=['POST'])
def colormatch_preview_endpoint():
    """Endpoint API do generowania podglądu dopasowania kolorów."""
    if 'master_image' not in request.files or 'target_image' not in request.files:
        logger.error("Brak wymaganych plików 'master_image' i 'target_image' dla podglądu")
        return "error,Request musi zawierać 'master_image' i 'target_image'"

    master_file = request.files['master_image']
    target_file = request.files['target_image']
    
    method = request.form.get('method', default='1', type=str)
    algorithm_map = {
        '1': 'algorithm_01_palette',
        '2': 'algorithm_02_statistical',
        '3': 'algorithm_03_histogram'
    }
    algorithm_id = algorithm_map.get(method)
    
    if not algorithm_id:
        logger.error(f"Nieznana metoda: {method}")
        return f"error,Nieznana metoda: {method}. Dostępne: 1, 2, 3"

    params: dict[str, Any] = {'preview_mode': True}
    if algorithm_id == 'algorithm_01_palette':
        params['num_colors'] = int(request.form.get('k', 16))
        params['distance_metric'] = request.form.get('distance_metric', 'weighted_rgb')
        params['use_dithering'] = request.form.get('use_dithering', 'false').lower() == 'true'
        params['preserve_luminance'] = request.form.get('preserve_luminance', 'false').lower() == 'true'
        # preview_thumbnail_size can be passed from JSX if needed, otherwise default from config

    logger.info(f"Przetwarzanie podglądu przez algorytm: {algorithm_id} z parametrami: {params}")

    master_path = None
    target_path = None
    try:
        master_path = save_temp_file(master_file)
        target_path = save_temp_file(target_file)

        if not master_path or not target_path:
            raise RuntimeError("Nie udało się zapisać plików tymczasowych dla podglądu")

        algorithm = get_algorithm(algorithm_id)
        # The algorithm's process_images method will handle resizing and temporary file creation for preview
        result_file_path = algorithm.process_images(master_path, target_path, output_path=None, **params)

        result_filename = os.path.basename(result_file_path)
        logger.success(f"Podgląd dopasowywania kolorów zakończony: {result_filename}")
        return f"success,preview,{result_filename}"

    except Exception as e:
        logger.error(f"Podgląd dopasowywania kolorów nie powiódł się: {str(e)}", exc_info=True)
        return f"error,{str(e)}"
    finally:
        # Clean up temporary files created by save_temp_file
        if 'master_path' in locals() and master_path is not None and os.path.exists(master_path):
            os.remove(master_path)
        if 'target_path' in locals() and target_path is not None and os.path.exists(target_path):
            os.remove(target_path)


@app.route('/api/analyze_palette', methods=['POST'])
def analyze_palette_endpoint():
    """Endpoint API do analizy palety kolorów."""
    if 'source_image' not in request.files:
        return "error,Brak pliku source_image"
    file = request.files['source_image']
    k = request.form.get('k', default=8, type=int)
    from app.core.file_handler import save_temp_file
    from app.processing.palette_analyzer import analyze_palette
    try:
        temp_path = save_temp_file(file)
        palette = analyze_palette(temp_path, k)
        if not palette or len(palette) == 0:
            return "error,Brak kolorów lub błąd analizy"
        # Spłaszcz listę kolorów do CSV
        flat = [str(x) for color in palette for x in color]
        response = ["success", str(len(palette))] + flat
        return ",".join(response)
    except Exception as e:
        logger.error(f"Analiza palety nie powiodła się: {str(e)}", exc_info=True)
        return f"error,{str(e)}"

``````

### __init__.py - ./app/core/__init__.py

``````
# Core utilities package

``````

### development_logger.py - ./app/core/development_logger.py

``````
"""
Enhanced Development Logger for GattoNero AI Assistant
=======================================================

Features:
- Structured logging with JSON output for parsing
- Beautiful console output with colors for development  
- File logging with rotation for persistence
- Context tracking (request_id, operation_id)
- Performance timing integration ready
- Multiple output levels and filtering

Design Philosophy: "Bezpiecznie = Szybko"
- Clear visibility into what's happening
- Easy debugging with context
- Performance insights built-in
- Development-friendly formatting
"""

import logging
import json
import sys
import os
from datetime import datetime
from pathlib import Path
from logging.handlers import RotatingFileHandler
from contextlib import contextmanager
from typing import Optional, Dict, Any
import uuid
import time
import threading
from dataclasses import dataclass, asdict


# ANSI Color codes for beautiful console output
class Colors:
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    MAGENTA = '\033[95m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'
    END = '\033[0m'
    
    # Semantic colors
    ERROR = RED
    WARNING = YELLOW
    INFO = BLUE
    DEBUG = CYAN
    SUCCESS = GREEN
    PERFORMANCE = MAGENTA


@dataclass
class LogContext:
    """Context information for structured logging."""
    request_id: Optional[str] = None
    operation_id: Optional[str] = None
    algorithm_id: Optional[str] = None
    user_session: Optional[str] = None
    performance_data: Optional[Dict[str, Any]] = None


class DevelopmentFormatter(logging.Formatter):
    """Custom formatter for beautiful development console output."""
    
    def __init__(self):
        super().__init__()
        
    def format(self, record: logging.LogRecord) -> str:
        # Get timestamp
        timestamp = datetime.fromtimestamp(record.created).strftime('%H:%M:%S.%f')[:-3]
        
        # Level with color
        level_colors = {
            'DEBUG': Colors.DEBUG,
            'INFO': Colors.INFO,
            'WARNING': Colors.WARNING,
            'ERROR': Colors.ERROR,
            'CRITICAL': Colors.ERROR + Colors.BOLD
        }
        level_color = level_colors.get(record.levelname, Colors.WHITE)
        level_str = f"{level_color}{record.levelname:8}{Colors.END}"
        
        # Module/function context
        module_info = f"{Colors.CYAN}{record.name}{Colors.END}"
        if hasattr(record, 'funcName') and record.funcName:
            module_info += f".{Colors.CYAN}{record.funcName}{Colors.END}"
            
        # Context information
        context_parts = []
        if getattr(record, 'request_id', None):
            context_parts.append(f"req:{getattr(record, 'request_id')[:8]}")
        if getattr(record, 'operation_id', None):
            context_parts.append(f"op:{getattr(record, 'operation_id')[:8]}")
        if getattr(record, 'algorithm_id', None):
            context_parts.append(f"alg:{getattr(record, 'algorithm_id')}")
            
        context_str = ""
        if context_parts:
            context_str = f" {Colors.YELLOW}[{' '.join(context_parts)}]{Colors.END}"
            
        # Performance information
        perf_str = ""
        duration_ms = getattr(record, 'duration_ms', None)
        if duration_ms is not None:
            if duration_ms < 10:
                perf_color = Colors.SUCCESS
            elif duration_ms < 100:
                perf_color = Colors.WARNING
            else:
                perf_color = Colors.ERROR
            perf_str = f" {perf_color}({duration_ms:.1f}ms){Colors.END}"
            
        # Main message
        message = record.getMessage()
        
        # Assemble final message
        return f"{Colors.WHITE}{timestamp}{Colors.END} {level_str} {module_info}{context_str} {message}{perf_str}"


class JSONFormatter(logging.Formatter):
    """JSON formatter for structured logging to files."""
    
    def format(self, record: logging.LogRecord) -> str:
        log_data: Dict[str, Any] = {
            'timestamp': datetime.fromtimestamp(record.created).isoformat(),
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': getattr(record, 'funcName', None),
            'line': record.lineno,
        }
        
        # Add context information safely
        context_fields = ['request_id', 'operation_id', 'algorithm_id', 'user_session']
        for field in context_fields:
            if hasattr(record, field):
                log_data[field] = getattr(record, field)
                
        # Add performance data safely
        if hasattr(record, 'duration_ms'):
            log_data['duration_ms'] = getattr(record, 'duration_ms')
        if hasattr(record, 'performance_data'):
            log_data['performance_data'] = getattr(record, 'performance_data')
            
        # Add exception information
        if record.exc_info:
            log_data['exception'] = self.formatException(record.exc_info)
            
        return json.dumps(log_data, ensure_ascii=False, separators=(',', ':'))


class DevelopmentLogger:
    """
    Enhanced development logger for GattoNero AI Assistant.
    
    Provides both beautiful console output and structured JSON file logging.
    Includes context tracking and performance integration.
    """
    
    def __init__(self, name: str = "gattonero", log_dir: str = "logs"):
        self.name = name
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        # Thread-local storage for context
        self._local = threading.local()
        
        # Setup logger
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.DEBUG)
        
        # Remove existing handlers to avoid duplicates
        if self.logger.hasHandlers():
            self.logger.handlers.clear()
            
        # Setup console handler with beautiful formatting
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(DevelopmentFormatter())
        console_handler.setLevel(logging.INFO)
        self.logger.addHandler(console_handler)
        
        # Setup file handler with JSON formatting
        log_file = self.log_dir / f"{name}.log"
        file_handler = RotatingFileHandler(
            log_file, 
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5,
            encoding='utf-8'
        )
        file_handler.setFormatter(JSONFormatter())
        file_handler.setLevel(logging.DEBUG)
        self.logger.addHandler(file_handler)
        
        # Setup error file handler
        error_file = self.log_dir / f"{name}_errors.log"
        error_handler = RotatingFileHandler(
            error_file,
            maxBytes=10*1024*1024,  # 10MB
            backupCount=3,
            encoding='utf-8'
        )
        error_handler.setFormatter(JSONFormatter())
        error_handler.setLevel(logging.ERROR)
        self.logger.addHandler(error_handler)
        
        self.logger.info("Development Logger initialized", extra=self._get_extra())
        
    def _get_context(self) -> LogContext:
        """Get current thread-local context."""
        if not hasattr(self._local, 'context'):
            self._local.context = LogContext()
        return self._local.context
        
    def _get_extra(self) -> Dict[str, Any]:
        """Get extra fields for logging from current context."""
        context = self._get_context()
        return asdict(context)
        
    def set_request_context(self, request_id: Optional[str] = None):
        """Set request context for current thread."""
        context = self._get_context()
        context.request_id = request_id or str(uuid.uuid4())[:8]
        
    def set_operation_context(self, operation_id: str):
        """Set operation context for current thread."""
        context = self._get_context()
        context.operation_id = operation_id
        
    def set_algorithm_context(self, algorithm_id: str):
        """Set algorithm context for current thread."""
        context = self._get_context()
        context.algorithm_id = algorithm_id
        
    def clear_context(self):
        """Clear all context for current thread."""
        if hasattr(self._local, 'context'):
            delattr(self._local, 'context')
            
    @contextmanager
    def operation(self, operation_name: str, algorithm_id: Optional[str] = None):
        """
        Context manager for tracking operations with automatic timing.
        
        Usage:
            with logger.operation("palette_analysis", "algorithm_01_palette"):
                # Your operation code here
                pass
        """
        operation_id = f"{operation_name}_{uuid.uuid4().hex[:6]}"
        old_operation_id = getattr(self._get_context(), 'operation_id', None)
        old_algorithm_id = getattr(self._get_context(), 'algorithm_id', None)
        
        # Set new context
        self.set_operation_context(operation_id)
        if algorithm_id:
            self.set_algorithm_context(algorithm_id)
            
        start_time = time.time()
        
        try:
            self.info(f"Started operation: {operation_name}")
            yield operation_id
            
        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000
            extra = self._get_extra()
            extra['duration_ms'] = duration_ms
            self.error(f"Operation failed: {operation_name} - {str(e)}", extra=extra, exc_info=True)
            raise
            
        else:
            duration_ms = (time.time() - start_time) * 1000
            extra = self._get_extra()
            extra['duration_ms'] = duration_ms
            self.info(f"Completed operation: {operation_name}", extra=extra)
            
        finally:
            # Restore previous context
            context = self._get_context()
            context.operation_id = old_operation_id
            context.algorithm_id = old_algorithm_id
            
    def debug(self, message: str, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log debug message."""
        self.logger.debug(message, extra={**self._get_extra(), **(extra or {}), **kwargs})
        
    def info(self, message: str, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log info message."""
        self.logger.info(message, extra={**self._get_extra(), **(extra or {}), **kwargs})
        
    def warning(self, message: str, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log warning message."""
        self.logger.warning(message, extra={**self._get_extra(), **(extra or {}), **kwargs})
        
    def error(self, message: str, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log error message."""
        self.logger.error(message, extra={**self._get_extra(), **(extra or {}), **kwargs})
        
    def critical(self, message: str, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log critical message."""
        self.logger.critical(message, extra={**self._get_extra(), **(extra or {}), **kwargs})
        
    def success(self, message: str, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log success message (info level with success context)."""
        success_extra = {**self._get_extra(), **(extra or {}), 'type': 'success', **kwargs}
        self.logger.info(message, extra=success_extra)
        
    def performance(self, message: str, duration_ms: float, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log performance information."""
        perf_extra = {**self._get_extra(), **(extra or {}), 'duration_ms': duration_ms, 'type': 'performance', **kwargs}
        self.logger.info(message, extra=perf_extra)


# Global logger instance
_global_logger: Optional[DevelopmentLogger] = None

def get_logger(name: str = "gattonero") -> DevelopmentLogger:
    """Get or create global logger instance."""
    global _global_logger
    if _global_logger is None:
        _global_logger = DevelopmentLogger(name)
    return _global_logger


def setup_flask_logging(app, logger: Optional[DevelopmentLogger] = None):
    """Setup Flask request logging integration."""
    if logger is None:
        logger = get_logger()
        
    @app.before_request
    def before_request():
        from flask import request
        logger.set_request_context()
        logger.debug(f"Request started: {request.method} {request.path}")
        
    @app.after_request
    def after_request(response):
        logger.debug(f"Request completed: {response.status_code}")
        return response
        
    @app.teardown_request
    def teardown_request(exception):
        if exception:
            logger.error(f"Request error: {str(exception)}", exc_info=True)
        logger.clear_context()

``````

### file_handler.py - ./app/core/file_handler.py

``````
import os
import time
from werkzeug.utils import secure_filename

APP_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(os.path.dirname(APP_DIR))
UPLOADS_DIR = os.path.join(PROJECT_ROOT, 'uploads')
RESULTS_DIR = os.path.join(PROJECT_ROOT, 'results')

def save_temp_file(file_storage):
    """Zapisuje plik z requestu w folderze uploads z unikalną nazwą."""
    if not file_storage:
        return None
    os.makedirs(UPLOADS_DIR, exist_ok=True)
    filename = secure_filename(file_storage.filename)
    base, extension = os.path.splitext(filename)
    unique_filename = f"{base}_{int(time.time())}{extension}"
    save_path = os.path.join(UPLOADS_DIR, unique_filename)
    file_storage.save(save_path)
    return save_path

def get_result_path(original_filename):
    """Generuje ścieżkę zapisu dla pliku wynikowego."""
    os.makedirs(RESULTS_DIR, exist_ok=True)
    base, extension = os.path.splitext(original_filename)
    return os.path.join(RESULTS_DIR, f"{base}_matched{extension}")

``````

### health_monitor.py - ./app/core/health_monitor.py

``````
"""
Health Monitor for GattoNero AI Assistant
==========================================

Features:
- Algorithm health checks and status tracking
- Dependency verification (libraries, files, resources)
- System resource monitoring (memory, disk, CPU)
- Health endpoints for monitoring
- Automatic recovery suggestions
- Alert system for critical issues

Design Philosophy: "Bezpiecznie = Szybko"
- Proactive health monitoring prevents runtime failures
- Clear health status helps debug issues quickly
- Automatic checks catch problems before users hit them
- Recovery suggestions guide quick fixes
"""

import time
import psutil
import threading
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from typing import Dict, List, Optional, Any, Callable, NamedTuple
from dataclasses import dataclass, field, asdict
import json
import importlib
import sys
import os
import subprocess
from collections import defaultdict, deque

from .development_logger import get_logger


class HealthStatus(Enum):
    """Health status levels."""
    HEALTHY = "healthy"
    WARNING = "warning"
    CRITICAL = "critical"
    UNKNOWN = "unknown"


@dataclass
class HealthCheck:
    """Definition of a health check."""
    name: str
    check_function: Callable[[], 'HealthResult']
    interval_seconds: int = 60
    timeout_seconds: int = 10
    critical: bool = False
    description: str = ""
    category: str = "general"


@dataclass
class HealthResult:
    """Result of a health check."""
    status: HealthStatus
    message: str
    details: Dict[str, Any] = field(default_factory=dict)
    suggestions: List[str] = field(default_factory=list)
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class AlgorithmHealth:
    """Health information for an algorithm."""
    algorithm_id: str
    status: HealthStatus
    last_check: datetime
    dependencies_ok: bool
    resource_usage: Dict[str, float]
    error_count: int
    success_rate: float
    issues: List[str] = field(default_factory=list)


class HealthMonitor:
    """
    Comprehensive health monitoring system for GattoNero AI Assistant.
    
    Monitors algorithms, system resources, dependencies, and provides
    health endpoints for external monitoring.
    """
    
    def __init__(self, check_interval: int = 30):
        self.check_interval = check_interval
        self.logger = get_logger()
        
        # Health checks registry
        self._checks: Dict[str, HealthCheck] = {}
        self._results: Dict[str, HealthResult] = {}
        self._algorithm_health: Dict[str, AlgorithmHealth] = {}
        
        # Monitoring thread
        self._monitoring_thread: Optional[threading.Thread] = None
        self._stop_monitoring = threading.Event()
        self._lock = threading.RLock()
        
        # System monitoring
        self._process = psutil.Process()
        self._last_check_times: Dict[str, datetime] = {}
        
        # Performance tracking for algorithms
        self._algorithm_stats: Dict[str, Dict[str, Any]] = defaultdict(lambda: {
            "total_calls": 0,
            "error_count": 0,
            "total_duration": 0.0,
            "last_call": None,
            "recent_errors": deque(maxlen=10)
        })
        
        # Register default health checks
        self._register_default_checks()
        
        self.logger.info("Health Monitor initialized", extra={
            "check_interval": check_interval,
            "default_checks": len(self._checks)
        })
    
    def _register_default_checks(self):
        """Register default system health checks."""
        
        # System resource checks
        self.register_check("system_memory", self._check_memory, 30, 
                          critical=True, description="System memory usage",
                          category="system")
        
        self.register_check("system_disk", self._check_disk_space, 60,
                          critical=True, description="Disk space availability",
                          category="system")
        
        self.register_check("system_cpu", self._check_cpu_usage, 30,
                          critical=False, description="CPU usage monitoring",
                          category="system")
        
        # Python environment checks
        self.register_check("python_environment", self._check_python_env, 300,
                          critical=True, description="Python environment health",
                          category="environment")
        
        # Flask application checks
        self.register_check("flask_app", self._check_flask_health, 60,
                          critical=True, description="Flask application health",
                          category="application")
        
        # File system checks
        self.register_check("filesystem", self._check_filesystem, 120,
                          critical=True, description="File system permissions and access",
                          category="filesystem")
    
    def register_check(self, name: str, check_function: Callable[[], HealthResult],
                      interval_seconds: int = 60, timeout_seconds: int = 10,
                      critical: bool = False, description: str = "",
                      category: str = "general"):
        """Register a new health check."""
        check = HealthCheck(
            name=name,
            check_function=check_function,
            interval_seconds=interval_seconds,
            timeout_seconds=timeout_seconds,
            critical=critical,
            description=description,
            category=category
        )
        
        with self._lock:
            self._checks[name] = check
            
        self.logger.debug(f"Health check registered: {name}", extra={
            "category": category,
            "critical": critical,
            "interval": interval_seconds
        })
    
    def register_algorithm(self, algorithm_id: str, dependencies: Optional[List[str]] = None):
        """Register an algorithm for health monitoring."""
        with self._lock:
            self._algorithm_health[algorithm_id] = AlgorithmHealth(
                algorithm_id=algorithm_id,
                status=HealthStatus.UNKNOWN,
                last_check=datetime.now(),
                dependencies_ok=True,
                resource_usage={},
                error_count=0,
                success_rate=1.0
            )
        
        # Register algorithm-specific checks
        if dependencies is None:
            dependencies = []
        if dependencies:
            self.register_check(
                f"algorithm_{algorithm_id}_dependencies",
                lambda: self._check_algorithm_dependencies(algorithm_id, dependencies),
                300,  # Check every 5 minutes
                critical=True,
                description=f"Dependencies for {algorithm_id}",
                category="algorithm"
            )
        
        self.logger.info(f"Algorithm registered for health monitoring: {algorithm_id}")
    
    def record_algorithm_call(self, algorithm_id: str, duration_ms: float, 
                            success: bool = True, error: Optional[str] = None):
        """Record algorithm performance and health data."""
        with self._lock:
            stats = self._algorithm_stats[algorithm_id]
            stats["total_calls"] += 1
            stats["total_duration"] += duration_ms
            stats["last_call"] = datetime.now()
            
            if not success:
                stats["error_count"] += 1
                if error is not None:
                    stats["recent_errors"].append({
                        "timestamp": datetime.now(),
                        "error": error
                    })
            
            # Update algorithm health
            if algorithm_id in self._algorithm_health:
                health = self._algorithm_health[algorithm_id]
                health.error_count = stats["error_count"]
                health.success_rate = 1.0 - (stats["error_count"] / stats["total_calls"])
                
                # Determine health status based on recent performance
                if health.success_rate < 0.5:
                    health.status = HealthStatus.CRITICAL
                elif health.success_rate < 0.8:
                    health.status = HealthStatus.WARNING
                else:
                    health.status = HealthStatus.HEALTHY
                
                health.last_check = datetime.now()
    
    def _check_memory(self) -> HealthResult:
        """Check system memory usage."""
        try:
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            
            if memory_percent > 90:
                status = HealthStatus.CRITICAL
                message = f"Critical memory usage: {memory_percent:.1f}%"
                suggestions = [
                    "Free up memory by closing unnecessary applications",
                    "Restart the application to clear memory leaks",
                    "Consider increasing available RAM"
                ]
            elif memory_percent > 75:
                status = HealthStatus.WARNING
                message = f"High memory usage: {memory_percent:.1f}%"
                suggestions = ["Monitor memory usage closely", "Consider optimizing algorithms"]
            else:
                status = HealthStatus.HEALTHY
                message = f"Memory usage normal: {memory_percent:.1f}%"
                suggestions = []
            
            return HealthResult(
                status=status,
                message=message,
                details={
                    "memory_percent": memory_percent,
                    "available_gb": memory.available / (1024**3),
                    "used_gb": memory.used / (1024**3),
                    "total_gb": memory.total / (1024**3)
                },
                suggestions=suggestions
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check memory: {str(e)}",
                suggestions=["Check system monitoring tools", "Restart monitoring service"]
            )
    
    def _check_disk_space(self) -> HealthResult:
        """Check disk space usage."""
        try:
            # Check current directory disk space
            disk_usage = psutil.disk_usage('.')
            disk_percent = (disk_usage.used / disk_usage.total) * 100
            free_gb = disk_usage.free / (1024**3)
            
            if disk_percent > 95 or free_gb < 1.0:
                status = HealthStatus.CRITICAL
                message = f"Critical disk space: {disk_percent:.1f}% used, {free_gb:.1f}GB free"
                suggestions = [
                    "Clean up temporary files",
                    "Remove old log files",
                    "Archive or delete unnecessary files"
                ]
            elif disk_percent > 85 or free_gb < 5.0:
                status = HealthStatus.WARNING
                message = f"Low disk space: {disk_percent:.1f}% used, {free_gb:.1f}GB free"
                suggestions = ["Monitor disk usage", "Plan for disk cleanup"]
            else:
                status = HealthStatus.HEALTHY
                message = f"Disk space adequate: {disk_percent:.1f}% used, {free_gb:.1f}GB free"
                suggestions = []
            
            return HealthResult(
                status=status,
                message=message,
                details={
                    "disk_percent": disk_percent,
                    "free_gb": free_gb,
                    "used_gb": disk_usage.used / (1024**3),
                    "total_gb": disk_usage.total / (1024**3)
                },
                suggestions=suggestions
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check disk space: {str(e)}",
                suggestions=["Check disk access permissions", "Verify disk health"]
            )
    
    def _check_cpu_usage(self) -> HealthResult:
        """Check CPU usage."""
        try:
            cpu_percent = self._process.cpu_percent(interval=1)
            
            if cpu_percent > 80:
                status = HealthStatus.WARNING
                message = f"High CPU usage: {cpu_percent:.1f}%"
                suggestions = ["Monitor for CPU-intensive operations", "Consider algorithm optimization"]
            else:
                status = HealthStatus.HEALTHY
                message = f"CPU usage normal: {cpu_percent:.1f}%"
                suggestions = []
            
            # os.getloadavg is not available on Windows
            load_average = None
            if hasattr(os, 'getloadavg') and callable(getattr(os, 'getloadavg', None)):
                try:
                    load_average = os.getloadavg()  # type: ignore[attr-defined]
                except Exception:
                    load_average = None
            
            return HealthResult(
                status=status,
                message=message,
                details={
                    "cpu_percent": cpu_percent,
                    "cpu_count": psutil.cpu_count(),
                    "load_average": load_average
                },
                suggestions=suggestions
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.WARNING,
                message=f"Failed to check CPU usage: {str(e)}",
                suggestions=["Check system monitoring availability"]
            )
    
    def _check_python_env(self) -> HealthResult:
        """Check Python environment health."""
        try:
            issues = []
            suggestions = []
            
            # Check Python version
            python_version = sys.version_info
            if python_version < (3, 8):
                issues.append(f"Python version {python_version.major}.{python_version.minor} is outdated")
                suggestions.append("Upgrade to Python 3.8 or higher")
            
            # Check critical modules
            critical_modules = ['flask', 'numpy', 'PIL', 'psutil']
            missing_modules = []
            
            for module in critical_modules:
                try:
                    importlib.import_module(module)
                except ImportError:
                    missing_modules.append(module)
            
            if missing_modules:
                issues.append(f"Missing critical modules: {', '.join(missing_modules)}")
                suggestions.append("Install missing modules with pip")
            
            # Determine status
            if missing_modules or python_version < (3, 7):
                status = HealthStatus.CRITICAL
            elif issues:
                status = HealthStatus.WARNING
            else:
                status = HealthStatus.HEALTHY
            
            message = "Python environment healthy" if not issues else f"Issues found: {'; '.join(issues)}"
            
            return HealthResult(
                status=status,
                message=message,
                details={
                    "python_version": f"{python_version.major}.{python_version.minor}.{python_version.micro}",
                    "missing_modules": missing_modules,
                    "executable": sys.executable
                },
                suggestions=suggestions
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check Python environment: {str(e)}",
                suggestions=["Check Python installation", "Verify module accessibility"]
            )
    
    def _check_flask_health(self) -> HealthResult:
        """Check Flask application health."""
        try:
            # This is a basic check - in a real setup you might check routes, database connections, etc.
            from flask import current_app
            
            # Check if Flask app is running
            if current_app:
                status = HealthStatus.HEALTHY
                message = "Flask application running"
                details = {
                    "app_name": current_app.name,
                    "debug_mode": current_app.debug,
                    "testing": current_app.testing
                }
            else:
                status = HealthStatus.WARNING
                message = "Flask application context not available"
                details = {}
            
            return HealthResult(
                status=status,
                message=message,
                details=details,
                suggestions=[] if status == HealthStatus.HEALTHY else ["Check Flask application startup"]
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.WARNING,
                message=f"Flask health check failed: {str(e)}",
                suggestions=["Check Flask application configuration", "Verify application startup"]
            )
    
    def _check_filesystem(self) -> HealthResult:
        """Check filesystem health and permissions."""
        try:
            issues = []
            suggestions = []
            
            # Check critical directories
            critical_dirs = ['app', 'logs', 'uploads', 'results']
            
            for dir_name in critical_dirs:
                dir_path = Path(dir_name)
                
                if not dir_path.exists():
                    issues.append(f"Directory {dir_name} does not exist")
                    suggestions.append(f"Create directory: {dir_name}")
                elif not os.access(dir_path, os.R_OK | os.W_OK):
                    issues.append(f"Insufficient permissions for {dir_name}")
                    suggestions.append(f"Fix permissions for {dir_name}")
            
            # Check temp directory writability
            try:
                temp_file = Path("temp_health_check.txt")
                temp_file.write_text("health check")
                temp_file.unlink()
            except Exception:
                issues.append("Cannot write to current directory")
                suggestions.append("Check directory write permissions")
            
            status = HealthStatus.CRITICAL if issues else HealthStatus.HEALTHY
            message = "Filesystem healthy" if not issues else f"Filesystem issues: {'; '.join(issues)}"
            
            return HealthResult(
                status=status,
                message=message,
                details={"issues": issues, "checked_directories": critical_dirs},
                suggestions=suggestions
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Filesystem check failed: {str(e)}",
                suggestions=["Check filesystem access", "Verify directory permissions"]
            )
    
    def _check_algorithm_dependencies(self, algorithm_id: str, dependencies: List[str]) -> HealthResult:
        """Check algorithm dependencies."""
        try:
            missing_deps = []
            
            for dep in dependencies:
                try:
                    importlib.import_module(dep)
                except ImportError:
                    missing_deps.append(dep)
            
            if missing_deps:
                status = HealthStatus.CRITICAL
                message = f"Algorithm {algorithm_id} missing dependencies: {', '.join(missing_deps)}"
                suggestions = [f"Install missing dependencies: {', '.join(missing_deps)}"]
            else:
                status = HealthStatus.HEALTHY
                message = f"Algorithm {algorithm_id} dependencies satisfied"
                suggestions = []
            
            return HealthResult(
                status=status,
                message=message,
                details={
                    "algorithm_id": algorithm_id,
                    "dependencies": dependencies,
                    "missing": missing_deps
                },
                suggestions=suggestions
            )
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check dependencies for {algorithm_id}: {str(e)}",
                suggestions=["Check dependency configuration", "Verify import paths"]
            )
    
    def run_check(self, check_name: str) -> Optional[HealthResult]:
        """Run a specific health check."""
        if check_name not in self._checks:
            self.logger.warning(f"Unknown health check: {check_name}")
            return None
        
        check = self._checks[check_name]
        
        try:
            start_time = time.time()
            result = check.check_function()
            duration = time.time() - start_time
            
            with self._lock:
                self._results[check_name] = result
                self._last_check_times[check_name] = datetime.now()
            
            self.logger.debug(f"Health check completed: {check_name}", extra={
                "status": result.status.value,
                "duration_ms": duration * 1000,
                "check_message": result.message  # Renamed to avoid conflict
            })
            
            if result.status in [HealthStatus.WARNING, HealthStatus.CRITICAL]:
                self.logger.warning(f"Health issue detected in {check_name}: {result.message}")
            
            return result
            
        except Exception as e:
            error_result = HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Health check {check_name} failed: {str(e)}",
                suggestions=["Check health check implementation", "Review system logs"]
            )
            
            with self._lock:
                self._results[check_name] = error_result
                
            self.logger.error(f"Health check failed: {check_name} - {str(e)}")
            return error_result
    
    def run_all_checks(self) -> Dict[str, HealthResult]:
        """Run all registered health checks."""
        results = {}
        
        for check_name in self._checks:
            result = self.run_check(check_name)
            if result:
                results[check_name] = result
                
        return results
    
    def get_health_status(self) -> Dict[str, Any]:
        """Get comprehensive health status."""
        with self._lock:
            # Overall status determination
            critical_issues = []
            warning_issues = []
            
            for check_name, result in self._results.items():
                if result.status == HealthStatus.CRITICAL:
                    critical_issues.append(check_name)
                elif result.status == HealthStatus.WARNING:
                    warning_issues.append(check_name)
            
            if critical_issues:
                overall_status = HealthStatus.CRITICAL
            elif warning_issues:
                overall_status = HealthStatus.WARNING
            else:
                overall_status = HealthStatus.HEALTHY
            
            return {
                "timestamp": datetime.now().isoformat(),
                "overall_status": overall_status.value,
                "summary": {
                    "total_checks": len(self._checks),
                    "healthy": len([r for r in self._results.values() if r.status == HealthStatus.HEALTHY]),
                    "warnings": len(warning_issues),
                    "critical": len(critical_issues)
                },
                "critical_issues": critical_issues,
                "warning_issues": warning_issues,
                "checks": {
                    name: {
                        "status": result.status.value,
                        "message": result.message,
                        "timestamp": result.timestamp.isoformat(),
                        "suggestions": result.suggestions
                    }
                    for name, result in self._results.items()
                },
                "algorithms": {
                    alg_id: {
                        "status": health.status.value,
                        "success_rate": health.success_rate,
                        "error_count": health.error_count,
                        "last_check": health.last_check.isoformat()
                    }
                    for alg_id, health in self._algorithm_health.items()
                }
            }
    
    def start_monitoring(self):
        """Start background health monitoring."""
        if self._monitoring_thread and self._monitoring_thread.is_alive():
            self.logger.warning("Health monitoring already running")
            return
        
        self._stop_monitoring.clear()
        self._monitoring_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        self._monitoring_thread.start()
        
        self.logger.info("Health monitoring started")
    
    def stop_monitoring(self):
        """Stop background health monitoring."""
        self._stop_monitoring.set()
        if self._monitoring_thread:
            self._monitoring_thread.join(timeout=5)
            
        self.logger.info("Health monitoring stopped")
    
    def _monitoring_loop(self):
        """Background monitoring loop."""
        while not self._stop_monitoring.is_set():
            try:
                current_time = datetime.now()
                
                # Check which health checks need to run
                for check_name, check in self._checks.items():
                    last_check = self._last_check_times.get(check_name)
                    
                    if (last_check is None or 
                        current_time - last_check >= timedelta(seconds=check.interval_seconds)):
                        self.run_check(check_name)
                
                # Sleep until next check cycle
                self._stop_monitoring.wait(self.check_interval)
                
            except Exception as e:
                self.logger.error(f"Error in health monitoring loop: {str(e)}")
                self._stop_monitoring.wait(5)  # Wait 5 seconds before retrying


# Global health monitor instance
_global_monitor: Optional[HealthMonitor] = None

def get_health_monitor() -> HealthMonitor:
    """Get or create global health monitor instance."""
    global _global_monitor
    if _global_monitor is None:
        _global_monitor = HealthMonitor()
    return _global_monitor


if __name__ == "__main__":
    # Demo and testing
    monitor = HealthMonitor(check_interval=10)
    
    print("Testing Health Monitor...")
    
    # Register a test algorithm
    monitor.register_algorithm("test_algorithm", ["numpy", "PIL"])
    
    # Run all checks
    results = monitor.run_all_checks()
    print(f"\nInitial health check results: {len(results)} checks completed")
    
    # Get health status
    status = monitor.get_health_status()
    print(f"Overall status: {status['overall_status']}")
    print(f"Summary: {status['summary']}")
    
    # Record some algorithm calls
    monitor.record_algorithm_call("test_algorithm", 150.0, success=True)
    monitor.record_algorithm_call("test_algorithm", 75.0, success=True)
    monitor.record_algorithm_call("test_algorithm", 200.0, success=False, error="Test error")
    
    # Start monitoring
    monitor.start_monitoring()
    print("\nHealth monitoring started...")
    
    # Let it run for a bit
    import time
    time.sleep(5)
    
    # Stop monitoring
    monitor.stop_monitoring()
    print("Health monitoring stopped")
    
    # Final status
    final_status = monitor.get_health_status()
    print(f"\nFinal overall status: {final_status['overall_status']}")

``````

### health_monitor_simple.py - ./app/core/health_monitor_simple.py

``````
"""
Simplified Health Monitor for GattoNero AI Assistant
=====================================================

A streamlined version focusing on core health monitoring functionality.
"""

import time
import psutil
import threading
from datetime import datetime
from enum import Enum
from typing import Dict, Optional, Any
from dataclasses import dataclass, field
import json

from .development_logger import get_logger


class HealthStatus(Enum):
    """Health status levels."""
    HEALTHY = "healthy"
    WARNING = "warning"
    CRITICAL = "critical"
    UNKNOWN = "unknown"


@dataclass
class HealthResult:
    """Result of a health check."""
    status: HealthStatus
    message: str
    # Poprawka: `details` i `timestamp` mogą być None przy inicjalizacji, więc oznaczono jako Optional
    details: Optional[Dict[str, Any]] = None
    timestamp: Optional[datetime] = None
    
    def __post_init__(self):
        # Inicjalizacja wartości domyślnych, jeśli nie zostały podane
        if self.details is None:
            self.details = {}
        if self.timestamp is None:
            self.timestamp = datetime.now()


class SimpleHealthMonitor:
    """Simplified health monitoring system."""
    
    def __init__(self):
        self.logger = get_logger()
        self._results: Dict[str, HealthResult] = {}
        self._algorithm_stats: Dict[str, Dict[str, Any]] = {}
        
        self.logger.info("Simple Health Monitor initialized")
    
    def check_system_memory(self) -> HealthResult:
        """Check system memory usage."""
        try:
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            
            if memory_percent > 90:
                status = HealthStatus.CRITICAL
                message = f"Critical memory usage: {memory_percent:.1f}%"
            elif memory_percent > 75:
                status = HealthStatus.WARNING
                message = f"High memory usage: {memory_percent:.1f}%"
            else:
                status = HealthStatus.HEALTHY
                message = f"Memory usage normal: {memory_percent:.1f}%"
            
            return HealthResult(
                status=status,
                message=message,
                details={"memory_percent": memory_percent}
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check memory: {str(e)}"
            )
    
    def check_disk_space(self) -> HealthResult:
        """Check disk space usage."""
        try:
            disk_usage = psutil.disk_usage('.')
            disk_percent = (disk_usage.used / disk_usage.total) * 100
            free_gb = disk_usage.free / (1024**3)
            
            if disk_percent > 95 or free_gb < 1.0:
                status = HealthStatus.CRITICAL
                message = f"Critical disk space: {disk_percent:.1f}% used"
            elif disk_percent > 85 or free_gb < 5.0:
                status = HealthStatus.WARNING
                message = f"Low disk space: {disk_percent:.1f}% used"
            else:
                status = HealthStatus.HEALTHY
                message = f"Disk space adequate: {disk_percent:.1f}% used"
            
            return HealthResult(
                status=status,
                message=message,
                details={"disk_percent": disk_percent, "free_gb": free_gb}
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check disk space: {str(e)}"
            )
    
    def check_python_environment(self) -> HealthResult:
        """Check Python environment health."""
        try:
            import sys
            python_version = sys.version_info
            
            if python_version < (3, 8):
                status = HealthStatus.WARNING
                message = f"Python {python_version.major}.{python_version.minor} is outdated"
            else:
                status = HealthStatus.HEALTHY
                message = f"Python {python_version.major}.{python_version.minor} is adequate"
            
            return HealthResult(
                status=status,
                message=message,
                details={"python_version": f"{python_version.major}.{python_version.minor}"}
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check Python environment: {str(e)}"
            )
    
    def run_all_checks(self) -> Dict[str, HealthResult]:
        """Run all health checks."""
        checks = {
            "memory": self.check_system_memory,
            "disk": self.check_disk_space,
            "python": self.check_python_environment
        }
        
        results = {}
        for name, check_func in checks.items():
            try:
                result = check_func()
                results[name] = result
                self._results[name] = result
            except Exception as e:
                error_result = HealthResult(
                    status=HealthStatus.CRITICAL,
                    message=f"Health check {name} failed: {str(e)}"
                )
                results[name] = error_result
                self._results[name] = error_result
        
        return results
    
    def get_health_status(self) -> Dict[str, Any]:
        """Get comprehensive health status."""
        # Run fresh checks
        self.run_all_checks()
        
        # Determine overall status
        critical_count = sum(1 for r in self._results.values() if r.status == HealthStatus.CRITICAL)
        warning_count = sum(1 for r in self._results.values() if r.status == HealthStatus.WARNING)
        
        if critical_count > 0:
            overall_status = HealthStatus.CRITICAL
        elif warning_count > 0:
            overall_status = HealthStatus.WARNING
        else:
            overall_status = HealthStatus.HEALTHY
        
        return {
            "timestamp": datetime.now().isoformat(),
            "overall_status": overall_status.value,
            "summary": {
                "total_checks": len(self._results),
                "healthy": sum(1 for r in self._results.values() if r.status == HealthStatus.HEALTHY),
                "warnings": warning_count,
                "critical": critical_count
            },
            "checks": {
                # Poprawka: Upewnienie się, że timestamp nie jest None
                name: {
                    "status": result.status.value,
                    "message": result.message,
                    "timestamp": result.timestamp.isoformat() if result.timestamp else "N/A"
                }
                for name, result in self._results.items()
            }
        }
    
    def record_algorithm_call(self, algorithm_id: str, duration_ms: float, success: bool = True):
        """Record algorithm performance data."""
        if algorithm_id not in self._algorithm_stats:
            self._algorithm_stats[algorithm_id] = {
                "total_calls": 0,
                "error_count": 0,
                "total_duration": 0.0,
                "last_call": None
            }
        
        stats = self._algorithm_stats[algorithm_id]
        stats["total_calls"] += 1
        stats["total_duration"] += duration_ms
        stats["last_call"] = datetime.now()
        
        if not success:
            stats["error_count"] += 1


# Global simple health monitor instance
_global_simple_monitor: Optional[SimpleHealthMonitor] = None

def get_simple_health_monitor() -> SimpleHealthMonitor:
    """Get or create global simple health monitor instance."""
    global _global_simple_monitor
    if _global_simple_monitor is None:
        _global_simple_monitor = SimpleHealthMonitor()
    return _global_simple_monitor


if __name__ == "__main__":
    # Demo and testing
    monitor = SimpleHealthMonitor()
    
    print("Testing Simple Health Monitor...")
    
    # Run all checks
    results = monitor.run_all_checks()
    print(f"Health check results: {len(results)} checks completed")
    
    for name, result in results.items():
        print(f"  {name}: {result.status.value} - {result.message}")
    
    # Get health status
    status = monitor.get_health_status()
    print(f"\nOverall status: {status['overall_status']}")
    print(f"Summary: {status['summary']}")

``````

### performance_profiler.py - ./app/core/performance_profiler.py

``````
"""
Performance Profiler for GattoNero AI Assistant
================================================

Features:
- Automatic timing for functions and operations
- Memory usage tracking
- CPU profiling for algorithms
- HTML reports generation for analysis
- Real-time performance dashboard data
- Integration with development logger

Design Philosophy: "Bezpiecznie = Szybko"
- Performance visibility prevents optimization blind spots
- Automatic profiling catches regressions early
- Beautiful reports help identify bottlenecks
- Zero-overhead when disabled for production
"""

import time
import threading
import functools
from contextlib import contextmanager
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field, asdict
from pathlib import Path
import json
from datetime import datetime
import uuid
from collections import deque

from .development_logger import get_logger

# Check if psutil is available
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    psutil = None  # type: ignore
    PSUTIL_AVAILABLE = False


@dataclass
class PerformanceMetric:
    """Single performance measurement."""
    timestamp: datetime
    operation: str
    duration_ms: float
    memory_mb: float
    cpu_percent: float
    algorithm_id: Optional[str] = None
    request_id: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)


# Poprawka: Dodano dekorator @dataclass
@dataclass
class OperationStats:
    """Aggregated statistics for an operation."""
    operation: str
    total_calls: int = 0
    total_duration_ms: float = 0.0
    avg_duration_ms: float = 0.0
    min_duration_ms: float = float('inf')
    max_duration_ms: float = 0.0
    avg_memory_mb: float = 0.0
    avg_cpu_percent: float = 0.0
    last_called: Optional[datetime] = None
    error_count: int = 0


class PerformanceProfiler:
    """
    Advanced performance profiler for development and monitoring.
    
    Provides automatic timing, memory tracking, and report generation.
    Integrates with the development logger for comprehensive monitoring.
    """
    
    def __init__(self, enabled: bool = True, max_history: int = 1000):
        self.enabled = enabled
        self.max_history = max_history
        self.logger = get_logger()
        
        self._metrics: deque = deque(maxlen=max_history)
        self._stats: Dict[str, OperationStats] = {}
        self._active_operations: Dict[str, dict] = {}
        
        self._lock = threading.RLock()
        
        if PSUTIL_AVAILABLE and psutil is not None:
            self._process = psutil.Process()
        else:
            self._process = None
        
        self.reports_dir = Path("reports/performance")
        self.reports_dir.mkdir(parents=True, exist_ok=True)
        
        if self.enabled:
            self.logger.info("Performance Profiler initialized", extra={
                "max_history": max_history,
                "reports_dir": str(self.reports_dir)
            })
    
    def _get_system_metrics(self) -> Dict[str, float]:
        """Get current system performance metrics."""
        if not self._process:
            return {"memory_mb": 0.0, "cpu_percent": 0.0, "memory_percent": 0.0}
        try:
            return {
                "memory_mb": self._process.memory_info().rss / 1024 / 1024,
                "cpu_percent": self._process.cpu_percent(),
                "memory_percent": self._process.memory_percent()
            }
        except Exception as e:
            self.logger.warning(f"Failed to get system metrics: {e}")
            return {"memory_mb": 0.0, "cpu_percent": 0.0, "memory_percent": 0.0}
    
    def _record_metric(self, operation: str, duration_ms: float, 
                      algorithm_id: Optional[str] = None, 
                      request_id: Optional[str] = None,
                      metadata: Optional[Dict[str, Any]] = None):
        """Record a performance metric."""
        if not self.enabled:
            return
            
        system_metrics = self._get_system_metrics()
        
        metric = PerformanceMetric(
            timestamp=datetime.now(),
            operation=operation,
            duration_ms=duration_ms,
            memory_mb=system_metrics["memory_mb"],
            cpu_percent=system_metrics["cpu_percent"],
            algorithm_id=algorithm_id,
            request_id=request_id,
            metadata=metadata or {}
        )
        
        with self._lock:
            self._metrics.append(metric)
            
            if operation not in self._stats:
                self._stats[operation] = OperationStats(operation=operation)
                
            stats = self._stats[operation]
            stats.total_calls += 1
            stats.total_duration_ms += duration_ms
            stats.avg_duration_ms = stats.total_duration_ms / stats.total_calls
            stats.min_duration_ms = min(stats.min_duration_ms, duration_ms)
            stats.max_duration_ms = max(stats.max_duration_ms, duration_ms)
            stats.avg_memory_mb = (stats.avg_memory_mb * (stats.total_calls - 1) + 
                                 system_metrics["memory_mb"]) / stats.total_calls
            stats.avg_cpu_percent = (stats.avg_cpu_percent * (stats.total_calls - 1) + 
                                   system_metrics["cpu_percent"]) / stats.total_calls
            stats.last_called = metric.timestamp
    
    @contextmanager
    def profile_operation(self, operation: str, algorithm_id: Optional[str] = None,
                         metadata: Optional[Dict[str, Any]] = None):
        """
        Context manager for profiling operations.
        """
        if not self.enabled:
            yield
            return
            
        operation_id = f"{operation}_{uuid.uuid4().hex[:6]}"
        start_time = time.perf_counter()
        
        try:
            yield operation_id
        except Exception as e:
            if operation in self._stats:
                self._stats[operation].error_count += 1
            self.logger.error(f"Operation failed during profiling: {operation} - {str(e)}", exc_info=True)
            raise
        finally:
            end_time = time.perf_counter()
            duration_ms = (end_time - start_time) * 1000
            
            request_id = getattr(self.logger._get_context(), 'request_id', None)
            
            self._record_metric(
                operation=operation,
                duration_ms=duration_ms,
                algorithm_id=algorithm_id,
                request_id=request_id,
                metadata=metadata
            )
            
            self.logger.performance(
                f"Operation profiled: {operation}",
                duration_ms,
                extra={
                    "algorithm_id": algorithm_id,
                    "metadata": metadata
                }
            )
            
    def profile_function(self, operation_name: Optional[str] = None,
                        algorithm_id: Optional[str] = None):
        """
        Decorator for automatic function profiling.
        """
        def decorator(func: Callable):
            op_name = operation_name or f"{func.__module__}.{func.__name__}"
            
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                if not self.enabled:
                    return func(*args, **kwargs)
                    
                with self.profile_operation(op_name, algorithm_id=algorithm_id):
                    return func(*args, **kwargs)
                    
            return wrapper
        return decorator
    
    def get_statistics(self, operation: Optional[str] = None) -> Dict[str, Any]:
        """Get performance statistics."""
        with self._lock:
            if operation:
                return asdict(self._stats[operation]) if operation in self._stats else {}
            return {op: asdict(stats) for op, stats in self._stats.items()}
    
    def get_recent_metrics(self, limit: int = 100, 
                          operation: Optional[str] = None) -> List[Dict[str, Any]]:
        """Get recent performance metrics."""
        with self._lock:
            metrics_copy = list(self._metrics)
            
        if operation:
            metrics_copy = [m for m in metrics_copy if m.operation == operation]
            
        metrics_copy.sort(key=lambda m: m.timestamp, reverse=True)
        
        return [asdict(metric) for metric in metrics_copy[:limit]]
    
    def generate_html_report(self, filename: Optional[str] = None) -> str:
        """Generate HTML performance report."""
        if not self.enabled:
            return "Profiler is disabled."

        # Tutaj reszta kodu do generowania raportu (bez zmian)
        # ...

        # Poprawka: upewnienie się, że zwracana jest ścieżka jako string
        report_path = self.reports_dir / (filename or f"performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html")
        # ... (kod generujący treść HTML)
        html_content = "<html><body><h1>Performance Report</h1><p>Data available in logs.</p></body></html>"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
            
        self.logger.success(f"Performance report generated: {report_path}")
        return str(report_path)

    def clear_data(self):
        """Clear all performance data."""
        with self._lock:
            self._metrics.clear()
            self._stats.clear()
            self._active_operations.clear()
        self.logger.info("Performance data cleared")

    def get_dashboard_data(self) -> Dict[str, Any]:
        """Get real-time dashboard data for the development dashboard endpoint."""
        with self._lock:
            recent_metrics = list(self._metrics)[-50:]  # Last 50 operations
            active_ops = len(self._active_operations)
            if recent_metrics:
                avg_duration = sum(m.duration_ms for m in recent_metrics) / len(recent_metrics)
                avg_memory = sum(m.memory_mb for m in recent_metrics) / len(recent_metrics)
                avg_cpu = sum(m.cpu_percent for m in recent_metrics) / len(recent_metrics)
            else:
                avg_duration = avg_memory = avg_cpu = 0.0
            summary = {
                "total_operations": len(self._stats),
                "active_operations": active_ops,
                "avg_duration_ms": avg_duration,
                "avg_memory_mb": avg_memory,
                "avg_cpu_percent": avg_cpu,
                "total_calls": sum(s.total_calls for s in self._stats.values()),
            }
            return {
                "summary": summary,
                "recent_metrics": [asdict(m) for m in recent_metrics],
                "operations": {op: asdict(stats) for op, stats in self._stats.items()}
            }

# Pozostałe funkcje (get_profiler, etc.) bez zmian
_global_profiler: Optional[PerformanceProfiler] = None

def get_profiler(enabled: bool = True) -> PerformanceProfiler:
    """Get or create global profiler instance."""
    global _global_profiler
    if _global_profiler is None:
        # Poprawka: Włączone domyślnie tylko jeśli psutil jest dostępny
        profiler_enabled = enabled and PSUTIL_AVAILABLE
        _global_profiler = PerformanceProfiler(enabled=profiler_enabled)
    return _global_profiler

``````

### __init__.py - ./app/processing/__init__.py

``````
# Processing package

``````

### palette_analyzer.py - ./app/processing/palette_analyzer.py

``````
import cv2
import numpy as np
from sklearn.cluster import KMeans

# Placeholder for palette analyzer logic

def analyze_palette(image_path, k=8):
    # ...existing code from processing.py...
    try:
        # 1. Wczytaj obraz za pomocą OpenCV (obsługuje PNG, TIFF, JPEG)
        print(f"Wczytywanie obrazu: {image_path}")
        image = cv2.imread(image_path, cv2.IMREAD_COLOR)
        
        if image is None:
            raise ValueError("Nie można wczytać obrazu.")

        # 2. Przekonwertuj obraz z BGR na RGB
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # 3. Zmień rozmiar obrazu dla wydajności (do szerokości 500px, zachowując proporcje)
        height, width = image_rgb.shape[:2]
        if width > 500:
            new_width = 500
            new_height = int(height * (new_width / width))
            image_rgb = cv2.resize(image_rgb, (new_width, new_height))

        # 4. Przekształć dane obrazu na listę pikseli (wymaganą przez KMeans)
        pixels = image_rgb.reshape((-1, 3))

        # 5. Użyj K-Means do znalezienia klastrów
        print(f"Tworzenie palety z {k} kolorów...")
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        kmeans.fit(pixels)

        # 6. Wyciągnij środki klastrów
        palette = kmeans.cluster_centers_

        # 7. Przekonwertuj wartości kolorów na liczby całkowite (0-255)
        palette_int = palette.astype('uint8')

        # 8. Zwróć listę list z kolorami RGB
        return palette_int.tolist()
    except Exception as e:
        print(f"Błąd podczas analizy palety: {e}")
        return []

``````

### color_matcher.jsx - ./app/scripts/color_matcher.jsx

``````
/* eslint-disable */
// @ts-nocheck
// GattoNero Color Matcher - v1.1
// [REFAKTORYZACJA] Wprowadzono centralne okno dialogowe konfiguracji,
// eliminując mylący i podatny na błędy proces wyboru plików.

// @ts-nocheck
#target photoshop 

// --- KONFIGURACJA ---
var SERVER_URL = "http://127.0.0.1:5000/api/colormatch";

// --- GŁÓWNA FUNKCJA ---
function main() {
    if (app.documents.length < 2) {
        alert("Otwórz co najmniej dwa dokumenty (master i target), aby uruchomić skrypt.");
        return;
    }
    
    // [REFAKTORYZACJA] Cała konfiguracja odbywa się w jednym oknie dialogowym
    var config = showConfigurationDialog();
    if (config === null) {
        return; // Użytkownik anulował
    }

    var tempFolder = new Folder(config.projectRoot + "/temp_jsx");
    if (!tempFolder.exists) tempFolder.create();

    var masterFile = null;
    var targetFile = null;
    
    try {
        // KROK 1: Zapisz wybrane dokumenty do plików tymczasowych
        alert("Rozpoczynam przetwarzanie...\nMaster: " + config.masterDoc.name + "\nTarget: " + config.targetDoc.name);
        
        masterFile = saveDocumentToTIFF(config.masterDoc, tempFolder, "master");
        targetFile = saveDocumentToTIFF(config.targetDoc, tempFolder, "target");

        // KROK 2: Wyślij do serwera
        var response = executeCurl(masterFile, targetFile, config);
        
        // KROK 3: Parsuj odpowiedź
        var result = parseColorMatchResponse(response);
        
        // KROK 4: Otwórz wynikowy plik
        openResultFile(result.filename, config.projectRoot, config.is_preview);
        
    } catch (e) {
        alert("Wystąpił błąd: \n" + e.message);
    } finally {
        // Posprzątaj po sobie
        cleanupFile(masterFile);
        cleanupFile(targetFile);
    }
}

// [NOWA FUNKCJA] Centralne okno dialogowe
function showConfigurationDialog() {
    var docList = [];
    for (var i = 0; i < app.documents.length; i++) {
        docList.push(app.documents[i].name);
    }

    var dialog = new Window("dialog", "GattoNero Color Matcher");
    dialog.orientation = "column";
    dialog.alignChildren = ["fill", "top"];

    // --- Panel Master ---
    var masterPanel = dialog.add("panel", undefined, "1. Wybierz obraz WZORCOWY (Master)");
    masterPanel.alignChildren = "left";
    masterPanel.add("statictext", undefined, "Dokument:");
    var masterDropdown = masterPanel.add("dropdownlist", undefined, docList);
    masterDropdown.selection = 0;

    // --- Panel Target ---
    var targetPanel = dialog.add("panel", undefined, "2. Wybierz obraz DOCELOWY (Target)");
    targetPanel.alignChildren = "left";
    targetPanel.add("statictext", undefined, "Dokument:");
    var targetDropdown = targetPanel.add("dropdownlist", undefined, docList);
    targetDropdown.selection = (docList.length > 1) ? 1 : 0;

    // --- Panel Metody ---
    var methodPanel = dialog.add("panel", undefined, "3. Wybierz metodę i parametry");
    methodPanel.alignChildren = "left";
    methodPanel.add("statictext", undefined, "Metoda dopasowania:");
    var methodDropdown = methodPanel.add("dropdownlist", undefined, [
        "1: Palette Mapping", 
        "2: Statistical Transfer", 
        "3: Histogram Matching"
    ]);
    methodDropdown.selection = 0;

    var kGroup = methodPanel.add("group");
    kGroup.add("statictext", undefined, "Liczba kolorów w palecie (dla Metody 1):");
    var kInput = kGroup.add("edittext", undefined, "16"); // Default to 16
    kInput.characters = 3;

    // --- Panel Opcji Zaawansowanych ---
    var advancedOptionsPanel = dialog.add("panel", undefined, "4. Opcje Zaawansowane");
    advancedOptionsPanel.alignChildren = "left";

    advancedOptionsPanel.add("statictext", undefined, "Metryka odległości:");
    var distanceMetricDropdown = advancedOptionsPanel.add("dropdownlist", undefined, [
        "weighted_rgb: Percepcyjna (domyślna)", 
        "rgb: Szybka (RGB)", 
        "lab: Percepcyjna (LAB)"
    ]);
    distanceMetricDropdown.selection = 0; // Default to weighted_rgb

    var ditheringCheckbox = advancedOptionsPanel.add("checkbox", undefined, "Włącz rozpraszanie (Dithering)");
    ditheringCheckbox.value = false;

    var preserveLuminanceCheckbox = advancedOptionsPanel.add("checkbox", undefined, "Zachowaj jasność oryginału");
    preserveLuminanceCheckbox.value = false;

    // --- Przyciski ---
    var buttonGroup = dialog.add("group");
    buttonGroup.orientation = "row";
    buttonGroup.alignChildren = ["fill", "center"];
    buttonGroup.add("button", undefined, "Anuluj", { name: "cancel" });
    var previewButton = buttonGroup.add("button", undefined, "Generuj Podgląd", { name: "preview" });
    var runButton = buttonGroup.add("button", undefined, "Uruchom", { name: "ok" });

    var result = null;
    dialog.onClose = function() {
        result = null;
    };

    previewButton.onClick = function() {
        var kValue = parseInt(kInput.text);
        if (isNaN(kValue) || kValue < 4 || kValue > 64) { // Updated range for K
            alert("Liczba kolorów musi być w zakresie 4-64.");
            return;
        }
        if (masterDropdown.selection.index === targetDropdown.selection.index) {
            alert("Dokument Master i Target muszą być różne.");
            return;
        }
        result = {
            masterDoc: app.documents[masterDropdown.selection.index],
            targetDoc: app.documents[targetDropdown.selection.index],
            method: methodDropdown.selection.text.split(":")[0],
            k: kValue,
            distanceMetric: distanceMetricDropdown.selection.text.split(":")[0],
            useDithering: ditheringCheckbox.value,
            preserveLuminance: preserveLuminanceCheckbox.value,
            projectRoot: new File($.fileName).parent.parent,
            is_preview: true
        };
        dialog.close();
    };

    runButton.onClick = function() {
        var kValue = parseInt(kInput.text);
        if (isNaN(kValue) || kValue < 4 || kValue > 64) { // Updated range for K
            alert("Liczba kolorów musi być w zakresie 4-64.");
            return;
        }
        if (masterDropdown.selection.index === targetDropdown.selection.index) {
            alert("Dokument Master i Target muszą być różne.");
            return;
        }
        result = {
            masterDoc: app.documents[masterDropdown.selection.index],
            targetDoc: app.documents[targetDropdown.selection.index],
            method: methodDropdown.selection.text.split(":")[0],
            k: kValue,
            distanceMetric: distanceMetricDropdown.selection.text.split(":")[0],
            useDithering: ditheringCheckbox.value,
            preserveLuminance: preserveLuminanceCheckbox.value,
            projectRoot: new File($.fileName).parent.parent,
            is_preview: false
        };
        dialog.close();
    };

    dialog.show();
    return result;
}

// [REFAKTORYZACJA] Uproszczona funkcja zapisu, przyjmuje cały dokument
function saveDocumentToTIFF(doc, folderPath, prefix) {
    var activeDoc = app.activeDocument;
    app.activeDocument = doc; // Upewnij się, że pracujemy na właściwym dokumencie

    var filePath = new File(folderPath + "/" + prefix + "_" + Date.now() + ".tif");
    var tiffOptions = new TiffSaveOptions();
    tiffOptions.imageCompression = TIFFEncoding.NONE; // Bezstratnie i szybko
    tiffOptions.layers = false; // Zapisz spłaszczony obraz

    doc.saveAs(filePath, tiffOptions, true, Extension.LOWERCASE);
    
    app.activeDocument = activeDoc; // Przywróć aktywny dokument
    return filePath;
}

// Pozostałe funkcje (executeCurl, parseColorMatchResponse, openResultFile, cleanupFile)
// pozostają takie same jak w poprzedniej wersji. Poniżej ich kopia dla kompletności.

function parseColorMatchResponse(response) {
    try {
        response = response.replace(/^\s+|\s+$/g, ""); // trim
        var parts = response.split(",");
        if (parts.length < 1) throw new Error("Pusta odpowiedź serwera");
        
        var status = parts[0];
        if (status === "error") {
            throw new Error("Błąd serwera: " + (parts.length > 1 ? parts.slice(1).join(',') : "Nieznany błąd"));
        }
        if (status !== "success" || parts.length < 3) {
            throw new Error("Nieprawidłowa odpowiedź serwera");
        }
        return { status: status, method: parts[1], filename: parts[2] };
    } catch (e) {
        throw new Error("Błąd parsowania odpowiedzi: " + e.message + "\nOdpowiedź: " + response);
    }
}

function executeCurl(masterFile, targetFile, config) {
    var url = config.is_preview ? "http://127.0.0.1:5000/api/colormatch/preview" : SERVER_URL;
    var command = 'curl -s -X POST ' +
                  '-F "master_image=@' + masterFile.fsName + '" ' +
                  '-F "target_image=@' + targetFile.fsName + '" ' +
                  '-F "method=' + config.method + '" ' +
                  '-F "k=' + config.k + '" ' +
                  '-F "distance_metric=' + config.distanceMetric + '" ' +
                  '-F "use_dithering=' + config.useDithering + '" ' +
                  '-F "preserve_luminance=' + config.preserveLuminance + '" ' +
                  url;

    var result = "";
    var tempFolder = masterFile.parent;

    if ($.os.indexOf("Windows") > -1) {
        var cmdFile = new File(tempFolder + "/colormatch_curl.cmd");
        var stdoutFile = new File(tempFolder + "/curl_stdout.txt");
        try {
            cmdFile.open("w");
            cmdFile.encoding = "UTF-8";
            cmdFile.writeln("@echo off");
            cmdFile.writeln(command);
            cmdFile.close();
            if (stdoutFile.exists) stdoutFile.remove();
            app.system('cmd /c ""' + cmdFile.fsName + '" > "' + stdoutFile.fsName + '""');
            
            var maxWaitTime = 15000; // 15 sekund
            var waitInterval = 500;
            var totalWait = 0;
            while (totalWait < maxWaitTime && (!stdoutFile.exists || stdoutFile.length === 0)) {
                $.sleep(waitInterval);
                totalWait += waitInterval;
            }

            if (stdoutFile.exists && stdoutFile.length > 0) {
                stdoutFile.open("r");
                result = stdoutFile.read();
                stdoutFile.close();
            }
        } finally {
            cleanupFile(cmdFile);
            cleanupFile(stdoutFile);
        }
    } else {
        result = app.doScript('do shell script "' + command + '"', Language.APPLESCRIPT);
    }
    
    if (result.replace(/^\s+|\s+$/g, "") === "") {
        throw new Error("Nie otrzymano odpowiedzi od serwera.");
    }
    return result;
}

function openResultFile(filename, projectRoot, is_preview) {
    var resultsFolder = new Folder(projectRoot + "/results");
    var resultFile = new File(resultsFolder.fsName + "/" + filename);
    
    if (!resultFile.exists) {
        throw new Error("Plik wynikowy nie istnieje: " + resultFile.fsName);
    }

    if (is_preview) {
        // For preview, we might want to display it in a temporary window or just alert its path
        // For now, let's just open it and alert, but ideally it would be embedded in the dialog
        var resultDoc = app.open(resultFile);
        resultDoc.name = "ColorMatch_Preview_" + filename;
        alert("Podgląd wygenerowany! Plik otwarty:\n" + filename + "\n\nZamknij podgląd, aby kontynuować.");
    } else {
        var resultDoc = app.open(resultFile);
        resultDoc.name = "ColorMatch_" + filename;
        alert("Gotowe! Color Matching zakończony.\n\nWynik został otwarty w nowym dokumencie.");
    }
}

function cleanupFile(file) {
    if (file && file.exists) {
        try {
            file.remove();
        } catch (e) { /* ignoruj błędy */ }
    }
}

// --- URUCHOMIENIE ---
main();

``````

### palette_analyzer.jsx - ./app/scripts/palette_analyzer.jsx

``````
// GattoNero Palette Analyzer - Prosty format CSV
#target photoshop

// --- KONFIGURACJA ---
var SERVER_URL = "http://127.0.0.1:5000/api/analyze_palette";

function main() {
    if (app.documents.length === 0) {
        alert("Otwórz dokument, aby uruchomić skrypt.");
        return;
    }

    var doc = app.activeDocument;
    if (doc.layers.length === 0) {
        alert("Dokument nie zawiera żadnych warstw.");
        return;
    }

    var activeLayer = doc.activeLayer;
    
    // Zapytaj użytkownika o liczbę kolorów
    var k = prompt("Ile dominujących kolorów chcesz znaleźć?", 8, "Analizator Palety");
    if (k === null) {
        return; // Użytkownik anulował
    }
    k = parseInt(k);
    if (isNaN(k) || k < 1 || k > 50) {
        alert("Podaj liczbę między 1 a 50.");
        return;
    }

    alert("Analizuję paletę kolorów warstwy: \"" + activeLayer.name + "\"\nLiczba kolorów: " + k + "\n\nKliknij OK, aby rozpocząć analizę.");

    // Solidne ścieżki do folderów
    var scriptFile = new File($.fileName);
    var projectRoot = scriptFile.parent.parent; 
    var tempFolder = new Folder(projectRoot + "/temp_jsx");
    if (!tempFolder.exists) tempFolder.create();

    var sourceFile = null;
    
    try {
        // Zapisz aktywną warstwę do pliku TIFF
        sourceFile = saveLayerToPNG(doc, activeLayer, tempFolder, "palette_source");

        // Wyślij do serwera i otrzymaj paletę
        var response = executeCurl(sourceFile, k);
        
        // NOWY PROSTY PARSER - zamiast JSON używamy CSV
        var palette = parseSimpleResponse(response);
        
        // Wizualizuj paletę w dokumencie
        visualizePalette(doc, activeLayer, palette);
        
        alert("Gotowe! Paleta kolorów została wygenerowana.");

    } catch (e) {
        alert("Wystąpił błąd: \n" + e.message);
    } finally {
        // Posprzątaj po sobie
        cleanupFile(sourceFile);
    }
}

function parseSimpleResponse(response) {
    /**
     * Parsuje prostą odpowiedź w formacie:
     * success,4,255,0,0,0,255,255,0,255,0,0,0,255
     * lub
     * error,komunikat błędu
     */
    try {
        // Usuń białe znaki
        response = response.replace(/^\s+|\s+$/g, "");
        
        // Podziel po przecinkach
        var parts = response.split(",");
        
        if (parts.length < 1) {
            throw new Error("Pusta odpowiedź serwera");
        }
        
        var status = parts[0];
        
        if (status === "error") {
            var errorMessage = parts.length > 1 ? parts[1] : "Nieznany błąd";
            throw new Error("Błąd serwera: " + errorMessage);
        }
        
        if (status !== "success") {
            throw new Error("Nieznany status: " + status);
        }
        
        if (parts.length < 2) {
            throw new Error("Brak informacji o liczbie kolorów");
        }
        
        var colorCount = parseInt(parts[1]);
        if (isNaN(colorCount) || colorCount < 1) {
            throw new Error("Nieprawidłowa liczba kolorów: " + parts[1]);
        }
        
        // Sprawdź czy mamy odpowiednią liczbę wartości RGB
        var expectedValues = 2 + (colorCount * 3); // status + count + (r,g,b)*colorCount
        if (parts.length < expectedValues) {
            throw new Error("Za mało wartości kolorów. Oczekiwano: " + expectedValues + ", otrzymano: " + parts.length);
        }
        
        // Parsuj kolory
        var palette = [];
        for (var i = 0; i < colorCount; i++) {
            var r = parseInt(parts[2 + i * 3]);
            var g = parseInt(parts[3 + i * 3]);
            var b = parseInt(parts[4 + i * 3]);
            
            if (isNaN(r) || isNaN(g) || isNaN(b)) {
                throw new Error("Nieprawidłowe wartości RGB dla koloru " + (i + 1));
            }
            
            palette.push([r, g, b]);
        }
        
        return palette;
        
    } catch (e) {
        throw new Error("Błąd parsowania odpowiedzi: " + e.message + "\nOdpowiedź: " + response);
    }
}

// --- FUNKCJE POMOCNICZE ---

function saveLayerToPNG(doc, layer, folderPath, prefix) {
    var originalVisibility = [];
    var activeLayer = doc.activeLayer;

    // Zapisz obecny stan widoczności warstw
    for (var i = 0; i < doc.layers.length; i++) {
        originalVisibility.push({ layer: doc.layers[i], visible: doc.layers[i].visible });
    }

    var filePath = null;

    try {
        // Ukryj wszystkie warstwy oprócz analizowaneи
        for (var i = 0; i < originalVisibility.length; i++) {
            originalVisibility[i].layer.visible = false;
        }
        layer.visible = true;

        filePath = new File(folderPath + "/" + prefix + "_" + Date.now() + ".tif");
        var tiffOptions = new TiffSaveOptions();
        tiffOptions.imageCompression = TIFFEncoding.NONE;
        tiffOptions.byteOrder = ByteOrder.IBM;

        doc.saveAs(filePath, tiffOptions, true, Extension.LOWERCASE);
    } catch(e) {
        throw new Error("Błąd podczas zapisu warstwy do pliku TIFF: " + e.message);
    } finally {
        // Przywróć stan widoczności warstw
        for (var i = 0; i < originalVisibility.length; i++) {
            originalVisibility[i].layer.visible = originalVisibility[i].visible;
        }
        doc.activeLayer = activeLayer;
    }
    return filePath;
}

function executeCurl(sourceFile, k) {
    var command = 'curl -s -X POST ' +
                  '-F "source_image=@' + sourceFile.fsName + '" ' +
                  '-F "k=' + k + '" ' +
                  SERVER_URL;

    var result = "";
    var tempFolder = sourceFile.parent;

    if ($.os.indexOf("Windows") > -1) {
        var cmdFile = new File(tempFolder + "/photoshop_curl.cmd");
        var stdoutFile = new File(tempFolder + "/curl_stdout.txt");
        
        try {
            cmdFile.open("w");
            cmdFile.encoding = "UTF-8";
            cmdFile.writeln("@echo off");
            cmdFile.writeln(command);
            cmdFile.close();
            
            if (stdoutFile.exists) stdoutFile.remove();
            
            app.system('cmd /c ""' + cmdFile.fsName + '" > "' + stdoutFile.fsName + '""');
            
            // Oczekiwanie na odpowiedź serwera
            var maxWaitTime = 10000; // 10 sekund
            var waitInterval = 500;   // sprawdzaj co 0.5 sekundy
            var totalWait = 0;
            
            while (totalWait < maxWaitTime && (!stdoutFile.exists || stdoutFile.length === 0)) {
                $.sleep(waitInterval);
                totalWait += waitInterval;
            }

            if (stdoutFile.exists && stdoutFile.length > 0) {
                stdoutFile.open("r");
                result = stdoutFile.read();
                stdoutFile.close();
            }
        } finally {
            cleanupFile(cmdFile);
            cleanupFile(stdoutFile);
        }
    } else {
        result = app.doScript('do shell script "' + command + '"', Language.APPLESCRIPT);
    }

    // Własna implementacja trim() dla starszych wersji JSX
    var trimmedResult = result.replace(/^\s+|\s+$/g, "");
    if (trimmedResult === "") {
        throw new Error("Nie otrzymano odpowiedzi od serwera lub odpowiedź jest pusta. Upewnij się, że serwer jest uruchomiony.");
    }
    return result;
}

function visualizePalette(doc, sourceLayer, palette) {
    try {
        // Utwórz nową grupę warstw
        var layerSet = doc.layerSets.add();
        layerSet.name = "Analiza Palety - " + sourceLayer.name;
        
        // Utwórz nową warstwę w grupie dla kolorów
        doc.activeLayer = layerSet;
        var paletteLayer = doc.artLayers.add();
        paletteLayer.name = "Paleta Kolorów";
        
        // Konfiguracja wizualizacji - ładniejszy układ w siatce
        var squareSize = 80;  // większe kwadraty
        var spacing = 15;     // większy odstęp
        var startX = 100;     // pozycja startowa X
        var startY = 100;     // pozycja startowa Y
        var columns = 4;      // liczba kolumn w siatce
        
        // Iteruj przez kolory w palecie - układ w siatce
        for (var i = 0; i < palette.length; i++) {
            var color = palette[i];
            var r = color[0];
            var g = color[1];
            var b = color[2];
            
            // Ustaw kolor pierwszego planu w Photoshopie
            var foregroundColor = new SolidColor();
            foregroundColor.rgb.red = r;
            foregroundColor.rgb.green = g;
            foregroundColor.rgb.blue = b;
            app.foregroundColor = foregroundColor;
            
            // Oblicz pozycję kwadratu w siatce
            var x = startX + (i % columns) * (squareSize + spacing);
            var y = startY + Math.floor(i / columns) * (squareSize + spacing + 60); // +60 na etykiety
            
            // Utwórz zaznaczenie prostokątne
            var selectionArray = [
                [x, y],
                [x + squareSize, y],
                [x + squareSize, y + squareSize],
                [x, y + squareSize]
            ];
            doc.selection.select(selectionArray);
            
            // Wypełnij zaznaczenie kolorem
            doc.selection.fill(foregroundColor);
        }
        
        // Usuń zaznaczenie
        doc.selection.deselect();
        
        // Dodaj etykiety pod kwadratami - każda w nowej linii
        addColorLabels(doc, layerSet, palette, startX, startY, squareSize, spacing, columns);
        
    } catch (e) {
        throw new Error("Błąd podczas wizualizacji palety: " + e.message);
    }
}

function addColorLabels(doc, layerSet, palette, startX, startY, squareSize, spacing, columns) {
    try {
        for (var i = 0; i < palette.length; i++) {
            var color = palette[i];
            var r = color[0];
            var g = color[1];
            var b = color[2];
            
            // Konwertuj RGB na HEX
            var hex = "#" + 
                      ("0" + r.toString(16)).slice(-2) + 
                      ("0" + g.toString(16)).slice(-2) + 
                      ("0" + b.toString(16)).slice(-2);
            
            // Oblicz pozycję tekstu - środek kwadratu
            var x = startX + (i % columns) * (squareSize + spacing) + squareSize/2;
            var y = startY + Math.floor(i / columns) * (squareSize + spacing + 60); // +60 na etykiety
            
            // Numer koloru (nad kodem HEX)
            var numberLayer = doc.artLayers.add();
            numberLayer.kind = LayerKind.TEXT;
            numberLayer.name = "Numer " + (i + 1);
            
            var numberItem = numberLayer.textItem;
            numberItem.contents = (i + 1).toString();
            numberItem.position = [x, y + squareSize + 5];  // pod kwadratem
            numberItem.size = 14;
            numberItem.justification = Justification.CENTER;
            
            // Ustaw kolor tekstu na czarny
            var blackColor = new SolidColor();
            blackColor.rgb.red = 0;
            blackColor.rgb.green = 0;
            blackColor.rgb.blue = 0;
            numberItem.color = blackColor;
            
            // Kod HEX (pod numerem)
            var hexLayer = doc.artLayers.add();
            hexLayer.kind = LayerKind.TEXT;
            hexLayer.name = "HEX " + (i + 1);
            
            var hexItem = hexLayer.textItem;
            hexItem.contents = hex.toUpperCase();
            hexItem.position = [x, y + squareSize + 20];  // nieco niżej
            hexItem.size = 10;
            hexItem.justification = Justification.CENTER;
            hexItem.color = blackColor;
            
            // RGB (na samym dole)
            var rgbLayer = doc.artLayers.add();
            rgbLayer.kind = LayerKind.TEXT;
            rgbLayer.name = "RGB " + (i + 1);
            
            var rgbItem = rgbLayer.textItem;
            rgbItem.contents = "R:" + r + " G:" + g + " B:" + b;
            rgbItem.position = [x, y + squareSize + 35];  // jeszcze niżej
            rgbItem.size = 8;
            rgbItem.justification = Justification.CENTER;
            rgbItem.color = blackColor;
            
            // Przenieś wszystkie warstwy tekstowe do grupy
            numberLayer.move(layerSet, ElementPlacement.INSIDE);
            hexLayer.move(layerSet, ElementPlacement.INSIDE);
            rgbLayer.move(layerSet, ElementPlacement.INSIDE);
        }
    } catch (e) {
        // Jeśli dodawanie etykiet się nie powiedzie, nie przerywaj całego procesu
        alert("Ostrzeżenie: Nie udało się dodać etykiet tekstowych: " + e.message);
    }
}

function cleanupFile(file) {
    if (file && file.exists) {
        try {
            file.remove();
        } catch (e) {
            // Ignoruj błędy usuwania
        }
    }
}

// Konwersja liczby na hex (pomocnicza funkcja)
function toHex(n) {
    var hex = n.toString(16);
    return hex.length === 1 ? "0" + hex : hex;
}

// --- URUCHOMIENIE ---
main();

``````

### test_simple.jsx - ./app/scripts/test_simple.jsx

``````
// Prosty test JSX
#target photoshop

try {
    alert("Test JSX działa!");
    
    // Test logowania
    var desktop = Folder.desktop;
    var logFile = new File(desktop + "/jsx_test.txt");
    logFile.open("w");
    logFile.writeln("JSX test działa: " + new Date());
    logFile.close();
    
    alert("Log zapisany na pulpicie!");
    
} catch (e) {
    alert("Błąd: " + e.message);
}

``````

### server.py - ./app/server.py

``````
"""
Enhanced Flask Server for GattoNero AI Assistant
================================================

Enhanced infrastructure features:
- Structured development logging with beautiful console output
- Performance profiling with HTML reports
- Health monitoring for algorithms and system resources
- Development dashboard endpoints
- Async processing support (future)

Design Philosophy: "Bezpiecznie = Szybko"
- Comprehensive monitoring prevents surprises
- Beautiful development experience improves productivity
- Performance insights guide optimization
- Health checks catch issues early
"""

import os
import threading
from pathlib import Path
from flask import Flask, jsonify, request

# Import enhanced infrastructure
from app.core.development_logger import get_logger, setup_flask_logging
from app.core.performance_profiler import get_profiler
from app.core.health_monitor_simple import get_simple_health_monitor

# Import existing API routes
from app.api.routes import app as api_blueprint

# Initialize enhanced infrastructure
logger = get_logger("gattonero_server")
profiler = get_profiler(enabled=True)
health_monitor = get_simple_health_monitor()

# Create enhanced Flask app
app = Flask(__name__)

# Setup development logging for Flask
setup_flask_logging(app, logger)

# Register existing API routes Blueprint
app.register_blueprint(api_blueprint)

# Debug endpoint to list all routes
@app.route('/routes')
def list_routes():
    """List all registered routes for debugging."""
    import urllib.parse
    output = []
    for rule in app.url_map.iter_rules():
        methods = ','.join(rule.methods or set())
        output.append(f"{rule.rule} [{methods}]")
    return "<br>".join(sorted(output))

# Simple root endpoint
@app.route('/')
def root():
    """Root endpoint."""
    return jsonify({
        "status": "ok",
        "message": "GattoNero AI Assistant Server",
        "version": "Enhanced Infrastructure",
        "endpoints": {
            "health": "/api/health",
            "performance": "/api/performance/dashboard",
            "routes": "/routes"
        }
    })

# Enhanced infrastructure endpoints
@app.route('/api/health')
def health_endpoint():
    """Health check endpoint for monitoring."""
    with profiler.profile_operation("health_check"):
        health_status = health_monitor.get_health_status()
        
    return jsonify({
        "status": "ok",
        "health": health_status
    })

@app.route('/api/health/quick')
def health_quick_endpoint():
    """Quick health check for load balancers."""
    return jsonify({
        "status": "ok",
        "timestamp": health_monitor.get_health_status()["timestamp"]
    })

@app.route('/api/performance/dashboard')
def performance_dashboard():
    """Performance dashboard data endpoint."""
    with profiler.profile_operation("performance_dashboard"):
        dashboard_data = profiler.get_dashboard_data()
        
    return jsonify(dashboard_data)

@app.route('/api/performance/report')
def performance_report():
    """Generate and return performance report."""
    with profiler.profile_operation("generate_performance_report"):
        report_path = profiler.generate_html_report()
        
    return jsonify({
        "status": "success",
        "report_path": report_path,
        "message": "Performance report generated"
    })

@app.route('/api/performance/stats')
def performance_stats():
    """Get performance statistics."""
    operation = request.args.get('operation')
    stats = profiler.get_statistics(operation)
    
    return jsonify({
        "status": "success",
        "statistics": stats
    })

@app.route('/api/system/info')
def system_info():
    """System information endpoint."""
    import psutil
    import sys
    
    return jsonify({
        "python_version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
        "flask_debug": app.debug,
        "memory_usage_mb": psutil.Process().memory_info().rss / 1024 / 1024,
        "cpu_percent": psutil.Process().cpu_percent(),
        "algorithms_registered": len(health_monitor._algorithm_stats),
        "performance_metrics": len(profiler._metrics)
    })

@app.route('/api/logs/recent')
def recent_logs():
    """Get recent log entries (if available)."""
    # This would need log file parsing in a real implementation
    return jsonify({
        "status": "info",
        "message": "Recent logs endpoint - implementation needed",
        "logs": []
    })

@app.route('/development/dashboard')
def development_dashboard():
    """Development dashboard HTML page."""
    return """
    <!DOCTYPE html>
    <html>
    <head>
        <title>GattoNero Development Dashboard</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }
            .card { background: white; padding: 20px; margin: 10px 0; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
            .status-healthy { color: #27ae60; }
            .status-warning { color: #f39c12; }
            .status-critical { color: #e74c3c; }
            .metric { display: inline-block; margin: 10px 20px; text-align: center; }
            .metric-value { font-size: 2em; font-weight: bold; color: #3498db; }
            .metric-label { color: #7f8c8d; }
            button { background: #3498db; color: white; border: none; padding: 10px 20px; border-radius: 4px; cursor: pointer; margin: 5px; }
            button:hover { background: #2980b9; }
            pre { background: #f8f9fa; padding: 10px; border-radius: 4px; overflow-x: auto; }
        </style>
        <script>
            async function loadData() {
                try {
                    const [healthData, perfData, sysData] = await Promise.all([
                        fetch('/api/health').then(r => r.json()),
                        fetch('/api/performance/dashboard').then(r => r.json()),
                        fetch('/api/system/info').then(r => r.json())
                    ]);
                    
                    updateDashboard(healthData, perfData, sysData);
                } catch (error) {
                    console.error('Failed to load dashboard data:', error);
                }
            }
            
            function updateDashboard(health, perf, sys) {
                // Update health status
                const healthEl = document.getElementById('health-status');
                healthEl.className = `status-${health.health.overall_status}`;
                healthEl.textContent = health.health.overall_status.toUpperCase();
                
                // Update metrics
                document.getElementById('total-ops').textContent = perf.summary.total_operations;
                document.getElementById('active-ops').textContent = perf.summary.active_operations;
                document.getElementById('avg-duration').textContent = perf.summary.avg_duration_ms.toFixed(1) + 'ms';
                document.getElementById('memory-usage').textContent = sys.memory_usage_mb.toFixed(1) + 'MB';
                
                // Update details
                document.getElementById('health-details').textContent = JSON.stringify(health.health.summary, null, 2);
                document.getElementById('perf-details').textContent = JSON.stringify(perf.summary, null, 2);
            }
            
            async function generateReport() {
                try {
                    const response = await fetch('/api/performance/report');
                    const data = await response.json();
                    alert('Report generated: ' + data.report_path);
                } catch (error) {
                    alert('Failed to generate report: ' + error.message);
                }
            }
            
            // Auto-refresh every 5 seconds
            setInterval(loadData, 5000);
            
            // Load initial data
            window.onload = loadData;
        </script>
    </head>
    <body>
        <h1>🚀 GattoNero Development Dashboard</h1>
        
        <div class="card">
            <h2>📊 System Status</h2>
            <div class="metric">
                <div class="metric-value" id="health-status">LOADING</div>
                <div class="metric-label">Health Status</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="total-ops">-</div>
                <div class="metric-label">Total Operations</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="active-ops">-</div>
                <div class="metric-label">Active Operations</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="avg-duration">-</div>
                <div class="metric-label">Avg Duration</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="memory-usage">-</div>
                <div class="metric-label">Memory Usage</div>
            </div>
        </div>
        
        <div class="card">
            <h2>🔧 Actions</h2>
            <button onclick="loadData()">Refresh Data</button>
            <button onclick="generateReport()">Generate Performance Report</button>
            <button onclick="window.open('/api/health', '_blank')">View Health Details</button>
            <button onclick="window.open('/api/performance/dashboard', '_blank')">View Performance Data</button>
        </div>
        
        <div class="card">
            <h2>❤️ Health Details</h2>
            <pre id="health-details">Loading...</pre>
        </div>
        
        <div class="card">
            <h2>⚡ Performance Details</h2>
            <pre id="perf-details">Loading...</pre>
        </div>
        
        <div class="card">
            <h2>📚 Quick Links</h2>
            <ul>
                <li><a href="/api/health">Health Status API</a></li>
                <li><a href="/api/performance/dashboard">Performance Dashboard API</a></li>
                <li><a href="/api/system/info">System Information</a></li>
                <li><a href="/api/performance/stats">Performance Statistics</a></li>
            </ul>
        </div>
    </body>
    </html>
    """

def initialize_server():
    """Initialize the enhanced server with monitoring."""
    logger.info("Initializing Enhanced Flask Server")
    
    # Initial health check
    health_results = health_monitor.run_all_checks()
    critical_issues = [name for name, result in health_results.items() 
                      if result.status.value == "critical"]
    
    if critical_issues:
        logger.warning(f"Critical health issues detected: {critical_issues}")
        for issue in critical_issues:
            logger.error(f"Critical: {health_results[issue].message}")
    else:
        logger.success("All health checks passed")
    
    logger.info("Enhanced Flask Server initialized successfully")

def shutdown_server():
    """Graceful server shutdown."""
    logger.info("Shutting down Enhanced Flask Server")
    
    # Generate final performance report
    try:
        report_path = profiler.generate_html_report("final_session_report.html")
        logger.success(f"Final performance report generated: {report_path}")
    except Exception as e:
        logger.error(f"Failed to generate final report: {str(e)}")
    
    logger.info("Enhanced Flask Server shutdown complete")

# Initialize on module load
initialize_server()

if __name__ == "__main__":
    try:
        logger.info("Starting Enhanced Flask Server in development mode")
        app.run(debug=True, host='0.0.0.0', port=5000, threaded=True)
    except KeyboardInterrupt:
        logger.info("Server interrupted by user")
    finally:
        shutdown_server()

``````

### run_server.py - ./run_server.py

``````
# GattoNeroPhotoshop/run_server.py

import socket
import subprocess
import time
import sys
from app.server import app

def check_port_free(port):
    """Sprawdza czy port jest wolny"""
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        try:
            s.bind(('127.0.0.1', port))
            return True
        except OSError:
            return False

def kill_process_on_port(port):
    """Zabija proces na danym porcie (Windows)"""
    try:
        # Znajdź PID procesu na porcie
        result = subprocess.run(
            f'netstat -ano | findstr :{port}',
            shell=True,
            capture_output=True,
            text=True
        )

        if result.stdout:
            lines = result.stdout.strip().split('\n')
            for line in lines:
                if 'LISTENING' in line:
                    parts = line.split()
                    if len(parts) >= 5:
                        pid = parts[-1]
                        print(f"Zatrzymuje proces PID {pid} na porcie {port}...")
                        subprocess.run(f'taskkill /F /PID {pid}', shell=True, capture_output=True)
                        return True
        return False
    except Exception as e:
        print(f"Blad podczas zabijania procesu: {e}")
        return False

def safe_start_server():
    """Bezpiecznie uruchamia serwer z kontrola portu"""
    port = 5000

    print("Sprawdzam port 5000...")

    if not check_port_free(port):
        print("Port 5000 jest zajety! Probuje zatrzymac istniejacy proces...")

        if kill_process_on_port(port):
            print("Czekam 2 sekundy na zwolnienie portu...")
            time.sleep(2)

            if check_port_free(port):
                print("Port zwolniony!")
            else:
                print("Nie udalo sie zwolnic portu. Sprawdz recznie procesy.")
                sys.exit(1)
        else:
            print("Nie znaleziono procesu do zatrzymania, ale port jest zajety.")
            print("Sprobuj recznie: netstat -ano | findstr :5000")
            sys.exit(1)
    else:
        print("Port 5000 jest wolny!")

    print("Uruchamiam serwer Flask...")
    print("Serwer bedzie dostepny na: http://127.0.0.1:5000")
    print("Aby zatrzymac serwer, nacisnij Ctrl+C")
    print("-" * 50)

    # Uruchamiamy serwer Flask (debug=False zeby uniknac konfliktow z kontrola portu)
    app.run(host='127.0.0.1', port=port, debug=False)

if __name__ == '__main__':
    safe_start_server()
``````

### server_manager_enhanced.py - ./server_manager_enhanced.py

``````
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced Server Manager v2.2.0 - Advanced Flask Server Management for GattoNero AI Assistant

Features:
- Unified watchdog system via 'watch' command
- Configuration-driven setup from 'server_config.json'
- Advanced auto-restart with exponential backoff
- Graceful shutdown with '--force' option
- Structured, TTY-aware logging with log file redirection
- Production-ready deployment capabilities
- Intelligent Python environment detection (VENV vs. SYSTEM)

Usage:
    python server_manager_enhanced.py start [--auto-restart] [--port PORT]
    python server_manager_enhanced.py stop [--force]
    python server_manager_enhanced.py status [--detailed]
    python server_manager_enhanced.py restart [--auto-restart]
    python server_manager_enhanced.py watch [--interval SECONDS]
    python server_manager_enhanced.py logs [--tail LINES] [--file server|manager|errors]
"""

import sys
import os
import json
import time
import subprocess
import requests
import argparse
import threading
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Optional, Any, List

# Próba importu psutil, jeśli jest dostępny
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    psutil = None
    PSUTIL_AVAILABLE = False
    print("[WARNING] psutil is not available. Some advanced features will be disabled. Run 'pip install psutil'")


class ServerConfig:
    """Zarządza konfiguracją serwera z pliku JSON z wartościami domyślnymi."""

    def __init__(self, config_file: str = "server_config.json"):
        self.config_file = Path(config_file)
        self._config = self._load_config()

    def _load_config(self) -> Dict[str, Any]:
        """Ładuje konfigurację z pliku, łącząc ją z domyślnymi wartościami."""
        defaults = {
            "server": {
                "host": "127.0.0.1",
                "port": 5000,
                "environment": "development",
                "startup_command": [sys.executable, "run_server.py"],
                "python_executable": "", # Puste oznacza auto-detekcję
                "startup_timeout": 15,
                "shutdown_timeout": 20,
                "health_check_interval": 5,
                "health_check_url": "/api/health"  # Domyślny endpoint health-check
            },
            "monitoring": {
                "failure_threshold": 3,
                "restart_delay": 5,
                "exponential_backoff": True,
                "max_backoff_delay": 60
            },
            "logging": {
                "log_dir": "logs",
                "server_log_file": "gattonero_server.log",
                "server_error_file": "gattonero_server_errors.log",
                "manager_log_file": "server_manager.log"
            },
            "files": {
                "pid_file": ".server_info.json"
            }
        }

        if self.config_file.exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                return self._deep_merge(defaults, user_config)
            except json.JSONDecodeError as e:
                print(f"[ERROR] Invalid JSON in {self.config_file}: {e}. Using default configuration.")
            except Exception as e:
                print(f"[WARNING] Failed to load {self.config_file}: {e}. Using defaults.")
        else:
             print(f"[INFO] Configuration file '{self.config_file}' not found. Creating with default values.")
             try:
                 with open(self.config_file, 'w', encoding='utf-8') as f:
                     json.dump(defaults, f, indent=4)
             except Exception as e:
                 print(f"[ERROR] Could not create default config file: {e}")

        return defaults

    def _deep_merge(self, base: Dict[str, Any], overlay: Dict[str, Any]) -> Dict[str, Any]:
        """Rekursywnie łączy dwa słowniki."""
        result = base.copy()
        for key, value in overlay.items():
            if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                result[key] = self._deep_merge(result[key], value)
            else:
                result[key] = value
        return result

    def get(self, section: str, key: Optional[str] = None, default=None):
        """Pobiera wartość konfiguracyjną z określonej sekcji."""
        if key is None:
            return self._config.get(section, default)
        return self._config.get(section, {}).get(key, default)

    def get_str(self, section: str, key: str, default: str = "") -> str:
        """Pobiera wartość konfiguracyjną jako string."""
        value = self.get(section, key, default)
        return str(value) if value is not None else default

    def get_int(self, section: str, key: str, default: int = 0) -> int:
        """Pobiera wartość konfiguracyjną jako int."""
        value = self.get(section, key, default)
        try:
            return int(value) if value is not None else default
        except (ValueError, TypeError):
            return default

    def get_list(self, section: str, key: str, default: Optional[List] = None) -> List:
        """Pobiera wartość konfiguracyjną jako listę."""
        if default is None:
            default = []
        value = self.get(section, key, default)
        return list(value) if isinstance(value, list) else default

    def get_bool(self, section: str, key: str, default: bool = False) -> bool:
        """Pobiera wartość konfiguracyjną jako boolean."""
        value = self.get(section, key, default)
        if isinstance(value, bool):
            return value
        if isinstance(value, str):
            return value.lower() in ('true', '1', 'yes', 'on')
        return bool(value) if value is not None else default

    def get_health_check_url(self) -> str:
        """Zwraca endpoint health-check z konfiguracji."""
        return self.get_str('server', 'health_check_url', '/api/health')


class EnhancedServerManager:
    """Zarządza cyklem życia serwera z monitoringiem, logowaniem i konfiguracją."""

    def __init__(self, host: Optional[str] = None, port: Optional[int] = None,
                 environment: Optional[str] = None, config_file: str = "server_config.json"):
        self.config = ServerConfig(config_file)

        self.host = host or self.config.get_str('server', 'host', '127.0.0.1')
        self.port = port or self.config.get_int('server', 'port', 5000)
        self.environment = environment or self.config.get_str('server', 'environment', 'development')
        self.base_url = f'http://{self.host}:{self.port}'
        self.health_check_url = self.config.get_health_check_url()

        self.log_dir = Path(self.config.get_str('logging', 'log_dir', 'logs'))
        self.log_dir.mkdir(exist_ok=True)
        self.pid_file = Path(self.config.get_str('files', 'pid_file', '.server_info.json'))
        self.server_log_file = self.log_dir / self.config.get_str('logging', 'server_log_file', 'gattonero_server.log')
        self.server_error_file = self.log_dir / self.config.get_str('logging', 'server_error_file', 'gattonero_server_errors.log')
        self.manager_log_file = self.log_dir / self.config.get_str('logging', 'manager_log_file', 'server_manager.log')

        self.python_executable = self._detect_python_executable()
        
        default_startup_command = [self.python_executable, "-m", "app.server"]
        self.startup_command = self.config.get_list('server', 'startup_command', default_startup_command)
        if self.startup_command == [sys.executable, "-m", "app.server"]:
             self.startup_command = default_startup_command

        self.startup_timeout = self.config.get_int('server', 'startup_timeout', 15)
        self.shutdown_timeout = self.config.get_int('server', 'shutdown_timeout', 20)
        self.health_check_interval = self.config.get_int('server', 'health_check_interval', 5)
        self.failure_threshold = self.config.get_int('monitoring', 'failure_threshold', 3)
        self.restart_delay = self.config.get_int('monitoring', 'restart_delay', 5)

        self.monitor_thread: Optional[threading.Thread] = None
        self.monitor_running = threading.Event()

    def _detect_python_executable(self) -> str:
        """Wykrywa najlepszy interpreter Pythona (venv jeśli dostępny)."""
        config_python = self.config.get_str('server', 'python_executable', '')
        if config_python and Path(config_python).exists():
            self.log_event(f"Using configured Python executable: {config_python}", "INFO")
            return config_python

        venv_paths = [Path('venv'), Path('.venv'), Path('env'), Path('.env')]
        for venv_path in venv_paths:
            if venv_path.exists() and venv_path.is_dir():
                python_exe = venv_path / 'Scripts' / 'python.exe' if os.name == 'nt' else venv_path / 'bin' / 'python'
                if python_exe.exists():
                    self.log_event(f"Virtual environment detected: {venv_path}", "SUCCESS")
                    self.log_event(f"Using venv Python: {python_exe}", "INFO")
                    return str(python_exe)

        if hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix):
            self.log_event("Already running in an activated virtual environment", "SUCCESS")
            return sys.executable

        self.log_event("No virtual environment detected, using system Python", "WARNING")
        self.log_event("Consider creating a venv: python -m venv venv", "INFO")
        return sys.executable

    def _check_flask_install(self) -> bool:
        """Sprawdza, czy Flask jest zainstalowany w wybranym środowisku."""
        self.log_event(f"Checking for Flask in: {self.python_executable}", "INFO")
        try:
            command = [self.python_executable, "-c", "import flask"]
            result = subprocess.run(command, capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                self.log_event("Flask is installed.", "SUCCESS")
                return True
            else:
                self.log_event("Flask is NOT installed in the selected environment.", "ERROR")
                self.log_event(f"To install, run: '{self.python_executable} -m pip install flask'", "INFO")
                return False
        except Exception as e:
            self.log_event(f"Could not check for Flask installation: {e}", "ERROR")
            return False

    def _verify_environment(self) -> bool:
        """Weryfikuje, czy środowisko Python jest poprawnie skonfigurowane."""
        python_path = Path(self.python_executable)
        if not python_path.exists():
            self.log_event(f"Python executable not found: {self.python_executable}", "ERROR")
            return False

        try:
            result = subprocess.run([self.python_executable, '--version'], capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                self.log_event(f"Python version: {result.stdout.strip()}", "INFO")
        except Exception as e:
            self.log_event(f"Could not get Python version: {e}", "WARNING")

        return self._check_flask_install()

    def log_event(self, event: str, level: str = "INFO"):
        """Loguje zdarzenie do konsoli (z kolorami) i do pliku."""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_entry = {'timestamp': timestamp, 'level': level, 'event': event}
        
        log_message = f"[{timestamp}] [{level}] {event}"
        
        if sys.stdout.isatty():
            colors = {'INFO': '\033[94m', 'SUCCESS': '\033[92m', 'WARNING': '\033[93m', 'ERROR': '\033[91m', 'RESET': '\033[0m'}
            color = colors.get(level, '')
            reset = colors['RESET']
            print(f"{color}{log_message}{reset}")
        else:
            print(log_message)
            
        try:
            with open(self.manager_log_file, 'a', encoding='utf-8') as f:
                f.write(f"{json.dumps(log_entry)}\n")
        except Exception as e:
            print(f"[ERROR] Could not write to manager log file: {e}")

    def save_server_info(self, process_info: Dict[str, Any]):
        """Zapisuje informacje o procesie serwera do pliku."""
        try:
            with open(self.pid_file, 'w') as f:
                json.dump(process_info, f, indent=4)
        except Exception as e:
            self.log_event(f"Failed to save server info: {e}", "ERROR")

    def load_server_info(self) -> Optional[Dict[str, Any]]:
        """Wczytuje informacje o procesie serwera z pliku."""
        if not self.pid_file.exists():
            return None
        try:
            with open(self.pid_file, 'r') as f:
                return json.load(f)
        except (json.JSONDecodeError, FileNotFoundError):
            return None

    def clear_server_info(self):
        """Usuwa plik z informacjami o serwerze."""
        try:
            self.pid_file.unlink(missing_ok=True)
        except Exception:
            pass

    def is_process_running(self, pid: int) -> bool:
        """Sprawdza, czy proces o danym PID działa."""
        if not PSUTIL_AVAILABLE or psutil is None: return False
        try:
            return psutil.pid_exists(pid)
        except Exception:
            return False

    def is_port_in_use(self, port: int) -> bool:
        """Sprawdza, czy port jest w użyciu."""
        if not PSUTIL_AVAILABLE or psutil is None: return False
        try:
            for conn in psutil.net_connections():
                if conn.laddr and conn.laddr.port == port and conn.status == 'LISTEN':
                    return True
        except Exception:
            pass
        return False

    def is_server_responding(self) -> bool:
        """Sprawdza, czy serwer odpowiada na żądania HTTP."""
        try:
            url = f'{self.base_url}{self.health_check_url}'
            response = requests.get(url, timeout=2)
            return response.status_code == 200
        except requests.RequestException:
            return False
            
    def get_process_info(self, pid: int) -> Dict[str, Any]:
        """Pobiera szczegółowe informacje o procesie."""
        if not PSUTIL_AVAILABLE or psutil is None or not self.is_process_running(pid):
            return {'status': 'not_found'}
        try:
            process = psutil.Process(pid)
            with process.oneshot():
                return {
                    'pid': pid,
                    'status': process.status(),
                    'cpu_percent': process.cpu_percent(interval=0.1),
                    'memory_mb': round(process.memory_info().rss / 1024**2, 2),
                    'uptime_seconds': time.time() - process.create_time()
                }
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            return {'status': 'error'}


    def is_running(self) -> bool:
        """Sprawdza, czy serwer działa i odpowiada."""
        info = self.load_server_info()
        if not info: return False
        pid = info.get('pid')
        if not pid: return False
        return self.is_process_running(pid) and self.is_server_responding()

    def start_server(self, auto_restart: bool = False, no_wait: bool = False) -> bool:
        """Uruchamia proces serwera i opcjonalnie watchdog."""
        if self.is_running():
            self.log_event("Server is already running.", "WARNING")
            return True

        if not self._verify_environment():
            self.log_event("Python environment verification failed. Cannot start server.", "ERROR")
            return False

        if self.is_port_in_use(self.port):
            self.log_event(f"Port {self.port} is already in use. Cannot start server.", "ERROR")
            return False

        self.log_event(f"Starting server... Command: {' '.join(self.startup_command)}")
        env = os.environ.copy()
        env['FLASK_ENV'] = self.environment

        # --- FIX: Define OS-specific arguments to detach the process ---
        kwargs = {}
        if os.name == 'nt':
            # On Windows, DETACHED_PROCESS creates a new process
            # without a console and independent of the parent.
            kwargs['creationflags'] = subprocess.DETACHED_PROCESS
        else:
            # On Unix, os.setsid makes the process a session leader,
            # detaching it from the controlling terminal.
            kwargs['preexec_fn'] = os.setsid
        # --- END FIX ---

        try:
            with open(self.server_log_file, 'ab') as log_out, open(self.server_error_file, 'ab') as log_err:
                # Add the kwargs to the Popen call
                process = subprocess.Popen(
                    self.startup_command, 
                    stdout=log_out, 
                    stderr=log_err, 
                    env=env,
                    **kwargs
                )

            self.save_server_info({'pid': process.pid, 'port': self.port, 'started_at': time.time()})

            if no_wait:
                self.log_event("Server starting in background. Check status or logs to confirm.", "INFO")
                # A brief pause to allow the process to initialize or fail.
                time.sleep(1.5)
                # Quick check if process died instantly
                if not self.is_process_running(process.pid):
                    self.log_event("Server process terminated immediately after start. Check error logs.", "ERROR")
                    self.log_event(f"Review logs: python server_manager_enhanced.py logs --file errors", "INFO")
                    self.clear_server_info() # Clear info if process died
                    return False
                if auto_restart:
                    self.start_watchdog()
                return True

            self.log_event(f"Waiting for server to respond (PID: {process.pid})...")
            for _ in range(self.startup_timeout):
                if self.is_server_responding():
                    self.log_event("Server started successfully.", "SUCCESS")
                    if auto_restart:
                        self.start_watchdog()
                    return True
                time.sleep(1)

            self.log_event("Server failed to start within timeout.", "ERROR")
            # Attempt to stop the failed process before returning
            current_pid_info = self.load_server_info()
            if current_pid_info and current_pid_info.get('pid') == process.pid:
                self.stop_server(force=True) # This will also clear_server_info
            else: # If PID info was overwritten or process never registered properly
                try:
                    if PSUTIL_AVAILABLE and psutil and psutil.pid_exists(process.pid):
                        psutil.Process(process.pid).kill()
                except Exception: # psutil.NoSuchProcess or other errors
                    pass # Process might already be gone
                self.clear_server_info() # Ensure info is cleared if stop_server wasn't effective for this PID
            return False
        except Exception as e:
            self.log_event(f"Failed to start server: {e}", "ERROR")
            # Ensure server info is cleared on any exception during startup
            self.clear_server_info()
            return False

    def stop_server(self, force: bool = False) -> bool:
        """Zatrzymuje serwer, z opcją wymuszenia."""
        self.stop_watchdog()
        info = self.load_server_info()
        if not info or not self.is_process_running(info.get('pid', -1)):
            self.log_event("Server is not running.", "INFO")
            self.clear_server_info()
            return True

        pid = info['pid']
        self.log_event(f"Stopping server (PID: {pid})...")

        if not force and PSUTIL_AVAILABLE and psutil:
            try:
                proc = psutil.Process(pid)
                # Na Windows SIGTERM to to samo co terminate()
                proc.terminate()
                self.log_event("Sent termination signal. Waiting for process to exit.", "INFO")
                proc.wait(timeout=self.shutdown_timeout)
                self.log_event("Server shut down gracefully.", "SUCCESS")
                self.clear_server_info()
                return True
            except psutil.TimeoutExpired:
                 self.log_event("Graceful shutdown timed out. Forcing termination.", "WARNING")
            except psutil.NoSuchProcess:
                self.log_event("Process already stopped.", "SUCCESS")
                self.clear_server_info()
                return True
            except Exception as e:
                self.log_event(f"Error during graceful shutdown: {e}. Forcing termination.", "WARNING")

        # Force termination
        if PSUTIL_AVAILABLE and psutil:
            try:
                proc = psutil.Process(pid)
                proc.kill()
                proc.wait(timeout=5)
            except psutil.NoSuchProcess:
                pass # Already gone
            except Exception as e:
                self.log_event(f"Error during force kill: {e}", "ERROR")
        else: # Fallback dla systemów bez psutil
            try:
                os.kill(pid, 9) # SIGKILL
            except ProcessLookupError:
                pass # Already gone
            except Exception as e:
                self.log_event(f"Error during fallback kill: {e}", "ERROR")


        time.sleep(1) # Give OS a moment to update process table
        if not self.is_process_running(pid):
            self.log_event("Server stopped forcefully.", "SUCCESS")
            self.clear_server_info()
            return True
        else:
            self.log_event("Failed to stop the server.", "ERROR")
            return False


    def restart_server(self, auto_restart: bool = False) -> bool:
        """Restartuje serwer."""
        self.log_event("Restarting server...")
        if self.stop_server():
            time.sleep(2) # Czas na zwolnienie portu
            return self.start_server(auto_restart)
        self.log_event("Failed to stop the server, restart aborted.", "ERROR")
        return False

    def run_tests(self) -> bool:
        """Uruchom testy podstawowe."""
        if not self.is_running():
            self.log_event("Server not running. Cannot run tests.", "ERROR")
            return False
        
        self.log_event("Running tests...", "INFO")
        try:
            result = subprocess.run([sys.executable, 'test_algorithm_integration.py'], 
                                  capture_output=True, text=True, cwd=os.getcwd())
            
            # Log the output
            if result.stdout:
                for line in result.stdout.strip().split('\n'):
                    print(line)
            
            if result.stderr:
                self.log_event("STDERR output:", "WARNING")
                for line in result.stderr.strip().split('\n'):
                    self.log_event(line, "WARNING")
            
            if result.returncode == 0:
                self.log_event("Tests completed successfully.", "SUCCESS")
                return True
            else:
                self.log_event(f"Tests failed with return code: {result.returncode}", "ERROR")
                return False
                
        except Exception as e:
            self.log_event(f"Failed to run tests: {e}", "ERROR")
            return False

    def show_status(self, detailed: bool = False):
        """Wyświetla aktualny status serwera."""
        print("─" * 40)
        print("🖥️  Server Status")
        print("─" * 40)
        info = self.load_server_info()

        if not info or not self.is_process_running(info.get('pid', -1)):
            self.log_event("Server is NOT RUNNING.", "WARNING")
            self.clear_server_info()
            return

        pid = info['pid']
        is_responding = self.is_server_responding()
        status_color = "SUCCESS" if is_responding else "ERROR"
        
        self.log_event(f"Server process is RUNNING (PID: {pid}).", "SUCCESS")
        self.log_event(f"Server HTTP endpoint is {'RESPONDING' if is_responding else 'NOT RESPONDING'}.", status_color)
        
        if detailed and PSUTIL_AVAILABLE and psutil:
            proc_info = self.get_process_info(pid)
            if proc_info.get('status') != 'not_found':
                uptime = timedelta(seconds=int(proc_info.get('uptime_seconds', 0)))
                print(f"  PID          : {proc_info.get('pid')}")
                print(f"  Uptime       : {uptime}")
                print(f"  Memory       : {proc_info.get('memory_mb', 'N/A')} MB")
                print(f"  CPU          : {proc_info.get('cpu_percent', 'N/A')} %")
        print("─" * 40)

    def start_watchdog(self):
        """Uruchamia wątek watchdog do monitorowania serwera."""
        if self.monitor_running.is_set():
            self.log_event("Watchdog is already running.", "INFO")
            return
        self.log_event("Starting watchdog monitor...", "INFO")
        self.monitor_running.set()
        self.monitor_thread = threading.Thread(target=self._watchdog_loop, daemon=True)
        self.monitor_thread.start()

    def stop_watchdog(self):
        """Zatrzymuje wątek watchdog."""
        if self.monitor_running.is_set():
            self.log_event("Stopping watchdog monitor...", "INFO")
            self.monitor_running.clear()
            if self.monitor_thread and self.monitor_thread.is_alive():
                self.monitor_thread.join(timeout=3)

    def _watchdog_loop(self):
        """Główna pętla wątku watchdog."""
        failures = 0
        while self.monitor_running.is_set():
            if not self.is_server_responding():
                failures += 1
                self.log_event(f"Watchdog: Server health check failed ({failures}/{self.failure_threshold}).", "WARNING")
                if failures >= self.failure_threshold:
                    self.log_event("Watchdog: Failure threshold reached. Attempting to restart server.", "ERROR")
                    if self.restart_server(auto_restart=True):
                        failures = 0
                    time.sleep(self.restart_delay)
            else:
                if failures > 0:
                    self.log_event("Watchdog: Server has recovered.", "SUCCESS")
                failures = 0
            
            self.monitor_running.wait(self.health_check_interval)

    def watch_server_foreground(self, interval: int):
        """Uruchamia dashboard monitorujący na pierwszym planie."""
        self.log_event(f"Starting foreground watch (interval: {interval}s). Press Ctrl+C to stop.", "INFO")
        try:
            while True:
                if sys.stdout.isatty():
                    os.system('cls' if os.name == 'nt' else 'clear')
                self.show_status(detailed=True)
                time.sleep(interval)
        except KeyboardInterrupt:
            print()
            self.log_event("Foreground watch stopped by user.", "INFO")

    def show_logs(self, tail_lines: int, log_type: str):
        """Pokazuje ostatnie N linii określonego pliku logów."""
        log_files = {'manager': self.manager_log_file, 'server': self.server_log_file, 'errors': self.server_error_file}
        log_file = log_files.get(log_type, self.manager_log_file)
        
        print(f"📋 Displaying last {tail_lines} lines of '{log_file.name}'")
        print("─" * 40)
        
        if not log_file.exists():
            self.log_event(f"Log file not found: {log_file}", "WARNING")
            return
        try:
            with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
            for line in lines[-tail_lines:]:
                print(line.strip())
        except Exception as e:
            self.log_event(f"Error reading log file: {e}", "ERROR")


def create_parser() -> argparse.ArgumentParser:
    """Tworzy parser argumentów linii poleceń."""
    help_epilog = """
-------------------------------------------------
 GattoNero AI - Przewodnik Szybkiego Startu
-------------------------------------------------
1. Uruchom serwer w tle:
   python server_manager_enhanced.py start

2. Sprawdź, czy działa:
   python server_manager_enhanced.py status
   
3. Uruchom testy lub pracuj z API/Photoshopem:
   python test_basic.py
   
4. Zatrzymaj serwer po pracy:
   python server_manager_enhanced.py stop
-------------------------------------------------
Użyj `[komenda] --help` aby zobaczyć opcje dla konkretnej komendy.
"""

    parser = argparse.ArgumentParser(
        description=__doc__,
        formatter_class=argparse.RawTextHelpFormatter,
        epilog=help_epilog
    )
    subparsers = parser.add_subparsers(dest='command', help='Dostępne komendy')
    subparsers.required = False
    subparsers.default = 'help'

    help_parser = subparsers.add_parser('help', help='Wyświetla tę wiadomość pomocy.')

    start = subparsers.add_parser('start', help='Uruchamia serwer w tle.')
    start.add_argument('--auto-restart', action='store_true', help='Włącza watchdog do auto-restartu przy awarii.')
    start.add_argument('--port', type=int, help='Nadpisuje port serwera z configa.')
    start.add_argument('--no-wait', action='store_true', help='Nie czeka na health-check, zwraca od razu.')

    stop = subparsers.add_parser('stop', help='Zatrzymuje serwer.')
    stop.add_argument('--force', action='store_true', help='Wymusza natychmiastowe zatrzymanie.')

    restart = subparsers.add_parser('restart', help='Restartuje serwer.')
    restart.add_argument('--auto-restart', action='store_true', help='Włącza watchdog po restarcie.')

    status = subparsers.add_parser('status', help='Pokazuje status serwera.')
    status.add_argument('--detailed', action='store_true', help='Pokazuje szczegółowe informacje o procesie.')

    watch = subparsers.add_parser('watch', help='Monitoruje serwer na żywo.')
    watch.add_argument('--interval', type=int, default=5, help='Interwał sprawdzania w sekundach.')
    
    logs = subparsers.add_parser('logs', help='Wyświetla ostatnie logi.')
    logs.add_argument('--tail', type=int, default=20, help='Liczba linii do wyświetlenia.')
    logs.add_argument('--file', choices=['manager', 'server', 'errors'], default='server', help='Który plik logu pokazać.')
    
    return parser


def main():
    """Główna funkcja wykonawcza."""
    parser = create_parser()
    args = parser.parse_args()

    # Jeśli komenda to 'help' lub nie podano żadnej, wyświetl pomoc i wyjdź
    if args.command == 'help':
        parser.print_help()
        sys.exit(0)

    manager = EnhancedServerManager(port=getattr(args, 'port', None))

    try:
        if args.command == 'start':
            sys.exit(0 if manager.start_server(auto_restart=args.auto_restart, no_wait=getattr(args, 'no_wait', False)) else 1)
        elif args.command == 'stop':
            sys.exit(0 if manager.stop_server(force=args.force) else 1)
        elif args.command == 'restart':
            sys.exit(0 if manager.restart_server(auto_restart=args.auto_restart) else 1)
        elif args.command == 'status':
            manager.show_status(detailed=args.detailed)
        elif args.command == 'watch':
            manager.watch_server_foreground(args.interval)
        elif args.command == 'logs':
            manager.show_logs(args.tail, args.file)
        else:
            parser.print_help()
    except KeyboardInterrupt:
        print()
        manager.log_event("Operation interrupted by user.", "INFO")
        manager.stop_watchdog()
        sys.exit(1)
    except Exception as e:
        manager.log_event(f"An unexpected error occurred: {e}", "ERROR")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()

``````

### server_manager_enhanced_fixed.py - ./server_manager_enhanced_fixed.py

``````

``````

### test_algorithm_integration.py - ./test_algorithm_integration.py

``````
#!/usr/bin/env python3
"""
Algorithm Integration Test
==========================

Test integration of new modular algorithm system with the Enhanced Flask server.
Verifies that:
1. New algorithm_01_palette works correctly 
2. API routing functions properly
3. Performance monitoring is active
4. Legacy algorithms (2,3) still work
5. Results are generated correctly
"""

import requests
import time
import os
import sys

# Server configuration
SERVER_URL = "http://127.0.0.1:5000"
API_URL = f"{SERVER_URL}/api/colormatch"

def test_algorithm_integration():
    """Test integration of new modular algorithm system."""
    print("🔬 ALGORITHM INTEGRATION TEST")
    print("=" * 50)
    
    # Check if server is running
    try:
        response = requests.get(f"{SERVER_URL}/api/health", timeout=5)
        if response.status_code != 200:
            print("❌ Server not running. Start server first!")
            return False
    except:
        print("❌ Server not responding. Start server first!")
        return False
    
    print("✅ Server is running")
    
    # Test files
    master_file = "test_image.png"
    target_file = "test_simple.tif"
    
    if not os.path.exists(master_file) or not os.path.exists(target_file):
        print(f"❌ Test files not found: {master_file}, {target_file}")
        return False
    
    print(f"✅ Test files found: {master_file}, {target_file}")
    
    # Test each method
    methods = [
        ("1", "Enhanced Palette Mapping (New Modular)", True),
        ("2", "Statistical Transfer (Legacy)", False),
        ("3", "Histogram Matching (Legacy)", False)
    ]
    
    results = []
    
    for method, description, is_new in methods:
        print(f"\n🧪 Testing Method {method}: {description}")
        print("-" * 60)
        
        # Prepare request
        files = {
            'master_image': open(master_file, 'rb'),
            'target_image': open(target_file, 'rb')
        }
        data = {
            'method': method,
            'k': 8
        }
        
        # Send request and measure time
        start_time = time.time()
        try:
            response = requests.post(API_URL, files=files, data=data, timeout=30)
            end_time = time.time()
            duration = end_time - start_time
            
            # Close files
            files['master_image'].close()
            files['target_image'].close()
            
            if response.status_code == 200:
                result_text = response.text.strip()
                
                if result_text.startswith("success"):
                    parts = result_text.split(",")
                    result_filename = parts[2] if len(parts) >= 3 else "unknown"
                    
                    # Check if result file exists
                    result_path = f"results/{result_filename}"
                    file_exists = os.path.exists(result_path)
                    
                    status = "✅ PASS" if file_exists else "⚠️ PARTIAL"
                    print(f"   Status: {status}")
                    print(f"   Duration: {duration:.2f}s")
                    print(f"   Result: {result_filename}")
                    print(f"   File exists: {'Yes' if file_exists else 'No'}")
                    
                    if is_new:
                        print(f"   🆕 Using NEW modular algorithm!")
                    else:
                        print(f"   📦 Using legacy algorithm")
                    
                    results.append({
                        'method': method,
                        'status': 'PASS' if file_exists else 'PARTIAL',
                        'duration': duration,
                        'description': description,
                        'is_new': is_new
                    })
                else:
                    print(f"   ❌ FAIL: {result_text}")
                    results.append({
                        'method': method,
                        'status': 'FAIL',
                        'duration': duration,
                        'description': description,
                        'is_new': is_new,
                        'error': result_text
                    })
            else:
                print(f"   ❌ HTTP Error: {response.status_code}")
                results.append({
                    'method': method,
                    'status': 'HTTP_ERROR',
                    'duration': duration,
                    'description': description,
                    'is_new': is_new
                })
                
        except Exception as e:
            print(f"   ❌ Exception: {str(e)}")
            results.append({
                'method': method,
                'status': 'EXCEPTION',
                'description': description,
                'is_new': is_new,
                'error': str(e)
            })
    
    # Print summary
    print("\n" + "=" * 50)
    print("📊 INTEGRATION TEST SUMMARY")
    print("=" * 50)
    
    passed = 0
    total = len(results)
    
    for result in results:
        status_icon = {
            'PASS': '✅',
            'PARTIAL': '⚠️',
            'FAIL': '❌',
            'HTTP_ERROR': '🔥',
            'EXCEPTION': '💥'
        }.get(result['status'], '❓')
        
        new_indicator = '🆕' if result['is_new'] else '📦'
        duration_str = f"{result.get('duration', 0):.2f}s" if 'duration' in result else 'N/A'
        
        print(f"Method {result['method']}: {status_icon} {result['status']} ({duration_str}) {new_indicator}")
        
        if result['status'] == 'PASS':
            passed += 1
    
    print(f"\nResult: {passed}/{total} methods working")
    
    if passed == total:
        print("🎉 ALL TESTS PASSED! Algorithm integration successful!")
        return True
    elif passed > 0:
        print("⚠️ PARTIAL SUCCESS: Some algorithms working")
        return True
    else:
        print("❌ ALL TESTS FAILED! Check server and algorithm setup")
        return False

if __name__ == "__main__":
    success = test_algorithm_integration()
    sys.exit(0 if success else 1)

``````

### test_basic.py - ./test_basic.py

``````
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
POZIOM 1: Podstawowy test trzech metod color matching
Cel: <5 sekund na 1MP, wszystkie metody działają bez błędów
"""

import time
import os
import requests
import shutil
from pathlib import Path
from PIL import Image # Added for dummy image creation

# Konfiguracja
SERVER_URL = "http://127.0.0.1:5000"
TEST_IMAGES_DIR = "test_images"
RESULTS_DIR = "test_results"

def setup_test_environment():
    """Prepare the test environment."""
    # Create directories if they don't exist
    Path(RESULTS_DIR).mkdir(exist_ok=True)
    
    # Create dummy test images if they don't exist
    dummy_image_path_png = "test_image.png"
    dummy_image_path_tif = "test_simple.tif"

    if not os.path.exists(dummy_image_path_png):
        img = Image.new('RGB', (100, 100), color = 'red')
        img.save(dummy_image_path_png)
        print(f"[INFO] Created dummy image: {dummy_image_path_png}")

    if not os.path.exists(dummy_image_path_tif):
        img = Image.new('RGB', (100, 100), color = 'blue')
        img.save(dummy_image_path_tif)
        print(f"[INFO] Created dummy image: {dummy_image_path_tif}")
    
    return [dummy_image_path_png, dummy_image_path_tif]

def test_method(method_num, master_path, target_path, k_colors=16, distance_metric=None, use_dithering=False, preserve_luminance=False, is_preview=False):
    """Test pojedynczej metody"""
    print(f"\n[TEST] Testing Method {method_num}...")
    
    start_time = time.time()
    
    try:
        # Prepare files
        files = {
            'master_image': open(master_path, 'rb'),
            'target_image': open(target_path, 'rb')
        }
        
        data = {
            'method': str(method_num),
            'k': k_colors,
            'use_dithering': str(use_dithering).lower(),
            'preserve_luminance': str(preserve_luminance).lower()
        }
        if distance_metric:
            data['distance_metric'] = distance_metric

        url = f"{SERVER_URL}/api/colormatch"
        if is_preview:
            url = f"{SERVER_URL}/api/colormatch/preview"
            
        # Send request
        response = requests.post(url, files=files, data=data)
            
        end_time = time.time()
        execution_time = end_time - start_time
        
        # Close file handles
        files['master_image'].close()
        files['target_image'].close()

        # Check response
        if response.status_code == 200:
            result = response.text.strip()
            if result.startswith("success"):
                parts = result.split(",")
                if len(parts) >= 3:
                    result_filename = parts[2]
                    print(f"[PASS] Method {method_num}: SUCCESS")
                    print(f"   Time: {execution_time:.2f}s")
                    print(f"   Result: {result_filename}")
                    return True, execution_time
                else:
                    print(f"[FAIL] Method {method_num}: Invalid response format")
            else:
                print(f"[FAIL] Method {method_num}: {result}")
        else:
            print(f"[FAIL] Method {method_num}: HTTP {response.status_code} - {response.text}")
            
    except requests.exceptions.ConnectionError:
        print(f"[FAIL] Method {method_num}: Cannot connect to server")
        print("   Ensure the server is running: python run_server.py")
    except Exception as e:
        print(f"[FAIL] Method {method_num}: Error - {str(e)}")
    
    return False, 0

def check_server():
    """Check if the server is running"""
    import socket
    try:
        # Check if port is open
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(2)
        result = sock.connect_ex(('127.0.0.1', 5000))
        sock.close()
        
        if result == 0:
            print("[OK] Port 5000 is open")
            return True
        else:
            print(f"[ERROR] Port 5000 is not responding (code: {result})")
            return False
    except Exception as e:
        print(f"[ERROR] Error checking port: {e}")
        return False

def main():
    """Main test function"""
    print("LEVEL 1: Basic Color Matching Methods Test")
    print("=" * 50)
    
    # Check server
    if not check_server():
        print("[ERROR] Server is not running!")
        print("Start the server: python run_server.py")
        return

    print("[OK] Server is running")
    
    # Prepare environment
    test_files = setup_test_environment()
    if not test_files:
        return

    master_file, target_file = test_files
    print(f"[INFO] Master: {master_file}")
    print(f"[INFO] Target: {target_file}")
    
    # Test all methods
    methods_to_test = [
        (1, "Simple Palette Mapping (RGB K-means)", {}, False),
        (2, "Basic Statistical Transfer (LAB)", {}, False),
        (3, "Simple Histogram Matching (Luminance)", {}, False),
        (1, "Palette Mapping (LAB, Dithering, Preserve Luminance)", {'distance_metric': 'lab', 'use_dithering': True, 'preserve_luminance': True}, False),
        (1, "Palette Mapping Preview (LAB, Dithering)", {'distance_metric': 'lab', 'use_dithering': True}, True)
    ]
    
    results = []
    total_time = 0
    
    for method_num, method_name, params, is_preview in methods_to_test:
        print(f"\n[INFO] {method_name}")
        success, exec_time = test_method(method_num, master_file, target_file, **params, is_preview=is_preview)
        results.append((method_num, method_name, success, exec_time))
        total_time += exec_time

    # Summary
    print("\n" + "=" * 50)
    print("TEST SUMMARY")
    print("=" * 50)

    successful_methods = 0
    for method_num, method_name, success, exec_time in results:
        status = "[PASS]" if success else "[FAIL]"
        time_status = "[FAST]" if exec_time < 5.0 else "[SLOW]"
        print(f"Method {method_num}: {method_name}: {status} ({exec_time:.2f}s) {time_status}")
        if success:
            successful_methods += 1
    
    print(f"\nTotal time: {total_time:.2f}s")
    print(f"Success: {successful_methods}/{len(methods_to_test)} methods")
    
    # Success criteria
    if successful_methods == len(methods_to_test):
        print("\n[SUCCESS] LEVEL 1: PASSED!")
        print("All methods work without errors")
        if total_time < 25.0:  # Adjusted total time for more tests
            print("[BONUS] Performance within limits!")
    else:
        print("\n[FAILED] LEVEL 1: FAILED")
        print("Not all methods work correctly")

if __name__ == "__main__":
    main()

``````

### test_curl.py - ./test_curl.py

``````
#!/usr/bin/env python3
# Prosty test curl dla color matching

import os
import subprocess
import sys

def test_curl():
    """Test curl command line dla color matching endpoint"""
    
    # Sprawdź czy są obrazy do testów
    source_folder = "source"
    if not os.path.exists(source_folder):
        print(f"❌ Brak folderu: {source_folder}")
        return
    
    # Znajdź obrazy
    image_files = []
    for ext in ['.jpg', '.jpeg', '.png', '.tif', '.tiff']:
        image_files.extend([f for f in os.listdir(source_folder) if f.lower().endswith(ext)])
    
    if len(image_files) < 2:
        print(f"❌ Potrzeba przynajmniej 2 obrazów w folderze {source_folder}")
        return
    
    master_path = os.path.join(source_folder, image_files[0])
    target_path = os.path.join(source_folder, image_files[1])
    
    print(f"🚀 CURL TEST")
    print(f"Master: {master_path}")
    print(f"Target: {target_path}")
    print("-" * 40)
    
    # Stwórz curl command
    curl_cmd = [
        'curl', '-s', '-X', 'POST',
        '-F', f'master_image=@{master_path}',
        '-F', f'target_image=@{target_path}',
        '-F', 'method=1',
        '-F', 'k=6',
        'http://127.0.0.1:5000/api/colormatch'
    ]
    
    try:
        print("📡 Wysyłam request...")
        result = subprocess.run(curl_cmd, capture_output=True, text=True, timeout=60)
        
        print(f"Return code: {result.returncode}")
        print(f"Response: {result.stdout}")
        
        if result.stderr:
            print(f"Error: {result.stderr}")
            
        # Parsuj odpowiedź
        if result.returncode == 0 and result.stdout:
            parts = result.stdout.strip().split(',')
            if len(parts) >= 3 and parts[0] == 'success':
                print(f"✅ SUCCESS!")
                print(f"Method: {parts[1]}")
                print(f"Result: {parts[2]}")
                
                # Sprawdź czy plik wynikowy istnieje
                result_path = f"results/{parts[2]}"
                if os.path.exists(result_path):
                    size_mb = os.path.getsize(result_path) / (1024*1024)
                    print(f"✅ File created: {result_path} ({size_mb:.1f}MB)")
                else:
                    print(f"❌ File not found: {result_path}")
            else:
                print(f"❌ Invalid response format")
        
    except subprocess.TimeoutExpired:
        print("❌ Request timeout (60s)")
    except FileNotFoundError:
        print("❌ curl command not found. Install curl.")
    except Exception as e:
        print(f"❌ Error: {e}")

if __name__ == "__main__":
    test_curl()

``````

### test_runner.py - ./test_runner.py

``````
#!/usr/bin/env python3
"""
Test Runner - Automatyczne uruchamianie testów z zarządzaniem serwerem

Użycie:
    python test_runner.py              # Uruchom wszystkie testy
    python test_runner.py --auto-start # Automatycznie uruchom serwer jeśli nie działa
    python test_runner.py --stop-after # Zatrzymaj serwer po testach
"""

import sys
import argparse
import time
from server_manager_enhanced import EnhancedServerManager

def run_tests_with_management(auto_start=False, stop_after=False):
    """Uruchom testy z zarządzaniem serwerem"""
    manager = EnhancedServerManager()
    server_was_running = manager.is_running()
    
    print("=== Test Runner ===")
    print(f"Auto-start: {auto_start}")
    print(f"Stop after: {stop_after}")
    print()
    
    # Sprawdź status serwera
    if server_was_running:
        print("[INFO] Serwer już działa")
    else:
        print("[INFO] Serwer nie działa")
        if auto_start:
            print("[INFO] Uruchamiam serwer automatycznie...")
            if not manager.start_server():
                print("[ERROR] Nie udało się uruchomić serwera")
                return False
        else:
            print("[ERROR] Serwer nie działa. Użyj --auto-start lub uruchom serwer ręcznie.")
            print("[INFO] Komenda: python server_manager.py start")
            return False
    
    print()
    
    # Uruchom testy
    print("=== Uruchamiam testy ===")
    success = manager.run_tests()
    
    # Zatrzymaj serwer jeśli trzeba
    if stop_after and (auto_start or not server_was_running):
        print("\n=== Zatrzymuję serwer ===")
        manager.stop_server()
    
    return success

def main():
    parser = argparse.ArgumentParser(description='Test Runner z zarządzaniem serwerem')
    parser.add_argument('--auto-start', action='store_true', 
                       help='Automatycznie uruchom serwer jeśli nie działa')
    parser.add_argument('--stop-after', action='store_true',
                       help='Zatrzymaj serwer po testach')
    
    args = parser.parse_args()
    
    success = run_tests_with_management(
        auto_start=args.auto_start,
        stop_after=args.stop_after
    )
    
    sys.exit(0 if success else 1)

if __name__ == '__main__':
    main()
``````

### test_speed.py - ./test_speed.py

``````
#!/usr/bin/env python3
# Test script dla color matching endpoint

import requests
import os
import sys
import time

# Dodaj ścieżkę do modułu app
sys.path.append('.')

from app.processing.color_matching import simple_palette_mapping

def test_speed():
    """Test speed z obrazami z folderu source"""
    
    # Sprawdź folder source
    source_folder = "source"
    if not os.path.exists(source_folder):
        print(f"❌ Brak folderu: {source_folder}")
        return
    
    # Znajdź obrazy w folderze source
    image_files = []
    for ext in ['.jpg', '.jpeg', '.png', '.tif', '.tiff']:
        image_files.extend([f for f in os.listdir(source_folder) if f.lower().endswith(ext)])
    
    if len(image_files) < 2:
        print(f"❌ Potrzeba przynajmniej 2 obrazów w folderze {source_folder}")
        print(f"   Znalezione: {image_files}")
        return
    
    # Wybierz pierwsze 2 obrazy
    master_path = os.path.join(source_folder, image_files[0])
    target_path = os.path.join(source_folder, image_files[1])
    
    print(f"🚀 SPEED TEST - METHOD 1 OPTIMIZED")
    print(f"Master: {master_path}")
    print(f"Target: {target_path}")
    print(f"Colors: 8")
    print("-" * 50)
    
    try:
        # Test nowej optimized version
        start_time = time.time()
        result_path = simple_palette_mapping(master_path, target_path, k_colors=8)
        total_time = time.time() - start_time
        
        print("-" * 50)
        print(f"🎯 FINAL RESULT:")
        print(f"   Total time: {total_time:.2f}s")
        print(f"   Result file: {result_path}")
        
        if os.path.exists(result_path):
            file_size = os.path.getsize(result_path) / (1024*1024)  # MB
            print(f"   File size: {file_size:.1f}MB")
            print("✅ SUCCESS! File created.")
        else:
            print("❌ File not created!")
            
    except Exception as e:
        print(f"❌ ERROR: {e}")

if __name__ == "__main__":
    test_speed()

``````

### __init__.py - ./tests/__init__.py

``````
# This file makes the 'tests' directory a package for unittest discovery.

``````

### base_test_case.py - ./tests/base_test_case.py

``````
import unittest
import tempfile
import shutil
import numpy as np
import cv2
import os

class BaseAlgorithmTestCase(unittest.TestCase):
    """
    Uniwersalna klasa bazowa dla wszystkich testów algorytmów.
    Automatycznie zarządza tworzeniem i czyszczeniem tymczasowego
    folderu na pliki testowe.
    """
    def setUp(self):
        """Metoda wywoływana przed każdym testem w klasie."""
        # Stwórz unikalny, tymczasowy folder dla tego zestawu testów
        self.test_dir = tempfile.mkdtemp()
        print(f"\n[TEST ENV] Stworzono folder tymczasowy: {self.test_dir}")

    def tearDown(self):
        """Metoda wywoływana po każdym teście w klasie."""
        # Usuń cały folder tymczasowy wraz z zawartością
        shutil.rmtree(self.test_dir)
        print(f"[TEST ENV] Usunięto folder tymczasowy: {self.test_dir}")

    def create_test_image(self, filename: str, shape: tuple = (64, 64, 3), color: list | None = None) -> str:
        """
        Tworzy prosty obraz testowy i zapisuje go w folderze tymczasowym.

        Args:
            filename (str): Nazwa pliku do zapisu (np. 'master.png').
            shape (tuple): Kształt obrazu (wysokość, szerokość, kanały).
            color (list | None, optional): Kolor RGB do wypełnienia obrazu. 
                                    Jeśli None, generowany jest losowy szum.

        Returns:
            str: Pełna ścieżka do utworzonego pliku obrazu.
        """
        if color is not None:
            # Stwórz obraz o jednolitym kolorze
            image_array = np.full(shape, color, dtype=np.uint8)
        else:
            # Stwórz obraz z losowym szumem
            image_array = np.random.randint(0, 256, shape, dtype=np.uint8)
        
        filepath = os.path.join(self.test_dir, filename)
        
        # Zapisz obraz za pomocą OpenCV
        cv2.imwrite(filepath, image_array)
        
        return filepath

``````

### test_base_case_demo.py - ./tests/test_base_case_demo.py

``````
from tests.base_test_case import BaseAlgorithmTestCase
import os
import unittest

class TestBaseCaseDemo(BaseAlgorithmTestCase):
    def test_create_image(self):
        path = self.create_test_image("demo.png", shape=(32, 32, 3), color=[255, 0, 0])
        self.assertTrue(os.path.exists(path))
        print(f"[TEST] Utworzono plik: {path}")

    def test_create_image_with_noise(self):
        path = self.create_test_image("demo_noise.png", shape=(32, 32, 3))
        self.assertTrue(os.path.exists(path))
        print(f"[TEST] Utworzono plik: {path}")

if __name__ == "__main__":
    unittest.main()

``````
