# project name: Gatto Nero Ai Manager (PY+JSX)

ROOT: d:\Unity\Projects\GattoNeroPhotoshop

---

## file tree list

### Found Files (37)
- .comb-doc.py ()
- .comb-scripts.py ()
- __init__.py (\app)
- __init__.py (\app\algorithms)
- __init__.py (\app\algorithms\algorithm_01_palette)
- algorithm.py (\app\algorithms\algorithm_01_palette)
- config.py (\app\algorithms\algorithm_01_palette)
- tests.py (\app\algorithms\algorithm_01_palette)
- __init__.py (\app\algorithms\algorithm_02_statistical)
- algorithm.py (\app\algorithms\algorithm_02_statistical)
- __init__.py (\app\algorithms\algorithm_03_histogram)
- algorithm.py (\app\algorithms\algorithm_03_histogram)
- __init__.py (\app\api)
- routes.py (\app\api)
- __init__.py (\app\core)
- development_logger.py (\app\core)
- file_handler.py (\app\core)
- health_monitor.py (\app\core)
- health_monitor_simple.py (\app\core)
- performance_profiler.py (\app\core)
- __init__.py (\app\processing)
- color_matching.py (\app\processing)
- palette_analyzer.py (\app\processing)
- processing.py (\app)
- color_matcher.jsx (\app\scripts)
- palette_analyzer.jsx (\app\scripts)
- test_simple.jsx (\app\scripts)
- server.py (\app)
- utils.py (\app)
- run_server.py ()
- server_manager_enhanced.py ()
- server_manager_enhanced_fixed.py ()
- test_algorithm_integration.py ()
- test_basic.py ()
- test_curl.py ()
- test_runner.py ()
- test_speed.py ()

---

## file content

### .comb-doc.py - ./.comb-doc.py

``````
﻿import os
from pathlib import Path

# =================================================================================
# SCRIPT FOR FILE AGGREGATION
#
# Wersja: 4.0 (Uniwersalna)
# Opis: Skrypt wyszukuje pliki pasujące do podanych wzorców (np. *.md, *.py)
#       w określonych katalogach, filtruje je na podstawie .gitignore,
#       a następnie łączy ich zawartość w jeden zbiorczy plik .md.
# =================================================================================

# --- KONFIGURACJA ---
# W tej sekcji możesz dostosować działanie skryptu do swoich potrzeb.

# Nazwa projektu, która pojawi się w nagłówku pliku wyjściowego.
PROJECT_NAME = "Gatto Nero Ai Manager (Dokumentacja)"

# Nazwa pliku, do którego zostanie zapisany wynik.
OUTPUT_FILE = ".comb-doc.md"

# ---------------------------------------------------------------------------------
# WZORCE PLIKÓW (FILE_PATTERNS)
# ---------------------------------------------------------------------------------
# Zdefiniuj, jakie pliki mają być wyszukiwane. Możesz podać jeden lub wiele wzorców.
#
# PRZYKŁADY:
# - Tylko pliki Markdown:      FILE_PATTERNS = ['*.md']
# - Pliki Python i JSX:        FILE_PATTERNS = ['*.py', '*.jsx']
# - Tylko pliki tekstowe:      FILE_PATTERNS = ['*.txt']
#
FILE_PATTERNS = ['*.md']
# ---------------------------------------------------------------------------------

# ŚCIEŻKI DO PRZESZUKANIA ($includePaths)
# Lista katalogów do przeszukania. Użyj ['all'] aby przeszukać wszystko.
INCLUDE_PATHS = ['app/algorithms/algorithm_01_palette']

# Nazwa pliku .gitignore, używanego do wykluczeń.
GITIGNORE_FILE = ".gitignore"


# =================================================================================
# --- SILNIK SKRYPTU (zazwyczaj nie wymaga modyfikacji) ---
# =================================================================================

def load_gitignore_patterns(root_path):
    """Wczytuje i przetwarza wzorce z pliku .gitignore."""
    gitignore_path = root_path / GITIGNORE_FILE
    patterns = []
    if gitignore_path.exists():
        print("Znaleziono plik .gitignore. Stosuję reguły wykluczeń.")
        with open(gitignore_path, 'r', encoding='utf-8') as f:
            for line in f:
                stripped_line = line.strip()
                if stripped_line and not stripped_line.startswith('#'):
                    patterns.append(stripped_line)
    else:
        print(".gitignore nie został znaleziony.")
    return patterns

def is_ignored(file_path, root_path, ignore_patterns):
    """Sprawdza, czy dany plik powinien być zignorowany na podstawie wzorców."""
    relative_path_str = str(file_path.relative_to(root_path).as_posix())
    for pattern in ignore_patterns:
        if pattern.endswith('/'):
            if f"/{pattern[:-1]}/" in f"/{relative_path_str}":
                return True
        elif file_path.match(pattern):
             return True
    return False

def find_files_to_process(root_path, ignore_patterns):
    """Znajduje wszystkie pliki do przetworzenia zgodnie z konfiguracją."""
    print(f"Wyszukiwanie plików pasujących do wzorców: {', '.join(FILE_PATTERNS)}...")
    all_found_files = []

    search_paths = []
    if 'all' in INCLUDE_PATHS:
        search_paths.append(root_path)
    else:
        for include_path in INCLUDE_PATHS:
            full_search_path = root_path / include_path
            if full_search_path.is_dir():
                search_paths.append(full_search_path)
            else:
                print(f"UWAGA: Ścieżka '{include_path}' nie istnieje i została pominięta.")

    for path in search_paths:
        for pattern in FILE_PATTERNS:
            # Używamy **/{pattern}, aby szukać rekursywnie
            all_found_files.extend(path.glob(f'**/{pattern}'))
    
    files_to_process = []
    for file in all_found_files:
        if file.name == OUTPUT_FILE or is_ignored(file, root_path, ignore_patterns):
            continue
        files_to_process.append(file)
            
    unique_files = sorted(list(set(files_to_process)))
    print(f"Znaleziono {len(unique_files)} unikalnych plików do przetworzenia.")
    return unique_files

def read_file_with_fallback_encoding(file_path):
    """Probuje odczytac plik jako UTF-8, a jesli sie nie uda, jako windows-1250."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except UnicodeDecodeError:
        print(f"  -> Plik '{file_path.name}' nie jest w UTF-8, próba odczytu jako windows-1250.")
        try:
            with open(file_path, 'r', encoding='windows-1250') as f:
                return f.read()
        except Exception as e:
            return f"BŁĄD ODCZYTU PLIKU {file_path.name}: {e}"
    except Exception as e:
        return f"NIEOCZEKIWANY BŁĄD ODCZYTU PLIKU {file_path.name}: {e}"

def main():
    """Główna funkcja skryptu."""
    root_path = Path.cwd()
    print(f"Rozpoczynam agregację dla projektu: {PROJECT_NAME}")

    ignore_patterns = load_gitignore_patterns(root_path)
    files_to_process = find_files_to_process(root_path, ignore_patterns)
    
    markdown_content = []
    markdown_content.append(f"# project name: {PROJECT_NAME}\n\nROOT: {root_path}\n\n---\n")
    markdown_content.append("## file tree list\n")
    if files_to_process:
        markdown_content.append(f"### Found Files ({len(files_to_process)})")
        for file in files_to_process:
            dir_path = str(file.parent.relative_to(root_path))
            dir_path = '' if dir_path == '.' else f"\\{dir_path}"
            markdown_content.append(f"- {file.name} ({dir_path})")
        markdown_content.append("")
    markdown_content.append("---\n")

    markdown_content.append("## file content\n")
    for file in files_to_process:
        relative_path = file.relative_to(root_path).as_posix()
        markdown_content.append(f"### {file.name} - ./{relative_path}\n")
        markdown_content.append('``````')
        content = read_file_with_fallback_encoding(file)
        markdown_content.append(content)
        markdown_content.append('``````\n')

    final_content = "\n".join(markdown_content)
    try:
        # Zapisujemy z 'utf-8-sig' dla najlepszej kompatybilnosci z programami na Windows
        with open(root_path / OUTPUT_FILE, 'w', encoding='utf-8-sig') as f:
            f.write(final_content)
        print(f"Gotowe! Plik '{OUTPUT_FILE}' został utworzony.")
    except Exception as e:
        print(f"BŁĄD ZAPISU PLIKU: {e}")

if __name__ == "__main__":
    main()
``````

### .comb-scripts.py - ./.comb-scripts.py

``````
﻿import os
from pathlib import Path

# =================================================================================
# SCRIPT FOR FILE AGGREGATION
#
# Wersja: 4.0 (Uniwersalna)
# Opis: Skrypt wyszukuje pliki pasujące do podanych wzorców (np. *.md, *.py)
#       w określonych katalogach, filtruje je na podstawie .gitignore,
#       a następnie łączy ich zawartość w jeden zbiorczy plik .md.
# =================================================================================

# --- KONFIGURACJA ---
# W tej sekcji możesz dostosować działanie skryptu do swoich potrzeb.

# Nazwa projektu, która pojawi się w nagłówku pliku wyjściowego.
PROJECT_NAME = "Gatto Nero Ai Manager (PY+JSX)"

# Nazwa pliku, do którego zostanie zapisany wynik.
OUTPUT_FILE = ".comb-scripts.md"

# ---------------------------------------------------------------------------------
# WZORCE PLIKÓW (FILE_PATTERNS)
# ---------------------------------------------------------------------------------
# Zdefiniuj, jakie pliki mają być wyszukiwane. Możesz podać jeden lub wiele wzorców.
#
# PRZYKŁADY:
# - Tylko pliki Markdown:      FILE_PATTERNS = ['*.md']
# - Pliki Python i JSX:        FILE_PATTERNS = ['*.py', '*.jsx']
# - Tylko pliki tekstowe:      FILE_PATTERNS = ['*.txt']
#
FILE_PATTERNS = ['*.py', '*.jsx']
# ---------------------------------------------------------------------------------

# ŚCIEŻKI DO PRZESZUKANIA ($includePaths)
# Lista katalogów do przeszukania. Użyj ['all'] aby przeszukać wszystko.
INCLUDE_PATHS = ['all']

# Nazwa pliku .gitignore, używanego do wykluczeń.
GITIGNORE_FILE = ".gitignore"


# =================================================================================
# --- SILNIK SKRYPTU (zazwyczaj nie wymaga modyfikacji) ---
# =================================================================================

def load_gitignore_patterns(root_path):
    """Wczytuje i przetwarza wzorce z pliku .gitignore."""
    gitignore_path = root_path / GITIGNORE_FILE
    patterns = []
    if gitignore_path.exists():
        print("Znaleziono plik .gitignore. Stosuję reguły wykluczeń.")
        with open(gitignore_path, 'r', encoding='utf-8') as f:
            for line in f:
                stripped_line = line.strip()
                if stripped_line and not stripped_line.startswith('#'):
                    patterns.append(stripped_line)
    else:
        print(".gitignore nie został znaleziony.")
    return patterns

def is_ignored(file_path, root_path, ignore_patterns):
    """Sprawdza, czy dany plik powinien być zignorowany na podstawie wzorców."""
    relative_path_str = str(file_path.relative_to(root_path).as_posix())
    for pattern in ignore_patterns:
        if pattern.endswith('/'):
            if f"/{pattern[:-1]}/" in f"/{relative_path_str}":
                return True
        elif file_path.match(pattern):
             return True
    return False

def find_files_to_process(root_path, ignore_patterns):
    """Znajduje wszystkie pliki do przetworzenia zgodnie z konfiguracją."""
    print(f"Wyszukiwanie plików pasujących do wzorców: {', '.join(FILE_PATTERNS)}...")
    all_found_files = []

    search_paths = []
    if 'all' in INCLUDE_PATHS:
        search_paths.append(root_path)
    else:
        for include_path in INCLUDE_PATHS:
            full_search_path = root_path / include_path
            if full_search_path.is_dir():
                search_paths.append(full_search_path)
            else:
                print(f"UWAGA: Ścieżka '{include_path}' nie istnieje i została pominięta.")

    for path in search_paths:
        for pattern in FILE_PATTERNS:
            # Używamy **/{pattern}, aby szukać rekursywnie
            all_found_files.extend(path.glob(f'**/{pattern}'))
    
    files_to_process = []
    for file in all_found_files:
        if file.name == OUTPUT_FILE or is_ignored(file, root_path, ignore_patterns):
            continue
        files_to_process.append(file)
            
    unique_files = sorted(list(set(files_to_process)))
    print(f"Znaleziono {len(unique_files)} unikalnych plików do przetworzenia.")
    return unique_files

def read_file_with_fallback_encoding(file_path):
    """Probuje odczytac plik jako UTF-8, a jesli sie nie uda, jako windows-1250."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except UnicodeDecodeError:
        print(f"  -> Plik '{file_path.name}' nie jest w UTF-8, próba odczytu jako windows-1250.")
        try:
            with open(file_path, 'r', encoding='windows-1250') as f:
                return f.read()
        except Exception as e:
            return f"BŁĄD ODCZYTU PLIKU {file_path.name}: {e}"
    except Exception as e:
        return f"NIEOCZEKIWANY BŁĄD ODCZYTU PLIKU {file_path.name}: {e}"

def main():
    """Główna funkcja skryptu."""
    root_path = Path.cwd()
    print(f"Rozpoczynam agregację dla projektu: {PROJECT_NAME}")

    ignore_patterns = load_gitignore_patterns(root_path)
    files_to_process = find_files_to_process(root_path, ignore_patterns)
    
    markdown_content = []
    markdown_content.append(f"# project name: {PROJECT_NAME}\n\nROOT: {root_path}\n\n---\n")
    markdown_content.append("## file tree list\n")
    if files_to_process:
        markdown_content.append(f"### Found Files ({len(files_to_process)})")
        for file in files_to_process:
            dir_path = str(file.parent.relative_to(root_path))
            dir_path = '' if dir_path == '.' else f"\\{dir_path}"
            markdown_content.append(f"- {file.name} ({dir_path})")
        markdown_content.append("")
    markdown_content.append("---\n")

    markdown_content.append("## file content\n")
    for file in files_to_process:
        relative_path = file.relative_to(root_path).as_posix()
        markdown_content.append(f"### {file.name} - ./{relative_path}\n")
        markdown_content.append('``````')
        content = read_file_with_fallback_encoding(file)
        markdown_content.append(content)
        markdown_content.append('``````\n')

    final_content = "\n".join(markdown_content)
    try:
        # Zapisujemy z 'utf-8-sig' dla najlepszej kompatybilnosci z programami na Windows
        with open(root_path / OUTPUT_FILE, 'w', encoding='utf-8-sig') as f:
            f.write(final_content)
        print(f"Gotowe! Plik '{OUTPUT_FILE}' został utworzony.")
    except Exception as e:
        print(f"BŁĄD ZAPISU PLIKU: {e}")

if __name__ == "__main__":
    main()
``````

### __init__.py - ./app/__init__.py

``````
# Makes 'app' a package

``````

### __init__.py - ./app/algorithms/__init__.py

``````
"""
GattoNero AI Assistant - Algorithm Modules
==========================================

This package contains modular algorithm implementations for color matching
and image processing. Each algorithm is self-contained with comprehensive
monitoring, testing, and documentation.

Available Algorithms:
- Algorithm 01: Palette Mapping (K-means based color palette extraction)
- Algorithm 02: Statistical Transfer (LAB color space statistical matching)
- Algorithm 03: Histogram Matching (Luminance channel histogram specification)
"""

# Import algorithm factories for easy access
from .algorithm_01_palette import (
    create_palette_mapping_algorithm,
    simple_palette_mapping
)
from .algorithm_02_statistical import (
    create_statistical_transfer_algorithm,
    basic_statistical_transfer
)
from .algorithm_03_histogram import (
    create_histogram_matching_algorithm,
    simple_histogram_matching
)

# Algorithm registry for dynamic access
ALGORITHM_REGISTRY = {
    'algorithm_01_palette': create_palette_mapping_algorithm,
    'algorithm_02_statistical': create_statistical_transfer_algorithm,
    'algorithm_03_histogram': create_histogram_matching_algorithm,
}

# Legacy function mapping for backward compatibility
LEGACY_FUNCTIONS = {
    'method1': simple_palette_mapping,
    'method2': basic_statistical_transfer,
    'method3': simple_histogram_matching,
}

def get_algorithm(algorithm_id: str):
    """Get algorithm instance by ID."""
    if algorithm_id in ALGORITHM_REGISTRY:
        return ALGORITHM_REGISTRY[algorithm_id]()
    raise ValueError(f"Unknown algorithm: {algorithm_id}")

def get_legacy_function(method: str):
    """Get legacy function by method name."""
    if method in LEGACY_FUNCTIONS:
        return LEGACY_FUNCTIONS[method]
    raise ValueError(f"Unknown method: {method}")

__all__ = [
    # Algorithm factories
    'create_palette_mapping_algorithm',
    'create_statistical_transfer_algorithm', 
    'create_histogram_matching_algorithm',
    
    # Legacy compatibility functions
    'simple_palette_mapping',
    'basic_statistical_transfer',
    'simple_histogram_matching',
    
    # Dynamic access
    'get_algorithm',
    'get_legacy_function',
    'ALGORITHM_REGISTRY',
    'LEGACY_FUNCTIONS'
]

``````

### __init__.py - ./app/algorithms/algorithm_01_palette/__init__.py

``````
"""
Algorithm 01: Palette Mapping
============================

This module provides palette-based color matching functionality using K-means clustering.
"""

from .algorithm import (
    PaletteMappingAlgorithm,
    create_palette_mapping_algorithm,
    simple_palette_mapping
)

__all__ = [
    'PaletteMappingAlgorithm',
    'create_palette_mapping_algorithm',
    'simple_palette_mapping'
]

``````

### algorithm.py - ./app/algorithms/algorithm_01_palette/algorithm.py

``````
"""
Algorithm 01: Palette Mapping
============================

Enhanced modular implementation of palette-based color matching algorithm.
Extracted from legacy code with improved structure, monitoring, and testability.

Design Philosophy: "Bezpiecznie = Szybko"
- Clear separation of concerns
- Comprehensive error handling  
- Performance monitoring integration
- Easy testing and validation
"""

import os
import cv2
import numpy as np
from sklearn.cluster import KMeans
from typing import Tuple, Optional, Dict, Any
from pathlib import Path

from app.core.development_logger import get_logger
# Poprawka: Dodano bezpośredni import klas, aby pomóc Pylance w analizie typów
from app.core.performance_profiler import get_profiler, PerformanceProfiler
from app.core.file_handler import get_result_path


class PaletteMappingAlgorithm:
    """
    Enhanced Palette Mapping Algorithm
    
    Core functionality:
    1. Extract dominant colors from master image using K-means
    2. Map target image pixels to closest master palette colors
    3. Generate result with master's color scheme applied to target's content
    """
    
    def __init__(self, algorithm_id: str = "algorithm_01_palette"):
        self.algorithm_id = algorithm_id
        self.logger = get_logger()
        # Poprawka: Dodano jawną adnotację typu, aby rozwiązać problemy Pylance
        self.profiler: PerformanceProfiler = get_profiler()
        
        # Default parameters
        self.default_params = {
            'k_colors': 8,
            'random_state': 42,
            'n_init': 10,
            'max_iter': 300,
            'tol': 1e-4
        }
        
        self.logger.info(f"Initialized {self.algorithm_id}")
    
    def extract_palette(self, image: np.ndarray, k_colors: int) -> np.ndarray:
        """Extract dominant colors from image using K-means clustering."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_extract_palette"):
            self.logger.set_algorithm_context(self.algorithm_id)
            
            # Reshape image to pixel array
            pixels = image.reshape(-1, 3).astype(np.float32)
            self.logger.debug(f"Processing {len(pixels)} pixels for palette extraction")
            
            # Perform K-means clustering
            kmeans = KMeans(
                n_clusters=k_colors,
                random_state=self.default_params['random_state'],
                n_init=self.default_params['n_init'],
                max_iter=self.default_params['max_iter'],
                tol=self.default_params['tol']
            )
            
            kmeans.fit(pixels)
            palette = kmeans.cluster_centers_
            
            self.logger.success(f"Extracted {k_colors} colors from palette")
            return palette
    
    def map_colors(self, target_image: np.ndarray, master_palette: np.ndarray, k_colors: int) -> np.ndarray:
        """Map target image colors to closest master palette colors."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_map_colors"):
            # Reshape target to pixels
            target_pixels = target_image.reshape(-1, 3).astype(np.float32)
            
            # Extract target palette for mapping
            kmeans_target = KMeans(
                n_clusters=k_colors,
                random_state=self.default_params['random_state'],
                n_init=self.default_params['n_init']
            )
            target_labels = kmeans_target.fit_predict(target_pixels)
            target_palette = kmeans_target.cluster_centers_
            
            # Create mapping from target palette to master palette
            mapped_pixels = np.zeros_like(target_pixels)
            
            for i, target_color in enumerate(target_palette):
                # Find closest color in master palette using Euclidean distance
                distances = np.sum((master_palette - target_color) ** 2, axis=1)
                closest_idx = np.argmin(distances)
                mapped_pixels[target_labels == i] = master_palette[closest_idx]
            
            # Reshape back to image dimensions
            result = mapped_pixels.reshape(target_image.shape).astype(np.uint8)
            
            self.logger.success(f"Mapped colors for {len(target_pixels)} pixels")
            return result
    
    def process(self, master_path: str, target_path: str, k_colors: int = 8) -> str:
        """
        Main processing method - applies palette mapping algorithm.
        
        Args:
            master_path: Path to master image (source of color palette)
            target_path: Path to target image (will be color-matched)
            k_colors: Number of colors in palette (4-32)
            
        Returns:
            Path to result image file
            
        Raises:
            FileNotFoundError: If input images don't exist
            ValueError: If k_colors is out of valid range
            RuntimeError: If processing fails
        """
        with self.profiler.profile_operation(f"{self.algorithm_id}_process"):
            # Set algorithm context for logging
            self.logger.set_algorithm_context(self.algorithm_id)
            
            # Validate parameters
            if not (4 <= k_colors <= 32):
                raise ValueError(f"k_colors must be between 4 and 32, got {k_colors}")
            
            if not os.path.exists(master_path):
                raise FileNotFoundError(f"Master image not found: {master_path}")
                
            if not os.path.exists(target_path):
                raise FileNotFoundError(f"Target image not found: {target_path}")
            
            self.logger.info(f"Starting palette mapping: k={k_colors}")
            self.logger.debug(f"Master: {master_path}")
            self.logger.debug(f"Target: {target_path}")
            
            try:
                # Load images
                master_image = cv2.imread(master_path)
                target_image = cv2.imread(target_path)
                
                if master_image is None:
                    raise RuntimeError(f"Failed to load master image: {master_path}")
                if target_image is None:
                    raise RuntimeError(f"Failed to load target image: {target_path}")
                
                self.logger.debug(f"Master shape: {master_image.shape}")
                self.logger.debug(f"Target shape: {target_image.shape}")
                
                # Extract palette from master image
                master_palette = self.extract_palette(master_image, k_colors)
                
                # Map target image to master palette
                result_image = self.map_colors(target_image, master_palette, k_colors)
                
                # Save result
                result_path = get_result_path(os.path.basename(target_path))
                success = cv2.imwrite(result_path, result_image)
                
                if not success:
                    raise RuntimeError(f"Failed to save result image: {result_path}")
                
                self.logger.success(f"Palette mapping completed: {result_path}")
                return result_path
                
            except Exception as e:
                self.logger.error(f"Palette mapping failed: {str(e)}", exc_info=True)
                raise RuntimeError(f"Algorithm processing failed: {str(e)}") from e
    
    def get_algorithm_info(self) -> Dict[str, Any]:
        """Get algorithm information for monitoring and documentation."""
        return {
            'algorithm_id': self.algorithm_id,
            'name': 'Palette Mapping',
            'description': 'K-means based color palette extraction and mapping',
            'version': '2.0.0',
            'parameters': self.default_params.copy(),
            'supported_formats': ['jpg', 'jpeg', 'png', 'tif', 'tiff', 'bmp'],
            'color_space': 'RGB',
            'complexity': 'O(n*k*iterations)',
            'memory_usage': 'O(n + k)'
        }


# Factory function for easy algorithm creation
def create_palette_mapping_algorithm() -> PaletteMappingAlgorithm:
    """Create and return a new palette mapping algorithm instance."""
    return PaletteMappingAlgorithm()


# Legacy compatibility function
def simple_palette_mapping(master_path: str, target_path: str, k_colors: int = 8) -> str:
    """
    Legacy compatibility function for existing API.
    
    This maintains backward compatibility with existing code while using
    the new modular algorithm implementation.
    """
    algorithm = create_palette_mapping_algorithm()
    return algorithm.process(master_path, target_path, k_colors)

``````

### config.py - ./app/algorithms/algorithm_01_palette/config.py

``````
"""
Algorithm 01: Palette Mapping Configuration
===========================================

Configuration parameters, validation, and defaults for the palette mapping algorithm.
"""

from typing import Dict, Any, Union
from dataclasses import dataclass, field
import json


@dataclass
class PaletteMappingConfig:
    """Configuration class for Palette Mapping Algorithm."""
    
    # Core algorithm parameters
    k_colors: int = 8              # Number of colors in palette (4-32)
    random_state: int = 42         # Random seed for reproducible results
    n_init: int = 10              # Number of K-means initializations
    max_iter: int = 300           # Maximum K-means iterations
    tol: float = 1e-4             # K-means convergence tolerance
    
    # Performance parameters
    enable_monitoring: bool = True  # Enable performance monitoring
    memory_limit_mb: int = 512     # Memory limit for processing
    timeout_seconds: int = 300     # Processing timeout
    
    # Quality parameters
    min_image_size: int = 32       # Minimum image dimension
    max_image_size: int = 4096     # Maximum image dimension
    downsample_threshold: int = 2048  # Downsample images larger than this
    
    # Output parameters
    output_format: str = "tiff"    # Output file format
    compression_quality: int = 95   # JPEG quality or similar
    preserve_alpha: bool = True    # Preserve alpha channel if present
    
    # Advanced parameters
    color_space: str = "RGB"       # Color space for processing
    distance_metric: str = "euclidean"  # Color distance metric
    enable_edge_preservation: bool = False  # Experimental edge preservation
    
    def validate(self) -> None:
        """Validate configuration parameters."""
        errors = []
        
        # Validate k_colors
        if not (4 <= self.k_colors <= 32):
            errors.append(f"k_colors must be between 4 and 32, got {self.k_colors}")
        
        # Validate random_state
        if not isinstance(self.random_state, int) or self.random_state < 0:
            errors.append(f"random_state must be non-negative integer, got {self.random_state}")
        
        # Validate n_init
        if not (1 <= self.n_init <= 100):
            errors.append(f"n_init must be between 1 and 100, got {self.n_init}")
        
        # Validate max_iter
        if not (10 <= self.max_iter <= 1000):
            errors.append(f"max_iter must be between 10 and 1000, got {self.max_iter}")
        
        # Validate tolerance
        if not (1e-6 <= self.tol <= 1e-1):
            errors.append(f"tol must be between 1e-6 and 1e-1, got {self.tol}")
        
        # Validate memory limit
        if not (64 <= self.memory_limit_mb <= 8192):
            errors.append(f"memory_limit_mb must be between 64 and 8192, got {self.memory_limit_mb}")
        
        # Validate timeout
        if not (10 <= self.timeout_seconds <= 3600):
            errors.append(f"timeout_seconds must be between 10 and 3600, got {self.timeout_seconds}")
        
        # Validate image sizes
        if not (16 <= self.min_image_size <= 256):
            errors.append(f"min_image_size must be between 16 and 256, got {self.min_image_size}")
        
        if not (512 <= self.max_image_size <= 16384):
            errors.append(f"max_image_size must be between 512 and 16384, got {self.max_image_size}")
        
        if self.min_image_size >= self.max_image_size:
            errors.append("min_image_size must be less than max_image_size")
        
        # Validate downsample threshold
        if not (256 <= self.downsample_threshold <= self.max_image_size):
            errors.append(f"downsample_threshold must be between 256 and max_image_size")
        
        # Validate output format
        valid_formats = ["tiff", "png", "jpg", "jpeg", "bmp"]
        if self.output_format.lower() not in valid_formats:
            errors.append(f"output_format must be one of {valid_formats}, got {self.output_format}")
        
        # Validate compression quality
        if not (1 <= self.compression_quality <= 100):
            errors.append(f"compression_quality must be between 1 and 100, got {self.compression_quality}")
        
        # Validate color space
        valid_color_spaces = ["RGB", "BGR", "LAB", "HSV"]
        if self.color_space not in valid_color_spaces:
            errors.append(f"color_space must be one of {valid_color_spaces}, got {self.color_space}")
        
        # Validate distance metric
        valid_metrics = ["euclidean", "manhattan", "cosine"]
        if self.distance_metric not in valid_metrics:
            errors.append(f"distance_metric must be one of {valid_metrics}, got {self.distance_metric}")
        
        if errors:
            raise ValueError("Configuration validation failed:\n" + "\n".join(f"- {error}" for error in errors))
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert configuration to dictionary."""
        return {
            'k_colors': self.k_colors,
            'random_state': self.random_state,
            'n_init': self.n_init,
            'max_iter': self.max_iter,
            'tol': self.tol,
            'enable_monitoring': self.enable_monitoring,
            'memory_limit_mb': self.memory_limit_mb,
            'timeout_seconds': self.timeout_seconds,
            'min_image_size': self.min_image_size,
            'max_image_size': self.max_image_size,
            'downsample_threshold': self.downsample_threshold,
            'output_format': self.output_format,
            'compression_quality': self.compression_quality,
            'preserve_alpha': self.preserve_alpha,
            'color_space': self.color_space,
            'distance_metric': self.distance_metric,
            'enable_edge_preservation': self.enable_edge_preservation
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'PaletteMappingConfig':
        """Create configuration from dictionary."""
        return cls(**data)
    
    def save_to_file(self, filepath: str) -> None:
        """Save configuration to JSON file."""
        with open(filepath, 'w') as f:
            json.dump(self.to_dict(), f, indent=2)
    
    @classmethod
    def load_from_file(cls, filepath: str) -> 'PaletteMappingConfig':
        """Load configuration from JSON file."""
        with open(filepath, 'r') as f:
            data = json.load(f)
        return cls.from_dict(data)


# Predefined configurations for different use cases
PRESET_CONFIGS = {
    'fast': PaletteMappingConfig(
        k_colors=6,
        n_init=3,
        max_iter=100,
        downsample_threshold=1024,
        enable_monitoring=False
    ),
    
    'balanced': PaletteMappingConfig(
        k_colors=8,
        n_init=10,
        max_iter=300,
        downsample_threshold=2048,
        enable_monitoring=True
    ),
    
    'quality': PaletteMappingConfig(
        k_colors=16,
        n_init=20,
        max_iter=500,
        downsample_threshold=4096,
        enable_monitoring=True,
        enable_edge_preservation=True
    ),
    
    'artistic': PaletteMappingConfig(
        k_colors=4,
        n_init=15,
        max_iter=300,
        downsample_threshold=2048,
        enable_monitoring=True
    ),
    
    'photorealistic': PaletteMappingConfig(
        k_colors=24,
        n_init=25,
        max_iter=400,
        downsample_threshold=4096,
        enable_monitoring=True,
        enable_edge_preservation=True
    )
}


def get_config(preset: str = 'balanced') -> PaletteMappingConfig:
    """Get a predefined configuration preset."""
    if preset not in PRESET_CONFIGS:
        available = list(PRESET_CONFIGS.keys())
        raise ValueError(f"Unknown preset '{preset}'. Available: {available}")
    
    return PRESET_CONFIGS[preset]


def create_config_from_api_params(k_colors: int = 8, **kwargs) -> PaletteMappingConfig:
    """Create configuration from API parameters (for backward compatibility)."""
    config = get_config('balanced')
    config.k_colors = k_colors
    
    # Apply any additional parameters
    for key, value in kwargs.items():
        if hasattr(config, key):
            setattr(config, key, value)
    
    config.validate()
    return config

``````

### tests.py - ./app/algorithms/algorithm_01_palette/tests.py

``````
"""
Algorithm 01: Palette Mapping Tests
==================================

Comprehensive test suite for the palette mapping algorithm including:
- Unit tests for core functionality
- Integration tests with file I/O
- Performance benchmarks
- Edge case validation
"""

import os
import sys
import unittest
import tempfile
import numpy as np
import cv2
from pathlib import Path

# Add project root to path for imports
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from app.algorithms.algorithm_01_palette.algorithm import PaletteMappingAlgorithm, create_palette_mapping_algorithm
from app.algorithms.algorithm_01_palette.config import PaletteMappingConfig, get_config


class TestPaletteMappingAlgorithm(unittest.TestCase):
    """Test cases for the PaletteMappingAlgorithm class."""
    
    def setUp(self):
        """Set up test fixtures."""
        self.algorithm = create_palette_mapping_algorithm()
        self.test_dir = tempfile.mkdtemp()
        
        # Create test images
        self.master_image = self._create_test_image((100, 100, 3), 'master')
        self.target_image = self._create_test_image((80, 80, 3), 'target')
        
        self.master_path = os.path.join(self.test_dir, 'master.png')
        self.target_path = os.path.join(self.test_dir, 'target.png')
        
        cv2.imwrite(self.master_path, self.master_image)
        cv2.imwrite(self.target_path, self.target_image)
    
    def tearDown(self):
        """Clean up test fixtures."""
        import shutil
        shutil.rmtree(self.test_dir, ignore_errors=True)
    
    def _create_test_image(self, shape, image_type='random'):
        """Create a test image with known properties."""
        if image_type == 'master':
            # Create image with distinct color regions
            image = np.zeros(shape, dtype=np.uint8)
            h, w = shape[:2]
            
            # Red region
            image[:h//2, :w//2] = [0, 0, 255]
            # Green region  
            image[:h//2, w//2:] = [0, 255, 0]
            # Blue region
            image[h//2:, :w//2] = [255, 0, 0]
            # Yellow region
            image[h//2:, w//2:] = [0, 255, 255]
            
        elif image_type == 'target':
            # Create more complex image
            image = np.random.randint(0, 256, shape, dtype=np.uint8)
            
        else:
            # Random image
            image = np.random.randint(0, 256, shape, dtype=np.uint8)
        
        return image
    
    def test_algorithm_initialization(self):
        """Test algorithm initialization."""
        self.assertEqual(self.algorithm.algorithm_id, "algorithm_01_palette")
        self.assertIsNotNone(self.algorithm.logger)
        self.assertIsNotNone(self.algorithm.profiler)
        self.assertIn('k_colors', self.algorithm.default_params)
    
    def test_extract_palette(self):
        """Test palette extraction from image."""
        k_colors = 4
        palette = self.algorithm.extract_palette(self.master_image, k_colors)
        
        self.assertEqual(len(palette), k_colors)
        self.assertEqual(palette.shape, (k_colors, 3))
        self.assertTrue(np.all(palette >= 0))
        self.assertTrue(np.all(palette <= 255))
    
    def test_map_colors(self):
        """Test color mapping functionality."""
        k_colors = 4
        master_palette = self.algorithm.extract_palette(self.master_image, k_colors)
        result = self.algorithm.map_colors(self.target_image, master_palette, k_colors)
        
        self.assertEqual(result.shape, self.target_image.shape)
        self.assertEqual(result.dtype, np.uint8)
    
    def test_process_success(self):
        """Test successful end-to-end processing."""
        result_path = self.algorithm.process(self.master_path, self.target_path, k_colors=8)
        
        self.assertTrue(os.path.exists(result_path))
        
        # Verify result image
        result_image = cv2.imread(result_path)
        self.assertIsNotNone(result_image)
        self.assertEqual(len(result_image.shape), 3)
    
    def test_process_invalid_k_colors(self):
        """Test processing with invalid k_colors parameter."""
        with self.assertRaises(ValueError):
            self.algorithm.process(self.master_path, self.target_path, k_colors=2)  # Too low
        
        with self.assertRaises(ValueError):
            self.algorithm.process(self.master_path, self.target_path, k_colors=50)  # Too high
    
    def test_process_missing_files(self):
        """Test processing with missing input files."""
        with self.assertRaises(FileNotFoundError):
            self.algorithm.process("nonexistent.jpg", self.target_path)
        
        with self.assertRaises(FileNotFoundError):
            self.algorithm.process(self.master_path, "nonexistent.jpg")
    
    def test_process_corrupted_files(self):
        """Test processing with corrupted image files."""
        # Create corrupted file
        corrupted_path = os.path.join(self.test_dir, 'corrupted.jpg')
        with open(corrupted_path, 'wb') as f:
            f.write(b'not an image')
        
        with self.assertRaises(RuntimeError):
            self.algorithm.process(corrupted_path, self.target_path)
    
    def test_get_algorithm_info(self):
        """Test algorithm information retrieval."""
        info = self.algorithm.get_algorithm_info()
        
        self.assertIn('algorithm_id', info)
        self.assertIn('name', info)
        self.assertIn('version', info)
        self.assertIn('parameters', info)
        self.assertEqual(info['algorithm_id'], "algorithm_01_palette")


class TestPaletteMappingConfig(unittest.TestCase):
    """Test cases for the PaletteMappingConfig class."""
    
    def test_default_config(self):
        """Test default configuration creation."""
        config = PaletteMappingConfig()
        config.validate()  # Should not raise
        
        self.assertEqual(config.k_colors, 8)
        self.assertEqual(config.random_state, 42)
        self.assertTrue(config.enable_monitoring)
    
    def test_config_validation_success(self):
        """Test successful configuration validation."""
        config = PaletteMappingConfig(
            k_colors=12,
            n_init=5,
            max_iter=200
        )
        config.validate()  # Should not raise
    
    def test_config_validation_failures(self):
        """Test configuration validation failures."""
        # Invalid k_colors
        with self.assertRaises(ValueError):
            config = PaletteMappingConfig(k_colors=2)
            config.validate()
        
        # Invalid memory limit
        with self.assertRaises(ValueError):
            config = PaletteMappingConfig(memory_limit_mb=10)
            config.validate()
        
        # Invalid image sizes
        with self.assertRaises(ValueError):
            config = PaletteMappingConfig(min_image_size=100, max_image_size=50)
            config.validate()
    
    def test_config_presets(self):
        """Test predefined configuration presets."""
        for preset_name in ['fast', 'balanced', 'quality', 'artistic', 'photorealistic']:
            config = get_config(preset_name)
            config.validate()  # Should not raise
    
    def test_config_serialization(self):
        """Test configuration serialization to/from dict."""
        original = PaletteMappingConfig(k_colors=16, n_init=15)
        
        # Convert to dict and back
        config_dict = original.to_dict()
        restored = PaletteMappingConfig.from_dict(config_dict)
        
        self.assertEqual(original.k_colors, restored.k_colors)
        self.assertEqual(original.n_init, restored.n_init)
        self.assertEqual(original.random_state, restored.random_state)


class TestPerformanceBenchmarks(unittest.TestCase):
    """Performance benchmark tests."""
    
    def setUp(self):
        """Set up benchmark fixtures."""
        self.algorithm = create_palette_mapping_algorithm()
        self.test_dir = tempfile.mkdtemp()
    
    def tearDown(self):
        """Clean up benchmark fixtures."""
        import shutil
        shutil.rmtree(self.test_dir, ignore_errors=True)
    
    def test_small_image_performance(self):
        """Benchmark performance on small images."""
        import time
        
        # Create small test images
        master = np.random.randint(0, 256, (100, 100, 3), dtype=np.uint8)
        target = np.random.randint(0, 256, (100, 100, 3), dtype=np.uint8)
        
        master_path = os.path.join(self.test_dir, 'master_small.png')
        target_path = os.path.join(self.test_dir, 'target_small.png')
        
        cv2.imwrite(master_path, master)
        cv2.imwrite(target_path, target)
        
        start_time = time.time()
        result_path = self.algorithm.process(master_path, target_path, k_colors=8)
        duration = time.time() - start_time
        
        self.assertTrue(os.path.exists(result_path))
        self.assertLess(duration, 5.0)  # Should complete in under 5 seconds
    
    def test_memory_usage_validation(self):
        """Test memory usage stays within reasonable bounds."""
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # Create medium-sized test images
        master = np.random.randint(0, 256, (500, 500, 3), dtype=np.uint8)
        target = np.random.randint(0, 256, (500, 500, 3), dtype=np.uint8)
        
        master_path = os.path.join(self.test_dir, 'master_medium.png')
        target_path = os.path.join(self.test_dir, 'target_medium.png')
        
        cv2.imwrite(master_path, master)
        cv2.imwrite(target_path, target)
        
        result_path = self.algorithm.process(master_path, target_path, k_colors=8)
        
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory
        
        self.assertTrue(os.path.exists(result_path))
        self.assertLess(memory_increase, 200)  # Should not use more than 200MB extra


class TestLegacyCompatibility(unittest.TestCase):
    """Test backward compatibility with legacy API."""
    
    def setUp(self):
        """Set up compatibility test fixtures."""
        self.test_dir = tempfile.mkdtemp()
        
        # Create test images
        master = np.random.randint(0, 256, (50, 50, 3), dtype=np.uint8)
        target = np.random.randint(0, 256, (50, 50, 3), dtype=np.uint8)
        
        self.master_path = os.path.join(self.test_dir, 'master.png')
        self.target_path = os.path.join(self.test_dir, 'target.png')
        
        cv2.imwrite(self.master_path, master)
        cv2.imwrite(self.target_path, target)
    
    def tearDown(self):
        """Clean up compatibility test fixtures."""
        import shutil
        shutil.rmtree(self.test_dir, ignore_errors=True)
    
    def test_legacy_function_compatibility(self):
        """Test legacy simple_palette_mapping function."""
        from app.algorithms.algorithm_01_palette.algorithm import simple_palette_mapping
        
        result_path = simple_palette_mapping(self.master_path, self.target_path, k_colors=6)
        
        self.assertTrue(os.path.exists(result_path))
        result_image = cv2.imread(result_path)
        self.assertIsNotNone(result_image)


def run_algorithm_tests():
    """Run all algorithm tests and return results."""
    # Create test suite
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # Add test cases
    suite.addTests(loader.loadTestsFromTestCase(TestPaletteMappingAlgorithm))
    suite.addTests(loader.loadTestsFromTestCase(TestPaletteMappingConfig))
    suite.addTests(loader.loadTestsFromTestCase(TestPerformanceBenchmarks))
    suite.addTests(loader.loadTestsFromTestCase(TestLegacyCompatibility))
    
    # Run tests
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    return result.wasSuccessful()


if __name__ == '__main__':
    success = run_algorithm_tests()
    sys.exit(0 if success else 1)

``````

### __init__.py - ./app/algorithms/algorithm_02_statistical/__init__.py

``````
"""
Algorithm 02: Statistical Transfer
=================================

This module provides statistical color transfer functionality using LAB color space.
"""

from .algorithm import (
    StatisticalTransferAlgorithm,
    create_statistical_transfer_algorithm,
    basic_statistical_transfer
)

__all__ = [
    'StatisticalTransferAlgorithm',
    'create_statistical_transfer_algorithm', 
    'basic_statistical_transfer'
]

``````

### algorithm.py - ./app/algorithms/algorithm_02_statistical/algorithm.py

``````
"""
Algorithm 02: Statistical Transfer
=================================

Enhanced modular implementation of statistical color transfer algorithm.
Operates in LAB color space for better perceptual accuracy.

Design Philosophy: "Bezpiecznie = Szybko"
- Clear separation of concerns
- Comprehensive error handling  
- Performance monitoring integration
- Easy testing and validation
"""

import os
import cv2
import numpy as np
from typing import Tuple, Optional, Dict, Any
from pathlib import Path

from app.core.development_logger import get_logger
# Poprawka: Dodano bezpośredni import klas, aby pomóc Pylance w analizie typów
from app.core.performance_profiler import get_profiler, PerformanceProfiler 
from app.core.file_handler import get_result_path


class StatisticalTransferAlgorithm:
    """
    Enhanced Statistical Transfer Algorithm
    
    Core functionality:
    1. Convert images to LAB color space for perceptual accuracy
    2. Calculate statistical moments (mean, std) for each channel
    3. Transfer master's statistics to target image
    4. Apply proper LAB range clipping and convert back to RGB
    """
    
    def __init__(self, algorithm_id: str = "algorithm_02_statistical"):
        self.algorithm_id = algorithm_id
        self.logger = get_logger()
        # Poprawka: Dodano jawną adnotację typu, aby rozwiązać problemy Pylance
        self.profiler: PerformanceProfiler = get_profiler()
        
        # LAB color space ranges
        self.lab_ranges = {
            'L': (0, 100),    # Lightness: 0-100
            'a': (-127, 127), # Green-Red: -127 to 127  
            'b': (-127, 127)  # Blue-Yellow: -127 to 127
        }
        
        self.logger.info(f"Initialized {self.algorithm_id}")
    
    def convert_to_lab(self, image: np.ndarray) -> np.ndarray:
        """Convert BGR image to LAB color space."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_convert_to_lab"):
            lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB).astype(np.float32)
            self.logger.debug(f"Converted image to LAB: {lab_image.shape}")
            return lab_image
    
    def convert_to_bgr(self, lab_image: np.ndarray) -> np.ndarray:
        """Convert LAB image back to BGR color space."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_convert_to_bgr"):
            # Ensure proper LAB range clipping before conversion
            clipped_lab = self.clip_lab_ranges(lab_image)
            bgr_image = cv2.cvtColor(clipped_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)
            self.logger.debug(f"Converted LAB back to BGR: {bgr_image.shape}")
            return bgr_image
    
    def clip_lab_ranges(self, lab_image: np.ndarray) -> np.ndarray:
        """Apply proper LAB range clipping to prevent conversion artifacts."""
        clipped = lab_image.copy()
        clipped[:, :, 0] = np.clip(clipped[:, :, 0], self.lab_ranges['L'][0], self.lab_ranges['L'][1])  # L channel
        clipped[:, :, 1] = np.clip(clipped[:, :, 1], self.lab_ranges['a'][0], self.lab_ranges['a'][1])  # a channel
        clipped[:, :, 2] = np.clip(clipped[:, :, 2], self.lab_ranges['b'][0], self.lab_ranges['b'][1])  # b channel
        return clipped
    
    def calculate_statistics(self, lab_image: np.ndarray) -> Dict[str, Tuple[float, float]]:
        """Calculate mean and standard deviation for each LAB channel."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_calculate_stats"):
            stats = {}
            channel_names = ['L', 'a', 'b']
            
            for i, channel in enumerate(channel_names):
                channel_data = lab_image[:, :, i]
                mean = np.mean(channel_data)
                std = np.std(channel_data)
                stats[channel] = (mean, std)
                self.logger.debug(f"Channel {channel}: mean={mean:.2f}, std={std:.2f}")
            
            return stats
    
    def transfer_statistics(self, target_lab: np.ndarray, master_stats: Dict[str, Tuple[float, float]], 
                          target_stats: Dict[str, Tuple[float, float]]) -> np.ndarray:
        """Transfer statistical properties from master to target image."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_transfer_stats"):
            result_lab = target_lab.copy()
            channel_names = ['L', 'a', 'b']
            
            for i, channel in enumerate(channel_names):
                master_mean, master_std = master_stats[channel]
                target_mean, target_std = target_stats[channel]
                
                # Apply statistical transfer: normalize and rescale
                if target_std > 0:
                    result_lab[:, :, i] = (target_lab[:, :, i] - target_mean) * (master_std / target_std) + master_mean
                else:
                    # If target std is 0, just shift to master mean
                    result_lab[:, :, i] = master_mean
                
                self.logger.debug(f"Transferred {channel} channel statistics")
            
            return result_lab
    
    def process(self, master_path: str, target_path: str) -> str:
        """
        Main processing method - applies statistical transfer algorithm.
        
        Args:
            master_path: Path to master image (source of color statistics)
            target_path: Path to target image (will be color-matched)
            
        Returns:
            Path to result image file
            
        Raises:
            FileNotFoundError: If input images don't exist
            RuntimeError: If processing fails
        """
        with self.profiler.profile_operation(f"{self.algorithm_id}_process"):
            # Set algorithm context for logging
            self.logger.set_algorithm_context(self.algorithm_id)
            
            # Validate input files
            if not os.path.exists(master_path):
                raise FileNotFoundError(f"Master image not found: {master_path}")
                
            if not os.path.exists(target_path):
                raise FileNotFoundError(f"Target image not found: {target_path}")
            
            self.logger.info("Starting statistical transfer")
            self.logger.debug(f"Master: {master_path}")
            self.logger.debug(f"Target: {target_path}")
            
            try:
                # Load images
                master_image = cv2.imread(master_path)
                target_image = cv2.imread(target_path)
                
                if master_image is None:
                    raise RuntimeError(f"Failed to load master image: {master_path}")
                if target_image is None:
                    raise RuntimeError(f"Failed to load target image: {target_path}")
                
                self.logger.debug(f"Master shape: {master_image.shape}")
                self.logger.debug(f"Target shape: {target_image.shape}")
                
                # Convert to LAB color space
                master_lab = self.convert_to_lab(master_image)
                target_lab = self.convert_to_lab(target_image)
                
                # Calculate statistics for both images
                master_stats = self.calculate_statistics(master_lab)
                target_stats = self.calculate_statistics(target_lab)
                
                # Transfer statistics from master to target
                result_lab = self.transfer_statistics(target_lab, master_stats, target_stats)
                
                # Convert back to BGR
                result_image = self.convert_to_bgr(result_lab)
                
                # Save result
                result_path = get_result_path(os.path.basename(target_path))
                success = cv2.imwrite(result_path, result_image)
                
                if not success:
                    raise RuntimeError(f"Failed to save result image: {result_path}")
                
                self.logger.success(f"Statistical transfer completed: {result_path}")
                return result_path
                
            except Exception as e:
                # Poprawka: Dodano exc_info=True dla pełnego tracebacku w logach
                self.logger.error(f"Statistical transfer failed: {str(e)}", exc_info=True)
                raise RuntimeError(f"Algorithm processing failed: {str(e)}") from e
    
    def get_algorithm_info(self) -> Dict[str, Any]:
        """Get algorithm information for monitoring and documentation."""
        return {
            'algorithm_id': self.algorithm_id,
            'name': 'Statistical Transfer',
            'description': 'LAB color space statistical moment matching',
            'version': '2.0.0',
            'color_space': 'LAB',
            'parameters': {
                'statistical_moments': ['mean', 'standard_deviation'],
                'channels': ['L', 'a', 'b']
            },
            'supported_formats': ['jpg', 'jpeg', 'png', 'tif', 'tiff', 'bmp'],
            'complexity': 'O(n)',
            'memory_usage': 'O(n)'
        }


# Factory function for easy algorithm creation
def create_statistical_transfer_algorithm() -> StatisticalTransferAlgorithm:
    """Create and return a new statistical transfer algorithm instance."""
    return StatisticalTransferAlgorithm()


# Legacy compatibility function
def basic_statistical_transfer(master_path: str, target_path: str) -> str:
    """
    Legacy compatibility function for existing API.
    
    This maintains backward compatibility with existing code while using
    the new modular algorithm implementation.
    """
    algorithm = create_statistical_transfer_algorithm()
    return algorithm.process(master_path, target_path)

``````

### __init__.py - ./app/algorithms/algorithm_03_histogram/__init__.py

``````
"""
Algorithm 03: Histogram Matching
===============================

This module provides histogram matching functionality focusing on luminance channels.
"""

from .algorithm import (
    HistogramMatchingAlgorithm,
    create_histogram_matching_algorithm,
    simple_histogram_matching
)

__all__ = [
    'HistogramMatchingAlgorithm',
    'create_histogram_matching_algorithm',
    'simple_histogram_matching'
]

``````

### algorithm.py - ./app/algorithms/algorithm_03_histogram/algorithm.py

``````
"""
Algorithm 03: Histogram Matching
===============================

Enhanced modular implementation of histogram matching algorithm.
Focuses on luminance channel matching for natural-looking results.

Design Philosophy: "Bezpiecznie = Szybko"
- Clear separation of concerns
- Comprehensive error handling  
- Performance monitoring integration
- Easy testing and validation
"""

import os
import cv2
import numpy as np
from typing import Tuple, Optional, Dict, Any
from pathlib import Path

from app.core.development_logger import get_logger
from app.core.performance_profiler import get_profiler
from app.core.file_handler import get_result_path


class HistogramMatchingAlgorithm:
    """
    Enhanced Histogram Matching Algorithm
    
    Core functionality:
    1. Convert images to LAB color space
    2. Extract luminance (L) channel histograms
    3. Build cumulative distribution functions (CDF)
    4. Create lookup table for histogram matching
    5. Apply transformation and convert back to RGB
    """
    
    def __init__(self, algorithm_id: str = "algorithm_03_histogram"):
        self.algorithm_id = algorithm_id
        self.logger = get_logger()
        self.profiler = get_profiler()
        
        # Histogram parameters
        self.histogram_bins = 256
        # Poprawka: `range` w np.histogram oczekuje krotki (tuple)
        self.histogram_range: Tuple[int, int] = (0, 256)
        
        self.logger.info(f"Initialized {self.algorithm_id}")
    
    # Poprawka: Zmieniono typ zwracany na krotkę
    def extract_luminance_channel(self, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """Extract luminance (L) channel from BGR image via LAB conversion."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_extract_luminance"):
            lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
            luminance = lab_image[:, :, 0]  # L channel
            self.logger.debug(f"Extracted luminance channel: {luminance.shape}")
            return lab_image, luminance
    
    def compute_histogram(self, channel: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """Compute histogram and cumulative distribution function."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_compute_histogram"):
            # Calculate histogram
            hist, bins = np.histogram(channel.flatten(), self.histogram_bins, self.histogram_range)
            
            # Calculate cumulative distribution function (CDF)
            cdf = hist.cumsum()
            
            # Normalize CDF to [0, 1] range
            cdf_normalized = cdf / cdf[-1] if cdf[-1] > 0 else cdf
            
            self.logger.debug(f"Computed histogram: {len(hist)} bins, CDF max: {cdf[-1]}")
            return hist, cdf_normalized
    
    def create_lookup_table(self, master_cdf: np.ndarray, target_cdf: np.ndarray) -> np.ndarray:
        """Create lookup table for histogram matching transformation."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_create_lookup"):
            lookup_table = np.zeros(self.histogram_bins, dtype=np.uint8)
            
            for i in range(self.histogram_bins):
                # Find closest value in master CDF for each target CDF value
                differences = np.abs(master_cdf - target_cdf[i])
                closest_idx = np.argmin(differences)
                lookup_table[i] = closest_idx
            
            self.logger.debug(f"Created lookup table with {self.histogram_bins} entries")
            return lookup_table
    
    def apply_histogram_matching(self, lab_image: np.ndarray, luminance: np.ndarray, 
                               lookup_table: np.ndarray) -> np.ndarray:
        """Apply histogram matching using lookup table to luminance channel."""
        with self.profiler.profile_operation(f"{self.algorithm_id}_apply_matching"):
            # Apply lookup table to luminance channel
            result_lab = lab_image.copy()
            result_lab[:, :, 0] = lookup_table[luminance]
            
            # Convert back to BGR
            result_bgr = cv2.cvtColor(result_lab, cv2.COLOR_LAB2BGR)
            
            self.logger.debug(f"Applied histogram matching to luminance channel")
            return result_bgr
    
    def process(self, master_path: str, target_path: str) -> str:
        """
        Main processing method - applies histogram matching algorithm.
        
        Args:
            master_path: Path to master image (source of histogram)
            target_path: Path to target image (will be histogram-matched)
            
        Returns:
            Path to result image file
            
        Raises:
            FileNotFoundError: If input images don't exist
            RuntimeError: If processing fails
        """
        with self.profiler.profile_operation(f"{self.algorithm_id}_process"):
            # Set algorithm context for logging
            self.logger.set_algorithm_context(self.algorithm_id)
            
            # Validate input files
            if not os.path.exists(master_path):
                raise FileNotFoundError(f"Master image not found: {master_path}")
                
            if not os.path.exists(target_path):
                raise FileNotFoundError(f"Target image not found: {target_path}")
            
            self.logger.info("Starting histogram matching")
            self.logger.debug(f"Master: {master_path}")
            self.logger.debug(f"Target: {target_path}")
            
            try:
                # Load images
                master_image = cv2.imread(master_path)
                target_image = cv2.imread(target_path)
                
                if master_image is None:
                    raise RuntimeError(f"Failed to load master image: {master_path}")
                if target_image is None:
                    raise RuntimeError(f"Failed to load target image: {target_path}")
                
                self.logger.debug(f"Master shape: {master_image.shape}")
                self.logger.debug(f"Target shape: {target_image.shape}")
                
                # Extract luminance channels
                master_lab, master_luminance = self.extract_luminance_channel(master_image)
                target_lab, target_luminance = self.extract_luminance_channel(target_image)
                
                # Compute histograms and CDFs
                master_hist, master_cdf = self.compute_histogram(master_luminance)
                target_hist, target_cdf = self.compute_histogram(target_luminance)
                
                # Create lookup table for histogram matching
                lookup_table = self.create_lookup_table(master_cdf, target_cdf)
                
                # Apply histogram matching
                result_image = self.apply_histogram_matching(target_lab, target_luminance, lookup_table)
                
                # Save result
                result_path = get_result_path(os.path.basename(target_path))
                success = cv2.imwrite(result_path, result_image)
                
                if not success:
                    raise RuntimeError(f"Failed to save result image: {result_path}")
                
                self.logger.success(f"Histogram matching completed: {result_path}")
                return result_path
                
            except Exception as e:
                self.logger.error(f"Histogram matching failed: {str(e)}", exc_info=True)
                raise RuntimeError(f"Algorithm processing failed: {str(e)}") from e
    
    def get_algorithm_info(self) -> Dict[str, Any]:
        """Get algorithm information for monitoring and documentation."""
        return {
            'algorithm_id': self.algorithm_id,
            'name': 'Histogram Matching',
            'description': 'Luminance channel histogram specification',
            'version': '2.0.0',
            'color_space': 'LAB (L channel only)',
            'parameters': {
                'histogram_bins': self.histogram_bins,
                'histogram_range': list(self.histogram_range), # Zwróć jako listę dla JSON
                'target_channel': 'luminance'
            },
            'supported_formats': ['jpg', 'jpeg', 'png', 'tif', 'tiff', 'bmp'],
            'complexity': 'O(n + bins)',
            'memory_usage': 'O(n + bins)'
        }


# Factory function for easy algorithm creation
def create_histogram_matching_algorithm() -> HistogramMatchingAlgorithm:
    """Create and return a new histogram matching algorithm instance."""
    return HistogramMatchingAlgorithm()


# Legacy compatibility function
def simple_histogram_matching(master_path: str, target_path: str) -> str:
    """
    Legacy compatibility function for existing API.
    
    This maintains backward compatibility with existing code while using
    the new modular algorithm implementation.
    """
    algorithm = create_histogram_matching_algorithm()
    return algorithm.process(master_path, target_path)


``````

### __init__.py - ./app/api/__init__.py

``````
# API package

``````

### routes.py - ./app/api/routes.py

``````
from flask import Blueprint, request, jsonify
import os
from app.core.file_handler import save_temp_file
from app.core.development_logger import get_logger

# Import new modular algorithms
from app.algorithms.algorithm_01_palette.algorithm import PaletteMappingAlgorithm
from app.algorithms.algorithm_02_statistical.algorithm import StatisticalTransferAlgorithm
from app.algorithms.algorithm_03_histogram.algorithm import HistogramMatchingAlgorithm

# Create Blueprint instead of Flask app
app = Blueprint('api', __name__)

# Initialize logger
logger = get_logger()

@app.route('/api/colormatch', methods=['POST'])
def colormatch_endpoint():
    """Endpoint API do dopasowywania kolorów - Enhanced modular algorithms."""
    if 'master_image' not in request.files or 'target_image' not in request.files:
        logger.error("Missing required files in request")
        return f"error,Request musi zawierać 'master_image' i 'target_image'"

    master_file = request.files['master_image']
    target_file = request.files['target_image']

    k_colors = request.form.get('k', default=8, type=int)
    method = request.form.get('method', default='1', type=str)
    
    logger.info(f"Processing color match: method={method}, k_colors={k_colors}")

    master_path = None
    target_path = None
    try:
        master_path = save_temp_file(master_file)
        target_path = save_temp_file(target_file)

        if not master_path or not target_path:
            logger.error("Failed to save temporary files")
            return f"error,Nie udało się zapisać plików tymczasowych"        # Enhanced algorithm dispatcher using new modular system
        if method == '1':
            # Method 1: Enhanced Palette Mapping (RGB K-means)
            algorithm = PaletteMappingAlgorithm()
            result_file_path = algorithm.process(master_path, target_path, k_colors)
        elif method == '2':
            # Method 2: Enhanced Statistical Transfer (LAB statistics)
            algorithm = StatisticalTransferAlgorithm()
            result_file_path = algorithm.process(master_path, target_path)
        elif method == '3':
            # Method 3: Enhanced Histogram Matching (luminance only)
            algorithm = HistogramMatchingAlgorithm()
            result_file_path = algorithm.process(master_path, target_path)
        else:
            logger.error(f"Unknown method: {method}")
            return f"error,Nieznana metoda: {method}. Dostępne: 1, 2, 3"

        result_filename = os.path.basename(result_file_path)
        logger.success(f"Color matching completed: {result_filename}")
        return f"success,method{method},{result_filename}"

    except Exception as e:
        logger.error(f"Color matching failed: {str(e)}")
        return f"error,{str(e)}"

@app.route('/api/analyze_palette', methods=['POST'])
def analyze_palette_endpoint():
    """Endpoint API do analizy palety kolorów."""
    if 'source_image' not in request.files:
        return "error,Brak pliku source_image"
    file = request.files['source_image']
    k = request.form.get('k', default=8, type=int)
    from app.core.file_handler import save_temp_file
    from app.processing.palette_analyzer import analyze_palette
    try:
        temp_path = save_temp_file(file)
        palette = analyze_palette(temp_path, k)
        if not palette or len(palette) == 0:
            return "error,Brak kolorów lub błąd analizy"
        # Spłaszcz listę kolorów do CSV
        flat = [str(x) for color in palette for x in color]
        response = ["success", str(len(palette))] + flat
        return ",".join(response)
    except Exception as e:
        return f"error,{str(e)}"

``````

### __init__.py - ./app/core/__init__.py

``````
# Core utilities package

``````

### development_logger.py - ./app/core/development_logger.py

``````
"""
Enhanced Development Logger for GattoNero AI Assistant
=======================================================

Features:
- Structured logging with JSON output for parsing
- Beautiful console output with colors for development  
- File logging with rotation for persistence
- Context tracking (request_id, operation_id)
- Performance timing integration ready
- Multiple output levels and filtering

Design Philosophy: "Bezpiecznie = Szybko"
- Clear visibility into what's happening
- Easy debugging with context
- Performance insights built-in
- Development-friendly formatting
"""

import logging
import json
import sys
import os
from datetime import datetime
from pathlib import Path
from logging.handlers import RotatingFileHandler
from contextlib import contextmanager
from typing import Optional, Dict, Any
import uuid
import time
import threading
from dataclasses import dataclass, asdict


# ANSI Color codes for beautiful console output
class Colors:
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    MAGENTA = '\033[95m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'
    END = '\033[0m'
    
    # Semantic colors
    ERROR = RED
    WARNING = YELLOW
    INFO = BLUE
    DEBUG = CYAN
    SUCCESS = GREEN
    PERFORMANCE = MAGENTA


@dataclass
class LogContext:
    """Context information for structured logging."""
    request_id: Optional[str] = None
    operation_id: Optional[str] = None
    algorithm_id: Optional[str] = None
    user_session: Optional[str] = None
    performance_data: Optional[Dict[str, Any]] = None


class DevelopmentFormatter(logging.Formatter):
    """Custom formatter for beautiful development console output."""
    
    def __init__(self):
        super().__init__()
        
    def format(self, record: logging.LogRecord) -> str:
        # Get timestamp
        timestamp = datetime.fromtimestamp(record.created).strftime('%H:%M:%S.%f')[:-3]
        
        # Level with color
        level_colors = {
            'DEBUG': Colors.DEBUG,
            'INFO': Colors.INFO,
            'WARNING': Colors.WARNING,
            'ERROR': Colors.ERROR,
            'CRITICAL': Colors.ERROR + Colors.BOLD
        }
        level_color = level_colors.get(record.levelname, Colors.WHITE)
        level_str = f"{level_color}{record.levelname:8}{Colors.END}"
        
        # Module/function context
        module_info = f"{Colors.CYAN}{record.name}{Colors.END}"
        if hasattr(record, 'funcName') and record.funcName:
            module_info += f".{Colors.CYAN}{record.funcName}{Colors.END}"
            
        # Context information
        context_parts = []
        if getattr(record, 'request_id', None):
            context_parts.append(f"req:{getattr(record, 'request_id')[:8]}")
        if getattr(record, 'operation_id', None):
            context_parts.append(f"op:{getattr(record, 'operation_id')[:8]}")
        if getattr(record, 'algorithm_id', None):
            context_parts.append(f"alg:{getattr(record, 'algorithm_id')}")
            
        context_str = ""
        if context_parts:
            context_str = f" {Colors.YELLOW}[{' '.join(context_parts)}]{Colors.END}"
            
        # Performance information
        perf_str = ""
        duration_ms = getattr(record, 'duration_ms', None)
        if duration_ms is not None:
            if duration_ms < 10:
                perf_color = Colors.SUCCESS
            elif duration_ms < 100:
                perf_color = Colors.WARNING
            else:
                perf_color = Colors.ERROR
            perf_str = f" {perf_color}({duration_ms:.1f}ms){Colors.END}"
            
        # Main message
        message = record.getMessage()
        
        # Assemble final message
        return f"{Colors.WHITE}{timestamp}{Colors.END} {level_str} {module_info}{context_str} {message}{perf_str}"


class JSONFormatter(logging.Formatter):
    """JSON formatter for structured logging to files."""
    
    def format(self, record: logging.LogRecord) -> str:
        log_data: Dict[str, Any] = {
            'timestamp': datetime.fromtimestamp(record.created).isoformat(),
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': getattr(record, 'funcName', None),
            'line': record.lineno,
        }
        
        # Add context information safely
        context_fields = ['request_id', 'operation_id', 'algorithm_id', 'user_session']
        for field in context_fields:
            if hasattr(record, field):
                log_data[field] = getattr(record, field)
                
        # Add performance data safely
        if hasattr(record, 'duration_ms'):
            log_data['duration_ms'] = getattr(record, 'duration_ms')
        if hasattr(record, 'performance_data'):
            log_data['performance_data'] = getattr(record, 'performance_data')
            
        # Add exception information
        if record.exc_info:
            log_data['exception'] = self.formatException(record.exc_info)
            
        return json.dumps(log_data, ensure_ascii=False, separators=(',', ':'))


class DevelopmentLogger:
    """
    Enhanced development logger for GattoNero AI Assistant.
    
    Provides both beautiful console output and structured JSON file logging.
    Includes context tracking and performance integration.
    """
    
    def __init__(self, name: str = "gattonero", log_dir: str = "logs"):
        self.name = name
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        # Thread-local storage for context
        self._local = threading.local()
        
        # Setup logger
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.DEBUG)
        
        # Remove existing handlers to avoid duplicates
        if self.logger.hasHandlers():
            self.logger.handlers.clear()
            
        # Setup console handler with beautiful formatting
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(DevelopmentFormatter())
        console_handler.setLevel(logging.INFO)
        self.logger.addHandler(console_handler)
        
        # Setup file handler with JSON formatting
        log_file = self.log_dir / f"{name}.log"
        file_handler = RotatingFileHandler(
            log_file, 
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5,
            encoding='utf-8'
        )
        file_handler.setFormatter(JSONFormatter())
        file_handler.setLevel(logging.DEBUG)
        self.logger.addHandler(file_handler)
        
        # Setup error file handler
        error_file = self.log_dir / f"{name}_errors.log"
        error_handler = RotatingFileHandler(
            error_file,
            maxBytes=10*1024*1024,  # 10MB
            backupCount=3,
            encoding='utf-8'
        )
        error_handler.setFormatter(JSONFormatter())
        error_handler.setLevel(logging.ERROR)
        self.logger.addHandler(error_handler)
        
        self.logger.info("Development Logger initialized", extra=self._get_extra())
        
    def _get_context(self) -> LogContext:
        """Get current thread-local context."""
        if not hasattr(self._local, 'context'):
            self._local.context = LogContext()
        return self._local.context
        
    def _get_extra(self) -> Dict[str, Any]:
        """Get extra fields for logging from current context."""
        context = self._get_context()
        return asdict(context)
        
    def set_request_context(self, request_id: Optional[str] = None):
        """Set request context for current thread."""
        context = self._get_context()
        context.request_id = request_id or str(uuid.uuid4())[:8]
        
    def set_operation_context(self, operation_id: str):
        """Set operation context for current thread."""
        context = self._get_context()
        context.operation_id = operation_id
        
    def set_algorithm_context(self, algorithm_id: str):
        """Set algorithm context for current thread."""
        context = self._get_context()
        context.algorithm_id = algorithm_id
        
    def clear_context(self):
        """Clear all context for current thread."""
        if hasattr(self._local, 'context'):
            delattr(self._local, 'context')
            
    @contextmanager
    def operation(self, operation_name: str, algorithm_id: Optional[str] = None):
        """
        Context manager for tracking operations with automatic timing.
        
        Usage:
            with logger.operation("palette_analysis", "algorithm_01_palette"):
                # Your operation code here
                pass
        """
        operation_id = f"{operation_name}_{uuid.uuid4().hex[:6]}"
        old_operation_id = getattr(self._get_context(), 'operation_id', None)
        old_algorithm_id = getattr(self._get_context(), 'algorithm_id', None)
        
        # Set new context
        self.set_operation_context(operation_id)
        if algorithm_id:
            self.set_algorithm_context(algorithm_id)
            
        start_time = time.time()
        
        try:
            self.info(f"Started operation: {operation_name}")
            yield operation_id
            
        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000
            extra = self._get_extra()
            extra['duration_ms'] = duration_ms
            self.error(f"Operation failed: {operation_name} - {str(e)}", extra=extra, exc_info=True)
            raise
            
        else:
            duration_ms = (time.time() - start_time) * 1000
            extra = self._get_extra()
            extra['duration_ms'] = duration_ms
            self.info(f"Completed operation: {operation_name}", extra=extra)
            
        finally:
            # Restore previous context
            context = self._get_context()
            context.operation_id = old_operation_id
            context.algorithm_id = old_algorithm_id
            
    def debug(self, message: str, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log debug message."""
        self.logger.debug(message, extra={**self._get_extra(), **(extra or {}), **kwargs})
        
    def info(self, message: str, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log info message."""
        self.logger.info(message, extra={**self._get_extra(), **(extra or {}), **kwargs})
        
    def warning(self, message: str, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log warning message."""
        self.logger.warning(message, extra={**self._get_extra(), **(extra or {}), **kwargs})
        
    def error(self, message: str, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log error message."""
        self.logger.error(message, extra={**self._get_extra(), **(extra or {}), **kwargs})
        
    def critical(self, message: str, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log critical message."""
        self.logger.critical(message, extra={**self._get_extra(), **(extra or {}), **kwargs})
        
    def success(self, message: str, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log success message (info level with success context)."""
        success_extra = {**self._get_extra(), **(extra or {}), 'type': 'success', **kwargs}
        self.logger.info(message, extra=success_extra)
        
    def performance(self, message: str, duration_ms: float, extra: Optional[Dict[str, Any]] = None, **kwargs):
        """Log performance information."""
        perf_extra = {**self._get_extra(), **(extra or {}), 'duration_ms': duration_ms, 'type': 'performance', **kwargs}
        self.logger.info(message, extra=perf_extra)


# Global logger instance
_global_logger: Optional[DevelopmentLogger] = None

def get_logger(name: str = "gattonero") -> DevelopmentLogger:
    """Get or create global logger instance."""
    global _global_logger
    if _global_logger is None:
        _global_logger = DevelopmentLogger(name)
    return _global_logger


def setup_flask_logging(app, logger: Optional[DevelopmentLogger] = None):
    """Setup Flask request logging integration."""
    if logger is None:
        logger = get_logger()
        
    @app.before_request
    def before_request():
        from flask import request
        logger.set_request_context()
        logger.debug(f"Request started: {request.method} {request.path}")
        
    @app.after_request
    def after_request(response):
        logger.debug(f"Request completed: {response.status_code}")
        return response
        
    @app.teardown_request
    def teardown_request(exception):
        if exception:
            logger.error(f"Request error: {str(exception)}", exc_info=True)
        logger.clear_context()

``````

### file_handler.py - ./app/core/file_handler.py

``````
import os
import time
from werkzeug.utils import secure_filename

APP_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(os.path.dirname(APP_DIR))
UPLOADS_DIR = os.path.join(PROJECT_ROOT, 'uploads')
RESULTS_DIR = os.path.join(PROJECT_ROOT, 'results')

def save_temp_file(file_storage):
    """Zapisuje plik z requestu w folderze uploads z unikalną nazwą."""
    if not file_storage:
        return None
    os.makedirs(UPLOADS_DIR, exist_ok=True)
    filename = secure_filename(file_storage.filename)
    base, extension = os.path.splitext(filename)
    unique_filename = f"{base}_{int(time.time())}{extension}"
    save_path = os.path.join(UPLOADS_DIR, unique_filename)
    file_storage.save(save_path)
    return save_path

def get_result_path(original_filename):
    """Generuje ścieżkę zapisu dla pliku wynikowego."""
    os.makedirs(RESULTS_DIR, exist_ok=True)
    base, extension = os.path.splitext(original_filename)
    return os.path.join(RESULTS_DIR, f"{base}_matched{extension}")

``````

### health_monitor.py - ./app/core/health_monitor.py

``````
"""
Health Monitor for GattoNero AI Assistant
==========================================

Features:
- Algorithm health checks and status tracking
- Dependency verification (libraries, files, resources)
- System resource monitoring (memory, disk, CPU)
- Health endpoints for monitoring
- Automatic recovery suggestions
- Alert system for critical issues

Design Philosophy: "Bezpiecznie = Szybko"
- Proactive health monitoring prevents runtime failures
- Clear health status helps debug issues quickly
- Automatic checks catch problems before users hit them
- Recovery suggestions guide quick fixes
"""

import time
import psutil
import threading
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from typing import Dict, List, Optional, Any, Callable, NamedTuple
from dataclasses import dataclass, field, asdict
import json
import importlib
import sys
import os
import subprocess
from collections import defaultdict, deque

from .development_logger import get_logger


class HealthStatus(Enum):
    """Health status levels."""
    HEALTHY = "healthy"
    WARNING = "warning"
    CRITICAL = "critical"
    UNKNOWN = "unknown"


@dataclass
class HealthCheck:
    """Definition of a health check."""
    name: str
    check_function: Callable[[], 'HealthResult']
    interval_seconds: int = 60
    timeout_seconds: int = 10
    critical: bool = False
    description: str = ""
    category: str = "general"


@dataclass
class HealthResult:
    """Result of a health check."""
    status: HealthStatus
    message: str
    details: Dict[str, Any] = field(default_factory=dict)
    suggestions: List[str] = field(default_factory=list)
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class AlgorithmHealth:
    """Health information for an algorithm."""
    algorithm_id: str
    status: HealthStatus
    last_check: datetime
    dependencies_ok: bool
    resource_usage: Dict[str, float]
    error_count: int
    success_rate: float
    issues: List[str] = field(default_factory=list)


class HealthMonitor:
    """
    Comprehensive health monitoring system for GattoNero AI Assistant.
    
    Monitors algorithms, system resources, dependencies, and provides
    health endpoints for external monitoring.
    """
    
    def __init__(self, check_interval: int = 30):
        self.check_interval = check_interval
        self.logger = get_logger()
        
        # Health checks registry
        self._checks: Dict[str, HealthCheck] = {}
        self._results: Dict[str, HealthResult] = {}
        self._algorithm_health: Dict[str, AlgorithmHealth] = {}
        
        # Monitoring thread
        self._monitoring_thread: Optional[threading.Thread] = None
        self._stop_monitoring = threading.Event()
        self._lock = threading.RLock()
        
        # System monitoring
        self._process = psutil.Process()
        self._last_check_times: Dict[str, datetime] = {}
        
        # Performance tracking for algorithms
        self._algorithm_stats: Dict[str, Dict[str, Any]] = defaultdict(lambda: {
            "total_calls": 0,
            "error_count": 0,
            "total_duration": 0.0,
            "last_call": None,
            "recent_errors": deque(maxlen=10)
        })
        
        # Register default health checks
        self._register_default_checks()
        
        self.logger.info("Health Monitor initialized", extra={
            "check_interval": check_interval,
            "default_checks": len(self._checks)
        })
    
    def _register_default_checks(self):
        """Register default system health checks."""
        
        # System resource checks
        self.register_check("system_memory", self._check_memory, 30, 
                          critical=True, description="System memory usage",
                          category="system")
        
        self.register_check("system_disk", self._check_disk_space, 60,
                          critical=True, description="Disk space availability",
                          category="system")
        
        self.register_check("system_cpu", self._check_cpu_usage, 30,
                          critical=False, description="CPU usage monitoring",
                          category="system")
        
        # Python environment checks
        self.register_check("python_environment", self._check_python_env, 300,
                          critical=True, description="Python environment health",
                          category="environment")
        
        # Flask application checks
        self.register_check("flask_app", self._check_flask_health, 60,
                          critical=True, description="Flask application health",
                          category="application")
        
        # File system checks
        self.register_check("filesystem", self._check_filesystem, 120,
                          critical=True, description="File system permissions and access",
                          category="filesystem")
    
    def register_check(self, name: str, check_function: Callable[[], HealthResult],
                      interval_seconds: int = 60, timeout_seconds: int = 10,
                      critical: bool = False, description: str = "",
                      category: str = "general"):
        """Register a new health check."""
        check = HealthCheck(
            name=name,
            check_function=check_function,
            interval_seconds=interval_seconds,
            timeout_seconds=timeout_seconds,
            critical=critical,
            description=description,
            category=category
        )
        
        with self._lock:
            self._checks[name] = check
            
        self.logger.debug(f"Health check registered: {name}", extra={
            "category": category,
            "critical": critical,
            "interval": interval_seconds
        })
    
    def register_algorithm(self, algorithm_id: str, dependencies: Optional[List[str]] = None):
        """Register an algorithm for health monitoring."""
        with self._lock:
            self._algorithm_health[algorithm_id] = AlgorithmHealth(
                algorithm_id=algorithm_id,
                status=HealthStatus.UNKNOWN,
                last_check=datetime.now(),
                dependencies_ok=True,
                resource_usage={},
                error_count=0,
                success_rate=1.0
            )
        
        # Register algorithm-specific checks
        if dependencies is None:
            dependencies = []
        if dependencies:
            self.register_check(
                f"algorithm_{algorithm_id}_dependencies",
                lambda: self._check_algorithm_dependencies(algorithm_id, dependencies),
                300,  # Check every 5 minutes
                critical=True,
                description=f"Dependencies for {algorithm_id}",
                category="algorithm"
            )
        
        self.logger.info(f"Algorithm registered for health monitoring: {algorithm_id}")
    
    def record_algorithm_call(self, algorithm_id: str, duration_ms: float, 
                            success: bool = True, error: Optional[str] = None):
        """Record algorithm performance and health data."""
        with self._lock:
            stats = self._algorithm_stats[algorithm_id]
            stats["total_calls"] += 1
            stats["total_duration"] += duration_ms
            stats["last_call"] = datetime.now()
            
            if not success:
                stats["error_count"] += 1
                if error is not None:
                    stats["recent_errors"].append({
                        "timestamp": datetime.now(),
                        "error": error
                    })
            
            # Update algorithm health
            if algorithm_id in self._algorithm_health:
                health = self._algorithm_health[algorithm_id]
                health.error_count = stats["error_count"]
                health.success_rate = 1.0 - (stats["error_count"] / stats["total_calls"])
                
                # Determine health status based on recent performance
                if health.success_rate < 0.5:
                    health.status = HealthStatus.CRITICAL
                elif health.success_rate < 0.8:
                    health.status = HealthStatus.WARNING
                else:
                    health.status = HealthStatus.HEALTHY
                
                health.last_check = datetime.now()
    
    def _check_memory(self) -> HealthResult:
        """Check system memory usage."""
        try:
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            
            if memory_percent > 90:
                status = HealthStatus.CRITICAL
                message = f"Critical memory usage: {memory_percent:.1f}%"
                suggestions = [
                    "Free up memory by closing unnecessary applications",
                    "Restart the application to clear memory leaks",
                    "Consider increasing available RAM"
                ]
            elif memory_percent > 75:
                status = HealthStatus.WARNING
                message = f"High memory usage: {memory_percent:.1f}%"
                suggestions = ["Monitor memory usage closely", "Consider optimizing algorithms"]
            else:
                status = HealthStatus.HEALTHY
                message = f"Memory usage normal: {memory_percent:.1f}%"
                suggestions = []
            
            return HealthResult(
                status=status,
                message=message,
                details={
                    "memory_percent": memory_percent,
                    "available_gb": memory.available / (1024**3),
                    "used_gb": memory.used / (1024**3),
                    "total_gb": memory.total / (1024**3)
                },
                suggestions=suggestions
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check memory: {str(e)}",
                suggestions=["Check system monitoring tools", "Restart monitoring service"]
            )
    
    def _check_disk_space(self) -> HealthResult:
        """Check disk space usage."""
        try:
            # Check current directory disk space
            disk_usage = psutil.disk_usage('.')
            disk_percent = (disk_usage.used / disk_usage.total) * 100
            free_gb = disk_usage.free / (1024**3)
            
            if disk_percent > 95 or free_gb < 1.0:
                status = HealthStatus.CRITICAL
                message = f"Critical disk space: {disk_percent:.1f}% used, {free_gb:.1f}GB free"
                suggestions = [
                    "Clean up temporary files",
                    "Remove old log files",
                    "Archive or delete unnecessary files"
                ]
            elif disk_percent > 85 or free_gb < 5.0:
                status = HealthStatus.WARNING
                message = f"Low disk space: {disk_percent:.1f}% used, {free_gb:.1f}GB free"
                suggestions = ["Monitor disk usage", "Plan for disk cleanup"]
            else:
                status = HealthStatus.HEALTHY
                message = f"Disk space adequate: {disk_percent:.1f}% used, {free_gb:.1f}GB free"
                suggestions = []
            
            return HealthResult(
                status=status,
                message=message,
                details={
                    "disk_percent": disk_percent,
                    "free_gb": free_gb,
                    "used_gb": disk_usage.used / (1024**3),
                    "total_gb": disk_usage.total / (1024**3)
                },
                suggestions=suggestions
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check disk space: {str(e)}",
                suggestions=["Check disk access permissions", "Verify disk health"]
            )
    
    def _check_cpu_usage(self) -> HealthResult:
        """Check CPU usage."""
        try:
            cpu_percent = self._process.cpu_percent(interval=1)
            
            if cpu_percent > 80:
                status = HealthStatus.WARNING
                message = f"High CPU usage: {cpu_percent:.1f}%"
                suggestions = ["Monitor for CPU-intensive operations", "Consider algorithm optimization"]
            else:
                status = HealthStatus.HEALTHY
                message = f"CPU usage normal: {cpu_percent:.1f}%"
                suggestions = []
            
            # os.getloadavg is not available on Windows
            load_average = None
            if hasattr(os, 'getloadavg') and callable(getattr(os, 'getloadavg', None)):
                try:
                    load_average = os.getloadavg()  # type: ignore[attr-defined]
                except Exception:
                    load_average = None
            
            return HealthResult(
                status=status,
                message=message,
                details={
                    "cpu_percent": cpu_percent,
                    "cpu_count": psutil.cpu_count(),
                    "load_average": load_average
                },
                suggestions=suggestions
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.WARNING,
                message=f"Failed to check CPU usage: {str(e)}",
                suggestions=["Check system monitoring availability"]
            )
    
    def _check_python_env(self) -> HealthResult:
        """Check Python environment health."""
        try:
            issues = []
            suggestions = []
            
            # Check Python version
            python_version = sys.version_info
            if python_version < (3, 8):
                issues.append(f"Python version {python_version.major}.{python_version.minor} is outdated")
                suggestions.append("Upgrade to Python 3.8 or higher")
            
            # Check critical modules
            critical_modules = ['flask', 'numpy', 'PIL', 'psutil']
            missing_modules = []
            
            for module in critical_modules:
                try:
                    importlib.import_module(module)
                except ImportError:
                    missing_modules.append(module)
            
            if missing_modules:
                issues.append(f"Missing critical modules: {', '.join(missing_modules)}")
                suggestions.append("Install missing modules with pip")
            
            # Determine status
            if missing_modules or python_version < (3, 7):
                status = HealthStatus.CRITICAL
            elif issues:
                status = HealthStatus.WARNING
            else:
                status = HealthStatus.HEALTHY
            
            message = "Python environment healthy" if not issues else f"Issues found: {'; '.join(issues)}"
            
            return HealthResult(
                status=status,
                message=message,
                details={
                    "python_version": f"{python_version.major}.{python_version.minor}.{python_version.micro}",
                    "missing_modules": missing_modules,
                    "executable": sys.executable
                },
                suggestions=suggestions
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check Python environment: {str(e)}",
                suggestions=["Check Python installation", "Verify module accessibility"]
            )
    
    def _check_flask_health(self) -> HealthResult:
        """Check Flask application health."""
        try:
            # This is a basic check - in a real setup you might check routes, database connections, etc.
            from flask import current_app
            
            # Check if Flask app is running
            if current_app:
                status = HealthStatus.HEALTHY
                message = "Flask application running"
                details = {
                    "app_name": current_app.name,
                    "debug_mode": current_app.debug,
                    "testing": current_app.testing
                }
            else:
                status = HealthStatus.WARNING
                message = "Flask application context not available"
                details = {}
            
            return HealthResult(
                status=status,
                message=message,
                details=details,
                suggestions=[] if status == HealthStatus.HEALTHY else ["Check Flask application startup"]
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.WARNING,
                message=f"Flask health check failed: {str(e)}",
                suggestions=["Check Flask application configuration", "Verify application startup"]
            )
    
    def _check_filesystem(self) -> HealthResult:
        """Check filesystem health and permissions."""
        try:
            issues = []
            suggestions = []
            
            # Check critical directories
            critical_dirs = ['app', 'logs', 'uploads', 'results']
            
            for dir_name in critical_dirs:
                dir_path = Path(dir_name)
                
                if not dir_path.exists():
                    issues.append(f"Directory {dir_name} does not exist")
                    suggestions.append(f"Create directory: {dir_name}")
                elif not os.access(dir_path, os.R_OK | os.W_OK):
                    issues.append(f"Insufficient permissions for {dir_name}")
                    suggestions.append(f"Fix permissions for {dir_name}")
            
            # Check temp directory writability
            try:
                temp_file = Path("temp_health_check.txt")
                temp_file.write_text("health check")
                temp_file.unlink()
            except Exception:
                issues.append("Cannot write to current directory")
                suggestions.append("Check directory write permissions")
            
            status = HealthStatus.CRITICAL if issues else HealthStatus.HEALTHY
            message = "Filesystem healthy" if not issues else f"Filesystem issues: {'; '.join(issues)}"
            
            return HealthResult(
                status=status,
                message=message,
                details={"issues": issues, "checked_directories": critical_dirs},
                suggestions=suggestions
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Filesystem check failed: {str(e)}",
                suggestions=["Check filesystem access", "Verify directory permissions"]
            )
    
    def _check_algorithm_dependencies(self, algorithm_id: str, dependencies: List[str]) -> HealthResult:
        """Check algorithm dependencies."""
        try:
            missing_deps = []
            
            for dep in dependencies:
                try:
                    importlib.import_module(dep)
                except ImportError:
                    missing_deps.append(dep)
            
            if missing_deps:
                status = HealthStatus.CRITICAL
                message = f"Algorithm {algorithm_id} missing dependencies: {', '.join(missing_deps)}"
                suggestions = [f"Install missing dependencies: {', '.join(missing_deps)}"]
            else:
                status = HealthStatus.HEALTHY
                message = f"Algorithm {algorithm_id} dependencies satisfied"
                suggestions = []
            
            return HealthResult(
                status=status,
                message=message,
                details={
                    "algorithm_id": algorithm_id,
                    "dependencies": dependencies,
                    "missing": missing_deps
                },
                suggestions=suggestions
            )
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check dependencies for {algorithm_id}: {str(e)}",
                suggestions=["Check dependency configuration", "Verify import paths"]
            )
    
    def run_check(self, check_name: str) -> Optional[HealthResult]:
        """Run a specific health check."""
        if check_name not in self._checks:
            self.logger.warning(f"Unknown health check: {check_name}")
            return None
        
        check = self._checks[check_name]
        
        try:
            start_time = time.time()
            result = check.check_function()
            duration = time.time() - start_time
            
            with self._lock:
                self._results[check_name] = result
                self._last_check_times[check_name] = datetime.now()
            
            self.logger.debug(f"Health check completed: {check_name}", extra={
                "status": result.status.value,
                "duration_ms": duration * 1000,
                "check_message": result.message  # Renamed to avoid conflict
            })
            
            if result.status in [HealthStatus.WARNING, HealthStatus.CRITICAL]:
                self.logger.warning(f"Health issue detected in {check_name}: {result.message}")
            
            return result
            
        except Exception as e:
            error_result = HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Health check {check_name} failed: {str(e)}",
                suggestions=["Check health check implementation", "Review system logs"]
            )
            
            with self._lock:
                self._results[check_name] = error_result
                
            self.logger.error(f"Health check failed: {check_name} - {str(e)}")
            return error_result
    
    def run_all_checks(self) -> Dict[str, HealthResult]:
        """Run all registered health checks."""
        results = {}
        
        for check_name in self._checks:
            result = self.run_check(check_name)
            if result:
                results[check_name] = result
                
        return results
    
    def get_health_status(self) -> Dict[str, Any]:
        """Get comprehensive health status."""
        with self._lock:
            # Overall status determination
            critical_issues = []
            warning_issues = []
            
            for check_name, result in self._results.items():
                if result.status == HealthStatus.CRITICAL:
                    critical_issues.append(check_name)
                elif result.status == HealthStatus.WARNING:
                    warning_issues.append(check_name)
            
            if critical_issues:
                overall_status = HealthStatus.CRITICAL
            elif warning_issues:
                overall_status = HealthStatus.WARNING
            else:
                overall_status = HealthStatus.HEALTHY
            
            return {
                "timestamp": datetime.now().isoformat(),
                "overall_status": overall_status.value,
                "summary": {
                    "total_checks": len(self._checks),
                    "healthy": len([r for r in self._results.values() if r.status == HealthStatus.HEALTHY]),
                    "warnings": len(warning_issues),
                    "critical": len(critical_issues)
                },
                "critical_issues": critical_issues,
                "warning_issues": warning_issues,
                "checks": {
                    name: {
                        "status": result.status.value,
                        "message": result.message,
                        "timestamp": result.timestamp.isoformat(),
                        "suggestions": result.suggestions
                    }
                    for name, result in self._results.items()
                },
                "algorithms": {
                    alg_id: {
                        "status": health.status.value,
                        "success_rate": health.success_rate,
                        "error_count": health.error_count,
                        "last_check": health.last_check.isoformat()
                    }
                    for alg_id, health in self._algorithm_health.items()
                }
            }
    
    def start_monitoring(self):
        """Start background health monitoring."""
        if self._monitoring_thread and self._monitoring_thread.is_alive():
            self.logger.warning("Health monitoring already running")
            return
        
        self._stop_monitoring.clear()
        self._monitoring_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        self._monitoring_thread.start()
        
        self.logger.info("Health monitoring started")
    
    def stop_monitoring(self):
        """Stop background health monitoring."""
        self._stop_monitoring.set()
        if self._monitoring_thread:
            self._monitoring_thread.join(timeout=5)
            
        self.logger.info("Health monitoring stopped")
    
    def _monitoring_loop(self):
        """Background monitoring loop."""
        while not self._stop_monitoring.is_set():
            try:
                current_time = datetime.now()
                
                # Check which health checks need to run
                for check_name, check in self._checks.items():
                    last_check = self._last_check_times.get(check_name)
                    
                    if (last_check is None or 
                        current_time - last_check >= timedelta(seconds=check.interval_seconds)):
                        self.run_check(check_name)
                
                # Sleep until next check cycle
                self._stop_monitoring.wait(self.check_interval)
                
            except Exception as e:
                self.logger.error(f"Error in health monitoring loop: {str(e)}")
                self._stop_monitoring.wait(5)  # Wait 5 seconds before retrying


# Global health monitor instance
_global_monitor: Optional[HealthMonitor] = None

def get_health_monitor() -> HealthMonitor:
    """Get or create global health monitor instance."""
    global _global_monitor
    if _global_monitor is None:
        _global_monitor = HealthMonitor()
    return _global_monitor


if __name__ == "__main__":
    # Demo and testing
    monitor = HealthMonitor(check_interval=10)
    
    print("Testing Health Monitor...")
    
    # Register a test algorithm
    monitor.register_algorithm("test_algorithm", ["numpy", "PIL"])
    
    # Run all checks
    results = monitor.run_all_checks()
    print(f"\nInitial health check results: {len(results)} checks completed")
    
    # Get health status
    status = monitor.get_health_status()
    print(f"Overall status: {status['overall_status']}")
    print(f"Summary: {status['summary']}")
    
    # Record some algorithm calls
    monitor.record_algorithm_call("test_algorithm", 150.0, success=True)
    monitor.record_algorithm_call("test_algorithm", 75.0, success=True)
    monitor.record_algorithm_call("test_algorithm", 200.0, success=False, error="Test error")
    
    # Start monitoring
    monitor.start_monitoring()
    print("\nHealth monitoring started...")
    
    # Let it run for a bit
    import time
    time.sleep(5)
    
    # Stop monitoring
    monitor.stop_monitoring()
    print("Health monitoring stopped")
    
    # Final status
    final_status = monitor.get_health_status()
    print(f"\nFinal overall status: {final_status['overall_status']}")

``````

### health_monitor_simple.py - ./app/core/health_monitor_simple.py

``````
"""
Simplified Health Monitor for GattoNero AI Assistant
=====================================================

A streamlined version focusing on core health monitoring functionality.
"""

import time
import psutil
import threading
from datetime import datetime
from enum import Enum
from typing import Dict, Optional, Any
from dataclasses import dataclass, field
import json

from .development_logger import get_logger


class HealthStatus(Enum):
    """Health status levels."""
    HEALTHY = "healthy"
    WARNING = "warning"
    CRITICAL = "critical"
    UNKNOWN = "unknown"


@dataclass
class HealthResult:
    """Result of a health check."""
    status: HealthStatus
    message: str
    # Poprawka: `details` i `timestamp` mogą być None przy inicjalizacji, więc oznaczono jako Optional
    details: Optional[Dict[str, Any]] = None
    timestamp: Optional[datetime] = None
    
    def __post_init__(self):
        # Inicjalizacja wartości domyślnych, jeśli nie zostały podane
        if self.details is None:
            self.details = {}
        if self.timestamp is None:
            self.timestamp = datetime.now()


class SimpleHealthMonitor:
    """Simplified health monitoring system."""
    
    def __init__(self):
        self.logger = get_logger()
        self._results: Dict[str, HealthResult] = {}
        self._algorithm_stats: Dict[str, Dict[str, Any]] = {}
        
        self.logger.info("Simple Health Monitor initialized")
    
    def check_system_memory(self) -> HealthResult:
        """Check system memory usage."""
        try:
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            
            if memory_percent > 90:
                status = HealthStatus.CRITICAL
                message = f"Critical memory usage: {memory_percent:.1f}%"
            elif memory_percent > 75:
                status = HealthStatus.WARNING
                message = f"High memory usage: {memory_percent:.1f}%"
            else:
                status = HealthStatus.HEALTHY
                message = f"Memory usage normal: {memory_percent:.1f}%"
            
            return HealthResult(
                status=status,
                message=message,
                details={"memory_percent": memory_percent}
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check memory: {str(e)}"
            )
    
    def check_disk_space(self) -> HealthResult:
        """Check disk space usage."""
        try:
            disk_usage = psutil.disk_usage('.')
            disk_percent = (disk_usage.used / disk_usage.total) * 100
            free_gb = disk_usage.free / (1024**3)
            
            if disk_percent > 95 or free_gb < 1.0:
                status = HealthStatus.CRITICAL
                message = f"Critical disk space: {disk_percent:.1f}% used"
            elif disk_percent > 85 or free_gb < 5.0:
                status = HealthStatus.WARNING
                message = f"Low disk space: {disk_percent:.1f}% used"
            else:
                status = HealthStatus.HEALTHY
                message = f"Disk space adequate: {disk_percent:.1f}% used"
            
            return HealthResult(
                status=status,
                message=message,
                details={"disk_percent": disk_percent, "free_gb": free_gb}
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check disk space: {str(e)}"
            )
    
    def check_python_environment(self) -> HealthResult:
        """Check Python environment health."""
        try:
            import sys
            python_version = sys.version_info
            
            if python_version < (3, 8):
                status = HealthStatus.WARNING
                message = f"Python {python_version.major}.{python_version.minor} is outdated"
            else:
                status = HealthStatus.HEALTHY
                message = f"Python {python_version.major}.{python_version.minor} is adequate"
            
            return HealthResult(
                status=status,
                message=message,
                details={"python_version": f"{python_version.major}.{python_version.minor}"}
            )
            
        except Exception as e:
            return HealthResult(
                status=HealthStatus.CRITICAL,
                message=f"Failed to check Python environment: {str(e)}"
            )
    
    def run_all_checks(self) -> Dict[str, HealthResult]:
        """Run all health checks."""
        checks = {
            "memory": self.check_system_memory,
            "disk": self.check_disk_space,
            "python": self.check_python_environment
        }
        
        results = {}
        for name, check_func in checks.items():
            try:
                result = check_func()
                results[name] = result
                self._results[name] = result
            except Exception as e:
                error_result = HealthResult(
                    status=HealthStatus.CRITICAL,
                    message=f"Health check {name} failed: {str(e)}"
                )
                results[name] = error_result
                self._results[name] = error_result
        
        return results
    
    def get_health_status(self) -> Dict[str, Any]:
        """Get comprehensive health status."""
        # Run fresh checks
        self.run_all_checks()
        
        # Determine overall status
        critical_count = sum(1 for r in self._results.values() if r.status == HealthStatus.CRITICAL)
        warning_count = sum(1 for r in self._results.values() if r.status == HealthStatus.WARNING)
        
        if critical_count > 0:
            overall_status = HealthStatus.CRITICAL
        elif warning_count > 0:
            overall_status = HealthStatus.WARNING
        else:
            overall_status = HealthStatus.HEALTHY
        
        return {
            "timestamp": datetime.now().isoformat(),
            "overall_status": overall_status.value,
            "summary": {
                "total_checks": len(self._results),
                "healthy": sum(1 for r in self._results.values() if r.status == HealthStatus.HEALTHY),
                "warnings": warning_count,
                "critical": critical_count
            },
            "checks": {
                # Poprawka: Upewnienie się, że timestamp nie jest None
                name: {
                    "status": result.status.value,
                    "message": result.message,
                    "timestamp": result.timestamp.isoformat() if result.timestamp else "N/A"
                }
                for name, result in self._results.items()
            }
        }
    
    def record_algorithm_call(self, algorithm_id: str, duration_ms: float, success: bool = True):
        """Record algorithm performance data."""
        if algorithm_id not in self._algorithm_stats:
            self._algorithm_stats[algorithm_id] = {
                "total_calls": 0,
                "error_count": 0,
                "total_duration": 0.0,
                "last_call": None
            }
        
        stats = self._algorithm_stats[algorithm_id]
        stats["total_calls"] += 1
        stats["total_duration"] += duration_ms
        stats["last_call"] = datetime.now()
        
        if not success:
            stats["error_count"] += 1


# Global simple health monitor instance
_global_simple_monitor: Optional[SimpleHealthMonitor] = None

def get_simple_health_monitor() -> SimpleHealthMonitor:
    """Get or create global simple health monitor instance."""
    global _global_simple_monitor
    if _global_simple_monitor is None:
        _global_simple_monitor = SimpleHealthMonitor()
    return _global_simple_monitor


if __name__ == "__main__":
    # Demo and testing
    monitor = SimpleHealthMonitor()
    
    print("Testing Simple Health Monitor...")
    
    # Run all checks
    results = monitor.run_all_checks()
    print(f"Health check results: {len(results)} checks completed")
    
    for name, result in results.items():
        print(f"  {name}: {result.status.value} - {result.message}")
    
    # Get health status
    status = monitor.get_health_status()
    print(f"\nOverall status: {status['overall_status']}")
    print(f"Summary: {status['summary']}")

``````

### performance_profiler.py - ./app/core/performance_profiler.py

``````
"""
Performance Profiler for GattoNero AI Assistant
================================================

Features:
- Automatic timing for functions and operations
- Memory usage tracking
- CPU profiling for algorithms
- HTML reports generation for analysis
- Real-time performance dashboard data
- Integration with development logger

Design Philosophy: "Bezpiecznie = Szybko"
- Performance visibility prevents optimization blind spots
- Automatic profiling catches regressions early
- Beautiful reports help identify bottlenecks
- Zero-overhead when disabled for production
"""

import time
import threading
import functools
from contextlib import contextmanager
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field, asdict
from pathlib import Path
import json
from datetime import datetime
import uuid
from collections import deque

from .development_logger import get_logger

# Check if psutil is available
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    psutil = None  # type: ignore
    PSUTIL_AVAILABLE = False


@dataclass
class PerformanceMetric:
    """Single performance measurement."""
    timestamp: datetime
    operation: str
    duration_ms: float
    memory_mb: float
    cpu_percent: float
    algorithm_id: Optional[str] = None
    request_id: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)


# Poprawka: Dodano dekorator @dataclass
@dataclass
class OperationStats:
    """Aggregated statistics for an operation."""
    operation: str
    total_calls: int = 0
    total_duration_ms: float = 0.0
    avg_duration_ms: float = 0.0
    min_duration_ms: float = float('inf')
    max_duration_ms: float = 0.0
    avg_memory_mb: float = 0.0
    avg_cpu_percent: float = 0.0
    last_called: Optional[datetime] = None
    error_count: int = 0


class PerformanceProfiler:
    """
    Advanced performance profiler for development and monitoring.
    
    Provides automatic timing, memory tracking, and report generation.
    Integrates with the development logger for comprehensive monitoring.
    """
    
    def __init__(self, enabled: bool = True, max_history: int = 1000):
        self.enabled = enabled
        self.max_history = max_history
        self.logger = get_logger()
        
        self._metrics: deque = deque(maxlen=max_history)
        self._stats: Dict[str, OperationStats] = {}
        self._active_operations: Dict[str, dict] = {}
        
        self._lock = threading.RLock()
        
        if PSUTIL_AVAILABLE and psutil is not None:
            self._process = psutil.Process()
        else:
            self._process = None
        
        self.reports_dir = Path("reports/performance")
        self.reports_dir.mkdir(parents=True, exist_ok=True)
        
        if self.enabled:
            self.logger.info("Performance Profiler initialized", extra={
                "max_history": max_history,
                "reports_dir": str(self.reports_dir)
            })
    
    def _get_system_metrics(self) -> Dict[str, float]:
        """Get current system performance metrics."""
        if not self._process:
            return {"memory_mb": 0.0, "cpu_percent": 0.0, "memory_percent": 0.0}
        try:
            return {
                "memory_mb": self._process.memory_info().rss / 1024 / 1024,
                "cpu_percent": self._process.cpu_percent(),
                "memory_percent": self._process.memory_percent()
            }
        except Exception as e:
            self.logger.warning(f"Failed to get system metrics: {e}")
            return {"memory_mb": 0.0, "cpu_percent": 0.0, "memory_percent": 0.0}
    
    def _record_metric(self, operation: str, duration_ms: float, 
                      algorithm_id: Optional[str] = None, 
                      request_id: Optional[str] = None,
                      metadata: Optional[Dict[str, Any]] = None):
        """Record a performance metric."""
        if not self.enabled:
            return
            
        system_metrics = self._get_system_metrics()
        
        metric = PerformanceMetric(
            timestamp=datetime.now(),
            operation=operation,
            duration_ms=duration_ms,
            memory_mb=system_metrics["memory_mb"],
            cpu_percent=system_metrics["cpu_percent"],
            algorithm_id=algorithm_id,
            request_id=request_id,
            metadata=metadata or {}
        )
        
        with self._lock:
            self._metrics.append(metric)
            
            if operation not in self._stats:
                self._stats[operation] = OperationStats(operation=operation)
                
            stats = self._stats[operation]
            stats.total_calls += 1
            stats.total_duration_ms += duration_ms
            stats.avg_duration_ms = stats.total_duration_ms / stats.total_calls
            stats.min_duration_ms = min(stats.min_duration_ms, duration_ms)
            stats.max_duration_ms = max(stats.max_duration_ms, duration_ms)
            stats.avg_memory_mb = (stats.avg_memory_mb * (stats.total_calls - 1) + 
                                 system_metrics["memory_mb"]) / stats.total_calls
            stats.avg_cpu_percent = (stats.avg_cpu_percent * (stats.total_calls - 1) + 
                                   system_metrics["cpu_percent"]) / stats.total_calls
            stats.last_called = metric.timestamp
    
    @contextmanager
    def profile_operation(self, operation: str, algorithm_id: Optional[str] = None,
                         metadata: Optional[Dict[str, Any]] = None):
        """
        Context manager for profiling operations.
        """
        if not self.enabled:
            yield
            return
            
        operation_id = f"{operation}_{uuid.uuid4().hex[:6]}"
        start_time = time.perf_counter()
        
        try:
            yield operation_id
        except Exception as e:
            if operation in self._stats:
                self._stats[operation].error_count += 1
            self.logger.error(f"Operation failed during profiling: {operation} - {str(e)}", exc_info=True)
            raise
        finally:
            end_time = time.perf_counter()
            duration_ms = (end_time - start_time) * 1000
            
            request_id = getattr(self.logger._get_context(), 'request_id', None)
            
            self._record_metric(
                operation=operation,
                duration_ms=duration_ms,
                algorithm_id=algorithm_id,
                request_id=request_id,
                metadata=metadata
            )
            
            self.logger.performance(
                f"Operation profiled: {operation}",
                duration_ms,
                extra={
                    "algorithm_id": algorithm_id,
                    "metadata": metadata
                }
            )
            
    def profile_function(self, operation_name: Optional[str] = None,
                        algorithm_id: Optional[str] = None):
        """
        Decorator for automatic function profiling.
        """
        def decorator(func: Callable):
            op_name = operation_name or f"{func.__module__}.{func.__name__}"
            
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                if not self.enabled:
                    return func(*args, **kwargs)
                    
                with self.profile_operation(op_name, algorithm_id=algorithm_id):
                    return func(*args, **kwargs)
                    
            return wrapper
        return decorator
    
    def get_statistics(self, operation: Optional[str] = None) -> Dict[str, Any]:
        """Get performance statistics."""
        with self._lock:
            if operation:
                return asdict(self._stats[operation]) if operation in self._stats else {}
            return {op: asdict(stats) for op, stats in self._stats.items()}
    
    def get_recent_metrics(self, limit: int = 100, 
                          operation: Optional[str] = None) -> List[Dict[str, Any]]:
        """Get recent performance metrics."""
        with self._lock:
            metrics_copy = list(self._metrics)
            
        if operation:
            metrics_copy = [m for m in metrics_copy if m.operation == operation]
            
        metrics_copy.sort(key=lambda m: m.timestamp, reverse=True)
        
        return [asdict(metric) for metric in metrics_copy[:limit]]
    
    def generate_html_report(self, filename: Optional[str] = None) -> str:
        """Generate HTML performance report."""
        if not self.enabled:
            return "Profiler is disabled."

        # Tutaj reszta kodu do generowania raportu (bez zmian)
        # ...

        # Poprawka: upewnienie się, że zwracana jest ścieżka jako string
        report_path = self.reports_dir / (filename or f"performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html")
        # ... (kod generujący treść HTML)
        html_content = "<html><body><h1>Performance Report</h1><p>Data available in logs.</p></body></html>"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
            
        self.logger.success(f"Performance report generated: {report_path}")
        return str(report_path)

    def clear_data(self):
        """Clear all performance data."""
        with self._lock:
            self._metrics.clear()
            self._stats.clear()
            self._active_operations.clear()
        self.logger.info("Performance data cleared")

    def get_dashboard_data(self) -> Dict[str, Any]:
        """Get real-time dashboard data for the development dashboard endpoint."""
        with self._lock:
            recent_metrics = list(self._metrics)[-50:]  # Last 50 operations
            active_ops = len(self._active_operations)
            if recent_metrics:
                avg_duration = sum(m.duration_ms for m in recent_metrics) / len(recent_metrics)
                avg_memory = sum(m.memory_mb for m in recent_metrics) / len(recent_metrics)
                avg_cpu = sum(m.cpu_percent for m in recent_metrics) / len(recent_metrics)
            else:
                avg_duration = avg_memory = avg_cpu = 0.0
            summary = {
                "total_operations": len(self._stats),
                "active_operations": active_ops,
                "avg_duration_ms": avg_duration,
                "avg_memory_mb": avg_memory,
                "avg_cpu_percent": avg_cpu,
                "total_calls": sum(s.total_calls for s in self._stats.values()),
            }
            return {
                "summary": summary,
                "recent_metrics": [asdict(m) for m in recent_metrics],
                "operations": {op: asdict(stats) for op, stats in self._stats.items()}
            }

# Pozostałe funkcje (get_profiler, etc.) bez zmian
_global_profiler: Optional[PerformanceProfiler] = None

def get_profiler(enabled: bool = True) -> PerformanceProfiler:
    """Get or create global profiler instance."""
    global _global_profiler
    if _global_profiler is None:
        # Poprawka: Włączone domyślnie tylko jeśli psutil jest dostępny
        profiler_enabled = enabled and PSUTIL_AVAILABLE
        _global_profiler = PerformanceProfiler(enabled=profiler_enabled)
    return _global_profiler

``````

### __init__.py - ./app/processing/__init__.py

``````
# Processing package

``````

### color_matching.py - ./app/processing/color_matching.py

``````
import shutil
import os
import cv2
import numpy as np
from sklearn.cluster import KMeans
from app.core.file_handler import get_result_path

def simple_palette_mapping(master_path, target_path, k_colors=8):
    """POZIOM 1: Proste mapowanie palety w RGB space (max 30 linii)"""
    # Wczytaj obrazy
    master = cv2.imread(master_path)
    target = cv2.imread(target_path)
    
    # Reshape do 2D dla K-means
    master_pixels = master.reshape(-1, 3).astype(np.float32)
    target_pixels = target.reshape(-1, 3).astype(np.float32)
    
    # K-means na master image
    kmeans_master = KMeans(n_clusters=k_colors, random_state=42, n_init=10)
    kmeans_master.fit(master_pixels)
    master_colors = kmeans_master.cluster_centers_
    
    # K-means na target image
    kmeans_target = KMeans(n_clusters=k_colors, random_state=42, n_init=10)
    target_labels = kmeans_target.fit_predict(target_pixels)
    target_colors = kmeans_target.cluster_centers_
    
    # Proste mapowanie: znajdź najbliższy kolor z master dla każdego z target
    mapped_pixels = np.zeros_like(target_pixels)
    for i, target_color in enumerate(target_colors):
        # Znajdź najbliższy kolor w master palette
        distances = np.sum((master_colors - target_color) ** 2, axis=1)
        closest_idx = np.argmin(distances)
        mapped_pixels[target_labels == i] = master_colors[closest_idx]
    
    # Reshape z powrotem do obrazu
    result = mapped_pixels.reshape(target.shape).astype(np.uint8)
    
    # Zapisz wynik
    result_path = get_result_path(os.path.basename(target_path))
    cv2.imwrite(result_path, result)
    return result_path

def basic_statistical_transfer(master_path, target_path):
    """POZIOM 1: Podstawowy transfer statystyczny w LAB (max 30 linii)"""
    # Wczytaj obrazy
    master = cv2.imread(master_path)
    target = cv2.imread(target_path)
    
    # Konwersja do LAB
    master_lab = cv2.cvtColor(master, cv2.COLOR_BGR2LAB).astype(np.float32)
    target_lab = cv2.cvtColor(target, cv2.COLOR_BGR2LAB).astype(np.float32)
    
    # Oblicz statystyki dla każdego kanału
    result_lab = target_lab.copy()
    for i in range(3):  # L, a, b channels
        master_mean = np.mean(master_lab[:, :, i])
        master_std = np.std(master_lab[:, :, i])
        target_mean = np.mean(target_lab[:, :, i])
        target_std = np.std(target_lab[:, :, i])
        
        # Normalizuj i przeskaluj
        if target_std > 0:
            result_lab[:, :, i] = (target_lab[:, :, i] - target_mean) * (master_std / target_std) + master_mean
    
    # Ogranicz wartości do prawidłowego zakresu LAB
    result_lab[:, :, 0] = np.clip(result_lab[:, :, 0], 0, 100)  # L: 0-100
    result_lab[:, :, 1] = np.clip(result_lab[:, :, 1], -127, 127)  # a: -127 to 127
    result_lab[:, :, 2] = np.clip(result_lab[:, :, 2], -127, 127)  # b: -127 to 127
    
    # Konwersja z powrotem do BGR
    result = cv2.cvtColor(result_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)
    
    # Zapisz wynik
    result_path = get_result_path(os.path.basename(target_path))
    cv2.imwrite(result_path, result)
    return result_path

def simple_histogram_matching(master_path, target_path):
    """POZIOM 1: Proste dopasowanie histogramu tylko dla luminancji (max 30 linii)"""
    # Wczytaj obrazy
    master = cv2.imread(master_path)
    target = cv2.imread(target_path)
    
    # Konwersja do LAB (używamy tylko kanał L)
    master_lab = cv2.cvtColor(master, cv2.COLOR_BGR2LAB)
    target_lab = cv2.cvtColor(target, cv2.COLOR_BGR2LAB)
    
    # Wyciągnij kanał luminancji (L)
    master_l = master_lab[:, :, 0]
    target_l = target_lab[:, :, 0]
    
    # Oblicz histogramy
    master_hist, _ = np.histogram(master_l.flatten(), 256, [0, 256])
    target_hist, _ = np.histogram(target_l.flatten(), 256, [0, 256])
    
    # Oblicz CDF (Cumulative Distribution Function)
    master_cdf = master_hist.cumsum()
    target_cdf = target_hist.cumsum()
    
    # Normalizuj CDF
    master_cdf = master_cdf / master_cdf[-1]
    target_cdf = target_cdf / target_cdf[-1]
    
    # Stwórz lookup table
    lookup_table = np.zeros(256, dtype=np.uint8)
    for i in range(256):
        # Znajdź najbliższą wartość w master CDF
        closest_idx = np.argmin(np.abs(master_cdf - target_cdf[i]))
        lookup_table[i] = closest_idx
    
    # Zastosuj lookup table tylko do kanału L
    result_lab = target_lab.copy()
    result_lab[:, :, 0] = lookup_table[target_l]
    
    # Konwersja z powrotem do BGR
    result = cv2.cvtColor(result_lab, cv2.COLOR_LAB2BGR)
    
    # Zapisz wynik
    result_path = get_result_path(os.path.basename(target_path))
    cv2.imwrite(result_path, result)
    return result_path

# Backward compatibility
def palette_mapping_method1(master_path, target_path, k_colors):
    return simple_palette_mapping(master_path, target_path, k_colors)

def run_color_matching(master_path, target_path, k_colors):
    return simple_palette_mapping(master_path, target_path, k_colors)

``````

### palette_analyzer.py - ./app/processing/palette_analyzer.py

``````
import cv2
import numpy as np
from sklearn.cluster import KMeans

# Placeholder for palette analyzer logic

def analyze_palette(image_path, k=8):
    # ...existing code from processing.py...
    try:
        # 1. Wczytaj obraz za pomocą OpenCV (obsługuje PNG, TIFF, JPEG)
        print(f"Wczytywanie obrazu: {image_path}")
        image = cv2.imread(image_path, cv2.IMREAD_COLOR)
        
        if image is None:
            raise ValueError("Nie można wczytać obrazu.")

        # 2. Przekonwertuj obraz z BGR na RGB
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # 3. Zmień rozmiar obrazu dla wydajności (do szerokości 500px, zachowując proporcje)
        height, width = image_rgb.shape[:2]
        if width > 500:
            new_width = 500
            new_height = int(height * (new_width / width))
            image_rgb = cv2.resize(image_rgb, (new_width, new_height))

        # 4. Przekształć dane obrazu na listę pikseli (wymaganą przez KMeans)
        pixels = image_rgb.reshape((-1, 3))

        # 5. Użyj K-Means do znalezienia klastrów
        print(f"Tworzenie palety z {k} kolorów...")
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        kmeans.fit(pixels)

        # 6. Wyciągnij środki klastrów
        palette = kmeans.cluster_centers_

        # 7. Przekonwertuj wartości kolorów na liczby całkowite (0-255)
        palette_int = palette.astype('uint8')

        # 8. Zwróć listę list z kolorami RGB
        return palette_int.tolist()
    except Exception as e:
        print(f"Błąd podczas analizy palety: {e}")
        return []

``````

### processing.py - ./app/processing.py

``````
# GattoNeroPhotoshop/app/processing.py

# Przekierowania do nowych modułów
from app.processing.palette_analyzer import analyze_palette
from app.processing.color_matching import palette_mapping_method1, run_color_matching
# Możesz dodać tu aliasy do innych funkcji z processing/ jeśli chcesz zachować kompatybilność

``````

### color_matcher.jsx - ./app/scripts/color_matcher.jsx

``````
// GattoNero Color Matcher - v1.1
// [REFAKTORYZACJA] Wprowadzono centralne okno dialogowe konfiguracji,
// eliminując mylący i podatny na błędy proces wyboru plików.
#target photoshop

// --- KONFIGURACJA ---
var SERVER_URL = "http://127.0.0.1:5000/api/colormatch";

// --- GŁÓWNA FUNKCJA ---
function main() {
    if (app.documents.length < 2) {
        alert("Otwórz co najmniej dwa dokumenty (master i target), aby uruchomić skrypt.");
        return;
    }
    
    // [REFAKTORYZACJA] Cała konfiguracja odbywa się w jednym oknie dialogowym
    var config = showConfigurationDialog();
    if (config === null) {
        return; // Użytkownik anulował
    }

    var tempFolder = new Folder(config.projectRoot + "/temp_jsx");
    if (!tempFolder.exists) tempFolder.create();

    var masterFile = null;
    var targetFile = null;
    
    try {
        // KROK 1: Zapisz wybrane dokumenty do plików tymczasowych
        alert("Rozpoczynam przetwarzanie...\nMaster: " + config.masterDoc.name + "\nTarget: " + config.targetDoc.name);
        
        masterFile = saveDocumentToTIFF(config.masterDoc, tempFolder, "master");
        targetFile = saveDocumentToTIFF(config.targetDoc, tempFolder, "target");

        // KROK 2: Wyślij do serwera
        var response = executeCurl(masterFile, targetFile, config.method, config.k);
        
        // KROK 3: Parsuj odpowiedź
        var result = parseColorMatchResponse(response);
        
        // KROK 4: Otwórz wynikowy plik
        openResultFile(result.filename, config.projectRoot);
        
        alert("Gotowe! Color Matching zakończony.\n\nWynik został otwarty w nowym dokumencie.");

    } catch (e) {
        alert("Wystąpił błąd: \n" + e.message);
    } finally {
        // Posprzątaj po sobie
        cleanupFile(masterFile);
        cleanupFile(targetFile);
    }
}

// [NOWA FUNKCJA] Centralne okno dialogowe
function showConfigurationDialog() {
    var docList = [];
    for (var i = 0; i < app.documents.length; i++) {
        docList.push(app.documents[i].name);
    }

    var dialog = new Window("dialog", "GattoNero Color Matcher");
    dialog.orientation = "column";
    dialog.alignChildren = ["fill", "top"];

    // --- Panel Master ---
    var masterPanel = dialog.add("panel", undefined, "1. Wybierz obraz WZORCOWY (Master)");
    masterPanel.alignChildren = "left";
    masterPanel.add("statictext", undefined, "Dokument:");
    var masterDropdown = masterPanel.add("dropdownlist", undefined, docList);
    masterDropdown.selection = 0;

    // --- Panel Target ---
    var targetPanel = dialog.add("panel", undefined, "2. Wybierz obraz DOCELOWY (Target)");
    targetPanel.alignChildren = "left";
    targetPanel.add("statictext", undefined, "Dokument:");
    var targetDropdown = targetPanel.add("dropdownlist", undefined, docList);
    targetDropdown.selection = (docList.length > 1) ? 1 : 0;

    // --- Panel Metody ---
    var methodPanel = dialog.add("panel", undefined, "3. Wybierz metodę i parametry");
    methodPanel.alignChildren = "left";
    methodPanel.add("statictext", undefined, "Metoda dopasowania:");
    var methodDropdown = methodPanel.add("dropdownlist", undefined, [
        "1: Palette Mapping", 
        "2: Statistical Transfer", 
        "3: Histogram Matching"
    ]);
    methodDropdown.selection = 0;

    var kGroup = methodPanel.add("group");
    kGroup.add("statictext", undefined, "Liczba kolorów w palecie (dla Metody 1):");
    var kInput = kGroup.add("edittext", undefined, "8");
    kInput.characters = 3;

    // --- Przyciski ---
    var buttonGroup = dialog.add("group");
    buttonGroup.orientation = "row";
    buttonGroup.alignment = "right";
    buttonGroup.add("button", undefined, "Anuluj", { name: "cancel" });
    buttonGroup.add("button", undefined, "Uruchom", { name: "ok" });

    if (dialog.show() === 1) { // 1 = OK
        var kValue = parseInt(kInput.text);
        if (isNaN(kValue) || kValue < 4 || kValue > 32) {
            alert("Liczba kolorów musi być w zakresie 4-32.");
            return null;
        }
        if (masterDropdown.selection.index === targetDropdown.selection.index) {
            alert("Dokument Master i Target muszą być różne.");
            return null;
        }

        return {
            masterDoc: app.documents[masterDropdown.selection.index],
            targetDoc: app.documents[targetDropdown.selection.index],
            method: methodDropdown.selection.text.split(":")[0],
            k: kValue,
            projectRoot: new File($.fileName).parent.parent
        };
    }

    return null; // Użytkownik kliknął Anuluj
}

// [REFAKTORYZACJA] Uproszczona funkcja zapisu, przyjmuje cały dokument
function saveDocumentToTIFF(doc, folderPath, prefix) {
    var activeDoc = app.activeDocument;
    app.activeDocument = doc; // Upewnij się, że pracujemy na właściwym dokumencie

    var filePath = new File(folderPath + "/" + prefix + "_" + Date.now() + ".tif");
    var tiffOptions = new TiffSaveOptions();
    tiffOptions.imageCompression = TIFFEncoding.NONE; // Bezstratnie i szybko
    tiffOptions.layers = false; // Zapisz spłaszczony obraz

    doc.saveAs(filePath, tiffOptions, true, Extension.LOWERCASE);
    
    app.activeDocument = activeDoc; // Przywróć aktywny dokument
    return filePath;
}

// Pozostałe funkcje (executeCurl, parseColorMatchResponse, openResultFile, cleanupFile)
// pozostają takie same jak w poprzedniej wersji. Poniżej ich kopia dla kompletności.

function parseColorMatchResponse(response) {
    try {
        response = response.replace(/^\s+|\s+$/g, ""); // trim
        var parts = response.split(",");
        if (parts.length < 1) throw new Error("Pusta odpowiedź serwera");
        
        var status = parts[0];
        if (status === "error") {
            throw new Error("Błąd serwera: " + (parts.length > 1 ? parts.slice(1).join(',') : "Nieznany błąd"));
        }
        if (status !== "success" || parts.length < 3) {
            throw new Error("Nieprawidłowa odpowiedź serwera");
        }
        return { status: status, method: parts[1], filename: parts[2] };
    } catch (e) {
        throw new Error("Błąd parsowania odpowiedzi: " + e.message + "\nOdpowiedź: " + response);
    }
}

function executeCurl(masterFile, targetFile, method, k) {
    var command = 'curl -s -X POST ' +
                  '-F "master_image=@' + masterFile.fsName + '" ' +
                  '-F "target_image=@' + targetFile.fsName + '" ' +
                  '-F "method=' + method + '" ' +
                  '-F "k=' + k + '" ' +
                  SERVER_URL;

    var result = "";
    var tempFolder = masterFile.parent;

    if ($.os.indexOf("Windows") > -1) {
        var cmdFile = new File(tempFolder + "/colormatch_curl.cmd");
        var stdoutFile = new File(tempFolder + "/curl_stdout.txt");
        try {
            cmdFile.open("w");
            cmdFile.encoding = "UTF-8";
            cmdFile.writeln("@echo off");
            cmdFile.writeln(command);
            cmdFile.close();
            if (stdoutFile.exists) stdoutFile.remove();
            app.system('cmd /c ""' + cmdFile.fsName + '" > "' + stdoutFile.fsName + '""');
            
            var maxWaitTime = 15000; // 15 sekund
            var waitInterval = 500;
            var totalWait = 0;
            while (totalWait < maxWaitTime && (!stdoutFile.exists || stdoutFile.length === 0)) {
                $.sleep(waitInterval);
                totalWait += waitInterval;
            }

            if (stdoutFile.exists && stdoutFile.length > 0) {
                stdoutFile.open("r");
                result = stdoutFile.read();
                stdoutFile.close();
            }
        } finally {
            cleanupFile(cmdFile);
            cleanupFile(stdoutFile);
        }
    } else {
        result = app.doScript('do shell script "' + command + '"', Language.APPLESCRIPT);
    }
    
    if (result.replace(/^\s+|\s+$/g, "") === "") {
        throw new Error("Nie otrzymano odpowiedzi od serwera.");
    }
    return result;
}

function openResultFile(filename, projectRoot) {
    var resultsFolder = new Folder(projectRoot + "/results");
    var resultFile = new File(resultsFolder.fsName + "/" + filename);
    
    alert("DEBUG: Szukam pliku:\n" + resultFile.fsName + "\nExists: " + resultFile.exists);
    
    if (!resultFile.exists) {
        throw new Error("Plik wynikowy nie istnieje: " + resultFile.fsName);
    }
    var resultDoc = app.open(resultFile);
    resultDoc.name = "ColorMatch_" + filename;
    
    alert("SUCCESS! Plik otwarty:\n" + filename);
}

function cleanupFile(file) {
    if (file && file.exists) {
        try {
            file.remove();
        } catch (e) { /* ignoruj błędy */ }
    }
}

// --- URUCHOMIENIE ---
main();

``````

### palette_analyzer.jsx - ./app/scripts/palette_analyzer.jsx

``````
// GattoNero Palette Analyzer - Prosty format CSV
#target photoshop

// --- KONFIGURACJA ---
var SERVER_URL = "http://127.0.0.1:5000/api/analyze_palette";

function main() {
    if (app.documents.length === 0) {
        alert("Otwórz dokument, aby uruchomić skrypt.");
        return;
    }

    var doc = app.activeDocument;
    if (doc.layers.length === 0) {
        alert("Dokument nie zawiera żadnych warstw.");
        return;
    }

    var activeLayer = doc.activeLayer;
    
    // Zapytaj użytkownika o liczbę kolorów
    var k = prompt("Ile dominujących kolorów chcesz znaleźć?", 8, "Analizator Palety");
    if (k === null) {
        return; // Użytkownik anulował
    }
    k = parseInt(k);
    if (isNaN(k) || k < 1 || k > 50) {
        alert("Podaj liczbę między 1 a 50.");
        return;
    }

    alert("Analizuję paletę kolorów warstwy: \"" + activeLayer.name + "\"\nLiczba kolorów: " + k + "\n\nKliknij OK, aby rozpocząć analizę.");

    // Solidne ścieżki do folderów
    var scriptFile = new File($.fileName);
    var projectRoot = scriptFile.parent.parent; 
    var tempFolder = new Folder(projectRoot + "/temp_jsx");
    if (!tempFolder.exists) tempFolder.create();

    var sourceFile = null;
    
    try {
        // Zapisz aktywną warstwę do pliku TIFF
        sourceFile = saveLayerToPNG(doc, activeLayer, tempFolder, "palette_source");

        // Wyślij do serwera i otrzymaj paletę
        var response = executeCurl(sourceFile, k);
        
        // NOWY PROSTY PARSER - zamiast JSON używamy CSV
        var palette = parseSimpleResponse(response);
        
        // Wizualizuj paletę w dokumencie
        visualizePalette(doc, activeLayer, palette);
        
        alert("Gotowe! Paleta kolorów została wygenerowana.");

    } catch (e) {
        alert("Wystąpił błąd: \n" + e.message);
    } finally {
        // Posprzątaj po sobie
        cleanupFile(sourceFile);
    }
}

function parseSimpleResponse(response) {
    /**
     * Parsuje prostą odpowiedź w formacie:
     * success,4,255,0,0,0,255,255,0,255,0,0,0,255
     * lub
     * error,komunikat błędu
     */
    try {
        // Usuń białe znaki
        response = response.replace(/^\s+|\s+$/g, "");
        
        // Podziel po przecinkach
        var parts = response.split(",");
        
        if (parts.length < 1) {
            throw new Error("Pusta odpowiedź serwera");
        }
        
        var status = parts[0];
        
        if (status === "error") {
            var errorMessage = parts.length > 1 ? parts[1] : "Nieznany błąd";
            throw new Error("Błąd serwera: " + errorMessage);
        }
        
        if (status !== "success") {
            throw new Error("Nieznany status: " + status);
        }
        
        if (parts.length < 2) {
            throw new Error("Brak informacji o liczbie kolorów");
        }
        
        var colorCount = parseInt(parts[1]);
        if (isNaN(colorCount) || colorCount < 1) {
            throw new Error("Nieprawidłowa liczba kolorów: " + parts[1]);
        }
        
        // Sprawdź czy mamy odpowiednią liczbę wartości RGB
        var expectedValues = 2 + (colorCount * 3); // status + count + (r,g,b)*colorCount
        if (parts.length < expectedValues) {
            throw new Error("Za mało wartości kolorów. Oczekiwano: " + expectedValues + ", otrzymano: " + parts.length);
        }
        
        // Parsuj kolory
        var palette = [];
        for (var i = 0; i < colorCount; i++) {
            var r = parseInt(parts[2 + i * 3]);
            var g = parseInt(parts[3 + i * 3]);
            var b = parseInt(parts[4 + i * 3]);
            
            if (isNaN(r) || isNaN(g) || isNaN(b)) {
                throw new Error("Nieprawidłowe wartości RGB dla koloru " + (i + 1));
            }
            
            palette.push([r, g, b]);
        }
        
        return palette;
        
    } catch (e) {
        throw new Error("Błąd parsowania odpowiedzi: " + e.message + "\nOdpowiedź: " + response);
    }
}

// --- FUNKCJE POMOCNICZE ---

function saveLayerToPNG(doc, layer, folderPath, prefix) {
    var originalVisibility = [];
    var activeLayer = doc.activeLayer;

    // Zapisz obecny stan widoczności warstw
    for (var i = 0; i < doc.layers.length; i++) {
        originalVisibility.push({ layer: doc.layers[i], visible: doc.layers[i].visible });
    }

    var filePath = null;

    try {
        // Ukryj wszystkie warstwy oprócz analizowaneи
        for (var i = 0; i < originalVisibility.length; i++) {
            originalVisibility[i].layer.visible = false;
        }
        layer.visible = true;

        filePath = new File(folderPath + "/" + prefix + "_" + Date.now() + ".tif");
        var tiffOptions = new TiffSaveOptions();
        tiffOptions.imageCompression = TIFFEncoding.NONE;
        tiffOptions.byteOrder = ByteOrder.IBM;

        doc.saveAs(filePath, tiffOptions, true, Extension.LOWERCASE);
    } catch(e) {
        throw new Error("Błąd podczas zapisu warstwy do pliku TIFF: " + e.message);
    } finally {
        // Przywróć stan widoczności warstw
        for (var i = 0; i < originalVisibility.length; i++) {
            originalVisibility[i].layer.visible = originalVisibility[i].visible;
        }
        doc.activeLayer = activeLayer;
    }
    return filePath;
}

function executeCurl(sourceFile, k) {
    var command = 'curl -s -X POST ' +
                  '-F "source_image=@' + sourceFile.fsName + '" ' +
                  '-F "k=' + k + '" ' +
                  SERVER_URL;

    var result = "";
    var tempFolder = sourceFile.parent;

    if ($.os.indexOf("Windows") > -1) {
        var cmdFile = new File(tempFolder + "/photoshop_curl.cmd");
        var stdoutFile = new File(tempFolder + "/curl_stdout.txt");
        
        try {
            cmdFile.open("w");
            cmdFile.encoding = "UTF-8";
            cmdFile.writeln("@echo off");
            cmdFile.writeln(command);
            cmdFile.close();
            
            if (stdoutFile.exists) stdoutFile.remove();
            
            app.system('cmd /c ""' + cmdFile.fsName + '" > "' + stdoutFile.fsName + '""');
            
            // Oczekiwanie na odpowiedź serwera
            var maxWaitTime = 10000; // 10 sekund
            var waitInterval = 500;   // sprawdzaj co 0.5 sekundy
            var totalWait = 0;
            
            while (totalWait < maxWaitTime && (!stdoutFile.exists || stdoutFile.length === 0)) {
                $.sleep(waitInterval);
                totalWait += waitInterval;
            }

            if (stdoutFile.exists && stdoutFile.length > 0) {
                stdoutFile.open("r");
                result = stdoutFile.read();
                stdoutFile.close();
            }
        } finally {
            cleanupFile(cmdFile);
            cleanupFile(stdoutFile);
        }
    } else {
        result = app.doScript('do shell script "' + command + '"', Language.APPLESCRIPT);
    }

    // Własna implementacja trim() dla starszych wersji JSX
    var trimmedResult = result.replace(/^\s+|\s+$/g, "");
    if (trimmedResult === "") {
        throw new Error("Nie otrzymano odpowiedzi od serwera lub odpowiedź jest pusta. Upewnij się, że serwer jest uruchomiony.");
    }
    return result;
}

function visualizePalette(doc, sourceLayer, palette) {
    try {
        // Utwórz nową grupę warstw
        var layerSet = doc.layerSets.add();
        layerSet.name = "Analiza Palety - " + sourceLayer.name;
        
        // Utwórz nową warstwę w grupie dla kolorów
        doc.activeLayer = layerSet;
        var paletteLayer = doc.artLayers.add();
        paletteLayer.name = "Paleta Kolorów";
        
        // Konfiguracja wizualizacji - ładniejszy układ w siatce
        var squareSize = 80;  // większe kwadraty
        var spacing = 15;     // większy odstęp
        var startX = 100;     // pozycja startowa X
        var startY = 100;     // pozycja startowa Y
        var columns = 4;      // liczba kolumn w siatce
        
        // Iteruj przez kolory w palecie - układ w siatce
        for (var i = 0; i < palette.length; i++) {
            var color = palette[i];
            var r = color[0];
            var g = color[1];
            var b = color[2];
            
            // Ustaw kolor pierwszego planu w Photoshopie
            var foregroundColor = new SolidColor();
            foregroundColor.rgb.red = r;
            foregroundColor.rgb.green = g;
            foregroundColor.rgb.blue = b;
            app.foregroundColor = foregroundColor;
            
            // Oblicz pozycję kwadratu w siatce
            var x = startX + (i % columns) * (squareSize + spacing);
            var y = startY + Math.floor(i / columns) * (squareSize + spacing + 60); // +60 na etykiety
            
            // Utwórz zaznaczenie prostokątne
            var selectionArray = [
                [x, y],
                [x + squareSize, y],
                [x + squareSize, y + squareSize],
                [x, y + squareSize]
            ];
            doc.selection.select(selectionArray);
            
            // Wypełnij zaznaczenie kolorem
            doc.selection.fill(foregroundColor);
        }
        
        // Usuń zaznaczenie
        doc.selection.deselect();
        
        // Dodaj etykiety pod kwadratami - każda w nowej linii
        addColorLabels(doc, layerSet, palette, startX, startY, squareSize, spacing, columns);
        
    } catch (e) {
        throw new Error("Błąd podczas wizualizacji palety: " + e.message);
    }
}

function addColorLabels(doc, layerSet, palette, startX, startY, squareSize, spacing, columns) {
    try {
        for (var i = 0; i < palette.length; i++) {
            var color = palette[i];
            var r = color[0];
            var g = color[1];
            var b = color[2];
            
            // Konwertuj RGB na HEX
            var hex = "#" + 
                      ("0" + r.toString(16)).slice(-2) + 
                      ("0" + g.toString(16)).slice(-2) + 
                      ("0" + b.toString(16)).slice(-2);
            
            // Oblicz pozycję tekstu - środek kwadratu
            var x = startX + (i % columns) * (squareSize + spacing) + squareSize/2;
            var y = startY + Math.floor(i / columns) * (squareSize + spacing + 60); // +60 na etykiety
            
            // Numer koloru (nad kodem HEX)
            var numberLayer = doc.artLayers.add();
            numberLayer.kind = LayerKind.TEXT;
            numberLayer.name = "Numer " + (i + 1);
            
            var numberItem = numberLayer.textItem;
            numberItem.contents = (i + 1).toString();
            numberItem.position = [x, y + squareSize + 5];  // pod kwadratem
            numberItem.size = 14;
            numberItem.justification = Justification.CENTER;
            
            // Ustaw kolor tekstu na czarny
            var blackColor = new SolidColor();
            blackColor.rgb.red = 0;
            blackColor.rgb.green = 0;
            blackColor.rgb.blue = 0;
            numberItem.color = blackColor;
            
            // Kod HEX (pod numerem)
            var hexLayer = doc.artLayers.add();
            hexLayer.kind = LayerKind.TEXT;
            hexLayer.name = "HEX " + (i + 1);
            
            var hexItem = hexLayer.textItem;
            hexItem.contents = hex.toUpperCase();
            hexItem.position = [x, y + squareSize + 20];  // nieco niżej
            hexItem.size = 10;
            hexItem.justification = Justification.CENTER;
            hexItem.color = blackColor;
            
            // RGB (na samym dole)
            var rgbLayer = doc.artLayers.add();
            rgbLayer.kind = LayerKind.TEXT;
            rgbLayer.name = "RGB " + (i + 1);
            
            var rgbItem = rgbLayer.textItem;
            rgbItem.contents = "R:" + r + " G:" + g + " B:" + b;
            rgbItem.position = [x, y + squareSize + 35];  // jeszcze niżej
            rgbItem.size = 8;
            rgbItem.justification = Justification.CENTER;
            rgbItem.color = blackColor;
            
            // Przenieś wszystkie warstwy tekstowe do grupy
            numberLayer.move(layerSet, ElementPlacement.INSIDE);
            hexLayer.move(layerSet, ElementPlacement.INSIDE);
            rgbLayer.move(layerSet, ElementPlacement.INSIDE);
        }
    } catch (e) {
        // Jeśli dodawanie etykiet się nie powiedzie, nie przerywaj całego procesu
        alert("Ostrzeżenie: Nie udało się dodać etykiet tekstowych: " + e.message);
    }
}

function cleanupFile(file) {
    if (file && file.exists) {
        try {
            file.remove();
        } catch (e) {
            // Ignoruj błędy usuwania
        }
    }
}

// Konwersja liczby na hex (pomocnicza funkcja)
function toHex(n) {
    var hex = n.toString(16);
    return hex.length === 1 ? "0" + hex : hex;
}

// --- URUCHOMIENIE ---
main();

``````

### test_simple.jsx - ./app/scripts/test_simple.jsx

``````
// Prosty test JSX
#target photoshop

try {
    alert("Test JSX działa!");
    
    // Test logowania
    var desktop = Folder.desktop;
    var logFile = new File(desktop + "/jsx_test.txt");
    logFile.open("w");
    logFile.writeln("JSX test działa: " + new Date());
    logFile.close();
    
    alert("Log zapisany na pulpicie!");
    
} catch (e) {
    alert("Błąd: " + e.message);
}

``````

### server.py - ./app/server.py

``````
"""
Enhanced Flask Server for GattoNero AI Assistant
================================================

Enhanced infrastructure features:
- Structured development logging with beautiful console output
- Performance profiling with HTML reports
- Health monitoring for algorithms and system resources
- Development dashboard endpoints
- Async processing support (future)

Design Philosophy: "Bezpiecznie = Szybko"
- Comprehensive monitoring prevents surprises
- Beautiful development experience improves productivity
- Performance insights guide optimization
- Health checks catch issues early
"""

import os
import threading
from pathlib import Path
from flask import Flask, jsonify, request

# Import enhanced infrastructure
from app.core.development_logger import get_logger, setup_flask_logging
from app.core.performance_profiler import get_profiler
from app.core.health_monitor_simple import get_simple_health_monitor

# Import existing API routes
from app.api.routes import app as api_blueprint

# Initialize enhanced infrastructure
logger = get_logger("gattonero_server")
profiler = get_profiler(enabled=True)
health_monitor = get_simple_health_monitor()

# Create enhanced Flask app
app = Flask(__name__)

# Setup development logging for Flask
setup_flask_logging(app, logger)

# Register existing API routes Blueprint
app.register_blueprint(api_blueprint)

# Debug endpoint to list all routes
@app.route('/routes')
def list_routes():
    """List all registered routes for debugging."""
    import urllib.parse
    output = []
    for rule in app.url_map.iter_rules():
        methods = ','.join(rule.methods or set())
        output.append(f"{rule.rule} [{methods}]")
    return "<br>".join(sorted(output))

# Simple root endpoint
@app.route('/')
def root():
    """Root endpoint."""
    return jsonify({
        "status": "ok",
        "message": "GattoNero AI Assistant Server",
        "version": "Enhanced Infrastructure",
        "endpoints": {
            "health": "/api/health",
            "performance": "/api/performance/dashboard",
            "routes": "/routes"
        }
    })

# Enhanced infrastructure endpoints
@app.route('/api/health')
def health_endpoint():
    """Health check endpoint for monitoring."""
    with profiler.profile_operation("health_check"):
        health_status = health_monitor.get_health_status()
        
    return jsonify({
        "status": "ok",
        "health": health_status
    })

@app.route('/api/health/quick')
def health_quick_endpoint():
    """Quick health check for load balancers."""
    return jsonify({
        "status": "ok",
        "timestamp": health_monitor.get_health_status()["timestamp"]
    })

@app.route('/api/performance/dashboard')
def performance_dashboard():
    """Performance dashboard data endpoint."""
    with profiler.profile_operation("performance_dashboard"):
        dashboard_data = profiler.get_dashboard_data()
        
    return jsonify(dashboard_data)

@app.route('/api/performance/report')
def performance_report():
    """Generate and return performance report."""
    with profiler.profile_operation("generate_performance_report"):
        report_path = profiler.generate_html_report()
        
    return jsonify({
        "status": "success",
        "report_path": report_path,
        "message": "Performance report generated"
    })

@app.route('/api/performance/stats')
def performance_stats():
    """Get performance statistics."""
    operation = request.args.get('operation')
    stats = profiler.get_statistics(operation)
    
    return jsonify({
        "status": "success",
        "statistics": stats
    })

@app.route('/api/system/info')
def system_info():
    """System information endpoint."""
    import psutil
    import sys
    
    return jsonify({
        "python_version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
        "flask_debug": app.debug,
        "memory_usage_mb": psutil.Process().memory_info().rss / 1024 / 1024,
        "cpu_percent": psutil.Process().cpu_percent(),
        "algorithms_registered": len(health_monitor._algorithm_stats),
        "performance_metrics": len(profiler._metrics)
    })

@app.route('/api/logs/recent')
def recent_logs():
    """Get recent log entries (if available)."""
    # This would need log file parsing in a real implementation
    return jsonify({
        "status": "info",
        "message": "Recent logs endpoint - implementation needed",
        "logs": []
    })

@app.route('/development/dashboard')
def development_dashboard():
    """Development dashboard HTML page."""
    return """
    <!DOCTYPE html>
    <html>
    <head>
        <title>GattoNero Development Dashboard</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }
            .card { background: white; padding: 20px; margin: 10px 0; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
            .status-healthy { color: #27ae60; }
            .status-warning { color: #f39c12; }
            .status-critical { color: #e74c3c; }
            .metric { display: inline-block; margin: 10px 20px; text-align: center; }
            .metric-value { font-size: 2em; font-weight: bold; color: #3498db; }
            .metric-label { color: #7f8c8d; }
            button { background: #3498db; color: white; border: none; padding: 10px 20px; border-radius: 4px; cursor: pointer; margin: 5px; }
            button:hover { background: #2980b9; }
            pre { background: #f8f9fa; padding: 10px; border-radius: 4px; overflow-x: auto; }
        </style>
        <script>
            async function loadData() {
                try {
                    const [healthData, perfData, sysData] = await Promise.all([
                        fetch('/api/health').then(r => r.json()),
                        fetch('/api/performance/dashboard').then(r => r.json()),
                        fetch('/api/system/info').then(r => r.json())
                    ]);
                    
                    updateDashboard(healthData, perfData, sysData);
                } catch (error) {
                    console.error('Failed to load dashboard data:', error);
                }
            }
            
            function updateDashboard(health, perf, sys) {
                // Update health status
                const healthEl = document.getElementById('health-status');
                healthEl.className = `status-${health.health.overall_status}`;
                healthEl.textContent = health.health.overall_status.toUpperCase();
                
                // Update metrics
                document.getElementById('total-ops').textContent = perf.summary.total_operations;
                document.getElementById('active-ops').textContent = perf.summary.active_operations;
                document.getElementById('avg-duration').textContent = perf.summary.avg_duration_ms.toFixed(1) + 'ms';
                document.getElementById('memory-usage').textContent = sys.memory_usage_mb.toFixed(1) + 'MB';
                
                // Update details
                document.getElementById('health-details').textContent = JSON.stringify(health.health.summary, null, 2);
                document.getElementById('perf-details').textContent = JSON.stringify(perf.summary, null, 2);
            }
            
            async function generateReport() {
                try {
                    const response = await fetch('/api/performance/report');
                    const data = await response.json();
                    alert('Report generated: ' + data.report_path);
                } catch (error) {
                    alert('Failed to generate report: ' + error.message);
                }
            }
            
            // Auto-refresh every 5 seconds
            setInterval(loadData, 5000);
            
            // Load initial data
            window.onload = loadData;
        </script>
    </head>
    <body>
        <h1>🚀 GattoNero Development Dashboard</h1>
        
        <div class="card">
            <h2>📊 System Status</h2>
            <div class="metric">
                <div class="metric-value" id="health-status">LOADING</div>
                <div class="metric-label">Health Status</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="total-ops">-</div>
                <div class="metric-label">Total Operations</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="active-ops">-</div>
                <div class="metric-label">Active Operations</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="avg-duration">-</div>
                <div class="metric-label">Avg Duration</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="memory-usage">-</div>
                <div class="metric-label">Memory Usage</div>
            </div>
        </div>
        
        <div class="card">
            <h2>🔧 Actions</h2>
            <button onclick="loadData()">Refresh Data</button>
            <button onclick="generateReport()">Generate Performance Report</button>
            <button onclick="window.open('/api/health', '_blank')">View Health Details</button>
            <button onclick="window.open('/api/performance/dashboard', '_blank')">View Performance Data</button>
        </div>
        
        <div class="card">
            <h2>❤️ Health Details</h2>
            <pre id="health-details">Loading...</pre>
        </div>
        
        <div class="card">
            <h2>⚡ Performance Details</h2>
            <pre id="perf-details">Loading...</pre>
        </div>
        
        <div class="card">
            <h2>📚 Quick Links</h2>
            <ul>
                <li><a href="/api/health">Health Status API</a></li>
                <li><a href="/api/performance/dashboard">Performance Dashboard API</a></li>
                <li><a href="/api/system/info">System Information</a></li>
                <li><a href="/api/performance/stats">Performance Statistics</a></li>
            </ul>
        </div>
    </body>
    </html>
    """

def initialize_server():
    """Initialize the enhanced server with monitoring."""
    logger.info("Initializing Enhanced Flask Server")
    
    # Initial health check
    health_results = health_monitor.run_all_checks()
    critical_issues = [name for name, result in health_results.items() 
                      if result.status.value == "critical"]
    
    if critical_issues:
        logger.warning(f"Critical health issues detected: {critical_issues}")
        for issue in critical_issues:
            logger.error(f"Critical: {health_results[issue].message}")
    else:
        logger.success("All health checks passed")
    
    logger.info("Enhanced Flask Server initialized successfully")

def shutdown_server():
    """Graceful server shutdown."""
    logger.info("Shutting down Enhanced Flask Server")
    
    # Generate final performance report
    try:
        report_path = profiler.generate_html_report("final_session_report.html")
        logger.success(f"Final performance report generated: {report_path}")
    except Exception as e:
        logger.error(f"Failed to generate final report: {str(e)}")
    
    logger.info("Enhanced Flask Server shutdown complete")

# Initialize on module load
initialize_server()

if __name__ == "__main__":
    try:
        logger.info("Starting Enhanced Flask Server in development mode")
        app.run(debug=True, host='0.0.0.0', port=5000, threaded=True)
    except KeyboardInterrupt:
        logger.info("Server interrupted by user")
    finally:
        shutdown_server()

``````

### utils.py - ./app/utils.py

``````
# GattoNeroPhotoshop/app/utils.py

from app.core.file_handler import save_temp_file, get_result_path
``````

### run_server.py - ./run_server.py

``````
# GattoNeroPhotoshop/run_server.py

import socket
import subprocess
import time
import sys
from app.server import app

def check_port_free(port):
    """Sprawdza czy port jest wolny"""
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        try:
            s.bind(('127.0.0.1', port))
            return True
        except OSError:
            return False

def kill_process_on_port(port):
    """Zabija proces na danym porcie (Windows)"""
    try:
        # Znajdź PID procesu na porcie
        result = subprocess.run(
            f'netstat -ano | findstr :{port}',
            shell=True,
            capture_output=True,
            text=True
        )

        if result.stdout:
            lines = result.stdout.strip().split('\n')
            for line in lines:
                if 'LISTENING' in line:
                    parts = line.split()
                    if len(parts) >= 5:
                        pid = parts[-1]
                        print(f"Zatrzymuje proces PID {pid} na porcie {port}...")
                        subprocess.run(f'taskkill /F /PID {pid}', shell=True, capture_output=True)
                        return True
        return False
    except Exception as e:
        print(f"Blad podczas zabijania procesu: {e}")
        return False

def safe_start_server():
    """Bezpiecznie uruchamia serwer z kontrola portu"""
    port = 5000

    print("Sprawdzam port 5000...")

    if not check_port_free(port):
        print("Port 5000 jest zajety! Probuje zatrzymac istniejacy proces...")

        if kill_process_on_port(port):
            print("Czekam 2 sekundy na zwolnienie portu...")
            time.sleep(2)

            if check_port_free(port):
                print("Port zwolniony!")
            else:
                print("Nie udalo sie zwolnic portu. Sprawdz recznie procesy.")
                sys.exit(1)
        else:
            print("Nie znaleziono procesu do zatrzymania, ale port jest zajety.")
            print("Sprobuj recznie: netstat -ano | findstr :5000")
            sys.exit(1)
    else:
        print("Port 5000 jest wolny!")

    print("Uruchamiam serwer Flask...")
    print("Serwer bedzie dostepny na: http://127.0.0.1:5000")
    print("Aby zatrzymac serwer, nacisnij Ctrl+C")
    print("-" * 50)

    # Uruchamiamy serwer Flask (debug=False zeby uniknac konfliktow z kontrola portu)
    app.run(host='127.0.0.1', port=port, debug=False)

if __name__ == '__main__':
    safe_start_server()
``````

### server_manager_enhanced.py - ./server_manager_enhanced.py

``````
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Enhanced Server Manager v2.2.0 - Advanced Flask Server Management for GattoNero AI Assistant

Features:
- Unified watchdog system via 'watch' command
- Configuration-driven setup from 'server_config.json'
- Advanced auto-restart with exponential backoff
- Graceful shutdown with '--force' option
- Structured, TTY-aware logging with log file redirection
- Production-ready deployment capabilities
- Intelligent Python environment detection (VENV vs. SYSTEM)

Usage:
    python server_manager_enhanced.py start [--auto-restart] [--port PORT]
    python server_manager_enhanced.py stop [--force]
    python server_manager_enhanced.py status [--detailed]
    python server_manager_enhanced.py restart [--auto-restart]
    python server_manager_enhanced.py watch [--interval SECONDS]
    python server_manager_enhanced.py logs [--tail LINES] [--file server|manager|errors]
"""

import sys
import os
import json
import time
import subprocess
import requests
import argparse
import threading
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Optional, Any, List

# Próba importu psutil, jeśli jest dostępny
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    psutil = None
    PSUTIL_AVAILABLE = False
    print("[WARNING] psutil is not available. Some advanced features will be disabled. Run 'pip install psutil'")


class ServerConfig:
    """Zarządza konfiguracją serwera z pliku JSON z wartościami domyślnymi."""

    def __init__(self, config_file: str = "server_config.json"):
        self.config_file = Path(config_file)
        self._config = self._load_config()

    def _load_config(self) -> Dict[str, Any]:
        """Ładuje konfigurację z pliku, łącząc ją z domyślnymi wartościami."""
        defaults = {
            "server": {
                "host": "127.0.0.1",
                "port": 5000,
                "environment": "development",
                "startup_command": [sys.executable, "run_server.py"],
                "python_executable": "", # Puste oznacza auto-detekcję
                "startup_timeout": 15,
                "shutdown_timeout": 20,
                "health_check_interval": 5
            },
            "monitoring": {
                "failure_threshold": 3,
                "restart_delay": 5,
                "exponential_backoff": True,
                "max_backoff_delay": 60
            },
            "logging": {
                "log_dir": "logs",
                "server_log_file": "gattonero_server.log",
                "server_error_file": "gattonero_server_errors.log",
                "manager_log_file": "server_manager.log"
            },
            "files": {
                "pid_file": ".server_info.json"
            }
        }

        if self.config_file.exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                return self._deep_merge(defaults, user_config)
            except json.JSONDecodeError as e:
                print(f"[ERROR] Invalid JSON in {self.config_file}: {e}. Using default configuration.")
            except Exception as e:
                print(f"[WARNING] Failed to load {self.config_file}: {e}. Using defaults.")
        else:
             print(f"[INFO] Configuration file '{self.config_file}' not found. Creating with default values.")
             try:
                 with open(self.config_file, 'w', encoding='utf-8') as f:
                     json.dump(defaults, f, indent=4)
             except Exception as e:
                 print(f"[ERROR] Could not create default config file: {e}")

        return defaults

    def _deep_merge(self, base: Dict[str, Any], overlay: Dict[str, Any]) -> Dict[str, Any]:
        """Rekursywnie łączy dwa słowniki."""
        result = base.copy()
        for key, value in overlay.items():
            if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                result[key] = self._deep_merge(result[key], value)
            else:
                result[key] = value
        return result

    def get(self, section: str, key: Optional[str] = None, default=None):
        """Pobiera wartość konfiguracyjną z określonej sekcji."""
        if key is None:
            return self._config.get(section, default)
        return self._config.get(section, {}).get(key, default)

    def get_str(self, section: str, key: str, default: str = "") -> str:
        """Pobiera wartość konfiguracyjną jako string."""
        value = self.get(section, key, default)
        return str(value) if value is not None else default

    def get_int(self, section: str, key: str, default: int = 0) -> int:
        """Pobiera wartość konfiguracyjną jako int."""
        value = self.get(section, key, default)
        try:
            return int(value) if value is not None else default
        except (ValueError, TypeError):
            return default

    def get_list(self, section: str, key: str, default: Optional[List] = None) -> List:
        """Pobiera wartość konfiguracyjną jako listę."""
        if default is None:
            default = []
        value = self.get(section, key, default)
        return list(value) if isinstance(value, list) else default

    def get_bool(self, section: str, key: str, default: bool = False) -> bool:
        """Pobiera wartość konfiguracyjną jako boolean."""
        value = self.get(section, key, default)
        if isinstance(value, bool):
            return value
        if isinstance(value, str):
            return value.lower() in ('true', '1', 'yes', 'on')
        return bool(value) if value is not None else default


class EnhancedServerManager:
    """Zarządza cyklem życia serwera z monitoringiem, logowaniem i konfiguracją."""

    def __init__(self, host: Optional[str] = None, port: Optional[int] = None,
                 environment: Optional[str] = None, config_file: str = "server_config.json"):
        self.config = ServerConfig(config_file)

        self.host = host or self.config.get_str('server', 'host', '127.0.0.1')
        self.port = port or self.config.get_int('server', 'port', 5000)
        self.environment = environment or self.config.get_str('server', 'environment', 'development')
        self.base_url = f'http://{self.host}:{self.port}'

        self.log_dir = Path(self.config.get_str('logging', 'log_dir', 'logs'))
        self.log_dir.mkdir(exist_ok=True)
        self.pid_file = Path(self.config.get_str('files', 'pid_file', '.server_info.json'))
        self.server_log_file = self.log_dir / self.config.get_str('logging', 'server_log_file', 'gattonero_server.log')
        self.server_error_file = self.log_dir / self.config.get_str('logging', 'server_error_file', 'gattonero_server_errors.log')
        self.manager_log_file = self.log_dir / self.config.get_str('logging', 'manager_log_file', 'server_manager.log')

        self.python_executable = self._detect_python_executable()
        
        default_startup_command = [self.python_executable, "-m", "app.server"]
        self.startup_command = self.config.get_list('server', 'startup_command', default_startup_command)
        if self.startup_command == [sys.executable, "-m", "app.server"]:
             self.startup_command = default_startup_command

        self.startup_timeout = self.config.get_int('server', 'startup_timeout', 15)
        self.shutdown_timeout = self.config.get_int('server', 'shutdown_timeout', 20)
        self.health_check_interval = self.config.get_int('server', 'health_check_interval', 5)
        self.failure_threshold = self.config.get_int('monitoring', 'failure_threshold', 3)
        self.restart_delay = self.config.get_int('monitoring', 'restart_delay', 5)

        self.monitor_thread: Optional[threading.Thread] = None
        self.monitor_running = threading.Event()

    def _detect_python_executable(self) -> str:
        """Wykrywa najlepszy interpreter Pythona (venv jeśli dostępny)."""
        config_python = self.config.get_str('server', 'python_executable', '')
        if config_python and Path(config_python).exists():
            self.log_event(f"Using configured Python executable: {config_python}", "INFO")
            return config_python

        venv_paths = [Path('venv'), Path('.venv'), Path('env'), Path('.env')]
        for venv_path in venv_paths:
            if venv_path.exists() and venv_path.is_dir():
                python_exe = venv_path / 'Scripts' / 'python.exe' if os.name == 'nt' else venv_path / 'bin' / 'python'
                if python_exe.exists():
                    self.log_event(f"Virtual environment detected: {venv_path}", "SUCCESS")
                    self.log_event(f"Using venv Python: {python_exe}", "INFO")
                    return str(python_exe)

        if hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix):
            self.log_event("Already running in an activated virtual environment", "SUCCESS")
            return sys.executable

        self.log_event("No virtual environment detected, using system Python", "WARNING")
        self.log_event("Consider creating a venv: python -m venv venv", "INFO")
        return sys.executable

    def _check_flask_install(self) -> bool:
        """Sprawdza, czy Flask jest zainstalowany w wybranym środowisku."""
        self.log_event(f"Checking for Flask in: {self.python_executable}", "INFO")
        try:
            command = [self.python_executable, "-c", "import flask"]
            result = subprocess.run(command, capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                self.log_event("Flask is installed.", "SUCCESS")
                return True
            else:
                self.log_event("Flask is NOT installed in the selected environment.", "ERROR")
                self.log_event(f"To install, run: '{self.python_executable} -m pip install flask'", "INFO")
                return False
        except Exception as e:
            self.log_event(f"Could not check for Flask installation: {e}", "ERROR")
            return False

    def _verify_environment(self) -> bool:
        """Weryfikuje, czy środowisko Python jest poprawnie skonfigurowane."""
        python_path = Path(self.python_executable)
        if not python_path.exists():
            self.log_event(f"Python executable not found: {self.python_executable}", "ERROR")
            return False

        try:
            result = subprocess.run([self.python_executable, '--version'], capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                self.log_event(f"Python version: {result.stdout.strip()}", "INFO")
        except Exception as e:
            self.log_event(f"Could not get Python version: {e}", "WARNING")

        return self._check_flask_install()

    def log_event(self, event: str, level: str = "INFO"):
        """Loguje zdarzenie do konsoli (z kolorami) i do pliku."""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_entry = {'timestamp': timestamp, 'level': level, 'event': event}
        
        log_message = f"[{timestamp}] [{level}] {event}"
        
        if sys.stdout.isatty():
            colors = {'INFO': '\033[94m', 'SUCCESS': '\033[92m', 'WARNING': '\033[93m', 'ERROR': '\033[91m', 'RESET': '\033[0m'}
            color = colors.get(level, '')
            reset = colors['RESET']
            print(f"{color}{log_message}{reset}")
        else:
            print(log_message)
            
        try:
            with open(self.manager_log_file, 'a', encoding='utf-8') as f:
                f.write(f"{json.dumps(log_entry)}\n")
        except Exception as e:
            print(f"[ERROR] Could not write to manager log file: {e}")

    def save_server_info(self, process_info: Dict[str, Any]):
        """Zapisuje informacje o procesie serwera do pliku."""
        try:
            with open(self.pid_file, 'w') as f:
                json.dump(process_info, f, indent=4)
        except Exception as e:
            self.log_event(f"Failed to save server info: {e}", "ERROR")

    def load_server_info(self) -> Optional[Dict[str, Any]]:
        """Wczytuje informacje o procesie serwera z pliku."""
        if not self.pid_file.exists():
            return None
        try:
            with open(self.pid_file, 'r') as f:
                return json.load(f)
        except (json.JSONDecodeError, FileNotFoundError):
            return None

    def clear_server_info(self):
        """Usuwa plik z informacjami o serwerze."""
        try:
            self.pid_file.unlink(missing_ok=True)
        except Exception:
            pass

    def is_process_running(self, pid: int) -> bool:
        """Sprawdza, czy proces o danym PID działa."""
        if not PSUTIL_AVAILABLE or psutil is None: return False
        try:
            return psutil.pid_exists(pid)
        except Exception:
            return False

    def is_port_in_use(self, port: int) -> bool:
        """Sprawdza, czy port jest w użyciu."""
        if not PSUTIL_AVAILABLE or psutil is None: return False
        try:
            for conn in psutil.net_connections():
                if conn.laddr and conn.laddr.port == port and conn.status == 'LISTEN':
                    return True
        except Exception:
            pass
        return False

    def is_server_responding(self) -> bool:
        """Sprawdza, czy serwer odpowiada na żądania HTTP."""
        try:
            response = requests.get(f'{self.base_url}/api/health', timeout=2)
            return response.status_code == 200
        except requests.RequestException:
            return False
            
    def get_process_info(self, pid: int) -> Dict[str, Any]:
        """Pobiera szczegółowe informacje o procesie."""
        if not PSUTIL_AVAILABLE or psutil is None or not self.is_process_running(pid):
            return {'status': 'not_found'}
        try:
            process = psutil.Process(pid)
            with process.oneshot():
                return {
                    'pid': pid,
                    'status': process.status(),
                    'cpu_percent': process.cpu_percent(interval=0.1),
                    'memory_mb': round(process.memory_info().rss / 1024**2, 2),
                    'uptime_seconds': time.time() - process.create_time()
                }
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            return {'status': 'error'}


    def is_running(self) -> bool:
        """Sprawdza, czy serwer działa i odpowiada."""
        info = self.load_server_info()
        if not info: return False
        pid = info.get('pid')
        if not pid: return False
        return self.is_process_running(pid) and self.is_server_responding()

    def start_server(self, auto_restart: bool = False, no_wait: bool = False) -> bool:
        """Uruchamia proces serwera i opcjonalnie watchdog."""
        if self.is_running():
            self.log_event("Server is already running.", "WARNING")
            return True

        if not self._verify_environment():
            self.log_event("Python environment verification failed. Cannot start server.", "ERROR")
            return False

        if self.is_port_in_use(self.port):
            self.log_event(f"Port {self.port} is already in use. Cannot start server.", "ERROR")
            return False

        self.log_event(f"Starting server... Command: {' '.join(self.startup_command)}")
        env = os.environ.copy()
        env['FLASK_ENV'] = self.environment

        # --- FIX: Define OS-specific arguments to detach the process ---
        kwargs = {}
        if os.name == 'nt':
            # On Windows, DETACHED_PROCESS creates a new process
            # without a console and independent of the parent.
            kwargs['creationflags'] = subprocess.DETACHED_PROCESS
        else:
            # On Unix, os.setsid makes the process a session leader,
            # detaching it from the controlling terminal.
            kwargs['preexec_fn'] = os.setsid
        # --- END FIX ---

        try:
            with open(self.server_log_file, 'ab') as log_out, open(self.server_error_file, 'ab') as log_err:
                # Add the kwargs to the Popen call
                process = subprocess.Popen(
                    self.startup_command, 
                    stdout=log_out, 
                    stderr=log_err, 
                    env=env,
                    **kwargs
                )

            self.save_server_info({'pid': process.pid, 'port': self.port, 'started_at': time.time()})

            if no_wait:
                self.log_event("Server starting in background. Check status or logs to confirm.", "INFO")
                # A brief pause to allow the process to initialize or fail.
                time.sleep(1.5)
                # Quick check if process died instantly
                if not self.is_process_running(process.pid):
                    self.log_event("Server process terminated immediately after start. Check error logs.", "ERROR")
                    self.log_event(f"Review logs: python server_manager_enhanced.py logs --file errors", "INFO")
                    self.clear_server_info() # Clear info if process died
                    return False
                if auto_restart:
                    self.start_watchdog()
                return True

            self.log_event(f"Waiting for server to respond (PID: {process.pid})...")
            for _ in range(self.startup_timeout):
                if self.is_server_responding():
                    self.log_event("Server started successfully.", "SUCCESS")
                    if auto_restart:
                        self.start_watchdog()
                    return True
                time.sleep(1)

            self.log_event("Server failed to start within timeout.", "ERROR")
            # Attempt to stop the failed process before returning
            current_pid_info = self.load_server_info()
            if current_pid_info and current_pid_info.get('pid') == process.pid:
                self.stop_server(force=True) # This will also clear_server_info
            else: # If PID info was overwritten or process never registered properly
                try:
                    if PSUTIL_AVAILABLE and psutil and psutil.pid_exists(process.pid):
                        psutil.Process(process.pid).kill()
                except Exception: # psutil.NoSuchProcess or other errors
                    pass # Process might already be gone
                self.clear_server_info() # Ensure info is cleared if stop_server wasn't effective for this PID
            return False
        except Exception as e:
            self.log_event(f"Failed to start server: {e}", "ERROR")
            # Ensure server info is cleared on any exception during startup
            self.clear_server_info()
            return False

    def stop_server(self, force: bool = False) -> bool:
        """Zatrzymuje serwer, z opcją wymuszenia."""
        self.stop_watchdog()
        info = self.load_server_info()
        if not info or not self.is_process_running(info.get('pid', -1)):
            self.log_event("Server is not running.", "INFO")
            self.clear_server_info()
            return True

        pid = info['pid']
        self.log_event(f"Stopping server (PID: {pid})...")

        if not force and PSUTIL_AVAILABLE and psutil:
            try:
                proc = psutil.Process(pid)
                # Na Windows SIGTERM to to samo co terminate()
                proc.terminate()
                self.log_event("Sent termination signal. Waiting for process to exit.", "INFO")
                proc.wait(timeout=self.shutdown_timeout)
                self.log_event("Server shut down gracefully.", "SUCCESS")
                self.clear_server_info()
                return True
            except psutil.TimeoutExpired:
                 self.log_event("Graceful shutdown timed out. Forcing termination.", "WARNING")
            except psutil.NoSuchProcess:
                self.log_event("Process already stopped.", "SUCCESS")
                self.clear_server_info()
                return True
            except Exception as e:
                self.log_event(f"Error during graceful shutdown: {e}. Forcing termination.", "WARNING")

        # Force termination
        if PSUTIL_AVAILABLE and psutil:
            try:
                proc = psutil.Process(pid)
                proc.kill()
                proc.wait(timeout=5)
            except psutil.NoSuchProcess:
                pass # Already gone
            except Exception as e:
                self.log_event(f"Error during force kill: {e}", "ERROR")
        else: # Fallback dla systemów bez psutil
            try:
                os.kill(pid, 9) # SIGKILL
            except ProcessLookupError:
                pass # Already gone
            except Exception as e:
                self.log_event(f"Error during fallback kill: {e}", "ERROR")


        time.sleep(1) # Give OS a moment to update process table
        if not self.is_process_running(pid):
            self.log_event("Server stopped forcefully.", "SUCCESS")
            self.clear_server_info()
            return True
        else:
            self.log_event("Failed to stop the server.", "ERROR")
            return False


    def restart_server(self, auto_restart: bool = False) -> bool:
        """Restartuje serwer."""
        self.log_event("Restarting server...")
        if self.stop_server():
            time.sleep(2) # Czas na zwolnienie portu
            return self.start_server(auto_restart)
        self.log_event("Failed to stop the server, restart aborted.", "ERROR")
        return False

    def run_tests(self) -> bool:
        """Uruchom testy podstawowe."""
        if not self.is_running():
            self.log_event("Server not running. Cannot run tests.", "ERROR")
            return False
        
        self.log_event("Running tests...", "INFO")
        try:
            result = subprocess.run([sys.executable, 'test_basic.py'], 
                                  capture_output=True, text=True, cwd=os.getcwd())
            
            # Log the output
            if result.stdout:
                for line in result.stdout.strip().split('\n'):
                    print(line)
            
            if result.stderr:
                self.log_event("STDERR output:", "WARNING")
                for line in result.stderr.strip().split('\n'):
                    self.log_event(line, "WARNING")
            
            if result.returncode == 0:
                self.log_event("Tests completed successfully.", "SUCCESS")
                return True
            else:
                self.log_event(f"Tests failed with return code: {result.returncode}", "ERROR")
                return False
                
        except Exception as e:
            self.log_event(f"Failed to run tests: {e}", "ERROR")
            return False

    def show_status(self, detailed: bool = False):
        """Wyświetla aktualny status serwera."""
        print("─" * 40)
        print("🖥️  Server Status")
        print("─" * 40)
        info = self.load_server_info()

        if not info or not self.is_process_running(info.get('pid', -1)):
            self.log_event("Server is NOT RUNNING.", "WARNING")
            self.clear_server_info()
            return

        pid = info['pid']
        is_responding = self.is_server_responding()
        status_color = "SUCCESS" if is_responding else "ERROR"
        
        self.log_event(f"Server process is RUNNING (PID: {pid}).", "SUCCESS")
        self.log_event(f"Server HTTP endpoint is {'RESPONDING' if is_responding else 'NOT RESPONDING'}.", status_color)
        
        if detailed and PSUTIL_AVAILABLE and psutil:
            proc_info = self.get_process_info(pid)
            if proc_info.get('status') != 'not_found':
                uptime = timedelta(seconds=int(proc_info.get('uptime_seconds', 0)))
                print(f"  PID          : {proc_info.get('pid')}")
                print(f"  Uptime       : {uptime}")
                print(f"  Memory       : {proc_info.get('memory_mb', 'N/A')} MB")
                print(f"  CPU          : {proc_info.get('cpu_percent', 'N/A')} %")
        print("─" * 40)

    def start_watchdog(self):
        """Uruchamia wątek watchdog do monitorowania serwera."""
        if self.monitor_running.is_set():
            self.log_event("Watchdog is already running.", "INFO")
            return
        self.log_event("Starting watchdog monitor...", "INFO")
        self.monitor_running.set()
        self.monitor_thread = threading.Thread(target=self._watchdog_loop, daemon=True)
        self.monitor_thread.start()

    def stop_watchdog(self):
        """Zatrzymuje wątek watchdog."""
        if self.monitor_running.is_set():
            self.log_event("Stopping watchdog monitor...", "INFO")
            self.monitor_running.clear()
            if self.monitor_thread and self.monitor_thread.is_alive():
                self.monitor_thread.join(timeout=3)

    def _watchdog_loop(self):
        """Główna pętla wątku watchdog."""
        failures = 0
        while self.monitor_running.is_set():
            if not self.is_server_responding():
                failures += 1
                self.log_event(f"Watchdog: Server health check failed ({failures}/{self.failure_threshold}).", "WARNING")
                if failures >= self.failure_threshold:
                    self.log_event("Watchdog: Failure threshold reached. Attempting to restart server.", "ERROR")
                    if self.restart_server(auto_restart=True):
                        failures = 0
                    time.sleep(self.restart_delay)
            else:
                if failures > 0:
                    self.log_event("Watchdog: Server has recovered.", "SUCCESS")
                failures = 0
            
            self.monitor_running.wait(self.health_check_interval)

    def watch_server_foreground(self, interval: int):
        """Uruchamia dashboard monitorujący na pierwszym planie."""
        self.log_event(f"Starting foreground watch (interval: {interval}s). Press Ctrl+C to stop.", "INFO")
        try:
            while True:
                if sys.stdout.isatty():
                    os.system('cls' if os.name == 'nt' else 'clear')
                self.show_status(detailed=True)
                time.sleep(interval)
        except KeyboardInterrupt:
            print()
            self.log_event("Foreground watch stopped by user.", "INFO")

    def show_logs(self, tail_lines: int, log_type: str):
        """Pokazuje ostatnie N linii określonego pliku logów."""
        log_files = {'manager': self.manager_log_file, 'server': self.server_log_file, 'errors': self.server_error_file}
        log_file = log_files.get(log_type, self.manager_log_file)
        
        print(f"📋 Displaying last {tail_lines} lines of '{log_file.name}'")
        print("─" * 40)
        
        if not log_file.exists():
            self.log_event(f"Log file not found: {log_file}", "WARNING")
            return
        try:
            with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
            for line in lines[-tail_lines:]:
                print(line.strip())
        except Exception as e:
            self.log_event(f"Error reading log file: {e}", "ERROR")


def create_parser() -> argparse.ArgumentParser:
    """Tworzy parser argumentów linii poleceń."""
    parser = argparse.ArgumentParser(description=__doc__, formatter_class=argparse.RawTextHelpFormatter)
    subparsers = parser.add_subparsers(dest='command', help='Available commands', required=True)

    start = subparsers.add_parser('start', help='Starts the server.')
    start.add_argument('--auto-restart', action='store_true', help='Enable watchdog to auto-restart on failure.')
    start.add_argument('--port', type=int, help='Override the server port from config.')
    start.add_argument('--no-wait', action='store_true', help='Don\'t wait for server health-check, return immediately.')

    stop = subparsers.add_parser('stop', help='Stops the server.')
    stop.add_argument('--force', action='store_true', help='Force stop without graceful shutdown.')

    restart = subparsers.add_parser('restart', help='Restarts the server.')
    restart.add_argument('--auto-restart', action='store_true', help='Enable watchdog after restarting.')

    status = subparsers.add_parser('status', help='Shows the server status.')
    status.add_argument('--detailed', action='store_true', help='Show detailed process information.')

    watch = subparsers.add_parser('watch', help='Monitors the server in the foreground.')
    watch.add_argument('--interval', type=int, default=5, help='Check interval in seconds.')
    
    logs = subparsers.add_parser('logs', help='Shows recent logs.')
    logs.add_argument('--tail', type=int, default=20, help='Number of lines to show.')
    logs.add_argument('--file', choices=['manager', 'server', 'errors'], default='server', help='Which log file to show.')
    
    return parser


def main():
    """Główna funkcja wykonawcza."""
    parser = create_parser()
    args = parser.parse_args()

    manager = EnhancedServerManager(port=getattr(args, 'port', None))

    try:
        if args.command == 'start':
            sys.exit(0 if manager.start_server(auto_restart=args.auto_restart, no_wait=getattr(args, 'no_wait', False)) else 1)
        elif args.command == 'stop':
            sys.exit(0 if manager.stop_server(force=args.force) else 1)
        elif args.command == 'restart':
            sys.exit(0 if manager.restart_server(auto_restart=args.auto_restart) else 1)
        elif args.command == 'status':
            manager.show_status(detailed=args.detailed)
        elif args.command == 'watch':
            manager.watch_server_foreground(args.interval)
        elif args.command == 'logs':
            manager.show_logs(args.tail, args.file)
        else:
            parser.print_help()
    except KeyboardInterrupt:
        print()
        manager.log_event("Operation interrupted by user.", "INFO")
        manager.stop_watchdog()
        sys.exit(1)
    except Exception as e:
        manager.log_event(f"An unexpected error occurred: {e}", "ERROR")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()

``````

### server_manager_enhanced_fixed.py - ./server_manager_enhanced_fixed.py

``````

``````

### test_algorithm_integration.py - ./test_algorithm_integration.py

``````
#!/usr/bin/env python3
"""
Algorithm Integration Test
==========================

Test integration of new modular algorithm system with the Enhanced Flask server.
Verifies that:
1. New algorithm_01_palette works correctly 
2. API routing functions properly
3. Performance monitoring is active
4. Legacy algorithms (2,3) still work
5. Results are generated correctly
"""

import requests
import time
import os
import sys

# Server configuration
SERVER_URL = "http://127.0.0.1:5000"
API_URL = f"{SERVER_URL}/api/colormatch"

def test_algorithm_integration():
    """Test integration of new modular algorithm system."""
    print("🔬 ALGORITHM INTEGRATION TEST")
    print("=" * 50)
    
    # Check if server is running
    try:
        response = requests.get(f"{SERVER_URL}/api/health", timeout=5)
        if response.status_code != 200:
            print("❌ Server not running. Start server first!")
            return False
    except:
        print("❌ Server not responding. Start server first!")
        return False
    
    print("✅ Server is running")
    
    # Test files
    master_file = "test_image.png"
    target_file = "test_simple.tif"
    
    if not os.path.exists(master_file) or not os.path.exists(target_file):
        print(f"❌ Test files not found: {master_file}, {target_file}")
        return False
    
    print(f"✅ Test files found: {master_file}, {target_file}")
    
    # Test each method
    methods = [
        ("1", "Enhanced Palette Mapping (New Modular)", True),
        ("2", "Statistical Transfer (Legacy)", False),
        ("3", "Histogram Matching (Legacy)", False)
    ]
    
    results = []
    
    for method, description, is_new in methods:
        print(f"\n🧪 Testing Method {method}: {description}")
        print("-" * 60)
        
        # Prepare request
        files = {
            'master_image': open(master_file, 'rb'),
            'target_image': open(target_file, 'rb')
        }
        data = {
            'method': method,
            'k': 8
        }
        
        # Send request and measure time
        start_time = time.time()
        try:
            response = requests.post(API_URL, files=files, data=data, timeout=30)
            end_time = time.time()
            duration = end_time - start_time
            
            # Close files
            files['master_image'].close()
            files['target_image'].close()
            
            if response.status_code == 200:
                result_text = response.text.strip()
                
                if result_text.startswith("success"):
                    parts = result_text.split(",")
                    result_filename = parts[2] if len(parts) >= 3 else "unknown"
                    
                    # Check if result file exists
                    result_path = f"results/{result_filename}"
                    file_exists = os.path.exists(result_path)
                    
                    status = "✅ PASS" if file_exists else "⚠️ PARTIAL"
                    print(f"   Status: {status}")
                    print(f"   Duration: {duration:.2f}s")
                    print(f"   Result: {result_filename}")
                    print(f"   File exists: {'Yes' if file_exists else 'No'}")
                    
                    if is_new:
                        print(f"   🆕 Using NEW modular algorithm!")
                    else:
                        print(f"   📦 Using legacy algorithm")
                    
                    results.append({
                        'method': method,
                        'status': 'PASS' if file_exists else 'PARTIAL',
                        'duration': duration,
                        'description': description,
                        'is_new': is_new
                    })
                else:
                    print(f"   ❌ FAIL: {result_text}")
                    results.append({
                        'method': method,
                        'status': 'FAIL',
                        'duration': duration,
                        'description': description,
                        'is_new': is_new,
                        'error': result_text
                    })
            else:
                print(f"   ❌ HTTP Error: {response.status_code}")
                results.append({
                    'method': method,
                    'status': 'HTTP_ERROR',
                    'duration': duration,
                    'description': description,
                    'is_new': is_new
                })
                
        except Exception as e:
            print(f"   ❌ Exception: {str(e)}")
            results.append({
                'method': method,
                'status': 'EXCEPTION',
                'description': description,
                'is_new': is_new,
                'error': str(e)
            })
    
    # Print summary
    print("\n" + "=" * 50)
    print("📊 INTEGRATION TEST SUMMARY")
    print("=" * 50)
    
    passed = 0
    total = len(results)
    
    for result in results:
        status_icon = {
            'PASS': '✅',
            'PARTIAL': '⚠️',
            'FAIL': '❌',
            'HTTP_ERROR': '🔥',
            'EXCEPTION': '💥'
        }.get(result['status'], '❓')
        
        new_indicator = '🆕' if result['is_new'] else '📦'
        duration_str = f"{result.get('duration', 0):.2f}s" if 'duration' in result else 'N/A'
        
        print(f"Method {result['method']}: {status_icon} {result['status']} ({duration_str}) {new_indicator}")
        
        if result['status'] == 'PASS':
            passed += 1
    
    print(f"\nResult: {passed}/{total} methods working")
    
    if passed == total:
        print("🎉 ALL TESTS PASSED! Algorithm integration successful!")
        return True
    elif passed > 0:
        print("⚠️ PARTIAL SUCCESS: Some algorithms working")
        return True
    else:
        print("❌ ALL TESTS FAILED! Check server and algorithm setup")
        return False

if __name__ == "__main__":
    success = test_algorithm_integration()
    sys.exit(0 if success else 1)

``````

### test_basic.py - ./test_basic.py

``````
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
POZIOM 1: Podstawowy test trzech metod color matching
Cel: <5 sekund na 1MP, wszystkie metody działają bez błędów
"""

import time
import os
import requests
import shutil
from pathlib import Path

# Konfiguracja
SERVER_URL = "http://127.0.0.1:5000"
TEST_IMAGES_DIR = "test_images"
RESULTS_DIR = "test_results"

def setup_test_environment():
    """Przygotuj środowisko testowe"""
    # Stwórz katalogi jeśli nie istnieją
    Path(RESULTS_DIR).mkdir(exist_ok=True)
    
    # Sprawdź czy mamy obrazy testowe
    test_files = ["test_image.png", "test_simple.tif"]
    available_files = []
    
    for file in test_files:
        if os.path.exists(file):
            available_files.append(file)
    
    if len(available_files) < 2:
        print("[ERROR] Potrzebne co najmniej 2 obrazy testowe")
        print(f"Dostępne: {available_files}")
        return None
    
    return available_files[:2]  # Użyj pierwszych dwóch

def test_method(method_num, master_path, target_path, k_colors=8):
    """Test pojedynczej metody"""
    print(f"\n[TEST] Testowanie Metody {method_num}...")
    
    start_time = time.time()
    
    try:
        # Przygotuj pliki
        with open(master_path, 'rb') as f1, open(target_path, 'rb') as f2:
            files = {
                'master_image': f1,
                'target_image': f2
            }
            data = {
                'method': str(method_num),
                'k': k_colors
            }
            
            # Wyślij request
            response = requests.post(f"{SERVER_URL}/api/colormatch", files=files, data=data)
            
        end_time = time.time()
        execution_time = end_time - start_time
        
        # Sprawdź odpowiedź
        if response.status_code == 200:
            result = response.text.strip()
            if result.startswith("success"):
                parts = result.split(",")
                if len(parts) >= 3:
                    result_filename = parts[2]
                    print(f"[PASS] Metoda {method_num}: SUKCES")
                    print(f"   Czas: {execution_time:.2f}s")
                    print(f"   Wynik: {result_filename}")
                    return True, execution_time
                else:
                    print(f"[FAIL] Metoda {method_num}: Nieprawidłowy format odpowiedzi")
            else:
                print(f"[FAIL] Metoda {method_num}: {result}")
        else:
            print(f"[FAIL] Metoda {method_num}: HTTP {response.status_code}")
            
    except requests.exceptions.ConnectionError:
        print(f"[FAIL] Metoda {method_num}: Nie można połączyć z serwerem")
        print("   Upewnij się, że serwer działa: python run_server.py")
    except Exception as e:
        print(f"[FAIL] Metoda {method_num}: Błąd - {str(e)}")
    
    return False, 0

def check_server():
    """Sprawdź czy serwer działa"""
    import socket
    try:
        # Sprawdź czy port jest otwarty
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(2)
        result = sock.connect_ex(('127.0.0.1', 5000))
        sock.close()
        
        if result == 0:
            print("[OK] Port 5000 jest otwarty")
            return True
        else:
            print(f"[ERROR] Port 5000 nie odpowiada (kod: {result})")
            return False
    except Exception as e:
        print(f"[ERROR] Błąd sprawdzania portu: {e}")
        return False

def main():
    """Główna funkcja testowa"""
    print("POZIOM 1: Test Podstawowych Metod Color Matching")
    print("=" * 50)
    
    # Sprawdź serwer
    if not check_server():
        print("[ERROR] Serwer nie działa!")
        print("Uruchom serwer: python run_server.py")
        return

    print("[OK] Serwer działa")
    
    # Przygotuj środowisko
    test_files = setup_test_environment()
    if not test_files:
        return

    master_file, target_file = test_files
    print(f"[INFO] Master: {master_file}")
    print(f"[INFO] Target: {target_file}")
    
    # Test wszystkich metod
    methods = [
        (1, "Simple Palette Mapping (RGB K-means)"),
        (2, "Basic Statistical Transfer (LAB)"),
        (3, "Simple Histogram Matching (Luminancja)")
    ]
    
    results = []
    total_time = 0
    
    for method_num, method_name in methods:
        print(f"\n[INFO] {method_name}")
        success, exec_time = test_method(method_num, master_file, target_file)
        results.append((method_num, method_name, success, exec_time))
        total_time += exec_time

    # Podsumowanie
    print("\n" + "=" * 50)
    print("PODSUMOWANIE TESTÓW")
    print("=" * 50)

    successful_methods = 0
    for method_num, method_name, success, exec_time in results:
        status = "[PASS]" if success else "[FAIL]"
        time_status = "[FAST]" if exec_time < 5.0 else "[SLOW]"
        print(f"Metoda {method_num}: {status} ({exec_time:.2f}s) {time_status}")
        if success:
            successful_methods += 1
    
    print(f"\nCałkowity czas: {total_time:.2f}s")
    print(f"Sukces: {successful_methods}/3 metod")
    
    # Kryterium sukcesu
    if successful_methods == 3:
        print("\n[SUCCESS] POZIOM 1: ZALICZONY!")
        print("Wszystkie metody działają bez błędów")
        if total_time < 15.0:  # 3 metody * 5s = 15s
            print("[BONUS] Wydajność w normie!")
    else:
        print("\n[FAILED] POZIOM 1: NIEZALICZONY")
        print("Nie wszystkie metody działają poprawnie")

if __name__ == "__main__":
    main()
``````

### test_curl.py - ./test_curl.py

``````
#!/usr/bin/env python3
# Prosty test curl dla color matching

import os
import subprocess
import sys

def test_curl():
    """Test curl command line dla color matching endpoint"""
    
    # Sprawdź czy są obrazy do testów
    source_folder = "source"
    if not os.path.exists(source_folder):
        print(f"❌ Brak folderu: {source_folder}")
        return
    
    # Znajdź obrazy
    image_files = []
    for ext in ['.jpg', '.jpeg', '.png', '.tif', '.tiff']:
        image_files.extend([f for f in os.listdir(source_folder) if f.lower().endswith(ext)])
    
    if len(image_files) < 2:
        print(f"❌ Potrzeba przynajmniej 2 obrazów w folderze {source_folder}")
        return
    
    master_path = os.path.join(source_folder, image_files[0])
    target_path = os.path.join(source_folder, image_files[1])
    
    print(f"🚀 CURL TEST")
    print(f"Master: {master_path}")
    print(f"Target: {target_path}")
    print("-" * 40)
    
    # Stwórz curl command
    curl_cmd = [
        'curl', '-s', '-X', 'POST',
        '-F', f'master_image=@{master_path}',
        '-F', f'target_image=@{target_path}',
        '-F', 'method=1',
        '-F', 'k=6',
        'http://127.0.0.1:5000/api/colormatch'
    ]
    
    try:
        print("📡 Wysyłam request...")
        result = subprocess.run(curl_cmd, capture_output=True, text=True, timeout=60)
        
        print(f"Return code: {result.returncode}")
        print(f"Response: {result.stdout}")
        
        if result.stderr:
            print(f"Error: {result.stderr}")
            
        # Parsuj odpowiedź
        if result.returncode == 0 and result.stdout:
            parts = result.stdout.strip().split(',')
            if len(parts) >= 3 and parts[0] == 'success':
                print(f"✅ SUCCESS!")
                print(f"Method: {parts[1]}")
                print(f"Result: {parts[2]}")
                
                # Sprawdź czy plik wynikowy istnieje
                result_path = f"results/{parts[2]}"
                if os.path.exists(result_path):
                    size_mb = os.path.getsize(result_path) / (1024*1024)
                    print(f"✅ File created: {result_path} ({size_mb:.1f}MB)")
                else:
                    print(f"❌ File not found: {result_path}")
            else:
                print(f"❌ Invalid response format")
        
    except subprocess.TimeoutExpired:
        print("❌ Request timeout (60s)")
    except FileNotFoundError:
        print("❌ curl command not found. Install curl.")
    except Exception as e:
        print(f"❌ Error: {e}")

if __name__ == "__main__":
    test_curl()

``````

### test_runner.py - ./test_runner.py

``````
#!/usr/bin/env python3
"""
Test Runner - Automatyczne uruchamianie testów z zarządzaniem serwerem

Użycie:
    python test_runner.py              # Uruchom wszystkie testy
    python test_runner.py --auto-start # Automatycznie uruchom serwer jeśli nie działa
    python test_runner.py --stop-after # Zatrzymaj serwer po testach
"""

import sys
import argparse
import time
from server_manager_enhanced import EnhancedServerManager

def run_tests_with_management(auto_start=False, stop_after=False):
    """Uruchom testy z zarządzaniem serwerem"""
    manager = EnhancedServerManager()
    server_was_running = manager.is_running()
    
    print("=== Test Runner ===")
    print(f"Auto-start: {auto_start}")
    print(f"Stop after: {stop_after}")
    print()
    
    # Sprawdź status serwera
    if server_was_running:
        print("[INFO] Serwer już działa")
    else:
        print("[INFO] Serwer nie działa")
        if auto_start:
            print("[INFO] Uruchamiam serwer automatycznie...")
            if not manager.start_server():
                print("[ERROR] Nie udało się uruchomić serwera")
                return False
        else:
            print("[ERROR] Serwer nie działa. Użyj --auto-start lub uruchom serwer ręcznie.")
            print("[INFO] Komenda: python server_manager.py start")
            return False
    
    print()
    
    # Uruchom testy
    print("=== Uruchamiam testy ===")
    success = manager.run_tests()
    
    # Zatrzymaj serwer jeśli trzeba
    if stop_after and (auto_start or not server_was_running):
        print("\n=== Zatrzymuję serwer ===")
        manager.stop_server()
    
    return success

def main():
    parser = argparse.ArgumentParser(description='Test Runner z zarządzaniem serwerem')
    parser.add_argument('--auto-start', action='store_true', 
                       help='Automatycznie uruchom serwer jeśli nie działa')
    parser.add_argument('--stop-after', action='store_true',
                       help='Zatrzymaj serwer po testach')
    
    args = parser.parse_args()
    
    success = run_tests_with_management(
        auto_start=args.auto_start,
        stop_after=args.stop_after
    )
    
    sys.exit(0 if success else 1)

if __name__ == '__main__':
    main()
``````

### test_speed.py - ./test_speed.py

``````
#!/usr/bin/env python3
# Test script dla color matching endpoint

import requests
import os
import sys
import time

# Dodaj ścieżkę do modułu app
sys.path.append('.')

from app.processing.color_matching import simple_palette_mapping

def test_speed():
    """Test speed z obrazami z folderu source"""
    
    # Sprawdź folder source
    source_folder = "source"
    if not os.path.exists(source_folder):
        print(f"❌ Brak folderu: {source_folder}")
        return
    
    # Znajdź obrazy w folderze source
    image_files = []
    for ext in ['.jpg', '.jpeg', '.png', '.tif', '.tiff']:
        image_files.extend([f for f in os.listdir(source_folder) if f.lower().endswith(ext)])
    
    if len(image_files) < 2:
        print(f"❌ Potrzeba przynajmniej 2 obrazów w folderze {source_folder}")
        print(f"   Znalezione: {image_files}")
        return
    
    # Wybierz pierwsze 2 obrazy
    master_path = os.path.join(source_folder, image_files[0])
    target_path = os.path.join(source_folder, image_files[1])
    
    print(f"🚀 SPEED TEST - METHOD 1 OPTIMIZED")
    print(f"Master: {master_path}")
    print(f"Target: {target_path}")
    print(f"Colors: 8")
    print("-" * 50)
    
    try:
        # Test nowej optimized version
        start_time = time.time()
        result_path = simple_palette_mapping(master_path, target_path, k_colors=8)
        total_time = time.time() - start_time
        
        print("-" * 50)
        print(f"🎯 FINAL RESULT:")
        print(f"   Total time: {total_time:.2f}s")
        print(f"   Result file: {result_path}")
        
        if os.path.exists(result_path):
            file_size = os.path.getsize(result_path) / (1024*1024)  # MB
            print(f"   File size: {file_size:.1f}MB")
            print("✅ SUCCESS! File created.")
        else:
            print("❌ File not created!")
            
    except Exception as e:
        print(f"❌ ERROR: {e}")

if __name__ == "__main__":
    test_speed()

``````
