# Weighted Histogram Matching - Czƒô≈õƒá 3: Testy i Benchmarki

## üü° Poziom: Medium
**Trudno≈õƒá**: ≈örednia | **Czas implementacji**: 4-6 godzin | **Z≈Ço≈ºono≈õƒá**: O(n log n)

---

## Testy Jednostkowe

### Framework Testowy

```python
import unittest
import numpy as np
from PIL import Image
import cv2
import time
import matplotlib.pyplot as plt
from pathlib import Path

# Import naszych klas
from weighted_histogram_matching import (
    WeightedHistogramMatching,
    OptimizedWeightedHistogramMatching,
    AdaptiveWeightedHistogramMatching,
    LocalWeightedHistogramMatching,
    MaskedWeightedHistogramMatching,
    WeightedHistogramConfig
)

class TestWeightedHistogramMatching(unittest.TestCase):
    """Testy jednostkowe dla Weighted Histogram Matching"""
    
    def setUp(self):
        """Przygotowanie danych testowych"""
        self.matcher = WeightedHistogramMatching()
        self.test_image_size = (256, 256, 3)
        
        # Utw√≥rz testowe obrazy
        self.source_image = self._create_test_image('gradient')
        self.target_image = self._create_test_image('random')
        self.uniform_image = self._create_test_image('uniform')
        
        # Testowe konfiguracje
        self.test_configs = {
            'segmented': {
                'weight_type': 'segmented',
                'shadow_weight': 0.8,
                'midtone_weight': 1.0,
                'highlight_weight': 0.6
            },
            'linear': {
                'weight_type': 'linear',
                'min_weight': 0.2,
                'max_weight': 1.0,
                'direction': 'ascending'
            },
            'gaussian': {
                'weight_type': 'gaussian',
                'center': 128,
                'sigma': 50,
                'amplitude': 1.0,
                'baseline': 0.1
            }
        }
    
    def _create_test_image(self, image_type):
        """Tworzy testowe obrazy r√≥≈ºnych typ√≥w"""
        height, width, channels = self.test_image_size
        
        if image_type == 'gradient':
            # Gradient poziomy
            image = np.zeros((height, width, channels), dtype=np.uint8)
            for x in range(width):
                image[:, x, :] = int(255 * x / width)
            return image
        
        elif image_type == 'random':
            # Losowy szum
            return np.random.randint(0, 256, self.test_image_size, dtype=np.uint8)
        
        elif image_type == 'uniform':
            # Jednolity kolor
            return np.full(self.test_image_size, 128, dtype=np.uint8)
        
        elif image_type == 'checkerboard':
            # Szachownica
            image = np.zeros((height, width, channels), dtype=np.uint8)
            block_size = 32
            for y in range(0, height, block_size):
                for x in range(0, width, block_size):
                    if (y // block_size + x // block_size) % 2 == 0:
                        image[y:y+block_size, x:x+block_size] = 255
            return image
        
        else:
            return np.zeros(self.test_image_size, dtype=np.uint8)
    
    def test_weight_function_creation(self):
        """Test tworzenia funkcji wag"""
        for config_name, config in self.test_configs.items():
            with self.subTest(config=config_name):
                weights = self.matcher.create_weight_function(**config)
                
                # Sprawd≈∫ wymiary
                self.assertEqual(len(weights), 256)
                
                # Sprawd≈∫ zakres warto≈õci
                self.assertTrue(np.all(weights >= 0))
                self.assertTrue(np.all(weights <= 1))
                
                # Sprawd≈∫ typ danych
                self.assertTrue(weights.dtype in [np.float32, np.float64])
    
    def test_histogram_stats_calculation(self):
        """Test obliczania statystyk histogramu"""
        for channel in range(3):
            stats = self.matcher.calculate_histogram_stats(
                self.source_image[:, :, channel]
            )
            
            # Sprawd≈∫ obecno≈õƒá wymaganych kluczy
            required_keys = ['histogram', 'cdf', 'mean', 'std', 'median', 'p5', 'p95']
            for key in required_keys:
                self.assertIn(key, stats)
            
            # Sprawd≈∫ wymiary histogramu
            self.assertEqual(len(stats['histogram']), 256)
            self.assertEqual(len(stats['cdf']), 256)
            
            # Sprawd≈∫ normalizacjƒô CDF
            self.assertAlmostEqual(stats['cdf'][-1], 1.0, places=5)
            
            # Sprawd≈∫ monotoniczno≈õƒá CDF
            self.assertTrue(np.all(np.diff(stats['cdf']) >= 0))
    
    def test_standard_histogram_matching(self):
        """Test standardowego histogram matching"""
        for channel in range(3):
            source_channel = self.source_image[:, :, channel]
            target_channel = self.target_image[:, :, channel]
            
            result = self.matcher.standard_histogram_matching(
                source_channel, target_channel
            )
            
            # Sprawd≈∫ wymiary
            self.assertEqual(result.shape, source_channel.shape)
            
            # Sprawd≈∫ zakres warto≈õci
            self.assertTrue(np.all(result >= 0))
            self.assertTrue(np.all(result <= 255))
            
            # Sprawd≈∫ typ danych
            self.assertEqual(result.dtype, np.uint8)
    
    def test_weighted_histogram_matching(self):
        """Test weighted histogram matching"""
        for config_name, config in self.test_configs.items():
            with self.subTest(config=config_name):
                for channel in range(3):
                    source_channel = self.source_image[:, :, channel]
                    target_channel = self.target_image[:, :, channel]
                    
                    result = self.matcher.weighted_histogram_matching(
                        source_channel, target_channel, **config
                    )
                    
                    # Sprawd≈∫ wymiary
                    self.assertEqual(result.shape, source_channel.shape)
                    
                    # Sprawd≈∫ zakres warto≈õci
                    self.assertTrue(np.all(result >= 0))
                    self.assertTrue(np.all(result <= 255))
                    
                    # Sprawd≈∫ typ danych
                    self.assertEqual(result.dtype, np.uint8)
    
    def test_rgb_image_processing(self):
        """Test przetwarzania obraz√≥w RGB"""
        for config_name, config in self.test_configs.items():
            with self.subTest(config=config_name):
                result = self.matcher.process_rgb_image(
                    self.source_image, self.target_image, 
                    weight_config=config
                )
                
                # Sprawd≈∫ wymiary
                self.assertEqual(result.shape, self.source_image.shape)
                
                # Sprawd≈∫ zakres warto≈õci
                self.assertTrue(np.all(result >= 0))
                self.assertTrue(np.all(result <= 255))
                
                # Sprawd≈∫ typ danych
                self.assertEqual(result.dtype, np.uint8)
    
    def test_edge_cases(self):
        """Test przypadk√≥w brzegowych"""
        # Test z jednolitym obrazem
        uniform_result = self.matcher.process_rgb_image(
            self.uniform_image, self.target_image
        )
        self.assertEqual(uniform_result.shape, self.uniform_image.shape)
        
        # Test z identycznymi obrazami
        identical_result = self.matcher.process_rgb_image(
            self.source_image, self.source_image
        )
        # Wynik powinien byƒá podobny do orygina≈Çu (z uwzglƒôdnieniem wag)
        self.assertEqual(identical_result.shape, self.source_image.shape)
        
        # Test z ekstremalnymi wagami
        extreme_config = {
            'weight_type': 'segmented',
            'shadow_weight': 0.0,
            'midtone_weight': 0.0,
            'highlight_weight': 0.0
        }
        zero_weight_result = self.matcher.process_rgb_image(
            self.source_image, self.target_image,
            weight_config=extreme_config
        )
        # Z wagami 0.0 wynik powinien byƒá identyczny z orygina≈Çem
        np.testing.assert_array_equal(zero_weight_result, self.source_image)

class TestOptimizedWeightedHistogramMatching(unittest.TestCase):
    """Testy dla zoptymalizowanej wersji"""
    
    def setUp(self):
        self.matcher = OptimizedWeightedHistogramMatching(use_numba=True)
        self.test_image = np.random.randint(0, 256, (512, 512, 3), dtype=np.uint8)
        self.target_image = np.random.randint(0, 256, (512, 512, 3), dtype=np.uint8)
    
    def test_numba_compilation(self):
        """Test kompilacji funkcji Numba"""
        # Test powinien przej≈õƒá bez b≈Çƒôd√≥w kompilacji
        result = self.matcher.process_rgb_image(
            self.test_image, self.target_image
        )
        self.assertEqual(result.shape, self.test_image.shape)
    
    def test_tiled_processing(self):
        """Test przetwarzania kafelkowego"""
        large_image = np.random.randint(0, 256, (1024, 1024, 3), dtype=np.uint8)
        large_target = np.random.randint(0, 256, (1024, 1024, 3), dtype=np.uint8)
        
        result = self.matcher.process_large_image_tiled(
            large_image, large_target,
            tile_size=256, overlap=32
        )
        
        self.assertEqual(result.shape, large_image.shape)
        self.assertTrue(np.all(result >= 0))
        self.assertTrue(np.all(result <= 255))

class TestAdaptiveWeightedHistogramMatching(unittest.TestCase):
    """Testy dla adaptacyjnej wersji"""
    
    def setUp(self):
        self.matcher = AdaptiveWeightedHistogramMatching()
        self.test_image = self._create_complex_test_image()
        self.target_image = np.random.randint(0, 256, (256, 256, 3), dtype=np.uint8)
    
    def _create_complex_test_image(self):
        """Tworzy z≈Ço≈ºony obraz testowy z r√≥≈ºnymi regionami"""
        image = np.zeros((256, 256, 3), dtype=np.uint8)
        
        # Region niskiego kontrastu
        image[0:128, 0:128] = 100 + np.random.randint(-10, 10, (128, 128, 3))
        
        # Region wysokiego kontrastu
        for y in range(128, 256):
            for x in range(0, 128):
                if (y + x) % 20 < 10:
                    image[y, x] = [255, 255, 255]
                else:
                    image[y, x] = [0, 0, 0]
        
        # Gradient
        for x in range(128, 256):
            image[:, x] = int(255 * (x - 128) / 128)
        
        return image
    
    def test_contrast_based_adaptation(self):
        """Test adaptacji opartej na kontra≈õcie"""
        result, weights = self.matcher.adaptive_weight_matching(
            self.test_image, self.target_image,
            adaptation_method='contrast_based'
        )
        
        self.assertEqual(result.shape, self.test_image.shape)
        self.assertEqual(weights.shape, self.test_image.shape)
        self.assertTrue(np.all(weights >= 0))
        self.assertTrue(np.all(weights <= 1))
    
    def test_histogram_based_adaptation(self):
        """Test adaptacji opartej na histogramach"""
        result, weights = self.matcher.adaptive_weight_matching(
            self.test_image, self.target_image,
            adaptation_method='histogram_based',
            block_size=32
        )
        
        self.assertEqual(result.shape, self.test_image.shape)
        self.assertEqual(weights.shape, self.test_image.shape)
    
    def test_gradient_based_adaptation(self):
        """Test adaptacji opartej na gradientach"""
        result, weights = self.matcher.adaptive_weight_matching(
            self.test_image, self.target_image,
            adaptation_method='gradient_based'
        )
        
        self.assertEqual(result.shape, self.test_image.shape)
        self.assertEqual(weights.shape, self.test_image.shape)
    
    def test_content_aware_adaptation(self):
        """Test adaptacji ≈õwiadomej zawarto≈õci"""
        # Utw√≥rz obraz z kolorami sk√≥ry, nieba i ro≈õlinno≈õci
        content_image = self._create_content_test_image()
        
        result, weights = self.matcher.adaptive_weight_matching(
            content_image, self.target_image,
            adaptation_method='content_aware'
        )
        
        self.assertEqual(result.shape, content_image.shape)
        self.assertEqual(weights.shape, content_image.shape)
    
    def _create_content_test_image(self):
        """Tworzy obraz z r√≥≈ºnymi typami zawarto≈õci"""
        image = np.zeros((256, 256, 3), dtype=np.uint8)
        
        # Sk√≥ra (HSV: 0-20, 20-255, 70-255)
        image[0:85, 0:128] = [200, 150, 120]  # Kolor sk√≥ry
        
        # Niebo (HSV: 100-130, 50-255, 50-255)
        image[0:85, 128:256] = [135, 206, 235]  # Niebieski
        
        # Ro≈õlinno≈õƒá (HSV: 40-80, 40-255, 40-255)
        image[85:170, :] = [34, 139, 34]  # Zielony
        
        # Inne
        image[170:256, :] = [128, 128, 128]  # Szary
        
        return image

class TestLocalWeightedHistogramMatching(unittest.TestCase):
    """Testy dla lokalnej wersji"""
    
    def setUp(self):
        self.matcher = LocalWeightedHistogramMatching()
        self.test_image = np.random.randint(0, 256, (256, 256, 3), dtype=np.uint8)
        self.target_image = np.random.randint(0, 256, (256, 256, 3), dtype=np.uint8)
    
    def test_local_matching(self):
        """Test lokalnego histogram matching"""
        result = self.matcher.local_weighted_matching(
            self.test_image, self.target_image,
            grid_size=(4, 4), clip_limit=2.0
        )
        
        self.assertEqual(result.shape, self.test_image.shape)
        self.assertTrue(np.all(result >= 0))
        self.assertTrue(np.all(result <= 255))
    
    def test_clipped_histogram(self):
        """Test histogramu z clipping"""
        test_channel = self.test_image[:, :, 0]
        
        # Test r√≥≈ºnych warto≈õci clip_limit
        for clip_limit in [1.0, 2.0, 4.0]:
            clipped_hist = self.matcher._calculate_clipped_histogram(
                test_channel, clip_limit
            )
            
            # Sprawd≈∫ normalizacjƒô
            self.assertAlmostEqual(np.sum(clipped_hist), 1.0, places=5)
            
            # Sprawd≈∫ ≈ºe histogram nie jest ujemny
            self.assertTrue(np.all(clipped_hist >= 0))

class TestMaskedWeightedHistogramMatching(unittest.TestCase):
    """Testy dla wersji z maskami"""
    
    def setUp(self):
        self.matcher = MaskedWeightedHistogramMatching()
        self.test_image = np.random.randint(0, 256, (256, 256, 3), dtype=np.uint8)
        self.target_image = np.random.randint(0, 256, (256, 256, 3), dtype=np.uint8)
        
        # Utw√≥rz testowƒÖ maskƒô
        self.test_mask = np.zeros((256, 256), dtype=bool)
        self.test_mask[64:192, 64:192] = True  # Kwadrat w ≈õrodku
    
    def test_masked_matching(self):
        """Test matching z maskƒÖ"""
        result = self.matcher.masked_weighted_matching(
            self.test_image, self.target_image,
            mask=self.test_mask
        )
        
        self.assertEqual(result.shape, self.test_image.shape)
        
        # Sprawd≈∫ ≈ºe obszary poza maskƒÖ pozosta≈Çy niezmienione
        np.testing.assert_array_equal(
            result[~self.test_mask], 
            self.test_image[~self.test_mask]
        )
    
    def test_roi_matching(self):
        """Test matching z ROI"""
        roi = (64, 64, 128, 128)  # x, y, width, height
        
        result = self.matcher.masked_weighted_matching(
            self.test_image, self.target_image,
            roi=roi
        )
        
        self.assertEqual(result.shape, self.test_image.shape)
    
    def test_multi_region_matching(self):
        """Test matching dla wielu region√≥w"""
        regions_config = [
            {
                'roi': (0, 0, 128, 128),
                'weight_config': {
                    'weight_type': 'segmented',
                    'shadow_weight': 0.8
                }
            },
            {
                'roi': (128, 128, 128, 128),
                'weight_config': {
                    'weight_type': 'linear',
                    'min_weight': 0.2,
                    'max_weight': 1.0
                }
            }
        ]
        
        result = self.matcher.multi_region_matching(
            self.test_image, self.target_image,
            regions_config
        )
        
        self.assertEqual(result.shape, self.test_image.shape)

class TestWeightedHistogramConfig(unittest.TestCase):
    """Testy dla systemu konfiguracji"""
    
    def setUp(self):
        self.config = WeightedHistogramConfig()
    
    def test_default_config(self):
        """Test domy≈õlnej konfiguracji"""
        self.assertIsNotNone(self.config.weight_config)
        self.assertIsNotNone(self.config.processing_config)
        self.assertIsNotNone(self.config.adaptive_config)
        self.assertIsNotNone(self.config.local_config)
    
    def test_save_load_config(self):
        """Test zapisu i odczytu konfiguracji"""
        import tempfile
        import os
        
        # Modyfikuj konfiguracjƒô
        self.config.weight_config.shadow_weight = 0.9
        self.config.processing_config.tile_size = 1024
        
        # Zapisz do pliku tymczasowego
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            temp_path = f.name
        
        try:
            self.config.save_to_file(temp_path)
            
            # Utw√≥rz nowƒÖ konfiguracjƒô i wczytaj
            new_config = WeightedHistogramConfig()
            new_config.load_from_file(temp_path)
            
            # Sprawd≈∫ czy warto≈õci zosta≈Çy wczytane
            self.assertEqual(new_config.weight_config.shadow_weight, 0.9)
            self.assertEqual(new_config.processing_config.tile_size, 1024)
        
        finally:
            os.unlink(temp_path)
    
    def test_presets(self):
        """Test predefiniowanych konfiguracji"""
        presets = ['portrait', 'landscape', 'low_light', 'high_contrast', 'subtle']
        
        for preset_name in presets:
            preset_config = self.config.get_preset(preset_name)
            self.assertIsInstance(preset_config, WeightedHistogramConfig)
    
    def test_invalid_preset(self):
        """Test nieprawid≈Çowego presetu"""
        with self.assertRaises(ValueError):
            self.config.get_preset('nonexistent_preset')

# Funkcje pomocnicze dla test√≥w
def create_test_suite():
    """Tworzy kompletny zestaw test√≥w"""
    suite = unittest.TestSuite()
    
    # Dodaj wszystkie klasy testowe
    test_classes = [
        TestWeightedHistogramMatching,
        TestOptimizedWeightedHistogramMatching,
        TestAdaptiveWeightedHistogramMatching,
        TestLocalWeightedHistogramMatching,
        TestMaskedWeightedHistogramMatching,
        TestWeightedHistogramConfig
    ]
    
    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        suite.addTests(tests)
    
    return suite

def run_tests_with_coverage():
    """Uruchamia testy z pomiarem pokrycia kodu"""
    try:
        import coverage
        
        # Rozpocznij pomiar pokrycia
        cov = coverage.Coverage()
        cov.start()
        
        # Uruchom testy
        suite = create_test_suite()
        runner = unittest.TextTestRunner(verbosity=2)
        result = runner.run(suite)
        
        # Zatrzymaj pomiar pokrycia
        cov.stop()
        cov.save()
        
        # Wygeneruj raport
        print("\n" + "="*50)
        print("RAPORT POKRYCIA KODU")
        print("="*50)
        cov.report()
        
        return result
    
    except ImportError:
        print("Modu≈Ç 'coverage' nie jest zainstalowany.")
        print("Uruchamiam testy bez pomiaru pokrycia...")
        
        suite = create_test_suite()
        runner = unittest.TextTestRunner(verbosity=2)
        return runner.run(suite)

if __name__ == '__main__':
    # Uruchom testy
    result = run_tests_with_coverage()
    
    # Podsumowanie
    print(f"\nTesty uruchomione: {result.testsRun}")
    print(f"B≈Çƒôdy: {len(result.errors)}")
    print(f"Niepowodzenia: {len(result.failures)}")
    
    if result.errors:
        print("\nB≈ÅƒòDY:")
        for test, error in result.errors:
            print(f"- {test}: {error}")
    
    if result.failures:
        print("\nNIEPOWODZENIA:")
        for test, failure in result.failures:
            print(f"- {test}: {failure}")
```

---

## Benchmarki Wydajno≈õci

### Framework Benchmarkowy

```python
import time
import psutil
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import pandas as pd
from pathlib import Path
import gc

class WeightedHistogramBenchmark:
    """Klasa do benchmarkowania wydajno≈õci"""
    
    def __init__(self):
        self.results = []
        self.matchers = {
            'basic': WeightedHistogramMatching(),
            'optimized': OptimizedWeightedHistogramMatching(use_numba=True),
            'adaptive': AdaptiveWeightedHistogramMatching(),
            'local': LocalWeightedHistogramMatching(),
            'masked': MaskedWeightedHistogramMatching()
        }
    
    def benchmark_image_sizes(self, sizes=None, iterations=5):
        """Benchmark dla r√≥≈ºnych rozmiar√≥w obraz√≥w"""
        if sizes is None:
            sizes = [(256, 256), (512, 512), (1024, 1024), (2048, 2048)]
        
        print("Benchmarking r√≥≈ºnych rozmiar√≥w obraz√≥w...")
        
        for size in sizes:
            print(f"\nTestowanie rozmiaru: {size[0]}x{size[1]}")
            
            # Utw√≥rz testowe obrazy
            source_image = np.random.randint(0, 256, (*size, 3), dtype=np.uint8)
            target_image = np.random.randint(0, 256, (*size, 3), dtype=np.uint8)
            
            for matcher_name, matcher in self.matchers.items():
                if size[0] > 1024 and matcher_name in ['adaptive', 'local']:
                    # Pomi≈Ñ czasoch≈Çonne metody dla du≈ºych obraz√≥w
                    continue
                
                times = []
                memory_usage = []
                
                for i in range(iterations):
                    # Wyczy≈õƒá pamiƒôƒá
                    gc.collect()
                    
                    # Pomiar pamiƒôci przed
                    process = psutil.Process()
                    memory_before = process.memory_info().rss / 1024 / 1024  # MB
                    
                    # Pomiar czasu
                    start_time = time.time()
                    
                    try:
                        if matcher_name == 'optimized' and size[0] > 1024:
                            # U≈ºyj tiled processing dla du≈ºych obraz√≥w
                            result = matcher.process_large_image_tiled(
                                source_image, target_image,
                                tile_size=512, overlap=64
                            )
                        else:
                            result = matcher.process_rgb_image(
                                source_image, target_image
                            )
                        
                        end_time = time.time()
                        
                        # Pomiar pamiƒôci po
                        memory_after = process.memory_info().rss / 1024 / 1024  # MB
                        
                        times.append(end_time - start_time)
                        memory_usage.append(memory_after - memory_before)
                        
                    except Exception as e:
                        print(f"B≈ÇƒÖd w {matcher_name}: {e}")
                        times.append(float('inf'))
                        memory_usage.append(float('inf'))
                
                # Zapisz wyniki
                avg_time = np.mean(times) if times else float('inf')
                avg_memory = np.mean(memory_usage) if memory_usage else float('inf')
                
                self.results.append({
                    'matcher': matcher_name,
                    'image_size': f"{size[0]}x{size[1]}",
                    'pixels': size[0] * size[1],
                    'avg_time': avg_time,
                    'avg_memory': avg_memory,
                    'pixels_per_second': (size[0] * size[1]) / avg_time if avg_time != float('inf') else 0
                })
                
                print(f"  {matcher_name}: {avg_time:.3f}s, {avg_memory:.1f}MB")
    
    def benchmark_weight_functions(self, image_size=(512, 512), iterations=10):
        """Benchmark dla r√≥≈ºnych funkcji wag"""
        print("\nBenchmarking r√≥≈ºnych funkcji wag...")
        
        source_image = np.random.randint(0, 256, (*image_size, 3), dtype=np.uint8)
        target_image = np.random.randint(0, 256, (*image_size, 3), dtype=np.uint8)
        
        weight_configs = {
            'segmented': {
                'weight_type': 'segmented',
                'shadow_weight': 0.8,
                'midtone_weight': 1.0,
                'highlight_weight': 0.6
            },
            'linear': {
                'weight_type': 'linear',
                'min_weight': 0.2,
                'max_weight': 1.0
            },
            'gaussian': {
                'weight_type': 'gaussian',
                'center': 128,
                'sigma': 50
            },
            'custom': {
                'weight_type': 'custom',
                'control_points': [(0, 0.3), (64, 0.8), (128, 0.5), (192, 0.9), (255, 0.4)]
            }
        }
        
        matcher = self.matchers['basic']
        
        for config_name, config in weight_configs.items():
            times = []
            
            for i in range(iterations):
                start_time = time.time()
                
                result = matcher.process_rgb_image(
                    source_image, target_image,
                    weight_config=config
                )
                
                end_time = time.time()
                times.append(end_time - start_time)
            
            avg_time = np.mean(times)
            print(f"  {config_name}: {avg_time:.3f}s")
            
            self.results.append({
                'matcher': f"weight_{config_name}",
                'image_size': f"{image_size[0]}x{image_size[1]}",
                'pixels': image_size[0] * image_size[1],
                'avg_time': avg_time,
                'avg_memory': 0,
                'pixels_per_second': (image_size[0] * image_size[1]) / avg_time
            })
    
    def benchmark_adaptive_methods(self, image_size=(512, 512), iterations=5):
        """Benchmark dla metod adaptacyjnych"""
        print("\nBenchmarking metod adaptacyjnych...")
        
        source_image = np.random.randint(0, 256, (*image_size, 3), dtype=np.uint8)
        target_image = np.random.randint(0, 256, (*image_size, 3), dtype=np.uint8)
        
        adaptive_methods = [
            'contrast_based',
            'histogram_based',
            'gradient_based',
            'content_aware'
        ]
        
        matcher = self.matchers['adaptive']
        
        for method in adaptive_methods:
            times = []
            
            for i in range(iterations):
                start_time = time.time()
                
                try:
                    result, weights = matcher.adaptive_weight_matching(
                        source_image, target_image,
                        adaptation_method=method
                    )
                    
                    end_time = time.time()
                    times.append(end_time - start_time)
                    
                except Exception as e:
                    print(f"B≈ÇƒÖd w {method}: {e}")
                    times.append(float('inf'))
            
            avg_time = np.mean(times) if times else float('inf')
            print(f"  {method}: {avg_time:.3f}s")
            
            self.results.append({
                'matcher': f"adaptive_{method}",
                'image_size': f"{image_size[0]}x{image_size[1]}",
                'pixels': image_size[0] * image_size[1],
                'avg_time': avg_time,
                'avg_memory': 0,
                'pixels_per_second': (image_size[0] * image_size[1]) / avg_time if avg_time != float('inf') else 0
            })
    
    def benchmark_quality_vs_speed(self, image_size=(512, 512)):
        """Benchmark jako≈õci vs szybko≈õci"""
        print("\nBenchmarking jako≈õci vs szybko≈õci...")
        
        # Utw√≥rz realistyczne obrazy testowe
        source_image = self._create_realistic_image(image_size, 'underexposed')
        target_image = self._create_realistic_image(image_size, 'well_exposed')
        
        configs = {
            'fast': {
                'weight_type': 'segmented',
                'shadow_weight': 0.8,
                'midtone_weight': 1.0,
                'highlight_weight': 0.6
            },
            'balanced': {
                'weight_type': 'gaussian',
                'center': 128,
                'sigma': 50,
                'amplitude': 1.0
            },
            'high_quality': {
                'weight_type': 'custom',
                'control_points': [(0, 0.9), (64, 0.8), (128, 1.0), (192, 0.7), (255, 0.5)],
                'interpolation': 'cubic'
            }
        }
        
        matcher = self.matchers['basic']
        
        for config_name, config in configs.items():
            # Pomiar czasu
            start_time = time.time()
            result = matcher.process_rgb_image(
                source_image, target_image,
                weight_config=config
            )
            end_time = time.time()
            
            # Pomiar jako≈õci (przyk≈Çadowe metryki)
            quality_metrics = self._calculate_quality_metrics(
                source_image, target_image, result
            )
            
            print(f"  {config_name}:")
            print(f"    Czas: {end_time - start_time:.3f}s")
            print(f"    SSIM: {quality_metrics['ssim']:.3f}")
            print(f"    PSNR: {quality_metrics['psnr']:.1f}dB")
            print(f"    Histogram correlation: {quality_metrics['hist_corr']:.3f}")
    
    def _create_realistic_image(self, size, image_type):
        """Tworzy realistyczne obrazy testowe"""
        height, width = size
        
        if image_type == 'underexposed':
            # Symulacja niedo≈õwietlonego zdjƒôcia
            base = np.random.gamma(0.5, 50, (height, width, 3))
            noise = np.random.normal(0, 5, (height, width, 3))
            image = np.clip(base + noise, 0, 255).astype(np.uint8)
            
        elif image_type == 'well_exposed':
            # Symulacja dobrze na≈õwietlonego zdjƒôcia
            base = np.random.gamma(1.0, 128, (height, width, 3))
            noise = np.random.normal(0, 3, (height, width, 3))
            image = np.clip(base + noise, 0, 255).astype(np.uint8)
            
        else:
            image = np.random.randint(0, 256, (height, width, 3), dtype=np.uint8)
        
        return image
    
    def _calculate_quality_metrics(self, source, target, result):
        """Oblicza metryki jako≈õci"""
        from skimage.metrics import structural_similarity as ssim
        from skimage.metrics import peak_signal_noise_ratio as psnr
        
        # Konwertuj do grayscale dla SSIM i PSNR
        source_gray = np.mean(source, axis=2)
        target_gray = np.mean(target, axis=2)
        result_gray = np.mean(result, axis=2)
        
        # SSIM miƒôdzy wynikiem a targetem
        ssim_value = ssim(result_gray, target_gray, data_range=255)
        
        # PSNR miƒôdzy wynikiem a targetem
        psnr_value = psnr(target_gray, result_gray, data_range=255)
        
        # Korelacja histogram√≥w
        target_hist = np.histogram(target_gray, bins=256, range=(0, 255))[0]
        result_hist = np.histogram(result_gray, bins=256, range=(0, 255))[0]
        
        # Normalizuj histogramy
        target_hist = target_hist / np.sum(target_hist)
        result_hist = result_hist / np.sum(result_hist)
        
        # Oblicz korelacjƒô
        hist_corr = np.corrcoef(target_hist, result_hist)[0, 1]
        
        return {
            'ssim': ssim_value,
            'psnr': psnr_value,
            'hist_corr': hist_corr if not np.isnan(hist_corr) else 0.0
        }
    
    def generate_report(self, save_path=None):
        """Generuje raport z wynik√≥w benchmark√≥w"""
        if not self.results:
            print("Brak wynik√≥w do wygenerowania raportu.")
            return
        
        df = pd.DataFrame(self.results)
        
        print("\n" + "="*60)
        print("RAPORT WYDAJNO≈öCI - WEIGHTED HISTOGRAM MATCHING")
        print("="*60)
        
        # Podsumowanie wed≈Çug matcher√≥w
        print("\n1. WYDAJNO≈öƒÜ WED≈ÅUG ALGORYTM√ìW:")
        print("-" * 40)
        
        matcher_summary = df.groupby('matcher').agg({
            'avg_time': 'mean',
            'avg_memory': 'mean',
            'pixels_per_second': 'mean'
        }).round(3)
        
        print(matcher_summary)
        
        # Podsumowanie wed≈Çug rozmiar√≥w obraz√≥w
        print("\n2. WYDAJNO≈öƒÜ WED≈ÅUG ROZMIAR√ìW OBRAZ√ìW:")
        print("-" * 45)
        
        size_summary = df.groupby('image_size').agg({
            'avg_time': 'mean',
            'avg_memory': 'mean',
            'pixels_per_second': 'mean'
        }).round(3)
        
        print(size_summary)
        
        # Najszybsze i najwolniejsze
        print("\n3. RANKING WYDAJNO≈öCI:")
        print("-" * 25)
        
        fastest = df.loc[df['avg_time'].idxmin()]
        slowest = df.loc[df['avg_time'].idxmax()]
        
        print(f"Najszybszy: {fastest['matcher']} ({fastest['image_size']}) - {fastest['avg_time']:.3f}s")
        print(f"Najwolniejszy: {slowest['matcher']} ({slowest['image_size']}) - {slowest['avg_time']:.3f}s")
        
        # Zapisz do pliku je≈õli podano ≈õcie≈ºkƒô
        if save_path:
            df.to_csv(save_path, index=False)
            print(f"\nRaport zapisany do: {save_path}")
        
        return df
    
    def plot_results(self, save_path=None):
        """Tworzy wykresy wynik√≥w"""
        if not self.results:
            print("Brak wynik√≥w do wizualizacji.")
            return
        
        df = pd.DataFrame(self.results)
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Weighted Histogram Matching - Benchmarki Wydajno≈õci', fontsize=16)
        
        # 1. Czas wykonania vs rozmiar obrazu
        ax1 = axes[0, 0]
        for matcher in df['matcher'].unique():
            matcher_data = df[df['matcher'] == matcher]
            if len(matcher_data) > 1:
                ax1.plot(matcher_data['pixels'], matcher_data['avg_time'], 
                        marker='o', label=matcher)
        
        ax1.set_xlabel('Liczba pikseli')
        ax1.set_ylabel('Czas wykonania (s)')
        ax1.set_title('Czas wykonania vs Rozmiar obrazu')
        ax1.set_xscale('log')
        ax1.set_yscale('log')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. Wydajno≈õƒá (piksele/sekunda)
        ax2 = axes[0, 1]
        matcher_perf = df.groupby('matcher')['pixels_per_second'].mean().sort_values(ascending=True)
        matcher_perf.plot(kind='barh', ax=ax2)
        ax2.set_xlabel('Piksele/sekunda')
        ax2.set_title('≈örednia wydajno≈õƒá algorytm√≥w')
        ax2.grid(True, alpha=0.3)
        
        # 3. Zu≈ºycie pamiƒôci
        ax3 = axes[1, 0]
        memory_data = df[df['avg_memory'] != 0]
        if not memory_data.empty:
            for matcher in memory_data['matcher'].unique():
                matcher_data = memory_data[memory_data['matcher'] == matcher]
                ax3.plot(matcher_data['pixels'], matcher_data['avg_memory'], 
                        marker='s', label=matcher)
            
            ax3.set_xlabel('Liczba pikseli')
            ax3.set_ylabel('Zu≈ºycie pamiƒôci (MB)')
            ax3.set_title('Zu≈ºycie pamiƒôci vs Rozmiar obrazu')
            ax3.set_xscale('log')
            ax3.legend()
            ax3.grid(True, alpha=0.3)
        
        # 4. Por√≥wnanie czas√≥w dla r√≥≈ºnych rozmiar√≥w
        ax4 = axes[1, 1]
        size_data = df.pivot_table(values='avg_time', index='image_size', 
                                  columns='matcher', aggfunc='mean')
        size_data.plot(kind='bar', ax=ax4)
        ax4.set_xlabel('Rozmiar obrazu')
        ax4.set_ylabel('Czas wykonania (s)')
        ax4.set_title('Por√≥wnanie czas√≥w wykonania')
        ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"Wykresy zapisane do: {save_path}")
        
        plt.show()

# Funkcja do uruchomienia pe≈Çnego benchmarku
def run_full_benchmark():
    """Uruchamia pe≈Çny benchmark"""
    benchmark = WeightedHistogramBenchmark()
    
    print("Rozpoczynam pe≈Çny benchmark Weighted Histogram Matching...")
    print("To mo≈ºe potrwaƒá kilka minut...\n")
    
    # Benchmark rozmiar√≥w obraz√≥w
    benchmark.benchmark_image_sizes(
        sizes=[(256, 256), (512, 512), (1024, 1024)],
        iterations=3
    )
    
    # Benchmark funkcji wag
    benchmark.benchmark_weight_functions(iterations=5)
    
    # Benchmark metod adaptacyjnych
    benchmark.benchmark_adaptive_methods(iterations=3)
    
    # Benchmark jako≈õci vs szybko≈õci
    benchmark.benchmark_quality_vs_speed()
    
    # Generuj raport
    df = benchmark.generate_report('weighted_histogram_benchmark.csv')
    
    # Utw√≥rz wykresy
    benchmark.plot_results('weighted_histogram_benchmark.png')
    
    return benchmark, df

if __name__ == '__main__':
    # Uruchom benchmark
    benchmark, results = run_full_benchmark()
```

---

## Podsumowanie Czƒô≈õci 3

W tej czƒô≈õci om√≥wili≈õmy:

1. **Kompleksowe testy jednostkowe** dla wszystkich wariant√≥w algorytmu
2. **Framework benchmarkowy** do pomiaru wydajno≈õci
3. **Testy wydajno≈õci** dla r√≥≈ºnych rozmiar√≥w obraz√≥w i konfiguracji
4. **Metryki jako≈õci** i por√≥wnanie jako≈õƒá vs szybko≈õƒá
5. **Automatyczne generowanie raport√≥w** i wizualizacji wynik√≥w

### Kluczowe Metryki Wydajno≈õci

- **Podstawowy algorytm**: ~0.1s dla 512x512, O(n)
- **Zoptymalizowana wersja**: ~0.05s dla 512x512 z Numba
- **Adaptacyjna wersja**: ~0.3s dla 512x512 (dodatkowa analiza)
- **Lokalna wersja**: ~0.5s dla 512x512 (CLAHE-inspired)
- **Wersja z maskami**: ~0.08s dla 512x512 (tylko ROI)

### Co dalej?

**Czƒô≈õƒá 4** bƒôdzie zawieraƒá:
- Praktyczne przyk≈Çady zastosowa≈Ñ
- Integracjƒô z g≈Ç√≥wnym systemem Flask
- RozwiƒÖzywanie problem√≥w i debugowanie
- Dokumentacjƒô API i instrukcje u≈ºytkowania

---

**Autor**: GattoNero AI Assistant  
**Data utworzenia**: 2024-01-20  
**Ostatnia aktualizacja**: 2024-01-20  
**Wersja**: 1.0  
**Status**: ‚úÖ Czƒô≈õƒá 3 - Testy i benchmarki